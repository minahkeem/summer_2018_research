{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from rake_nltk import Rake\n",
    "\n",
    "es = Elasticsearch([{'host': 'nyuvis-web.poly.edu', 'port': 80, 'url_prefix': 'es'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'abstract': 'It is known that determinining whether a DEC-POMDP, namely, a cooperative partially observable stochastic game (POSG), has a cooperative strategy with positive expected reward is complete for NEXP. It was not known until now how cooperation affected that complexity. We show that, for competitive POSGs, the complexity of determining whether one team has a positive-expected-reward strategy is complete for the class NEXP with an oracle for NP.',\n",
       "  'id': '3163',\n",
       "  'title': 'Competition Adds Complexity',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose a model that leverages the millions of clicks received by web search engines, to predict document relevance. This allows the comparison of ranking functions when clicks are available but complete relevance judgments are not. After an initial training phase using a set of relevance judgments paired with click data, we show that our model can predict the relevance score of documents that have not been judged. These predictions can be used to evaluate the performance of a search engine, using our novel formalization of the confidence of the standard evaluation metric discounted cumulative gain (DCG), so comparisons can be made across time and datasets. This contrasts with previous methods which can provide only pair-wise relevance judgements between results shown for the same query. When no relevance judgments are available, we can identify the better of two ranked lists up to 82% of the time, and with only two relevance judgments for each query, we can identify the better ranking up to 94% of the time. While our experiments are on sponsored search results, which is the financial backbone of web search, our method is general enough to be applicable to algorithmic web search results as well. Furthermore, we give an algorithm to guide the selection of additional documents to judge to improve confidence.',\n",
       "  'id': '3190',\n",
       "  'title': 'Evaluating Search Engines by Modeling the Relationship Between Relevance and Clicks',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Empirical risk minimization offers well-known learning guarantees when training and test data come from the same domain. In the real world, though, we often wish to adapt a classifier from a source domain with a large amount of training data to different target domain with very little training data. In this work we give uniform convergence bounds for algorithms that minimize a convex combination of source and target empirical risk. The bounds explicitly model the inherent trade-off between training on a large but inaccurate source data set and a small but accurate target training set. Our theory also gives results when we have multiple source domains, each of which may have a different number of instances, and we exhibit cases in which minimizing a non-uniform combination of source risks can achieve much lower target error than standard empirical risk minimization.',\n",
       "  'id': '3212',\n",
       "  'title': 'Learning Bounds for Domain Adaptation',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'The notion of algorithmic stability has been used effectively in the past to derive tight generalization bounds. A key advantage of these bounds is that they are de- signed for specific learning algorithms, exploiting their particular properties. But, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed (i.i.d.). In many machine learning applications, however, this assumption does not hold. The observations received by the learning algorithm often have some inherent temporal dependence, which is clear in system diagnosis or time series prediction problems. This paper studies the scenario where the observations are drawn from a station- ary beta-mixing sequence, which implies a dependence between observations that weaken over time. It proves novel stability-based generalization bounds that hold even with this more general setting. These bounds strictly generalize the bounds given in the i.i.d. case. We also illustrate their application in the case of several general classes of learning algorithms, including Support Vector Regression and Kernel Ridge Regression.',\n",
       "  'id': '3239',\n",
       "  'title': 'Stability Bounds for Non-i.i.d. Processes',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Planning in partially observable environments remains a challenging problem, despite significant recent advances in offline approximation techniques. A few online methods have also been proposed recently, and proven to be remarkably scalable, but without the theoretical guarantees of their offline counterparts. Thus it seems natural to try to unify offline and online techniques, preserving the theoretical properties of the former, and exploiting the scalability of the latter. In this paper, we provide theoretical guarantees on an anytime algorithm for POMDPs which aims to reduce the error made by approximate offline value iteration algorithms through the use of an efficient online searching procedure. The algorithm uses search heuristics based on an error analysis of lookahead search, to guide the online search towards reachable beliefs with the most potential to reduce error. We provide a general theorem showing that these search heuristics are admissible, and lead to complete and epsilon-optimal algorithms. This is, to the best of our knowledge, the strongest theoretical result available for online POMDP solution methods. We also provide empirical evidence showing that our approach is also practical, and can find (provably) near-optimal solutions in reasonable time.',\n",
       "  'id': '3250',\n",
       "  'title': 'Theoretical Analysis of Heuristic Search Methods for Online POMDPs',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"We describe a novel noisy-logical distribution for representing the distribution of a binary output variable conditioned on multiple binary input variables. The distribution is represented in terms of noisy-or's and noisy-and-not's of causal features which are conjunctions of the binary inputs. The standard noisy-or and noisy-and-not models, used in causal reasoning and artificial intelligence, are special cases of the noisy-logical distribution. We prove that the noisy-logical distribution is complete in the sense that it can represent all conditional distributions provided a sufficient number of causal factors are used. We illustrate the noisy-logical distribution by showing that it can account for new experimental findings on how humans perform causal reasoning in more complex contexts. Finally, we speculate on the use of the noisy-logical distribution for causal reasoning and artificial intelligence.\",\n",
       "  'id': '3259',\n",
       "  'title': 'The Noisy-Logical Distribution and its Application to Causal Inference',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Cascade detectors have been shown to operate extremely rapidly, with high accuracy, and have important applications such as face detection. Driven by this success, cascade earning has been an area of active research in recent years. Nevertheless, there are still challenging technical problems during the training process of cascade detectors. In particular, determining the optimal target detection rate for each stage of the cascade remains an unsolved issue. In this paper, we propose the multiple instance pruning (MIP) algorithm for soft cascades. This algorithm computes a set of thresholds which aggressively terminate computation with no reduction in detection rate or increase in false positive rate on the training dataset. The algorithm is based on two key insights: i) examples that are destined to be rejected by the complete classifier can be safely pruned early; ii) face detection is a multiple instance learning problem. The MIP process is fully automatic and requires no assumptions of probability distributions, statistical independence, or ad hoc intermediate rejection targets. Experimental results on the MIT+CMU dataset demonstrate significant performance advantages.',\n",
       "  'id': '3265',\n",
       "  'title': 'Multiple-Instance Pruning For Learning Efficient Cascade Detectors',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We describe an efficient learning procedure for multilayer generative models that combine the best aspects of Markov random fields and deep, directed belief nets. The generative models can be learned one layer at a time and when learning is complete they have a very fast inference procedure for computing a good approximation to the posterior distribution in all of the hidden layers. Each hidden layer has its own MRF whose energy function is modulated by the top-down directed connections from the layer above. To generate from the model, each layer in turn must settle to equilibrium given its top-down input. We show that this type of model is good at capturing the statistics of patches of natural images.',\n",
       "  'id': '3279',\n",
       "  'title': 'Modeling image patches with a directed hierarchy of Markov random fields',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"Recent research has studied the role of sparsity in high dimensional regression and signal reconstruction, establishing theoretical limits for recovering sparse models from sparse data. In this paper we study a variant of this problem where the original $n$ input variables are compressed by a random linear transformation to $m \\\\ll n$ examples in $p$ dimensions, and establish conditions under which a sparse linear model can be successfully recovered from the compressed data. A primary motivation for this compression procedure is to anonymize the data and preserve privacy by revealing little information about the original data. We characterize the number of random projections that are required for $\\\\ell_1$-regularized compressed regression to identify the nonzero coefficients in the true model with probability approaching one, a property called ``sparsistence.'' In addition, we show that $\\\\ell_1$-regularized compressed regression asymptotically predicts as well as an oracle linear model, a property called ``persistence.'' Finally, we characterize the privacy properties of the compression procedure in information-theoretic terms, establishing upper bounds on the rate of information communicated between the compressed and uncompressed data that decay to zero.\",\n",
       "  'id': '3280',\n",
       "  'title': 'Compressed Regression',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We address the problem of factorial learning which associates a set of latent causes or features with the observed data. Factorial models usually assume that each feature has a single occurrence in a given data point. However, there are data such as images where latent features have multiple occurrences, e.g. a visual object class can have multiple instances shown in the same image. To deal with such cases, we present a probability model over non-negative integer valued matrices with possibly unbounded number of columns. This model can play the role of the prior in an nonparametric Bayesian learning scenario where both the latent features and the number of their occurrences are unknown. We use this prior together with a likelihood model for unsupervised learning from images using a Markov Chain Monte Carlo inference algorithm.',\n",
       "  'id': '3309',\n",
       "  'title': 'The Infinite Gamma-Poisson Feature Model',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Computational models of visual cortex, and in particular those based on sparse coding, have enjoyed much recent attention. Despite this currency, the question of how sparse or how over-complete a sparse representation should be, has gone without principled answer. Here, we use Bayesian model-selection methods to address these questions for a sparse-coding model based on a Student-t prior. Having validated our methods on toy data, we find that natural images are indeed best modelled by extremely sparse distributions; although for the Student-t prior, the associated optimal basis size is only modestly overcomplete.',\n",
       "  'id': '3312',\n",
       "  'title': 'On Sparsity and Overcompleteness in Image Models',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present an algorithm called Optimistic Linear Programming (OLP) for learning to optimize average reward in an irreducible but otherwise unknown Markov decision process (MDP). OLP uses its experience so far to estimate the MDP. It chooses actions by optimistically maximizing estimated future rewards over a set of next-state transition probabilities that are close to the estimates: a computation that corresponds to solving linear programs. We show that the total expected reward obtained by OLP up to time $T$ is within $C(P)\\\\log T$ of the reward obtained by the optimal policy, where $C(P)$ is an explicit, MDP-dependent constant. OLP is closely related to an algorithm proposed by Burnetas and Katehakis with four key differences: OLP is simpler, it does not require knowledge of the supports of transition probabilities and the proof of the regret bound is simpler, but our regret bound is a constant factor larger than the regret of their algorithm. OLP is also similar in flavor to an algorithm recently proposed by Auer and Ortner. But OLP is simpler and its regret bound has a better dependence on the size of the MDP.',\n",
       "  'id': '3329',\n",
       "  'title': 'Optimistic Linear Programming gives Logarithmic Regret for Irreducible MDPs',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose to test for the homogeneity of two samples by using Kernel Fisher discriminant Analysis. This provides us with a consistent nonparametric test statistic, for which we derive the asymptotic distribution under the null hypothesis. We give experimental evidence of the relevance of our method on both artificial and real datasets.',\n",
       "  'id': '3335',\n",
       "  'title': 'Testing for Homogeneity with Kernel Fisher Discriminant Analysis',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose a randomized algorithm for large scale SVM learning which solves the problem by iterating over random subsets of the data. Crucial to the algorithm for scalability is the size of the subsets chosen. In the context of text classification we show that, by using ideas from random projections, a sample size of O(log n) can be used to obtain a solution which is close to the optimal with a high probability. Experiments done on synthetic and real life data sets demonstrate that the algorithm scales up SVM learners, without loss in accuracy.',\n",
       "  'id': '3352',\n",
       "  'title': 'A Randomized Algorithm for Large Scale Support Vector Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Can we leverage learning techniques to build a fast nearest-neighbor (NN) retrieval data structure? We present a general learning framework for the NN problem in which sample queries are used to learn the parameters of a data structure that minimize the retrieval time and/or the miss rate. We explore the potential of this novel framework through two popular NN data structures: KD-trees and the rectilinear structures employed by locality sensitive hashing. We derive a generalization theory for these data structure classes and present simple learning algorithms for both. Experimental results reveal that learning often improves on the already strong performance of these data structures.',\n",
       "  'id': '3357',\n",
       "  'title': 'A learning framework for nearest neighbor search',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'This paper proposes constraint propagation relaxation (CPR), a probabilistic approach to classical constraint propagation that provides another view on the whole parametric family of survey propagation algorithms SP(&#961;), ranging from belief propagation (&#961; = 0) to (pure) survey propagation(&#961; = 1). More importantly, the approach elucidates the implicit, but fundamental assumptions underlying SP(&#961;), thus shedding some light on its effectiveness and leading to applications beyond k-SAT.',\n",
       "  'id': '3361',\n",
       "  'title': 'CPR for CSPs: A Probabilistic Relaxation of Constraint Propagation',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose a novel method for {\\\\em linear} dimensionality reduction of manifold modeled data. First, we show that with a small number $M$ of {\\\\em random projections} of sample points in $\\\\reals^N$ belonging to an unknown $K$-dimensional Euclidean manifold, the intrinsic dimension (ID) of the sample set can be estimated to high accuracy. Second, we rigorously prove that using only this set of random projections, we can estimate the structure of the underlying manifold. In both cases, the number random projections required is linear in $K$ and logarithmic in $N$, meaning that $K<M\\\\ll N$. To handle practical situations, we develop a greedy algorithm to estimate the smallest size of the projection space required to perform manifold learning. Our method is particularly relevant in distributed sensing systems and leads to significant potential savings in data acquisition, storage and transmission costs.',\n",
       "  'id': '3191',\n",
       "  'title': 'Random Projections for Manifold Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a probabilistic approach to language change in which word forms are represented by phoneme sequences that undergo stochastic edits along the branches of a phylogenetic tree. Our framework combines the advantages of the classical comparative method with the robustness of corpus-based probabilistic models. We use this framework to explore the consequences of two different schemes for defining probabilistic models of phonological change, evaluating these schemes using the reconstruction of ancient word forms in Romance languages. The result is an efficient inference procedure for automatically inferring ancient word forms from modern languages, which can be generalized to support inferences about linguistic phylogenies.',\n",
       "  'id': '3196',\n",
       "  'title': 'A Probabilistic Approach to Language Change',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We study the following question: is the two-dimensional structure of images a very strong prior or is it something that can be learned with a few examples of natural images? If someone gave us a learning task involving images for which the two-dimensional topology of pixels was not known, could we discover it automatically and exploit it? For example suppose that the pixels had been permuted in a fixed but unknown way, could we recover the relative two-dimensional location of pixels on images? The surprising result presented here is that not only the answer is yes but that about as few as a thousand images are enough to approximately recover the relative locations of about a thousand pixels. This is achieved using a manifold learning algorithm applied to pixels associated with a measure of distributional similarity between pixel intensities. We compare different topology-extraction approaches and show how having the two-dimensional topology can be exploited.',\n",
       "  'id': '3206',\n",
       "  'title': 'Learning the 2-D Topology of Images',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'The peristimulus time historgram (PSTH) and its more continuous cousin, the spike density function (SDF) are staples in the analytic toolkit of neurophysiologists. The former is usually obtained by binning spiketrains, whereas the standard method for the latter is smoothing with a Gaussian kernel. Selection of a bin with or a kernel size is often done in an relatively arbitrary fashion, even though there have been recent attempts to remedy this situation \\\\cite{ShimazakiBinningNIPS2006,ShimazakiBinningNECO2007}. We develop an exact Bayesian, generative model approach to estimating PSHTs and demonstate its superiority to competing methods. Further advantages of our scheme include automatic complexity control and error bars on its predictions.',\n",
       "  'id': '3216',\n",
       "  'title': 'Bayesian binning beats approximate alternatives: estimating peri-stimulus time histograms',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Traditional analysis methods for single-trial classification of electro-encephalography (EEG) focus on two types of paradigms: phase locked methods, in which the amplitude of the signal is used as the feature for classification, i.e. event related potentials; and second order methods, in which the feature of interest is the power of the signal, i.e event related (de)synchronization. The process of deciding which paradigm to use is ad hoc and is driven by knowledge of neurological findings. Here we propose a unified method in which the algorithm learns the best first and second order spatial and temporal features for classification of EEG based on a bilinear model. The efficiency of the method is demonstrated in simulated and real EEG from a benchmark data set for Brain Computer Interface.',\n",
       "  'id': '3236',\n",
       "  'title': 'Second Order Bilinear Discriminant Analysis for single trial EEG analysis',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'It has been shown that adapting a dictionary of basis functions to the statistics of natural images so as to maximize sparsity in the coefficients results in a set of dictionary elements whose spatial properties resemble those of V1 (primary visual cortex) receptive fields. However, the resulting sparse coefficients still exhibit pronounced statistical dependencies, thus violating the independence assumption of the sparse coding model. Here, we propose a model that attempts to capture the dependencies among the basis function coefficients by including a pairwise coupling term in the prior over the coefficient activity states. When adapted to the statistics of natural images, the coupling terms learn a combination of facilitatory and inhibitory interactions among neighboring basis functions. These learned interactions may offer an explanation for the function of horizontal connections in V1, and we discuss the implications of our findings for physiological experiments.',\n",
       "  'id': '3237',\n",
       "  'title': 'Learning Horizontal Connections in a Sparse Coding Model of Natural Images',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a novel linear clustering framework (Diffrac) which relies on a linear discriminative cost function and a convex relaxation of a combinatorial optimization problem. The large convex optimization problem is solved through a sequence of lower dimensional singular value decompositions. This framework has several attractive properties: (1) although apparently similar to K-means, it exhibits superior clustering performance than K-means, in particular in terms of robustness to noise. (2) It can be readily extended to non linear clustering if the discriminative cost function is based on positive definite kernels, and can then be seen as an alternative to spectral clustering. (3) Prior information on the partition is easily incorporated, leading to state-of-the-art performance for semi-supervised learning, for clustering or classification. We present empirical evaluations of our algorithms on synthetic and real medium-scale datasets.',\n",
       "  'id': '3269',\n",
       "  'title': 'DIFFRAC: a discriminative and flexible framework for clustering',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Diffusion processes are a family of continuous-time continuous-state stochastic processes that are in general only partially observed. The joint estimation of the forcing parameters and the system noise (volatility) in these dynamical systems is a crucial, but non-trivial task, especially when the system is nonlinear and multi-modal. We propose a variational treatment of diffusion processes, which allows us to estimate these parameters by simple gradient techniques and which is computationally less demanding than most MCMC approaches. Furthermore, our parameter inference scheme does not break down when the time step gets smaller, unlike most current approaches. Finally, we show how a cheap estimate of the posterior over the parameters can be constructed based on the variational free energy.',\n",
       "  'id': '3282',\n",
       "  'title': 'Variational Inference for Diffusion Processes',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'In this paper we develop a Gaussian process (GP) framework to model a collection of reciprocal random variables defined on the \\\\emph{edges} of a network. We show how to construct GP priors, i.e.,~covariance functions, on the edges of directed, undirected, and bipartite graphs. The model suggests an intimate connection between \\\\emph{link prediction} and \\\\emph{transfer learning}, which were traditionally considered two separate research topics. Though a straightforward GP inference has a very high complexity, we develop an efficient learning algorithm that can handle a large number of observations. The experimental results on several real-world data sets verify superior learning capacity.',\n",
       "  'id': '3284',\n",
       "  'title': 'Gaussian Process Models for Link Analysis and Transfer Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Loopy belief propagation has been employed in a wide variety of applications with great empirical success, but it comes with few theoretical guarantees. In this paper we investigate the use of the max-product form of belief propagation for weighted matching problems on general graphs. We show that max-product converges to the correct answer if the linear programming (LP) relaxation of the weighted matching problem is tight and does not converge if the LP relaxation is loose. This provides an exact characterization of max-product performance and reveals connections to the widely used optimization technique of LP relaxation. In addition, we demonstrate that max-product is effective in solving practical weighted matching problems in a distributed fashion by applying it to the problem of self-organization in sensor networks.',\n",
       "  'id': '3285',\n",
       "  'title': 'Linear programming analysis of loopy belief propagation for weighted matching',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Using multiple regularization hyperparameters is an effective method for managing model complexity in problems where input features have varying amounts of noise. While algorithms for choosing multiple hyperparameters are often used in neural networks and support vector machines, they are not common in structured prediction tasks, such as sequence labeling or parsing. In this paper, we consider the problem of learning regularization hyperparameters for log-linear models, a class of probabilistic models for structured prediction tasks which includes conditional random fields (CRFs). Using an implicit differentiation trick, we derive an efficient gradient-based method for learning Gaussian regularization priors with multiple hyperparameters. In both simulations and the real-world task of computational RNA secondary structure prediction, we find that multiple hyperparameter learning provides a significant boost in accuracy compared to models learned using only a single regularization hyperparameter.',\n",
       "  'id': '3286',\n",
       "  'title': 'Efficient multiple hyperparameter learning for log-linear models',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"This paper describes a new model for human visual classification that enables the recovery of image features that explain human subjects' performance on different visual classification tasks. Unlike previous methods, this algorithm does not model their performance with a single linear classifier operating on raw image pixels. Instead, it models classification as the combination of multiple feature detectors. This approach extracts more information about human visual classification than has been previously possible with other methods and provides a foundation for further exploration.\",\n",
       "  'id': '3289',\n",
       "  'title': 'GRIFT: A graphical model for inferring visual classification features from human data',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a general boosting method extending functional gradient boosting to optimize complex loss functions that are encountered in many machine learning problems. Our approach is based on optimization of quadratic upper bounds of the loss functions which allows us to present a rigorous convergence analysis of the algorithm. More importantly, this general framework enables us to use a standard regression base learner such as decision trees for fitting any loss function. We illustrate an application of the proposed method in learning ranking functions for Web search by combining both preference data and labeled data for training. We present experimental results for Web search using data from a commercial search engine that show significant improvements of our proposed methods over some existing methods.',\n",
       "  'id': '3305',\n",
       "  'title': 'A General Boosting Method and its Application to Learning Ranking Functions for Web Search',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Functional Magnetic Resonance Imaging (fMRI) provides an unprecedented window into the complex functioning of the human brain, typically detailing the activity of thousands of voxels during hundreds of sequential time points. Unfortunately, the interpretation of fMRI is complicated due both to the relatively unknown connection between the hemodynamic response and neural activity and the unknown spatiotemporal characteristics of the cognitive patterns themselves. Here, we use data from the Experience Based Cognition competition to compare global and local methods of prediction applying both linear and nonlinear techniques of dimensionality reduction. We build global low dimensional representations of an fMRI dataset, using linear and nonlinear methods. We learn a set of time series that are implicit functions of the fMRI data, and predict the values of these times series in the future from the knowledge of the fMRI data only. We find effective, low-dimensional models based on the principal components of cognitive activity in classically-defined anatomical regions, the Brodmann Areas. Furthermore for some of the stimuli, the top predictive regions were stable across subjects and episodes, including Wernicke?s area for verbal instructions, visual cortex for facial and body features, and visual-temporal regions (Brodmann Area 7) for velocity. These interpretations and the relative simplicity of our approach provide a transparent and conceptual basis upon which to build more sophisticated techniques for fMRI decoding. To our knowledge, this is the first time that classical areas have been used in fMRI for an effective prediction of complex natural experience.',\n",
       "  'id': '3320',\n",
       "  'title': 'Locality and low-dimensions in the prediction of natural experience from fMRI',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'In this paper, we propose a method for support vector machine classification using indefinite kernels. Instead of directly minimizing or stabilizing a nonconvex loss function, our method simultaneously finds the support vectors and a proxy kernel matrix used in computing the loss. This can be interpreted as a robust classification problem where the indefinite kernel matrix is treated as a noisy observation of the true positive semidefinite kernel. Our formulation keeps the problem convex and relatively large problems can be solved efficiently using the analytic center cutting plane method. We compare the performance of our technique with other methods on several data sets.',\n",
       "  'id': '3339',\n",
       "  'title': 'Support Vector Machine Classification with Indefinite Kernels',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"Adaptation to other initially unknown agents often requires computing an effective counter-strategy. In the Bayesian paradigm, one must find a good counter-strategy to the inferred posterior of the other agents' behavior. In the experts paradigm, one may want to choose experts that are good counter-strategies to the other agents' expected behavior. In this paper we introduce a technique for computing robust counter-strategies for adaptation in multiagent scenarios under a variety of paradigms. The strategies can take advantage of a suspected tendency in the decisions of the other agents, while bounding the worst-case performance when the tendency is not observed. The technique involves solving a modified game, and therefore can make use of recently developed algorithms for solving very large extensive games. We demonstrate the effectiveness of the technique in two-player Texas Hold'em. We show that the computed poker strategies are substantially more robust than best response counter-strategies, while still exploiting a suspected tendency. We also compose the generated strategies in an experts algorithm showing a dramatic improvement in performance over using simple best responses.\",\n",
       "  'id': '3347',\n",
       "  'title': 'Computing Robust Counter-Strategies',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a new and efficient semi-supervised training method for parameter estimation and feature selection in conditional random fields (CRFs). In real-world applications such as activity recognition, unlabeled sensor traces are relatively easy to obtain whereas labeled examples are expensive and tedious to collect. Furthermore, the ability to automatically select a small subset of discriminatory features from a large pool can be advantageous in terms of computational speed as well as accuracy. In this paper, we introduce the semi-supervised virtual evidence boosting (sVEB) algorithm for training CRFs -- a semi-supervised extension to the recently developed virtual evidence boosting (VEB) method for feature selection and parameter learning. Semi-supervised VEB takes advantage of the unlabeled data via minimum entropy regularization -- the objective function combines the unlabeled conditional entropy with labeled conditional pseudo-likelihood. The sVEB algorithm reduces the overall system cost as well as the human labeling cost required during training, which are both important considerations in building real world inference systems. In a set of experiments on synthetic data and real activity traces collected from wearable sensors, we illustrate that our algorithm benefits from both the use of unlabeled data and automatic feature selection, and outperforms other semi-supervised training approaches.',\n",
       "  'id': '3348',\n",
       "  'title': 'Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We show that under suitable assumptions (primarily linearization) a simple and perspicuous online learning rule for Information Bottleneck optimization with spiking neurons can be derived. This rule performs on common benchmark tasks as well as a rather complex rule that has previously been proposed \\\\cite{KlampflETAL:07b}. Furthermore, the transparency of this new learning rule makes a theoretical analysis of its convergence properties feasible. A variation of this learning rule (with sign changes) provides a theoretically founded method for performing Principal Component Analysis {(PCA)} with spiking neurons. By applying this rule to an ensemble of neurons, different principal components of the input can be extracted. In addition, it is possible to preferentially extract those principal components from incoming signals $X$ that are related or are not related to some additional target signal $Y_T$. In a biological interpretation, this target signal $Y_T$ (also called relevance variable) could represent proprioceptive feedback, input from other sensory modalities, or top-down signals.',\n",
       "  'id': '3168',\n",
       "  'title': 'Simplified Rules and Theoretical Analysis for Information Bottleneck Optimization and PCA with Spiking Neurons',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We construct a biologically motivated stochastic differential model of the neural and hemodynamic activity underlying the observed Blood Oxygen Level Dependent (BOLD) signal in Functional Magnetic Resonance Imaging (fMRI). The model poses a difficult parameter estimation problem, both theoretically due to the nonlinearity and divergence of the differential system, and computationally due to its time and space complexity. We adapt a particle filter and smoother to the task, and discuss some of the practical approaches used to tackle the difficulties, including use of sparse matrices and parallelisation. Results demonstrate the tractability of the approach in its application to an effective connectivity study.',\n",
       "  'id': '3172',\n",
       "  'title': 'Continuous Time Particle Filtering for fMRI',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Independent component analysis (ICA) is a powerful method to decouple signals. Most of the algorithms performing ICA do not consider the temporal correlations of the signal, but only higher moments of its amplitude distribution. Moreover, they require some preprocessing of the data (whitening) so as to remove second order correlations. In this paper, we are interested in understanding the neural mechanism responsible for solving ICA. We present an online learning rule that exploits delayed correlations in the input. This rule performs ICA by detecting joint variations in the firing rates of pre- and postsynaptic neurons, similar to a local rate-based Hebbian learning rule.',\n",
       "  'id': '3174',\n",
       "  'title': 'An online Hebbian learning rule that performs Independent Component Analysis',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a theoretical study on the discriminative clustering framework, recently proposed for simultaneous subspace selection via linear discriminant analysis (LDA) and clustering. Empirical results have shown its favorable performance in comparison with several other popular clustering algorithms. However, the inherent relationship between subspace selection and clustering in this framework is not well understood, due to the iterative nature of the algorithm. We show in this paper that this iterative subspace selection and clustering is equivalent to kernel K-means with a specific kernel Gram matrix. This provides significant and new insights into the nature of this subspace selection procedure. Based on this equivalence relationship, we propose the Discriminative K-means (DisKmeans) algorithm for simultaneous LDA subspace selection and clustering, as well as an automatic parameter estimation procedure. We also present the nonlinear extension of DisKmeans using kernels. We show that the learning of the kernel matrix over a convex set of pre-specified kernel matrices can be incorporated into the clustering formulation. The connection between DisKmeans and several other clustering algorithms is also analyzed. The presented theories and algorithms are evaluated through experiments on a collection of benchmark data sets.',\n",
       "  'id': '3176',\n",
       "  'title': 'Discriminative K-means for Clustering',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present Epoch-Greedy, an algorithm for multi-armed bandits with observable side information. Epoch-Greedy has the following properties: No knowledge of a time horizon $T$ is necessary. The regret incurred by Epoch-Greedy is controlled by a sample complexity bound for a hypothesis class. The regret scales as $O(T^{2/3} S^{1/3})$ or better (sometimes, much better). Here $S$ is the complexity term in a sample complexity bound for standard supervised learning.',\n",
       "  'id': '3178',\n",
       "  'title': 'The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a novel message passing algorithm for approximating the MAP problem in graphical models. The algorithm is similar in structure to max-product but unlike max-product it always converges, and can be proven to find the exact MAP solution in various settings. The algorithm is derived via block coordinate descent in a dual of the LP relaxation of MAP, but does not require any tunable parameters such as step size or tree weights. We also describe a generalization of the method to cluster based potentials. The new method is tested on synthetic and real-world problems, and compares favorably with previous approaches.',\n",
       "  'id': '3200',\n",
       "  'title': 'Fixing Max-Product: Convergent Message Passing Algorithms for MAP LP-Relaxations',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Biological movement is built up of sub-blocks or motion primitives. Such primitives provide a compact representation of movement which is also desirable in robotic control applications. We analyse handwriting data to gain a better understanding of use of primitives and their timings in biological movements. Inference of the shape and the timing of primitives can be done using a factorial HMM based model, allowing the handwriting to be represented in primitive timing space. This representation provides a distribution of spikes corresponding to the primitive activations, which can also be modelled using HMM architectures. We show how the coupling of the low level primitive model, and the higher level timing model during inference can produce good reconstructions of handwriting, with shared primitives for all characters modelled. This coupled model also captures the variance profile of the dataset which is accounted for by spike timing jitter. The timing code provides a compact representation of the movement while generating a movement without an explicit timing model produces a scribbling style of output.',\n",
       "  'id': '3204',\n",
       "  'title': 'Modelling motion primitives and their timing in biologically executed movements',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'On-line handwriting recognition is unusual among sequence labelling tasks in that the underlying generator of the observed data, i.e. the movement of the pen, is recorded directly. However, the raw data can be difficult to interpret because each letter is spread over many pen locations. As a consequence, sophisticated pre-processing is required to obtain inputs suitable for conventional sequence labelling algorithms, such as HMMs. In this paper we describe a system capable of directly transcribing raw on-line handwriting data. The system consists of a recurrent neural network trained for sequence labelling, combined with a probabilistic language model. In experiments on an unconstrained on-line database, we record excellent results using either raw or pre-processed data, well outperforming a benchmark HMM in both cases.',\n",
       "  'id': '3213',\n",
       "  'title': 'Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'When training and test samples follow different input distributions (i.e., the situation called \\\\emph{covariate shift}), the maximum likelihood estimator is known to lose its consistency. For regaining consistency, the log-likelihood terms need to be weighted according to the \\\\emph{importance} (i.e., the ratio of test and training input densities). Thus, accurately estimating the importance is one of the key tasks in covariate shift adaptation. A naive approach is to first estimate training and test input densities and then estimate the importance by the ratio of the density estimates. However, since density estimation is a hard problem, this approach tends to perform poorly especially in high dimensional cases. In this paper, we propose a direct importance estimation method that does not require the input density estimates. Our method is equipped with a natural model selection procedure so tuning parameters such as the kernel width can be objectively optimized. This is an advantage over a recently developed method of direct importance estimation. Simulations illustrate the usefulness of our approach.',\n",
       "  'id': '3248',\n",
       "  'title': 'Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We consider the estimation problem in Gaussian graphical models with arbitrary structure. We analyze the Embedded Trees algorithm, which solves a sequence of problems on tractable subgraphs thereby leading to the solution of the estimation problem on an intractable graph. Our analysis is based on the recently developed walk-sum interpretation of Gaussian estimation. We show that non-stationary iterations of the Embedded Trees algorithm using any sequence of subgraphs converge in walk-summable models. Based on walk-sum calculations, we develop adaptive methods that optimize the choice of subgraphs used at each iteration with a view to achieving maximum reduction in error. These adaptive procedures provide a significant speedup in convergence over stationary iterative methods, and also appear to converge in a larger class of models.',\n",
       "  'id': '3275',\n",
       "  'title': 'Adaptive Embedded Subgraph Algorithms using Walk-Sum Analysis',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"In recent years, the language model Latent Dirichlet Allocation (LDA), which clusters co-occurring words into topics, has been widely appled in the computer vision field. However, many of these applications have difficulty with modeling the spatial and temporal structure among visual words, since LDA assumes that a document is a ``bag-of-words''. It is also critical to properly design ``words'' and ?documents? when using a language model to solve vision problems. In this paper, we propose a topic model Spatial Latent Dirichlet Allocation (SLDA), which better encodes spatial structure among visual words that are essential for solving many vision problems. The spatial information is not encoded in the value of visual words but in the design of documents. Instead of knowing the partition of words into documents \\\\textit{a priori}, the word-document assignment becomes a random hidden variable in SLDA. There is a generative procedure, where knowledge of spatial structure can be flexibly added as a prior, grouping visual words which are close in space into the same document. We use SLDA to discover objects from a collection of images, and show it achieves better performance than LDA.\",\n",
       "  'id': '3278',\n",
       "  'title': 'Spatial Latent Dirichlet Allocation',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Web servers on the Internet need to maintain high reliability, but the cause of intermittent failures of web transactions is non-obvious. We use Bayesian inference to diagnose problems with web services. This diagnosis problem is far larger than any previously attempted: it requires inference of 10^4 possible faults from 10^5 observations. Further, such inference must be performed in less than a second. Inference can be done at this speed by combining a variational approximation, a mean-field approximation, and the use of stochastic gradient descent to optimize a variational cost function. We use this fast inference to diagnose a time series of anomalous HTTP requests taken from a real web service. The inference is fast enough to analyze network logs with billions of entries in a matter of hours.',\n",
       "  'id': '3292',\n",
       "  'title': 'Fast Variational Inference for Large-scale Internet Diagnosis',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"This article discusses a latent variable model for inference and prediction of symmetric relational data. The model, based on the idea of the eigenvalue decomposition, represents the relationship between two nodes as the weighted inner-product of node-specific vectors of latent characteristics. This ``eigenmodel'' generalizes other popular latent variable models, such as latent class and distance models: It is shown mathematically that any latent class or distance model has a representation as an eigenmodel, but not vice-versa. The practical implications of this are examined in the context of three real datasets, for which the eigenmodel has as good or better out-of-sample predictive performance than the other two models.\",\n",
       "  'id': '3294',\n",
       "  'title': 'Modeling homophily and stochastic equivalence in symmetric relational data',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Active learning sequentially selects unlabeled instances to label with the goal of reducing the effort needed to learn a good classifier. Most previous studies in active learning have focused on selecting one unlabeled instance at one time while retraining in each iteration. However, single instance selection systems are unable to exploit a parallelized labeler when one is available. Recently a few batch mode active learning approaches have been proposed that select a set of most informative unlabeled instances in each iteration, guided by some heuristic scores. In this paper, we propose a discriminative batch mode active learning approach that formulates the instance selection task as a continuous optimization problem over auxiliary instance selection variables. The optimization is formuated to maximize the discriminative classification performance of the target classifier, while also taking the unlabeled data into account. Although the objective is not convex, we can manipulate a quasi-Newton method to obtain a good local solution. Our empirical studies on UCI datasets show that the proposed active learning is more effective than current state-of-the art batch mode active learning algorithms.',\n",
       "  'id': '3295',\n",
       "  'title': 'Discriminative Batch Mode Active Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'The control of high-dimensional, continuous, non-linear systems is a key problem in reinforcement learning and control. Local, trajectory-based methods, using techniques such as Differential Dynamic Programming (DDP) are not directly subject to the curse of dimensionality, but generate only local controllers. In this paper, we introduce Receding Horizon DDP (RH-DDP), an extension to the classic DDP algorithm, which allows us to construct stable and robust controllers based on a library of local-control trajectories. We demonstrate the effectiveness of our approach on a series of high-dimensional control problems using a simulated multi-link swimming robot. These experiments show that our approach effectively circumvents dimensionality issues, and is capable of dealing effectively with problems with (at least) 34 state and 14 action dimensions.',\n",
       "  'id': '3297',\n",
       "  'title': 'Receding Horizon Differential Dynamic Programming',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'This paper introduces kernels on attributed pointsets, which are sets of vectors embedded in an euclidean space. The embedding gives the notion of neighborhood, which is used to define positive semidefinite kernels on pointsets. Two novel kernels on neighborhoods are proposed, one evaluating the attribute similarity and the other evaluating shape similarity. Shape similarity function is motivated from spectral graph matching techniques. The kernels are tested on three real life applications: face recognition, photo album tagging, and shot annotation in video sequences, with encouraging results.',\n",
       "  'id': '3304',\n",
       "  'title': 'Kernels on Attributed Pointsets with Applications',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"We combine two threads of research on approximate dynamic programming: random sampling of states and using local trajectory optimizers to globally optimize a policy and associated value function. This combination allows us to replace a dense multidimensional grid with a much sparser adaptive sampling of states. Our focus is on finding steady state policies for the deterministic time invariant discrete time control problems with continuous states and actions often found in robotics. In this paper we show that we can now solve problems we couldn't solve previously with regular grid-based approaches.\",\n",
       "  'id': '3350',\n",
       "  'title': 'Random Sampling of States in Dynamic Programming',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Automatic relevance determination (ARD), and the closely-related sparse Bayesian learning (SBL) framework, are effective tools for pruning large numbers of irrelevant features. However, popular update rules used for this process are either prohibitively slow in practice and/or heuristic in nature without proven convergence properties. This paper furnishes an alternative means of optimizing a general ARD cost function using an auxiliary function that can naturally be solved using a series of re-weighted L1 problems. The result is an efficient algorithm that can be implemented using standard convex programming toolboxes and is guaranteed to converge to a stationary point unlike existing methods. The analysis also leads to additional insights into the behavior of previous ARD updates as well as the ARD cost function. For example, the standard fixed-point updates of MacKay (1992) are shown to be iteratively solving a particular min-max problem, although they are not guaranteed to lead to a stationary point. The analysis also reveals that ARD is exactly equivalent to performing MAP estimation using a particular feature- and noise-dependent \\\\textit{non-factorial} weight prior with several desirable properties over conventional priors with respect to feature selection. In particular, it provides a tighter approximation to the L0 quasi-norm sparsity measure than the L1 norm. Overall these results suggests alternative cost functions and update procedures for selecting features and promoting sparse solutions.',\n",
       "  'id': '3372',\n",
       "  'title': 'A New View of Automatic Relevance Determination',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present the first truly polynomial algorithm for learning the structure of bounded-treewidth junction trees -- an attractive subclass of probabilistic graphical models that permits both the compact representation of probability distributions and efficient exact inference. For a constant treewidth, our algorithm has polynomial time and sample complexity, and provides strong theoretical guarantees in terms of $KL$ divergence from the true distribution. We also present a lazy extension of our approach that leads to very significant speed ups in practice, and demonstrate the viability of our method empirically, on several real world datasets. One of our key new theoretical insights is a method for bounding the conditional mutual information of arbitrarily large sets of random variables with only a polynomial number of mutual information computations on fixed-size subsets of variables, when the underlying distribution can be approximated by a bounded treewidth junction tree.',\n",
       "  'id': '3164',\n",
       "  'title': 'Efficient Principled Learning of Thin Junction Trees',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose a new approach for dealing with the estimation of the location of change-points in one-dimensional piecewise constant signals observed in white noise. Our approach consists in reframing this task in a variable selection context. We use a penalized least-squares criterion with a l1-type penalty for this purpose. We prove that, in an appropriate asymptotic framework, this method provides consistent estimators of the change-points. Then, we explain how to implement this method in practice by combining the LAR algorithm and a reduced version of the dynamic programming algorithm and we apply it to synthetic and real data.',\n",
       "  'id': '3188',\n",
       "  'title': 'Catching Change-points with Lasso',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a simple variant of the k-d tree which automatically adapts to intrinsic low dimensional structure in data.',\n",
       "  'id': '3195',\n",
       "  'title': 'Learning the structure of manifolds using random projections',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'A new algorithm for on-line learning linear-threshold functions is proposed which efficiently combines second-order statistics about the data with the logarithmic behavior\" of multiplicative/dual-norm algorithms. An initial theoretical analysis is provided suggesting that our algorithm might be viewed as a standard Perceptron algorithm operating on a transformed sequence of examples with improved margin properties. We also report on experiments carried out on datasets from diverse domains, with the goal of comparing to known Perceptron algorithms (first-order, second-order, additive, multiplicative). Our learning procedure seems to generalize quite well, and converges faster than the corresponding multiplicative baseline algorithms.\"',\n",
       "  'id': '3209',\n",
       "  'title': 'On higher-order perceptron algorithms',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We show how to use unlabeled data and a deep belief net (DBN) to learn a good covariance kernel for a Gaussian process. We first learn a deep generative model of the unlabeled data using the fast, greedy algorithm introduced by Hinton et.al. If the data is high-dimensional and highly-structured, a Gaussian kernel applied to the top layer of features in the DBN works much better than a similar kernel applied to the raw input. Performance at both regression and classification can then be further improved by using backpropagation through the DBN to discriminatively fine-tune the covariance kernel.',\n",
       "  'id': '3211',\n",
       "  'title': 'Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to find the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difficult because the space of choices is infinite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool finds the best parameters while minimizing the number of queries.',\n",
       "  'id': '3219',\n",
       "  'title': 'Active Preference Learning with Discrete Choice Data',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Stimulus selectivity of sensory neurons is often characterized by estimating their receptive field properties such as orientation selectivity. Receptive fields are usually derived from the mean (or covariance) of the spike-triggered stimulus ensemble. This approach treats each spike as an independent message but does not take into account that information might be conveyed through patterns of neural activity that are distributed across space or time. Can we find a concise description for the processing of a whole population of neurons analogous to the receptive field for single neurons? Here, we present a generalization of the linear receptive field which is not bound to be triggered on individual spikes but can be meaningfully linked to distributed response patterns. More precisely, we seek to identify those stimulus features and the corresponding patterns of neural activity that are most reliably coupled. We use an extension of reverse-correlation methods based on canonical correlation analysis. The resulting population receptive fields span the subspace of stimuli that is most informative about the population response. We evaluate our approach using both neuronal models and multi-electrode recordings from rabbit retinal ganglion cells. We show how the model can be extended to capture nonlinear stimulus-response relationships using kernel canonical correlation analysis, which makes it possible to test different coding mechanisms. Our technique can also be used to calculate receptive fields from multi-dimensional neural measurements such as those obtained from dynamic imaging methods.',\n",
       "  'id': '3220',\n",
       "  'title': 'Receptive Fields without Spike-Triggering',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We consider continuous state, continuous action batch reinforcement learning where the goal is to learn a good policy from a sufficiently rich trajectory generated by another policy. We study a variant of fitted Q-iteration, where the greedy action selection is replaced by searching for a policy in a restricted set of candidate policies by maximizing the average action values. We provide a rigorous theoretical analysis of this algorithm, proving what we believe is the first finite-time bounds for value-function based algorithms for continuous state- and action-space problems.',\n",
       "  'id': '3233',\n",
       "  'title': 'Fitted Q-iteration in continuous action-space MDPs',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Guided by the goal of obtaining an optimization algorithm that is both fast and yielding good generalization, we study the descent direction maximizing the decrease in generalization error or the probability of not increasing generalization error. The surprising result is that from both the Bayesian and frequentist perspectives this can yield the natural gradient direction. Although that direction can be very expensive to compute we develop an efficient, general, online approximation to the natural gradient descent which is suited to large scale problems. We report experimental results showing much faster convergence in computation time and in number of iterations with TONGA (Topmoumoute Online natural Gradient Algorithm) than with stochastic gradient descent, even on very large datasets.',\n",
       "  'id': '3234',\n",
       "  'title': 'Topmoumoute Online Natural Gradient Algorithm',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'An important problem in many fields is the analysis of counts data to extract meaningful latent components. Methods like Probabilistic Latent Semantic Analysis (PLSA) and Latent Dirichlet Allocation (LDA) have been proposed for this purpose. However, they are limited in the number of components they can extract and also do not have a provision to control the expressiveness\" of the extracted components. In this paper, we present a learning formulation to address these limitations by employing the notion of sparsity. We start with the PLSA framework and use an entropic prior in a maximum a posteriori formulation to enforce sparsity. We show that this allows the extraction of overcomplete sets of latent components which better characterize the data. We present experimental evidence of the utility of such representations.\"',\n",
       "  'id': '3235',\n",
       "  'title': 'Sparse Overcomplete Latent Variable Decomposition of Counts Data',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'This paper explores the use of a Maximal Average Margin (MAM) optimality principle for the design of learning algorithms. It is shown that the application of this risk minimization principle results in a class of (computationally) simple learning machines similar to the classical Parzen window classifier. A direct relation with the Rademacher complexities is established, as such facilitating analysis and providing a notion of certainty of prediction. This analysis is related to Support Vector Machines by means of a margin transformation. The power of the MAM principle is illustrated further by application to ordinal regression tasks, resulting in an $O(n)$ algorithm able to process large datasets in reasonable time.',\n",
       "  'id': '3243',\n",
       "  'title': 'A Risk Minimization Principle for a Class of Parzen Estimators',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a new analysis for the combination of binary classifiers. We propose a theoretical framework based on the Neyman-Pearson lemma to analyze combinations of classifiers. In particular, we give a method for finding the optimal decision rule for a combination of classifiers and prove that it has the optimal ROC curve. We also show how our method generalizes and improves on previous work on combining classifiers and generating ROC curves.',\n",
       "  'id': '3263',\n",
       "  'title': 'Optimal ROC Curve for a Combination of Classifiers',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'The classical hypothesis, that bottom-up saliency is a center-surround process, is combined with a more recent hypothesis that all saliency decisions are optimal in a decision-theoretic sense. The combined hypothesis is denoted as discriminant center-surround saliency, and the corresponding optimal saliency architecture is derived. This architecture equates the saliency of each image location to the discriminant power of a set of features with respect to the classification problem that opposes stimuli at center and surround, at that location. It is shown that the resulting saliency detector makes accurate quantitative predictions for various aspects of the psychophysics of human saliency, including non-linear properties beyond the reach of previous saliency models. Furthermore, it is shown that discriminant center-surround saliency can be easily generalized to various stimulus modalities (such as color, orientation and motion), and provides optimal solutions for many other saliency problems of interest for computer vision. Optimal solutions, under this hypothesis, are derived for a number of the former (including static natural images, dense motion fields, and even dynamic textures), and applied to a number of the latter (the prediction of human eye fixations, motion-based saliency in the presence of ego-motion, and motion-based saliency in the presence of highly dynamic backgrounds). In result, discriminant saliency is shown to predict eye fixations better than previous models, and produce background subtraction algorithms that outperform the state-of-the-art in computer vision.',\n",
       "  'id': '3264',\n",
       "  'title': 'The discriminant center-surround hypothesis for bottom-up saliency',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Markov jump processes play an important role in a large number of application domains. However, realistic systems are analytically intractable and they have traditionally been analysed using simulation based techniques, which do not provide a framework for statistical inference. We propose a mean field approximation to perform posterior inference and parameter estimation. The approximation allows a practical solution to the inference problem, {while still retaining a good degree of accuracy.} We illustrate our approach on two biologically motivated systems.',\n",
       "  'id': '3296',\n",
       "  'title': 'Variational inference for Markov jump processes',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation--estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.',\n",
       "  'id': '3323',\n",
       "  'title': 'The Tradeoffs of Large Scale Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to naturalistic stimuli and boosting the power of functional imaging. The method searches for sets of voxel timecourses that optimize a multivariate functional linear model in terms of Rsquare-statistic. Population based incremental learning is used to search for spatially distributed voxel clusters, taking into account the variation in Haemodynamic lag across brain areas and among subjects by voxel-wise non-linear registration of stimuli to fMRI data. The method captures spatially distributed brain responses to naturalistic stimuli without attempting to localize function. Application of the method for prediction of naturalistic stimuli from new and unknown fMRI data shows that the approach is capable of identifying distributed clusters of brain locations that are highly predictive of a specific stimuli.',\n",
       "  'id': '3326',\n",
       "  'title': 'Predicting Brain States from fMRI Data: Incremental Functional Principal Component Regression',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We introduce a hierarchical Bayesian model for the discovery of putative regulators from gene expression data only. The hierarchy incorporates the knowledge that there are just a few regulators that by themselves only regulate a handful of genes. This is implemented through a so-called spike-and-slab prior, a mixture of Gaussians with different widths, with mixing weights from a hierarchical Bernoulli model. For efficient inference we implemented expectation propagation. Running the model on a malaria parasite data set, we found four genes with significant homology to transcription factors in an amoebe, one RNA regulator and three genes of unknown function (out of the top ten genes considered).',\n",
       "  'id': '3362',\n",
       "  'title': 'Regulator Discovery from Gene Expression Time Series of Malaria Parasites: a Hierachical Approach',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a novel paradigm for statistical machine translation (SMT), based on joint modeling of word alignment and the topical aspects underlying bilingual document pairs via a hidden Markov Bilingual Topic AdMixture (HM-BiTAM). In this new paradigm, parallel sentence-pairs from a parallel document-pair are coupled via a certain semantic-flow, to ensure coherence of topical context in the alignment of matching words between languages, during likelihood-based training of topic-dependent translational lexicons, as well as topic representations in each language. The resulting trained HM-BiTAM can not only display topic patterns like other methods such as LDA, but now for bilingual corpora; it also offers a principled way of inferring optimal translation in a context-dependent way. Our method integrates the conventional IBM Models based on HMM --- a key component for most of the state-of-the-art SMT systems, with the recently proposed BiTAM model, and we report an extensive empirical analysis (in many way complementary to the description-oriented of our method in three aspects: word alignment, bilingual topic representation, and translation.',\n",
       "  'id': '3365',\n",
       "  'title': 'HM-BiTAM: Bilingual Topic Exploration, Word Alignment, and Translation',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject\\'s intent. An elegant approach to improve the accuracy of BCIs consists in a verification procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment confirms the previously reported presence of a new kind of ErrP. These Interaction ErrP\" exhibit a first sharp negative peak followed by a positive peak and a second broader negative peak (~290, ~350 and ~470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classifier embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject\\'s intent while trying to mentally drive the cursor of 73.1%. These results show that it\\'s possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the brain-computer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex.\"',\n",
       "  'id': '3377',\n",
       "  'title': 'EEG-Based Brain-Computer Interaction: Improved Accuracy by Automatic Single-Trial Error Detection',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Semi-supervised inductive learning concerns how to learn a decision rule from a data set containing both labeled and unlabeled data. Several boosting algorithms have been extended to semi-supervised learning with various strategies. To our knowledge, however, none of them takes local smoothness constraints among data into account during ensemble learning. In this paper, we introduce a local smoothness regularizer to semi-supervised boosting algorithms based on the universal optimization framework of margin cost functionals. Our regularizer is applicable to existing semi-supervised boosting algorithms to improve their generalization and speed up their training. Comparative results on synthetic, benchmark and real world tasks demonstrate the effectiveness of our local smoothness regularizer. We discuss relevant issues and relate our regularizer to previous work.',\n",
       "  'id': '3167',\n",
       "  'title': 'Regularized Boost for Semi-Supervised Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"Under natural viewing conditions, human observers shift their gaze to allocate processing resources to subsets of the visual input. Many computational models have aimed at predicting such voluntary attentional shifts. Although the importance of high level stimulus properties (higher order statistics, semantics) stands undisputed, most models are based on low-level features of the input alone. In this study we recorded eye-movements of human observers while they viewed photographs of natural scenes. About two thirds of the stimuli contained at least one person. We demonstrate that a combined model of face detection and low-level saliency clearly outperforms a low-level model in predicting locations humans fixate. This is reflected in our finding fact that observes, even when not instructed to look for anything particular, fixate on a face with a probability of over 80% within their first two fixations (500ms). Remarkably, the model's predictive performance in images that do not contain faces is not impaired by spurious face detector responses, which is suggestive of a bottom-up mechanism for face detection. In summary, we provide a novel computational approach which combines high level object knowledge (in our case: face locations) with low-level features to successfully predict the allocation of attentional resources.\",\n",
       "  'id': '3169',\n",
       "  'title': 'Predicting human gaze using low-level saliency combined with face detection',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Large repositories of source code create new challenges and opportunities for statistical machine learning. Here we first develop an infrastructure for the automated crawling, parsing, and database storage of open source software. The infrastructure allows us to gather Internet-scale source code. For instance, in one experiment, we gather 4,632 java projects from SourceForge and Apache totaling over 38 million lines of code from 9,250 developers. Simple statistical analyses of the data first reveal robust power-law behavior for package, SLOC, and method call distributions. We then develop and apply unsupervised author-topic, probabilistic models to automatically discover the topics embedded in the code and extract topic-word and author-topic distributions. In addition to serving as a convenient summary for program function and developer activities, these and other related distributions provide a statistical and information-theoretic basis for quantifying and analyzing developer similarity and competence, topic scattering, and document tangling, with direct applications to software engineering. Finally, by combining software textual content with structural information captured by our CodeRank approach, we are able to significantly improve software retrieval performance, increasing the AUC metric to 0.86-- roughly 10-30% better than previous approaches based on text alone.',\n",
       "  'id': '3171',\n",
       "  'title': 'Mining Internet-Scale Software Repositories',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We present a new local approximation algorithm for computing MAP and log-partition function for arbitrary exponential family distribution represented by a finite-valued pair-wise Markov random field (MRF), say G. Our algorithm is based on decomposing G into appropriately chosen small components; computing estimates locally in each of these components and then producing a good global solution. We prove that the algorithm can provide approximate solution within arbitrary accuracy when $G$ excludes some finite sized graph as its minor and G has bounded degree: all Planar graphs with bounded degree are examples of such graphs. The running time of the algorithm is $\\\\Theta(n)$ (n is the number of nodes in G), with constant dependent on accuracy, degree of graph and size of the graph that is excluded as a minor (constant for Planar graphs). Our algorithm for minor-excluded graphs uses the decomposition scheme of Klein, Plotkin and Rao (1993). In general, our algorithm works with any decomposition scheme and provides quantifiable approximation guarantee that depends on the decomposition scheme.',\n",
       "  'id': '3186',\n",
       "  'title': 'Local Algorithms for Approximate Inference in Minor-Excluded Graphs',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"We provide a provably efficient algorithm for learning Markov Decision Processes (MDPs) with continuous state and action spaces in the online setting. Specifically, we take a model-based approach and show that a special type of online linear regression allows us to learn MDPs with (possibly kernalized) linearly parameterized dynamics. This result builds on Kearns and Singh's work that provides a provably efficient algorithm for finite state MDPs. Our approach is not restricted to the linear setting, and is applicable to other classes of continuous MDPs.\",\n",
       "  'id': '3197',\n",
       "  'title': 'Online Linear Regression and Its Application to Model-Based Reinforcement Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We address the problem of adaptive sensor control in dynamic resource-constrained sensor networks. We focus on a meteorological sensing network comprising radars that can perform sector scanning rather than always scanning 360 degrees. We compare three sector scanning strategies. The sit-and-spin strategy always scans 360 degrees. The limited lookahead strategy additionally uses the expected environmental state K decision epochs in the future, as predicted from Kalman filters, in its decision-making. The full lookahead strategy uses all expected future states by casting the problem as a Markov decision process and using reinforcement learning to estimate the optimal scan strategy. We show that the main benefits of using a lookahead strategy are when there are multiple meteorological phenomena in the environment, and when the maximum radius of any phenomenon is sufficiently smaller than the radius of the radars. We also show that there is a trade-off between the average quality with which a phenomenon is scanned and the number of decision epochs before which a phenomenon is rescanned.',\n",
       "  'id': '3199',\n",
       "  'title': 'Scan Strategies for Meteorological Radars',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Support Vector Machines (SVMs) suffer from a widely recognized scalability problem in both memory use and computational time. To improve scalability, we have developed a parallel SVM algorithm (PSVM), which reduces memory use through performing a row-based, approximate matrix factorization, and which loads only essential data to each machine to perform parallel computation. Let $n$ denote the number of training instances, $p$ the reduced matrix dimension after factorization ($p$ is significantly smaller than $n$), and $m$ the number of machines. PSVM reduces the memory requirement from $\\\\MO$($n^2$) to $\\\\MO$($np/m$), and improves computation time to $\\\\MO$($np^2/m$). Empirical studies on up to $500$ computers shows PSVM to be effective.',\n",
       "  'id': '3202',\n",
       "  'title': 'Parallelizing Support Vector Machines on Distributed Computers',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Fair discriminative pedestrian finders are now available. In fact, these pedestrian finders make most errors on pedestrians in configurations that are uncommon in the training data, for example, mounting a bicycle. This is undesirable. However, the human configuration can itself be estimated discriminatively using structure learning. We demonstrate a pedestrian finder which first finds the most likely human pose in the window using a discriminative procedure trained with structure learning on a small dataset. We then present features (local histogram of oriented gradient and local PCA of gradient) based on that configuration to an SVM classifier. We show, using the INRIA Person dataset, that estimates of configuration significantly improve the accuracy of a discriminative pedestrian finder.',\n",
       "  'id': '3210',\n",
       "  'title': 'Configuration Estimates Improve Pedestrian Finding',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"Sound localization by barn owls is commonly modeled as a matching procedure where localization cues derived from auditory inputs are compared to stored templates. While the matching models can explain properties of neural responses, no model explains how the owl resolves spatial ambiguity in the localization cues to produce accurate localization near the center of gaze. Here, we examine two models for the barn owl's sound localization behavior. First, we consider a maximum likelihood estimator in order to further evaluate the cue matching model. Second, we consider a maximum a posteriori estimator to test if a Bayesian model with a prior that emphasizes directions near the center of gaze can reproduce the owl's localization behavior. We show that the maximum likelihood estimator can not reproduce the owl's behavior, while the maximum a posteriori estimator is able to match the behavior. This result suggests that the standard cue matching model will not be sufficient to explain sound localization behavior in the barn owl. The Bayesian model provides a new framework for analyzing sound localization in the barn owl and leads to predictions about the owl's localization behavior.\",\n",
       "  'id': '3244',\n",
       "  'title': 'Optimal models of sound localization by barn owls',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"We study the relation between notions of game-theoretic equilibria which are based on stability under a set of deviations, and empirical equilibria which are reached by rational players. Rational players are modelled by players using no regret algorithms, which guarantee that their payoff in the long run is almost as much as the most they could hope to achieve by consistently deviating from the algorithm's suggested action. We show that for a given set of deviations over the strategy set of a player, it is possible to efficiently approximate fixed points of a given deviation if and only if there exist efficient no regret algorithms resistant to the deviations. Further, we show that if all players use a no regret algorithm, then the empirical distribution of their plays converges to an equilibrium.\",\n",
       "  'id': '3249',\n",
       "  'title': 'Computational Equivalence of Fixed Points and No Regret Algorithms, and Convergence to Equilibria',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'In a multiple instance (MI) learning problem, instances are naturally organized into bags and it is the bags, instead of individual instances, that are labeled for training. MI learners assume that every instance in a bag labeled negative is actually negative, whereas at least one instance in a bag labeled positive is actually positive. We present a framework for active learning in the multiple-instance setting. In particular, we consider the case in which an MI learner is allowed to selectively query unlabeled instances in positive bags. This approach is well motivated in domains in which it is inexpensive to acquire bag labels and possible, but expensive, to acquire instance labels. We describe a method for learning from labels at mixed levels of granularity, and introduce two active query selection strategies motivated by the MI setting. Our experiments show that learning from instance labels can significantly improve performance of a basic MI learning algorithm in two multiple-instance domains: content-based image recognition and text classification.',\n",
       "  'id': '3252',\n",
       "  'title': 'Multiple-Instance Active Learning',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Many tasks in speech processing involve classification of long term characteristics of a speech segment such as language, speaker, dialect, or topic. A natural technique for determining these characteristics is to first convert the input speech into a sequence of tokens such as words, phones, etc. From these tokens, we can then look for distinctive phrases, keywords, that characterize the speech. In many applications, a set of distinctive keywords may not be known a priori. In this case, an automatic method of building up keywords from short context units such as phones is desirable. We propose a method for construction of keywords based upon Support Vector Machines. We cast the problem of keyword selection as a feature selection problem for n-grams of phones. We propose an alternating filter-wrapper method that builds successively longer keywords. Application of this method on a language recognition task shows that the technique produces interesting and significant qualitative and quantitative results.',\n",
       "  'id': '3272',\n",
       "  'title': 'Discriminative Keyword Selection Using Support Vector Machines',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We consider the learning task consisting in predicting as well as the best function in a finite reference set G up to the smallest possible additive term. If R(g) denotes the generalization error of a prediction function g, under reasonable assumptions on the loss function (typically satisfied by the least square loss when the output is bounded), it is known that the progressive mixture rule g_n satisfies E R(g_n) < min_{g in G} R(g) + Cst (log|G|)/n where n denotes the size of the training set, E denotes the expectation wrt the training set distribution. This work shows that, surprisingly, for appropriate reference sets G, the deviation convergence rate of the progressive mixture rule is only no better than Cst / sqrt{n}, and not the expected Cst / n. It also provides an algorithm which does not suffer from this drawback.',\n",
       "  'id': '3303',\n",
       "  'title': 'Progressive mixture rules are deviation suboptimal',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"Motivated in part by the hierarchical organization of cortex, a number of algorithms have recently been proposed that try to learn hierarchical, or ``deep,'' structure from unlabeled data. While several authors have formally or informally compared their algorithms to computations performed in visual area V1 (and the cochlea), little attempt has been made thus far to evaluate these algorithms in terms of their fidelity for mimicking computations at deeper levels in the cortical hierarchy. This paper presents an unsupervised learning model that faithfully mimics certain properties of visual area V2. Specifically, we develop a sparse variant of the deep belief networks of Hinton et al. (2006). We learn two layers of nodes in the network, and demonstrate that the first layer, similar to prior work on sparse coding and ICA, results in localized, oriented, edge filters, similar to the Gabor functions known to model V1 cell receptive fields. Further, the second layer in our model encodes correlations of the first layer responses in the data. Specifically, it picks up both collinear (``contour'') features as well as corners and junctions. More interestingly, in a quantitative comparison, the encoding of these more complex ``corner'' features matches well with the results from the Ito & Komatsu's study of biological V2 responses. This suggests that our sparse variant of deep belief networks holds promise for modeling more higher-order features.\",\n",
       "  'id': '3313',\n",
       "  'title': 'Sparse deep belief net model for visual area V2',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We summarize the implementation of an analog VLSI chip hosting a network of 32 integrate-and-fire (IF) neurons with spike-frequency adaptation and 2,048 Hebbian plastic bistable spike-driven stochastic synapses endowed with a self-regulating mechanism which stops unnecessary synaptic changes. The synaptic matrix can be flexibly configured and provides both recurrent and AER-based connectivity with external, AER compliant devices. We demonstrate the ability of the network to efficiently classify overlapping patterns, thanks to the self-regulating mechanism.',\n",
       "  'id': '3316',\n",
       "  'title': 'A configurable analog VLSI neural network with spiking neurons and self-regulating plastic synapses',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We introduce supervised latent Dirichlet allocation (sLDA), a statistical model of labelled documents. The model accommodates a variety of response types. We derive a maximum-likelihood procedure for parameter estimation, which relies on variational approximations to handle intractable posterior expectations. Prediction problems motivate this research: we use the fitted model to predict response values for new documents. We test sLDA on two real-world problems: movie ratings predicted from reviews, and web page popularity predicted from text descriptions. We illustrate the benefits of sLDA versus modern regularized regression, as well as versus an unsupervised LDA analysis followed by a separate regression.',\n",
       "  'id': '3328',\n",
       "  'title': 'Supervised Topic Models',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"Binocular fusion takes place over a limited region smaller than one degree of visual angle (Panum's fusional area), which is on the order of the range of preferred disparities measured in populations of disparity-tuned neurons in the visual cortex. However, the actual range of binocular disparities encountered in natural scenes ranges over tens of degrees. This discrepancy suggests that there must be a mechanism for detecting whether the stimulus disparity is either inside or outside of the range of the preferred disparities in the population. Here, we present a statistical framework to derive feature in a population of V1 disparity neuron to determine the stimulus disparity within the preferred disparity range of the neural population. When optimized for natural images, it yields a feature that can be explained by the normalization which is a common model in V1 neurons. We further makes use of the feature to estimate the disparity in natural images. Our proposed model generates more correct estimates than coarse-to-fine multiple scales approaches and it can also identify regions with occlusion. The approach suggests another critical role for normalization in robust disparity estimation.\",\n",
       "  'id': '3334',\n",
       "  'title': 'Estimating disparity with confidence from energy neurons',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We propose a Gaussian process (GP) framework for robust inference in which a GP prior on the mixing weights of a two-component noise model augments the standard process over latent function values. This approach is a generalization of the mixture likelihood used in traditional robust GP regression, and a specialization of the GP mixture models suggested by Tresp (2000) and Rasmussen and Ghahramani (2002). The value of this restriction is in its tractable expectation propagation updates, which allow for faster inference and model selection, and better convergence than the standard mixture. An additional benefit over the latter method lies in our ability to incorporate knowledge of the noise domain to influence predictions, and to recover with the predictive distribution information about the outlier distribution via the gating process. The model has asymptotic complexity equal to that of conventional robust methods, but yields more confident predictions on benchmark problems than classical heavy-tailed models and exhibits improved stability for data with clustered corruptions, for which they fail altogether. We show further how our approach can be used without adjustment for more smoothly heteroscedastic data, and suggest how it could be extended to more general noise models. We also address similarities with the work of Goldberg et al. (1998), and the more recent contributions of Tresp, and Rasmussen and Ghahramani.',\n",
       "  'id': '3346',\n",
       "  'title': 'Robust Regression with Twinned Gaussian Processes',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Variational methods are frequently used to approximate or bound the partition or likelihood function of a Markov random field. Methods based on mean field theory are guaranteed to provide lower bounds, whereas certain types of convex relaxations provide upper bounds. In general, loopy belief propagation (BP) provides (often accurate) approximations, but not bounds. We prove that for a class of attractive binary models, the value specified by any fixed point of loopy BP always provides a lower bound on the true likelihood. Empirically, this bound is much better than the naive mean field bound, and requires no further work than running BP. We establish these lower bounds using a loop series expansion due to Chertkov and Chernyak, which we show can be derived as a consequence of the tree reparameterization characterization of BP fixed points.',\n",
       "  'id': '3354',\n",
       "  'title': 'Loop Series and Bethe Variational Bounds in Attractive Graphical Models',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'We consider the problem of Support Vector Machine transduction, which involves a combinatorial problem with exponential computational complexity in the number of unlabeled examples. Although several studies are devoted to Transductive SVM, they suffer either from the high computation complexity or from the solutions of local optimum. To address this problem, we propose solving Transductive SVM via a convex relaxation, which converts the NP-hard problem to a semi-definite programming. Compared with the other SDP relaxation for Transductive SVM, the proposed algorithm is computationally more efficient with the number of free parameters reduced from O(n2) to O(n) where n is the number of examples. Empirical study with several benchmark data sets shows the promising performance of the proposed algorithm in comparison with other state-of-the-art implementations of Transductive SVM.',\n",
       "  'id': '3356',\n",
       "  'title': 'Efficient Convex Relaxation for Transductive Support Vector Machine',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Unsupervised learning algorithms aim to discover the structure hidden in the data, and to learn representations that are more suitable as input to a supervised machine than the raw input. Many unsupervised methods are based on reconstructing the input from the representation, while constraining the representation to have certain desirable properties (e.g. low dimension, sparsity, etc). Others are based on approximating density by stochastically reconstructing the input from the representation. We describe a novel and efficient algorithm to learn sparse representations, and compare it theoretically and experimentally with a similar machines trained probabilistically, namely a Restricted Boltzmann Machine. We propose a simple criterion to compare and select different unsupervised machines based on the trade-off between the reconstruction error and the information content of the representation. We demonstrate this method by extracting features from a dataset of handwritten numerals, and from a dataset of natural image patches. We show that by stacking multiple levels of such machines and by training sequentially, high-order dependencies between the input variables can be captured.',\n",
       "  'id': '3363',\n",
       "  'title': 'Sparse Feature Learning for Deep Belief Networks',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Assessing similarity between features is a key step in object recognition and scene categorization tasks. We argue that knowledge on the distribution of distances generated by similarity functions is crucial in deciding whether features are similar or not. Intuitively one would expect that similarities between features could arise from any distribution. In this paper, we will derive the contrary, and report the theoretical result that $L_p$-norms --a class of commonly applied distance metrics-- from one feature vector to other vectors are Weibull-distributed if the feature values are correlated and non-identically distributed. Besides these assumptions being realistic for images, we experimentally show them to hold for various popular feature extraction algorithms, for a diverse range of images. This fundamental insight opens new directions in the assessment of feature similarity, with projected improvements in object and scene recognition algorithms.\\n\\nErratum: The authors of paper have declared that they have become convinced that the reasoning in the reference is too simple as a proof of their claims. As a consequence, they withdraw their theorems.',\n",
       "  'id': '3367',\n",
       "  'title': 'The Distribution Family of Similarity Distances',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'When we have several related tasks, solving them simultaneously is shown to be more effective than solving them individually. This approach is called multi-task learning (MTL) and has been studied extensively. Existing approaches to MTL often treat all the tasks as \\\\emph{uniformly related to each other and the relatedness of the tasks is controlled globally. For this reason, the existing methods can lead to undesired solutions when some tasks are not highly related to each other, and some pairs of related tasks can have significantly different solutions. In this paper, we propose a novel MTL algorithm that can overcome these problems. Our method makes use of a task network, which describes the relation structure among tasks. This allows us to deal with intricate relation structures in a systematic way. Furthermore, we control the relatedness of the tasks locally, so all pairs of related tasks are guaranteed to have similar solutions. We apply the above idea to support vector machines (SVMs) and show that the optimization problem can be cast as a second order cone program, which is convex and can be solved efficiently. The usefulness of our approach is demonstrated through simulations with protein super-family classification and ordinal regression problems.',\n",
       "  'id': '3368',\n",
       "  'title': 'Multi-Task Learning via Conic Programming',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"We propose an extended probabilistic model for human perception. We argue that in many circumstances, human observers simultaneously evaluate sensory evidence under different hypotheses regarding the underlying physical process that might have generated the sensory information. Within this context, inference can be optimal if the observer weighs each hypothesis according to the correct belief in that hypothesis. But if the observer commits to a particular hypothesis, the belief in that hypothesis is converted into subjective certainty, and subsequent perceptual behavior is suboptimal, conditioned only on the chosen hypothesis. We demonstrate that this framework can explain psychophysical data of a recently reported decision-estimation experiment. The model well accounts for the data, predicting the same estimation bias as a consequence of the preceding decision step. The power of the framework is that it has no free parameters except the degree of the observer's uncertainty about its internal sensory representation. All other parameters are defined by the particular experiment which allows us to make quantitative predictions of human perception to two modifications of the original experiment.\",\n",
       "  'id': '3369',\n",
       "  'title': 'A Bayesian Model of Conditioned Perception',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'Social tags are user-generated keywords associated with some resource on the Web. In the case of music, social tags have become an important component of Web2.0\" recommender systems, allowing users to generate playlists based on use-dependent terms such as \"chill\" or \"jogging\" that have been applied to particular songs. In this paper, we propose a method for predicting these social tags directly from MP3 files. Using a set of boosted classifiers, we map audio features onto social tags collected from the Web. The resulting automatic tags (or \"autotags\") furnish information about music that is otherwise untagged or poorly tagged, allowing for insertion of previously unheard music into a social recommender. This avoids the \\'\\'cold-start problem\\'\\' common in such systems. Autotags can also be used to smooth the tag space from which similarities and recommendations are made by providing a set of comparable baseline tags for all tracks in a recommender system.\"',\n",
       "  'id': '3370',\n",
       "  'title': 'Automatic Generation of Social Tags for Music Recommendation',\n",
       "  'year': '2007'},\n",
       " {'abstract': \"In this paper, we show that classical survival analysis involving censored data can naturally be cast as a ranking problem. The concordance index (CI), which quantifies the quality of rankings, is the standard performance measure for model \\\\emph{assessment} in survival analysis. In contrast, the standard approach to \\\\emph{learning} the popular proportional hazard (PH) model is based on Cox's partial likelihood. In this paper we devise two bounds on CI--one of which emerges directly from the properties of PH models--and optimize them \\\\emph{directly}. Our experimental results suggest that both methods perform about equally well, with our new approach giving slightly better results than the Cox's method. We also explain why a method designed to maximize the Cox's partial likelihood also ends up (approximately) maximizing the CI.\",\n",
       "  'id': '3375',\n",
       "  'title': 'On Ranking in Survival Analysis: Bounds on the Concordance Index',\n",
       "  'year': '2007'},\n",
       " {'abstract': 'The inverse dynamics problem for a robotic manipulator is to compute the torques needed at the joints to drive it along a given trajectory; it is beneficial to be able to learn this function for adaptive control. A given robot manipulator will often need to be controlled while holding different loads in its end effector, giving rise to a multi-task learning problem. We show how the structure of the inverse dynamics problem gives rise to a multi-task Gaussian process prior over functions, where the inter-task similarity depends on the underlying dynamic parameters. Experiments demonstrate that this multi-task formulation generally improves performance over either learning only on single tasks or pooling the data over all tasks.',\n",
       "  'id': '3385',\n",
       "  'title': 'Multi-task Gaussian Process Learning of Robot Inverse Dynamics',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We develop \\\\name\\\\ (STM), a nonparametric Bayesian model of parsed documents. \\\\Shortname\\\\ generates words that are both thematically and syntactically constrained, which combines the semantic insights of topic models with the syntactic information available from parse trees. Each word of a sentence is generated by a distribution that combines document-specific topic weights and parse-tree specific syntactic transitions. Words are assumed generated in an order that respects the parse tree. We derive an approximate posterior inference method based on variational methods for hierarchical Dirichlet processes, and we report qualitative and quantitative results on both synthetic data and hand-parsed documents.',\n",
       "  'id': '3398',\n",
       "  'title': 'Syntactic Topic Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We study the problem of domain transfer for a supervised classification task in mRNA splicing. We consider a number of recent domain transfer methods from machine learning, including some that are novel, and evaluate them on genomic sequence data from model organisms of varying evolutionary distance. We find that in cases where the organisms are not closely related, the use of domain adaptation methods can help improve classification performance.',\n",
       "  'id': '3407',\n",
       "  'title': 'An Empirical Analysis of Domain Adaptation Algorithms for Genomic Sequence Analysis',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Multi-level hierarchical models provide an attractive framework for incorporating correlations induced in a response variable organized in a hierarchy. Model fitting is challenging, especially for hierarchies with large number of nodes. We provide a novel algorithm based on a multi-scale Kalman filter that is both scalable and easy to implement. For non-Gaussian responses, quadratic approximation to the log-likelihood results in biased estimates. We suggest a bootstrap strategy to correct such biases. Our method is illustrated through simulation studies and analyses of real world data sets in health care and online advertising.',\n",
       "  'id': '3416',\n",
       "  'title': 'Fast Computation of Posterior Mode in Multi-Level Hierarchical Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We provide statistical performance guarantees for a recently introduced kernel classifier that optimizes the $L_2$ or integrated squared error (ISE) of a difference of densities. The classifier is similar to a support vector machine (SVM) in that it is the solution of a quadratic program and yields a sparse classifier. Unlike SVMs, however, the $L_2$ kernel classifier does not involve a regularization parameter. We prove a distribution free concentration inequality for a cross-validation based estimate of the ISE, and apply this result to deduce an oracle inequality and consistency of the classifier on the sense of both ISE and probability of error. Our results can also be specialized to give performance guarantees for an existing method of $L_2$ kernel density estimation.',\n",
       "  'id': '3425',\n",
       "  'title': 'Performance analysis for L\\\\_2 kernel classification',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduce a new interpretation of multiscale random fields (MSRFs) that admits efficient optimization in the framework of regular (single level) random fields (RFs). It is based on a new operator, called append, that combines sets of random variables (RVs) to single RVs. We assume that a MSRF can be decomposed into disjoint trees that link RVs at different pyramid levels. The append operator is then applied to map RVs in each tree structure to a single RV. We demonstrate the usefulness of the proposed approach on a challenging task involving grouping contours of target shapes in images. MSRFs provide a natural representation of multiscale contour models, which are needed in order to cope with unstable contour decompositions. The append operator allows us to find optimal image labels using the classical framework of relaxation labeling, Alternative methods like Markov Chain Monte Carlo (MCMC) could also be used.',\n",
       "  'id': '3430',\n",
       "  'title': 'Multiscale Random Fields with Application to Contour Grouping',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'It has been shown that the problem of $\\\\ell_1$-penalized least-square regression commonly referred to as the Lasso or Basis Pursuit DeNoising leads to solutions that are sparse and therefore achieves model selection. We propose in this paper an algorithm to solve the Lasso with online observations. We introduce an optimization problem that allows us to compute an homotopy from the current solution to the solution after observing a new data point. We compare our method to Lars and present an application to compressed sensing with sequential observations. Our approach can also be easily extended to compute an homotopy from the current solution to the solution after removing a data point, which leads to an efficient algorithm for leave-one-out cross-validation.',\n",
       "  'id': '3431',\n",
       "  'title': 'An Homotopy Algorithm for the Lasso with Online Observations',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'One of the original goals of computer vision was to fully understand a natural scene. This requires solving several problems simultaneously, including object detection, labeling of meaningful regions, and 3d reconstruction. While great progress has been made in tackling each of these problems in isolation, only recently have researchers again been considering the difficult task of assembling various methods to the mutual benefit of all. We consider learning a set of such classification models in such a way that they both solve their own problem and help each other. We develop a framework known as Cascaded Classification Models (CCM), where repeated instantiations of these classifiers are coupled by their input/output variables in a cascade that improves performance at each level. Our method requires only a limited ???black box??? interface with the models, allowing us to use very sophisticated, state-of-the-art classifiers without having to look under the hood. We demonstrate the effectiveness of our method on a large set of natural images by combining the subtasks of scene categorization, object detection, multiclass image segmentation, and 3d scene reconstruction.',\n",
       "  'id': '3472',\n",
       "  'title': 'Cascaded Classification Models: Combining Models for Holistic Scene Understanding',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose a multiplicative approximation scheme (MAS) for inference problems in graphical models, which can be applied to various inference algorithms. The method uses $\\\\epsilon$-decompositions which decompose functions used throughout the inference procedure into functions over smaller sets of variables with a known error $\\\\epsilon$. MAS translates these local approximations into bounds on the accuracy of the results. We show how to optimize $\\\\epsilon$-decompositions and provide a fast closed-form solution for an $L_2$ approximation. Applying MAS to the Variable Elimination inference algorithm, we introduce an algorithm we call DynaDecomp which is extremely fast in practice and provides guaranteed error bounds on the result. The superior accuracy and efficiency of DynaDecomp is demonstrated.',\n",
       "  'id': '3479',\n",
       "  'title': 'MAS: a multiplicative approximation scheme for probabilistic inference',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Recently, fitted Q-iteration (FQI) based methods have become more popular due to their increased sample efficiency, a more stable learning process and the higher quality of the resulting policy. However, these methods remain hard to use for continuous action spaces which frequently occur in real-world tasks, e.g., in robotics and other technical applications. The greedy action selection commonly used for the policy improvement step is particularly problematic as it is expensive for continuous actions, can cause an unstable learning process, introduces an optimization bias and results in highly non-smooth policies unsuitable for real-world systems. In this paper, we show that by using a soft-greedy action selection the policy improvement step used in FQI can be simplified to an inexpensive advantage-weighted regression. With this result, we are able to derive a new, computationally efficient FQI algorithm which can even deal with high dimensional action spaces.',\n",
       "  'id': '3501',\n",
       "  'title': 'Fitted Q-iteration by Advantage Weighted Regression',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Ranking is at the heart of many information retrieval applications. Unlike standard regression or classification, in which we predict outputs independently, in ranking, we are interested in predicting structured outputs so that misranking one object can significantly affect whether we correctly rank the other objects. In practice, the problem of ranking involves a large number of objects to be ranked and either approximate structured prediction methods are required, or assumptions of independence between object scores must be made in order to make the problem tractable. We present a probabilistic method for learning to rank using the graphical modelling framework of cumulative distribution networks (CDNs), where we can take into account the structure inherent to the problem of ranking by modelling the joint cumulative distribution functions (CDFs) over multiple pairwise preferences. We apply our framework to the problem of document retrieval in the case of the OHSUMED benchmark dataset. We will show that the RankNet, ListNet and ListMLE probabilistic models can be viewed as particular instances of CDNs and that our proposed framework allows for the exploration of a broad class of flexible structured loss functionals for ranking learning.',\n",
       "  'id': '3502',\n",
       "  'title': 'Structured ranking learning using cumulative distribution networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Working memory is a central topic of cognitive neuroscience because it is critical for solving real world problems in which information from multiple temporally distant sources must be combined to generate appropriate behavior. However, an often neglected fact is that learning to use working memory effectively is itself a difficult problem. The Gating\" framework is a collection of psychological models that show how dopamine can train the basal ganglia and prefrontal cortex to form useful working memory representations in certain types of problems. We bring together gating with ideas from machine learning about using finite memory systems in more general problems. Thus we present a normative Gating model that learns, by online temporal difference methods, to use working memory to maximize discounted future rewards in general partially observable settings. The model successfully solves a benchmark working memory problem, and exhibits limitations similar to those observed in human experiments. Moreover, the model introduces a concise, normative definition of high level cognitive concepts such as working memory and cognitive control in terms of maximizing discounted future rewards.\"',\n",
       "  'id': '3508',\n",
       "  'title': 'Learning to Use Working Memory in Partially Observable Environments through Dopaminergic Reinforcement',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We provide sharp bounds for Rademacher and Gaussian complexities of (constrained) linear classes. These bounds make short work of providing a number of corollaries including: risk bounds for linear prediction (including settings where the weight vectors are constrained by either $L_2$ or $L_1$ constraints), margin bounds (including both $L_2$ and $L_1$ margins, along with more general notions based on relative entropy), a proof of the PAC-Bayes theorem, and $L_2$ covering numbers (with $L_p$ norm constraints and relative entropy constraints). In addition to providing a unified analysis, the results herein provide some of the sharpest risk and margin bounds (improving upon a number of previous results). Interestingly, our results show that the uniform convergence rates of empirical risk minimization algorithms tightly match the regret bounds of online learning algorithms for linear prediction (up to a constant factor of 2).',\n",
       "  'id': '3510',\n",
       "  'title': 'On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"One major role of primary visual cortex (V1) in vision is the encoding of the orientation of lines and contours. The role of the local recurrent network in these computations is, however, still a matter of debate. To address this issue, we analyze intracellular recording data of cat V1, which combine measuring the tuning of a range of neuronal properties with a precise localization of the recording sites in the orientation preference map. For the analysis, we consider a network model of Hodgkin-Huxley type neurons arranged according to a biologically plausible two-dimensional topographic orientation preference map. We then systematically vary the strength of the recurrent excitation and inhibition relative to the strength of the afferent input. Each parametrization gives rise to a different model instance for which the tuning of model neurons at different locations of the orientation map is compared to the experimentally measured orientation tuning of membrane potential, spike output, excitatory, and inhibitory conductances. A quantitative analysis shows that the data provides strong evidence for a network model in which the afferent input is dominated by strong, balanced contributions of recurrent excitation and inhibition. This recurrent regime is close to a regime of 'instability', where strong, self-sustained activity of the network occurs. The firing rate of neurons in the best-fitting network is particularly sensitive to small modulations of model parameters, which could be one of the functional benefits of a network operating in this particular regime.\",\n",
       "  'id': '3513',\n",
       "  'title': 'Dependence of Orientation Tuning on Recurrent Excitation and Inhibition in a Network Model of V1',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present cutoff averaging\", a technique for converting any conservative online learning algorithm into a batch learning algorithm. Most online-to-batch conversion techniques work well with certain types of online learning algorithms and not with others, whereas cutoff averaging explicitly tries to adapt to the characteristics of the online algorithm being converted. An attractive property of our technique is that it preserves the efficiency of the original online algorithm, making it approporiate for large-scale learning problems. We provide a statistical analysis of our technique and back our theoretical claims with experimental results.\"',\n",
       "  'id': '3514',\n",
       "  'title': 'From Online to Batch Learning with Cutoff-Averaging',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"We address the problem of learning classifiers for several related tasks that may differ in their joint distribution of input and output variables. For each task, small - possibly even empty - labeled samples and large unlabeled samples are available. While the unlabeled samples reflect the target distribution, the labeled samples may be biased. We derive a solution that produces resampling weights which match the pool of all examples to the target distribution of any given task. Our work is motivated by the problem of predicting sociodemographic features for users of web portals, based on the content which they have accessed. Here, questionnaires offered to a small portion of each portal's users produce biased samples. Transfer learning enables us to make predictions even for new portals with few or no training data and improves the overall prediction accuracy.\",\n",
       "  'id': '3515',\n",
       "  'title': 'Transfer Learning by Distribution Matching for Targeted Advertising',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduces a new probability distribution over a potentially infinite number of binary Markov chains which we call the Markov Indian buffet process. This process extends the IBP to allow temporal dependencies in the hidden variables. We use this stochastic process to build a nonparametric extension of the factorial hidden Markov model. After working out an inference scheme which combines slice sampling and dynamic programming we demonstrate how the infinite factorial hidden Markov model can be used for blind source separation.',\n",
       "  'id': '3518',\n",
       "  'title': 'The Infinite Factorial Hidden Markov Model',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We describe a new content publishing system that selects articles to serve to a user, choosing from an editorially programmed pool that is frequently refreshed. It is now deployed on a major Internet portal, and selects articles to serve to hundreds of millions of user visits per day, significantly increasing the number of user clicks over the original manual approach, in which editors periodically selected articles to display. Some of the challenges we face include a dynamic content pool, short article lifetimes, non-stationary click-through rates, and extremely high traffic volumes. The fundamental problem we must solve is to quickly identify which items are popular(perhaps within different user segments), and to exploit them while they remain current. We must also explore the underlying pool constantly to identify promising alternatives, quickly discarding poor performers. Our approach is based on tracking per article performance in near real time through online models. We describe the characteristics and constraints of our application setting, discuss our design choices, and show the importance and effectiveness of coupling online models with a simple randomization procedure. We discuss the challenges encountered in a production online content-publishing environment and highlight issues that deserve careful attention. Our analysis of this application also suggests a number of future research avenues.',\n",
       "  'id': '3560',\n",
       "  'title': 'Online Models for Content Optimization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'A principled mechanism for identifying conditional dependencies in time-series data is provided through structure learning of dynamic Bayesian networks (DBNs). An important assumption of DBN structure learning is that the data are generated by a stationary process???an assumption that is not true in many important settings. In this paper, we introduce a new class of graphical models called non-stationary dynamic Bayesian networks, in which the conditional dependence structure of the underlying data-generation process is permitted to change over time. Non-stationary dynamic Bayesian networks represent a new framework for studying problems in which the structure of a network is evolving over time. We define the non-stationary DBN model, present an MCMC sampling algorithm for learning the structure of the model from time-series data under different assumptions, and demonstrate the effectiveness of the algorithm on both simulated and biological data.',\n",
       "  'id': '3571',\n",
       "  'title': 'Non-stationary dynamic Bayesian networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a multi-label multiple kernel learning (MKL) formulation, in which the data are embedded into a low-dimensional space directed by the instance-label correlations encoded into a hypergraph. We formulate the problem in the kernel-induced feature space and propose to learn the kernel matrix as a linear combination of a given collection of kernel matrices in the MKL framework. The proposed learning formulation leads to a non-smooth min-max problem, and it can be cast into a semi-infinite linear program (SILP). We further propose an approximate formulation with a guaranteed error bound which involves an unconstrained and convex optimization problem. In addition, we show that the objective function of the approximate formulation is continuously differentiable with Lipschitz gradient, and hence existing methods can be employed to compute the optimal solution efficiently. We apply the proposed formulation to the automated annotation of Drosophila gene expression pattern images, and promising results have been reported in comparison with representative algorithms.',\n",
       "  'id': '3574',\n",
       "  'title': 'Multi-label Multiple Kernel Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks. Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold. In this paper, we describe a class of latent variable models of such data called Mixed Membership Stochastic Blockmodels. This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation. We develop a general variational inference algorithm for fast approximate posterior inference. We explore applications to social networks and protein interaction networks.',\n",
       "  'id': '3578',\n",
       "  'title': 'Mixed Membership Stochastic Blockmodels',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Neural probabilistic language models (NPLMs) have been shown to be competitive with and occasionally superior to the widely-used n-gram language models. The main drawback of NPLMs is their extremely long training and testing times. Morin and Bengio have proposed a hierarchical language model built around a binary tree of words that was two orders of magnitude faster than the non-hierarchical language model it was based on. However, it performed considerably worse than its non-hierarchical counterpart in spite of using a word tree created using expert knowledge. We introduce a fast hierarchical language model along with a simple feature-based algorithm for automatic construction of word trees from the data. We then show that the resulting models can outperform non-hierarchical models and achieve state-of-the-art performance.',\n",
       "  'id': '3583',\n",
       "  'title': 'A Scalable Hierarchical Distributed Language Model',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Probabilistic topic models (and their extensions) have become popular as models of latent structures in collections of text documents or images. These models are usually treated as generative models and trained using maximum likelihood estimation, an approach which may be suboptimal in the context of an overall classification problem. In this paper, we describe DiscLDA, a discriminative learning framework for such models as Latent Dirichlet Allocation (LDA) in the setting of dimensionality reduction with supervised side information. In DiscLDA, a class-dependent linear transformation is introduced on the topic mixture proportions. This parameter is estimated by maximizing the conditional likelihood using Monte Carlo EM. By using the transformed topic mixture proportions as a new representation of documents, we obtain a supervised dimensionality reduction algorithm that uncovers the latent structure in a document collection while preserving predictive power for the task of classification. We compare the predictive power of the latent structure of DiscLDA with unsupervised LDA on the 20 Newsgroup ocument classification task.',\n",
       "  'id': '3599',\n",
       "  'title': 'DiscLDA: Discriminative Learning for Dimensionality Reduction and Classification',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We study the profit-maximization problem of a monopolistic market-maker who sets two-sided prices in an asset market. The sequential decision problem is hard to solve because the state space is a function. We demonstrate that the belief state is well approximated by a Gaussian distribution. We prove a key monotonicity property of the Gaussian state update which makes the problem tractable, yielding the first optimal sequential market-making algorithm in an established model. The algorithm leads to a surprising insight: an optimal monopolist can provide more liquidity than perfectly competitive market-makers in periods of extreme uncertainty, because a monopolist is willing to absorb initial losses in order to learn a new valuation rapidly so she can extract higher profits later.',\n",
       "  'id': '3600',\n",
       "  'title': 'Adapting to a Market Shock: Optimal Sequential Market-Making',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In solving complex visual learning tasks, adopting multiple descriptors to more precisely characterize the data has been a feasible way for improving performance. These representations are typically high dimensional and assume diverse forms. Thus finding a way to transform them into a unified space of lower dimension generally facilitates the underlying tasks, such as object recognition or clustering. We describe an approach that incorporates multiple kernel learning with dimensionality reduction (MKL-DR). While the proposed framework is flexible in simultaneously tackling data in various feature representations, the formulation itself is general in that it is established upon graph embedding. It follows that any dimensionality reduction techniques explainable by graph embedding can be generalized by our method to consider data in multiple feature representations.',\n",
       "  'id': '3602',\n",
       "  'title': 'Dimensionality Reduction for Data in Multiple Feature Representations',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper we propose a new incremental spike sorting model that automatically eliminates refractory period violations, accounts for action potential waveform drift, and can handle appearance\" and \"disappearance\" of neurons. Our approach is to augment a known time-varying Dirichlet process that ties together a sequence of infinite Gaussian mixture models, one per action potential waveform observation, with an interspike-interval-dependent likelihood that prohibits refractory period violations. We demonstrate this model by showing results from sorting two publicly available neural data recordings for which the a partial ground truth labeling is known.\"',\n",
       "  'id': '3606',\n",
       "  'title': 'Dependent Dirichlet Process Spike Sorting',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"In recent work Long and Servedio LS05short presented a ``martingale boosting'' algorithm that works by constructing a branching program over weak classifiers and has a simple analysis based on elementary properties of random walks. LS05short showed that this martingale booster can tolerate random classification noise when it is run with a noise-tolerant weak learner; however, a drawback of the algorithm is that it is not adaptive, i.e. it cannot effectively take advantage of variation in the quality of the weak classifiers it receives. In this paper we present a variant of the original martingale boosting algorithm and prove that it is adaptive. This adaptiveness is achieved by modifying the original algorithm so that the random walks that arise in its analysis have different step size depending on the quality of the weak learner at each stage. The new algorithm inherits the desirable properties of the original LS05short algorithm, such as random classification noise tolerance, and has several other advantages besides adaptiveness: it requires polynomially fewer calls to the weak learner than the original algorithm, and it can be used with confidence-rated weak hypotheses that output real values rather than Boolean predictions.\",\n",
       "  'id': '3623',\n",
       "  'title': 'Adaptive Martingale Boosting',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Gates are a new notation for representing mixture models and context-sensitive independence in factor graphs. Factor graphs provide a natural representation for message-passing algorithms, such as expectation propagation. However, message passing in mixture models is not well captured by factor graphs unless the entire mixture is represented by one factor, because the message equations have a containment structure. Gates capture this containment structure graphically, allowing both the independences and the message-passing equations for a model to be readily visualized. Different variational approximations for mixture models can be understood as different ways of drawing the gates in a model. We present general equations for expectation propagation and variational message passing in the presence of gates.',\n",
       "  'id': '3379',\n",
       "  'title': 'Gates',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Uncertainty is omnipresent when we perceive or interact with our environment, and the Bayesian framework provides computational methods for dealing with it. Mathematical models for Bayesian decision making typically require datastructures that are hard to implement in neural networks. This article shows that even the simplest and experimentally best supported type of synaptic plasticity, Hebbian learning, in combination with a sparse, redundant neural code, can in principle learn to infer optimal Bayesian decisions. We present a concrete Hebbian learning rule operating on log-probability ratios. Modulated by reward-signals, this Hebbian plasticity rule also provides a new perspective for understanding how Bayesian inference could support fast reinforcement learning in the brain. In particular we show that recent experimental results by Yang and Shadlen [1] on reinforcement learning of probabilistic inference in primates can be modeled in this way.',\n",
       "  'id': '3391',\n",
       "  'title': 'Hebbian Learning of Bayes Optimal Decisions',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'How does one extract unknown but stereotypical events that are linearly superimposed within a signal with variable latencies and variable amplitudes? One could think of using template matching or matching pursuit to find the arbitrarily shifted linear components. However, traditional matching approaches require that the templates be known a priori. To overcome this restriction we use instead semi Non-Negative Matrix Factorization (semi-NMF) that we extend to allow for time shifts when matching the templates to the signal. The algorithm estimates templates directly from the data along with their non-negative amplitudes. The resulting method can be thought of as an adaptive template matching procedure. We demonstrate the procedure on the task of extracting spikes from single channel extracellular recordings. On these data the algorithm essentially performs spike detection and unsupervised spike clustering. Results on simulated data and extracellular recordings indicate that the method performs well for signal-to-noise ratios of 6dB or higher and that spike templates are recovered accurately provided they are sufficiently different.',\n",
       "  'id': '3408',\n",
       "  'title': 'Adaptive Template Matching with Shift-Invariant Semi-NMF',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'For supervised and unsupervised learning, positive definite kernels allow to use large and potentially infinite dimensional feature spaces with a computational cost that only depends on the number of observations. This is usually done through the penalization of predictor functions by Euclidean or Hilbertian norms. In this paper, we explore penalizing by sparsity-inducing norms such as the L1-norm or the block L1-norm. We assume that the kernel decomposes into a large sum of individual basis kernels which can be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a hierarchical multiple kernel learning framework, in polynomial time in the number of selected kernels. This framework is naturally applied to non linear variable selection; our extensive simulations on synthetic datasets and datasets from the UCI repository show that efficiently exploring the large feature space through sparsity-inducing norms leads to state-of-the-art predictive performance.',\n",
       "  'id': '3418',\n",
       "  'title': 'Exploring Large Feature Spaces with Hierarchical Multiple Kernel Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many machine learning algorithms require the summation of Gaussian kernel functions, an expensive operation if implemented straightforwardly. Several methods have been proposed to reduce the computational complexity of evaluating such sums, including tree and analysis based methods. These achieve varying speedups depending on the bandwidth, dimension, and prescribed error, making the choice between methods difficult for machine learning tasks. We provide an algorithm that combines tree methods with the Improved Fast Gauss Transform (IFGT). As originally proposed the IFGT suffers from two problems: (1) the Taylor series expansion does not perform well for very low bandwidths, and (2) parameter selection is not trivial and can drastically affect performance and ease of use. We address the first problem by employing a tree data structure, resulting in four evaluation methods whose performance varies based on the distribution of sources and targets and input parameters such as desired accuracy and bandwidth. To solve the second problem, we present an online tuning approach that results in a black box method that automatically chooses the evaluation method and its parameters to yield the best performance for the input data, desired accuracy, and bandwidth. In addition, the new IFGT parameter selection approach allows for tighter error bounds. Our approach chooses the fastest method at negligible additional cost, and has superior performance in comparisons with previous approaches.',\n",
       "  'id': '3420',\n",
       "  'title': 'Automatic online tuning for fast Gaussian summation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We define a metric for measuring behavior similarity between states in a Markov decision process (MDP), in which action similarity is taken into account. We show that the kernel of our metric corresponds exactly to the classes of states defined by MDP homomorphisms (Ravindran \\\\& Barto, 2003). We prove that the difference in the optimal value function of different states can be upper-bounded by the value of this metric, and that the bound is tighter than that provided by bisimulation metrics (Ferns et al. 2004, 2005). Our results hold both for discrete and for continuous actions. We provide an algorithm for constructing approximate homomorphisms, by using this metric to identify states that can be grouped together, as well as actions that can be matched. Previous research on this topic is based mainly on heuristics.',\n",
       "  'id': '3423',\n",
       "  'title': 'Bounding Performance Loss in Approximate MDP Homomorphisms',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose an efficient sequential Monte Carlo inference scheme for the recently proposed coalescent clustering model (Teh et al, 2008). Our algorithm has a quadratic runtime while those in (Teh et al, 2008) is cubic. In experiments, we were surprised to find that in addition to being more efficient, it is also a better sequential Monte Carlo sampler than the best in (Teh et al, 2008), when measured in terms of variance of estimated likelihood and effective sample size.',\n",
       "  'id': '3426',\n",
       "  'title': 'An Efficient Sequential Monte Carlo Algorithm for Coalescent Clustering',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Motor primitives or motion templates have become an important concept for both modeling human motor control as well as generating robot behaviors using imitation learning. Recent impressive results range from humanoid robot movement generation to timing models of human motions. The automatic generation of skill libraries containing multiple motion templates is an important step in robot learning. Such a skill learning system needs to cluster similar movements together and represent each resulting motion template as a generative model which is subsequently used for the execution of the behavior by a robot system. In this paper, we show how human trajectories captured as multidimensional time-series can be clustered using Bayesian mixtures of linear Gaussian state-space models based on the similarity of their dynamics. The appropriate number of templates is automatically determined by enforcing a parsimonious parametrization. As the resulting model is intractable, we introduce a novel approximation method based on variational Bayes, which is especially designed to enable the use of efficient inference algorithms. On recorded human Balero movements, this method is not only capable of finding reasonable motion templates but also yields a generative model which works well in the execution of this complex task on a simulated anthropomorphic SARCOS arm.',\n",
       "  'id': '3429',\n",
       "  'title': 'Using Bayesian Dynamical Systems for Motion Template Libraries',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Subspace-based learning problems involve data whose elements are linear subspaces of a vector space. To handle such data structures, Grassmann kernels have been proposed and used previously. In this paper, we analyze the relationship between Grassmann kernels and probabilistic similarity measures. Firstly, we show that the KL distance in the limit yields the Projection kernel on the Grassmann manifold, whereas the Bhattacharyya kernel becomes trivial in the limit and is suboptimal for subspace-based problems. Secondly, based on our analysis of the KL distance, we propose extensions of the Projection kernel which can be extended to the set of affine as well as scaled subspaces. We demonstrate the advantages of these extended kernels for classification and recognition tasks with Support Vector Machines and Kernel Discriminant Analysis using synthetic and real image databases.',\n",
       "  'id': '3433',\n",
       "  'title': 'Extended Grassmann Kernels for Subspace-Based Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'It is now well established that sparse signal models are well suited to restoration tasks and can effectively be learned from audio, image, and video data. Recent research has been aimed at learning discriminative sparse models instead of purely reconstructive ones. This paper proposes a new step in that direction with a novel sparse representation for signals belonging to different classes in terms of a shared dictionary and multiple decision functions. It is shown that the linear variant of the model admits a simple probabilistic interpretation, and that its most general variant also admits a simple interpretation in terms of kernels. An optimization framework for learning all the components of the proposed model is presented, along with experiments on standard handwritten digit and texture classification tasks.',\n",
       "  'id': '3448',\n",
       "  'title': 'Supervised Dictionary Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Large-margin structured estimation methods work by minimizing a convex upper bound of loss functions. While they allow for efficient optimization algorithms, these convex formulations are not tight and sacrifice the ability to accurately model the true loss. We present tighter non-convex bounds based on generalizing the notion of a ramp loss from binary classification to structured estimation. We show that a small modification of existing optimization algorithms suffices to solve this modified problem. On structured prediction tasks such as protein sequence alignment and web page ranking, our algorithm leads to improved accuracy.',\n",
       "  'id': '3451',\n",
       "  'title': 'Tighter Bounds for Structured Estimation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Hierarchical probabilistic modeling of discrete data has emerged as a powerful tool for text analysis. Posterior inference in such models is intractable, and practitioners rely on approximate posterior inference methods such as variational inference or Gibbs sampling. There has been much research in designing better approximations, but there is yet little theoretical understanding of which of the available techniques are appropriate, and in which data analysis settings. In this paper we provide the beginnings of such understanding. We analyze the improvement that the recently proposed collapsed variational inference (CVB) provides over mean field variational inference (VB) in latent Dirichlet allocation. We prove that the difference in the tightness of the bound on the likelihood of a document decreases as $O(k-1) + \\\\log m /m$, where $k$ is the number of topics in the model and $m$ is the number of words in a document. As a consequence, the advantage of CVB over VB is lost for long documents but increases with the number of topics. We demonstrate empirically that the theory holds, using simulated text data and two text corpora. We provide practical guidelines for choosing an approximation.',\n",
       "  'id': '3455',\n",
       "  'title': 'Relative Performance Guarantees for Approximate Inference in Latent Dirichlet Allocation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduce a novel framework for estimating vector fields using sparse basis field expansions (S-FLEX). The notion of basis fields, which are an extension of scalar basis functions, arises naturally in our framework from a rotational invariance requirement. We consider a regression setting as well as inverse problems. All variants discussed lead to second-order cone programming formulations. While our framework is generally applicable to any type of vector field, we focus in this paper on applying it to solving the EEG/MEG inverse problem. It is shown that significantly more precise and neurophysiologically more plausible location and shape estimates of cerebral current sources from EEG/MEG measurements become possible with our method when comparing to the state-of-the-art.',\n",
       "  'id': '3470',\n",
       "  'title': 'Estimating vector fields using sparse basis field expansions',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We provide a new analysis of an efficient margin-based algorithm for selective sampling in classification problems. Using the so-called Tsybakov low noise condition to parametrize the instance distribution, we show bounds on the convergence rate to the Bayes risk of both the fully supervised and the selective sampling versions of the basic algorithm. Our analysis reveals that, excluding logarithmic factors, the average risk of the selective sampler converges to the Bayes risk at rate $n^{-(1+\\\\alpha)/(3+\\\\alpha)}$, with labels being sampled at the same rate (here $n$ denotes the sample size, and $\\\\alpha > 0$ is the exponent in the low noise condition). We compare this convergence rate to the rate $n^{-(1+\\\\alpha)/(2+\\\\alpha)}$ achieved by the fully supervised algorithm using all labels. Experiments on textual data reveal that simple variants of the proposed selective sampler perform much better than popular and similarly efficient competitors.',\n",
       "  'id': '3477',\n",
       "  'title': 'Linear Classification and Selective Sampling Under Low Noise Conditions',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We describe a way of learning matrix representations of objects and relationships. The goal of learning is to allow multiplication of matrices to represent symbolic relationships between objects and symbolic relationships between relationships, which is the main novelty of the method. We demonstrate that this leads to excellent generalization in two different domains: modular arithmetic and family relationships. We show that the same system can learn first-order propositions such as $(2, 5) \\\\member +\\\\!3$ or $(Christopher, Penelope)\\\\member has\\\\_wife$, and higher-order propositions such as $(3, +\\\\!3) \\\\member plus$ and $(+\\\\!3, -\\\\!3) \\\\member inverse$ or $(has\\\\_husband, has\\\\_wife)\\\\in higher\\\\_oppsex$. We further demonstrate that the system understands how higher-order propositions are related to first-order ones by showing that it can correctly answer questions about first-order propositions involving the relations $+\\\\!3$ or $has\\\\_wife$ even though it has not been trained on any first-order examples involving these relations.',\n",
       "  'id': '3482',\n",
       "  'title': 'Using matrices to model symbolic relationship',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper, we address the question of what kind of knowledge is generally transferable from unlabeled text. We suggest and analyze the semantic correlation of words as a generally transferable structure of the language and propose a new method to learn this structure using an appropriately chosen latent variable model. This semantic correlation contains structural information of the language space and can be used to control the joint shrinkage of model parameters for any specific task in the same space through regularization. In an empirical study, we construct 190 different text classification tasks from a real-world benchmark, and the unlabeled documents are a mixture from all these tasks. We test the ability of various algorithms to use the mixed unlabeled text to enhance all classification tasks. Empirical results show that the proposed approach is a reliable and scalable method for semi-supervised learning, regardless of the source of unlabeled data, the specific task to be enhanced, and the prediction model used.',\n",
       "  'id': '3490',\n",
       "  'title': 'Learning the Semantic Correlation: An Alternative Way to Gain from Unlabeled Text',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"We consider the problem of extracting smooth low-dimensional ``neural trajectories'' that summarize the activity recorded simultaneously from tens to hundreds of neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional noisy spiking activity in a compact denoised form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the data are first ``denoised'' by smoothing over time, then a static dimensionality reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way, and account for spiking variability that may vary both across neurons and across time. We then present a novel method for extracting neural trajectories, Gaussian-process factor analysis (GPFA), which unifies the smoothing and dimensionality reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that GPFA provided a better characterization of the population activity than the two-stage methods. From the extracted single-trial neural trajectories, we directly observed a convergence in neural state during motor planning, an effect suggestive of attractor dynamics that was shown indirectly by previous studies.\",\n",
       "  'id': '3494',\n",
       "  'title': 'Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a novel mathematical formalism for the idea of a local model,\\'\\' a model of a potentially complex dynamical system that makes only certain predictions in only certain situations. As a result of its restricted responsibilities, a local model may be far simpler than a complete model of the system. We then show how one might combine several local models to produce a more detailed model. We demonstrate our ability to learn a collection of local models on a large-scale example and do a preliminary empirical comparison of learning a collection of local models and some other model learning methods.\"',\n",
       "  'id': '3503',\n",
       "  'title': 'Simple Local Models for Complex Dynamical Systems',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Compared to invasive Brain-Computer Interfaces (BCI), non-invasive BCI systems based on Electroencephalogram (EEG) signals have not been applied successfully for complex control tasks. In the present study, however, we demonstrate this is possible and report on the interaction of a human subject with a complex real device: a pinball machine. First results in this single subject study clearly show that fast and well-timed control well beyond chance level is possible, even though the environment is extremely rich and requires complex predictive behavior. Using machine learning methods for mental state decoding, BCI-based pinball control is possible within the first session without the necessity to employ lengthy subject training. While the current study is still of anecdotal nature, it clearly shows that very compelling control with excellent timing and dynamics is possible for a non-invasive BCI.',\n",
       "  'id': '3507',\n",
       "  'title': 'Playing Pinball with non-invasive BCI',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In a variety of behavioral tasks, subjects exhibit an automatic and apparently sub-optimal sequential effect: they respond more rapidly and accurately to a stimulus if it reinforces a local pattern in stimulus history, such as a string of repetitions or alternations, compared to when it violates such a pattern. This is often the case even if the local trends arise by chance in the context of a randomized design, such that stimulus history has no predictive power. In this work, we use a normative Bayesian framework to examine the hypothesis that such idiosyncrasies may reflect the inadvertent engagement of fundamental mechanisms critical for adapting to changing statistics in the natural environment. We show that prior belief in non-stationarity can induce experimentally observed sequential effects in an otherwise Bayes-optimal algorithm. The Bayesian algorithm is shown to be well approximated by linear-exponential filtering of past observations, a feature also apparent in the behavioral data. We derive an explicit relationship between the parameters and computations of the exact Bayesian algorithm and those of the approximate linear-exponential filter. Since the latter is equivalent to a leaky-integration process, a commonly used model of neuronal dynamics underlying perceptual decision-making and trial-to-trial dependencies, our model provides a principled account of why such dynamics are useful. We also show that near-optimal tuning of the leaky-integration process is possible, using stochastic gradient descent based only on the noisy binary inputs. This is a proof of concept that not only can neurons implement near-optimal prediction based on standard neuronal dynamics, but that they can also learn to tune the processing parameters without explicitly representing probabilities.',\n",
       "  'id': '3519',\n",
       "  'title': 'Sequential effects: Superstition or rational behavior?',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Most algorithms for solving Markov decision processes rely on a discount factor, which ensures their convergence. In fact, it is often used in problems with is no intrinsic motivation. In this paper, we show that when used in approximate dynamic programming, an artificially low discount factor may significantly improve the performance on some problems, such as Tetris. We propose two explanations for this phenomenon. Our first justification follows directly from the standard approximation error bounds: using a lower discount factor may decrease the approximation error bounds. However, we also show that these bounds are loose, a thus their decrease does not entirely justify a better practical performance. We thus propose another justification: when the rewards are received only sporadically (as it is the case in Tetris), we can derive tighter bounds, which support a significant performance increase with a decrease in the discount factor.',\n",
       "  'id': '3523',\n",
       "  'title': 'Biasing Approximate Dynamic Programming with a Lower Discount Factor',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Continuous attractor neural networks (CANNs) are emerging as promising models for describing the encoding of continuous stimuli in neural systems. Due to the translational invariance of their neuronal interactions, CANNs can hold a continuous family of neutrally stable states. In this study, we systematically explore how neutral stability of a CANN facilitates its tracking performance, a capacity believed to have wide applications in brain functions. We develop a perturbative approach that utilizes the dominant movement of the network stationary states in the state space. We quantify the distortions of the bump shape during tracking, and study their effects on the tracking performance. Results are obtained on the maximum speed for a moving stimulus to be trackable, and the reaction time to catch up an abrupt change in stimulus.',\n",
       "  'id': '3528',\n",
       "  'title': 'Tracking Changing Stimuli in Continuous Attractor Neural Networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'A visual attention system should respond placidly when common stimuli are presented, while at the same time keep alert to anomalous visual inputs. In this paper, a dynamic visual attention model based on the rarity of features is proposed. We introduce the Incremental Coding Length (ICL) to measure the perspective entropy gain of each feature. The objective of our model is to maximize the entropy of the sampled visual features. In order to optimize energy consumption, the limit amount of energy of the system is re-distributed amongst features according to their Incremental Coding Length. By selecting features with large coding length increments, the computational system can achieve attention selectivity in both static and dynamic scenes. We demonstrate that the proposed model achieves superior accuracy in comparison to mainstream approaches in static saliency map generation. Moreover, we also show that our model captures several less-reported dynamic visual search behaviors, such as attentional swing and inhibition of return.',\n",
       "  'id': '3531',\n",
       "  'title': 'Dynamic visual attention: searching for coding length increments',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many motor skills in humanoid robotics can be learned using parametrized motor primitives as done in imitation learning. However, most interesting motor learning problems are high-dimensional reinforcement learning problems often beyond the reach of current methods. In this paper, we extend previous work on policy learning from the immediate reward case to episodic reinforcement learning. We show that this results into a general, common framework also connected to policy gradient methods and yielding a novel algorithm for policy learning by assuming a form of exploration that is particularly well-suited for dynamic motor primitives. The resulting algorithm is an EM-inspired algorithm applicable in complex motor learning tasks. We compare this algorithm to alternative parametrized policy search methods and show that it outperforms previous methods. We apply it in the context of motor learning and show that it can learn a complex Ball-in-a-Cup task using a real Barrett WAM robot arm.',\n",
       "  'id': '3545',\n",
       "  'title': 'Policy Search for Motor Primitives in Robotics',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many nonlinear dynamical phenomena can be effectively modeled by a system that switches among a set of conditionally linear dynamical modes. We consider two such models: the switching linear dynamical system (SLDS) and the switching vector autoregressive (VAR) process. In this paper, we present a nonparametric approach to the learning of an unknown number of persistent, smooth dynamical modes by utilizing a hierarchical Dirichlet process prior. We develop a sampling algorithm that combines a truncated approximation to the Dirichlet process with an efficient joint sampling of the mode and state sequences. The utility and flexibility of our model are demonstrated on synthetic data, sequences of dancing honey bees, and the IBOVESPA stock index.',\n",
       "  'id': '3546',\n",
       "  'title': 'Nonparametric Bayesian Learning of Switching Linear Dynamical Systems',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper presents a theoretical analysis of the problem of adaptation with multiple sources. For each source domain, the distribution over the input points as well as a hypothesis with error at most \\\\epsilon are given. The problem consists of combining these hypotheses to derive a hypothesis with small error with respect to the target domain. We present several theoretical results relating to this problem. In particular, we prove that standard convex combinations of the source hypotheses may in fact perform very poorly and that, instead, combinations weighted by the source distributions benefit from favorable theoretical guarantees. Our main result shows that, remarkably, for any fixed target function, there exists a distribution weighted combining rule that has a loss of at most \\\\epsilon with respect to *any* target mixture of the source distributions. We further generalize the setting from a single target function to multiple consistent target functions and show the existence of a combining rule with error at most 3\\\\epsilon. Finally, we report empirical results for a multiple source adaptation problem with a real-world dataset.',\n",
       "  'id': '3550',\n",
       "  'title': 'Domain Adaptation with Multiple Sources',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Empirical evidence shows that in favorable situations semi-supervised learning (SSL) algorithms can capitalize on the abundancy of unlabeled training data to improve the performance of a learning task, in the sense that fewer labeled training data are needed to achieve a target error bound. However, in other situations unlabeled data do not seem to help. Recent attempts at theoretically characterizing the situations in which unlabeled data can help have met with little success, and sometimes appear to conflict with each other and intuition. In this paper, we attempt to bridge the gap between practice and theory of semi-supervised learning. We develop a rigorous framework for analyzing the situations in which unlabeled data can help and quantify the improvement possible using finite sample error bounds. We show that there are large classes of problems for which SSL can significantly outperform supervised learning, in finite sample regimes and sometimes also in terms of error convergence rates.',\n",
       "  'id': '3551',\n",
       "  'title': \"Unlabeled data: Now it helps, now it doesn't\",\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Correlations between spike counts are often used to analyze neural coding. The noise is typically assumed to be Gaussian. Yet, this assumption is often inappropriate, especially for low spike counts. In this study, we present copulas as an alternative approach. With copulas it is possible to use arbitrary marginal distributions such as Poisson or negative binomial that are better suited for modeling noise distributions of spike counts. Furthermore, copulas place a wide range of dependence structures at the disposal and can be used to analyze higher order interactions. We develop a framework to analyze spike count data by means of copulas. Methods for parameter inference based on maximum likelihood estimates and for computation of Shannon entropy are provided. We apply the method to our data recorded from macaque prefrontal cortex. The data analysis leads to three significant findings: (1) copula-based distributions provide better fits than discretized multivariate normal distributions; (2) negative binomial margins fit the data better than Poisson margins; and (3) a dependence model that includes only pairwise interactions overestimates the information entropy by at least 19% compared to the model with higher order interactions.',\n",
       "  'id': '3552',\n",
       "  'title': 'Modeling Short-term Noise Dependence of Spike Counts in Macaque Prefrontal Cortex',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Confidence-weighted (CW) learning [6], an online learning method for linear classifiers, maintains a Gaussian distributions over weight vectors, with a covariance matrix that represents uncertainty about weights and correlations. Confidence constraints ensure that a weight vector drawn from the hypothesis distribution correctly classifies examples with a specified probability. Within this framework, we derive a new convex form of the constraint and analyze it in the mistake bound model. Empirical evaluation with both synthetic and text data shows our version of CW learning achieves lower cumulative and out-of-sample errors than commonly used first-order and second-order online methods.',\n",
       "  'id': '3554',\n",
       "  'title': 'Exact Convex Confidence-Weighted Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduce a kernel-based method for change-point analysis within a sequence of temporal observations. Change-point analysis of an (unlabelled) sample of observations consists in, first, testing whether a change in the distribution occurs within the sample, and second, if a change occurs, estimating the change-point instant after which the distribution of the observations switches from one distribution to another different distribution. We propose a test statistics based upon the maximum kernel Fisher discriminant ratio as a measure of homogeneity between segments. We derive its limiting distribution under the null hypothesis (no change occurs), and establish the consistency under the alternative hypothesis (a change occurs). This allows to build a statistical hypothesis testing procedure for testing the presence of change-point, with a prescribed false-alarm probability and detection probability tending to one in the large-sample setting. If a change actually occurs, the test statistics also yields an estimator of the change-point location. Promising experimental results in temporal segmentation of mental tasks from BCI data and pop song indexation are presented.',\n",
       "  'id': '3556',\n",
       "  'title': 'Kernel Change-point Analysis',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In analogy to the PCA setting, the sparse PCA problem is often solved by iteratively alternating between two subtasks: cardinality-constrained rank-one variance maximization and matrix deflation. While the former has received a great deal of attention in the literature, the latter is seldom analyzed and is typically borrowed without justification from the PCA context. In this work, we demonstrate that the standard PCA deflation procedure is seldom appropriate for the sparse PCA setting. To rectify the situation, we first develop several heuristic deflation alternatives with more desirable properties. We then reformulate the sparse PCA optimization problem to explicitly reflect the maximum additional variance objective on each round. The result is a generalized deflation procedure that typically outperforms more standard techniques on real-world datasets.',\n",
       "  'id': '3575',\n",
       "  'title': 'Deflation Methods for Sparse PCA',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Young children demonstrate the ability to make inferences about the preferences of other agents based on their choices. However, there exists no overarching account of what children are doing when they learn about preferences or how they use that knowledge. We use a rational model of preference learning, drawing on ideas from economics and computer science, to explain the behavior of children in several recent experiments. Specifically, we show how a simple econometric model can be extended to capture two- to four-year-olds??? use of statistical information in inferring preferences, and their generalization of these preferences.',\n",
       "  'id': '3579',\n",
       "  'title': 'A rational model of preference learning and choice prediction by children',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We developed localized sliced inverse regression for supervised dimension reduction. It has the advantages of preventing degeneracy, increasing estimation accuracy, and automatic subclass discovery in classification problems. A semisupervised version is proposed for the use of unlabeled data. The utility is illustrated on simulated as well as real data sets.',\n",
       "  'id': '3595',\n",
       "  'title': 'Localized Sliced Inverse Regression',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Statistical evolutionary models provide an important mechanism for describing and understanding the escape response of a viral population under a particular therapy. We present a new hierarchical model that incorporates spatially varying mutation and recombination rates at the nucleotide level. It also maintains sep- arate parameters for treatment and control groups, which allows us to estimate treatment effects explicitly. We use the model to investigate the sequence evolu- tion of HIV populations exposed to a recently developed antisense gene therapy, as well as a more conventional drug therapy. The detection of biologically rele- vant and plausible signals in both therapy studies demonstrates the effectiveness of the method.',\n",
       "  'id': '3603',\n",
       "  'title': 'A spatially varying two-sample recombinant coalescent, with applications to HIV escape response',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Using machine learning algorithms to decode intended behavior from neural activity serves a dual purpose. First, these tools can be used to allow patients to interact with their environment through a Brain-Machine Interface (BMI). Second, analysis of the characteristics of such methods can reveal the significance of various features of neural activity, stimuli and responses to the encoding-decoding task. In this study we adapted, implemented and tested a machine learning method, called Kernel Auto-Regressive Moving Average (KARMA), for the task of inferring movements from neural activity in primary motor cortex. Our version of this algorithm is used in an on-line learning setting and is updated when feedback from the last inferred sequence become available. We first used it to track real hand movements executed by a monkey in a standard 3D motor control task. We then applied it in a closed-loop BMI setting to infer intended movement, while arms were restrained, allowing a monkey to perform the task using the BMI alone. KARMA is a recurrent method that learns a nonlinear model of output dynamics. It uses similarity functions (termed kernels) to compare between inputs. These kernels can be structured to incorporate domain knowledge into the method. We compare KARMA to various state-of-the-art methods by evaluating tracking performance and present results from the KARMA based BMI experiments.',\n",
       "  'id': '3607',\n",
       "  'title': 'Kernel-ARMA for Hand Tracking and Brain-Machine interfacing During 3D Motor Control',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Object matching is a fundamental operation in data analysis. It typically requires the definition of a similarity measure between the classes of objects to be matched. Instead, we develop an approach which is able to perform matching by requiring a similarity measure only within each of the classes. This is achieved by maximizing the dependency between matched pairs of observations by means of the Hilbert Schmidt Independence Criterion. This problem can be cast as one of maximizing a quadratic assignment problem with special structure and we present a simple algorithm for finding a locally optimal solution.',\n",
       "  'id': '3608',\n",
       "  'title': 'Kernelized Sorting',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The synchronous brain activity measured via MEG (or EEG) can be interpreted as arising from a collection (possibly large) of current dipoles or sources located throughout the cortex. Estimating the number, location, and orientation of these sources remains a challenging task, one that is significantly compounded by the effects of source correlations and the presence of interference from spontaneous brain activity, sensor noise, and other artifacts. This paper derives an empirical Bayesian method for addressing each of these issues in a principled fashion. The resulting algorithm guarantees descent of a cost function uniquely designed to handle unknown orientations and arbitrary correlations. Robust interference suppression is also easily incorporated. In a restricted setting, the proposed method is shown to have theoretically zero bias estimating both the location and orientation of multi-component dipoles even in the presence of correlations, unlike a variety of existing Bayesian localization methods or common signal processing techniques such as beamforming and sLORETA. Empirical results on both simulated and real data sets verify the efficacy of this approach.',\n",
       "  'id': '3609',\n",
       "  'title': 'Estimating the Location and Orientation of Complex, Correlated Neural Activity using MEG',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this work, we consider the problem of learning a positive semidefinite matrix. The critical issue is how to preserve positive semidefiniteness during the course of learning. Our algorithm is mainly inspired by LPBoost [1] and the general greedy convex optimization framework of Zhang [2]. We demonstrate the essence of the algorithm, termed PSDBoost (positive semidefinite Boosting), by focusing on a few different applications in machine learning. The proposed PSDBoost algorithm extends traditional Boosting algorithms in that its parameter is a positive semidefinite matrix with trace being one instead of a classifier. PSDBoost is based on the observation that any trace-one positive semidefinitematrix can be decomposed into linear convex combinations of trace-one rank-one matrices, which serve as base learners of PSDBoost. Numerical experiments are presented.',\n",
       "  'id': '3611',\n",
       "  'title': 'PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We develop as series of corrections to Expectation Propagation (EP), which is one of the most popular methods for approximate probabilistic inference. These corrections can lead to improvements of the inference approximation or serve as a sanity check, indicating when EP yields unrealiable results.',\n",
       "  'id': '3613',\n",
       "  'title': 'Improving on Expectation Propagation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We develop new techniques for time series classification based on hierarchical Bayesian generative models (called mixed-effect models) and the Fisher kernel derived from them. A key advantage of the new formulation is that one can compute the Fisher information matrix despite varying sequence lengths and sampling times. We therefore can avoid the ad hoc replacement of Fisher information matrix with the identity matrix commonly used in literature, which destroys the geometrical grounding of the kernel construction. In contrast, our construction retains the proper geometric structure resulting in a kernel that is properly invariant under change of coordinates in the model parameter space. Experiments on detecting cognitive decline show that classifiers based on the proposed kernel out-perform those based on generative models and other feature extraction routines.',\n",
       "  'id': '3617',\n",
       "  'title': 'Hierarchical Fisher Kernels for Longitudinal Data',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider the problem of obtaining the approximate maximum a posteriori estimate of a discrete random field characterized by pairwise potentials that form a truncated convex model. For this problem, we propose an improved st-mincut based move making algorithm. Unlike previous move making approaches, which either provide a loose bound or no bound on the quality of the solution (in terms of the corresponding Gibbs energy), our algorithm achieves the same guarantees as the standard linear programming (LP) relaxation. Compared to previous approaches based on the LP relaxation, e.g. interior-point algorithms or tree-reweighted message passing (TRW), our method is faster as it uses only the efficient st-mincut algorithm in its design. Furthermore, it directly provides us with a primal solution (unlike TRW and other related methods which attempt to solve the dual of the LP). We demonstrate the effectiveness of the proposed approach on both synthetic and standard real data problems. Our analysis also opens up an interesting question regarding the relationship between move making algorithms (such as $\\\\alpha$-expansion and the algorithms presented in this paper) and the randomized rounding schemes used with convex relaxations. We believe that further explorations in this direction would help design efficient algorithms for more complex relaxations.',\n",
       "  'id': '3618',\n",
       "  'title': 'Improved Moves for Truncated Convex Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Almost all successful machine learning algorithms and cognitive models require powerful representations capturing the features that are relevant to a particular problem. We draw on recent work in nonparametric Bayesian statistics to define a rational model of human feature learning that forms a featural representation from raw sensory data without pre-specifying the number of features. By comparing how the human perceptual system and our rational model use distributional and category information to infer feature representations, we seek to identify some of the forces that govern the process by which people separate and combine sensory primitives to form features.',\n",
       "  'id': '3621',\n",
       "  'title': 'Analyzing human feature learning as nonparametric Bayesian inference',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We apply robust Bayesian decision theory to improve both generative and discriminative learners under bias in class proportions in labeled training data, when the true class proportions are unknown. For the generative case, we derive an entropy-based weighting that maximizes expected log likelihood under the worst-case true class proportions. For the discriminative case, we derive a multinomial logistic model that minimizes worst-case conditional log loss. We apply our theory to the modeling of species geographic distributions from presence data, an extreme case of label bias since there is no absence data. On a benchmark dataset, we find that entropy-based weighting offers an improvement over constant estimates of class proportions, consistently reducing log loss on unbiased test data.',\n",
       "  'id': '3624',\n",
       "  'title': 'Generative and Discriminative Learning with Unknown Labeling Bias',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We address the challenge of assessing conservation of gene expression in complex, non-homogeneous datasets. Recent studies have demonstrated the success of probabilistic models in studying the evolution of gene expression in simple eukaryotic organisms such as yeast, for which measurements are typically scalar and independent. Models capable of studying expression evolution in much more complex organisms such as vertebrates are particularly important given the medical and scientific interest in species such as human and mouse. We present a statistical model that makes a number of significant extensions to previous models to enable characterization of changes in expression among highly complex organisms. We demonstrate the efficacy of our method on a microarray dataset containing diverse tissues from multiple vertebrate species. We anticipate that the model will be invaluable in the study of gene expression patterns in other diverse organisms as well, such as worms and insects.',\n",
       "  'id': '3384',\n",
       "  'title': 'A mixture model for the evolution of gene expression in non-homogeneous datasets',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We address the problem of estimating the ratio of two probability density functions (a.k.a.~the importance). The importance values can be used for various succeeding tasks such as non-stationarity adaptation or outlier detection. In this paper, we propose a new importance estimation method that has a closed-form solution; the leave-one-out cross-validation score can also be computed analytically. Therefore, the proposed method is computationally very efficient and numerically stable. We also elucidate theoretical properties of the proposed method such as the convergence rate and approximation error bound. Numerical experiments show that the proposed method is comparable to the best existing method in accuracy, while it is computationally more efficient than competing approaches.',\n",
       "  'id': '3387',\n",
       "  'title': 'Efficient Direct Density Ratio Estimation for Non-stationarity Adaptation and Outlier Detection',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Polysemy is a problem for methods that exploit image search engines to build object category models. Existing unsupervised approaches do not take word sense into consideration. We propose a new method that uses a dictionary to learn models of visual word sense from a large collection of unlabeled web data. The use of LDA to discover a latent sense space makes the model robust despite the very limited nature of dictionary definitions. The definitions are used to learn a distribution in the latent space that best represents a sense. The algorithm then uses the text surrounding image links to retrieve images with high probability of a particular dictionary sense. An object classifier is trained on the resulting sense-specific images. We evaluate our method on a dataset obtained by searching the web for polysemous words. Category classification experiments show that our dictionary-based approach outperforms baseline methods.',\n",
       "  'id': '3389',\n",
       "  'title': 'Unsupervised Learning of Visual Sense Models for Polysemous Words',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider the following instance of transfer learning: given a pair of regression problems, suppose that the regression coefficients share a partially common support, parameterized by the overlap fraction $\\\\overlap$ between the two supports. This set-up suggests the use of $1, \\\\infty$-regularized linear regression for recovering the support sets of both regression vectors. Our main contribution is to provide a sharp characterization of the sample complexity of this $1,\\\\infty$ relaxation, exactly pinning down the minimal sample size $n$ required for joint support recovery as a function of the model dimension $\\\\pdim$, support size $\\\\spindex$ and overlap $\\\\overlap \\\\in [0,1]$. For measurement matrices drawn from standard Gaussian ensembles, we prove that the joint $1,\\\\infty$-regularized method undergoes a phase transition characterized by order parameter $\\\\orpar(\\\\numobs, \\\\pdim, \\\\spindex, \\\\overlap) = \\\\numobs{(4 - 3 \\\\overlap) s \\\\log(p-(2-\\\\overlap)s)}$. More precisely, the probability of successfully recovering both supports converges to $1$ for scalings such that $\\\\orpar > 1$, and converges to $0$ to scalings for which $\\\\orpar < 1$. An implication of this threshold is that use of $1, \\\\infty$-regularization leads to gains in sample complexity if the overlap parameter is large enough ($\\\\overlap > 2/3$), but performs worse than a naive approach if $\\\\overlap < 2/3$. We illustrate the close agreement between these theoretical predictions, and the actual behavior in simulations. Thus, our results illustrate both the benefits and dangers associated with block-$1,\\\\infty$ regularization in high-dimensional inference.',\n",
       "  'id': '3392',\n",
       "  'title': 'Phase transitions for high-dimensional joint support recovery',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In kernel-based regression learning, optimizing each kernel individually is useful when the data density, curvature of regression surfaces (or decision boundaries) or magnitude of output noise (i.e., heteroscedasticity) varies spatially. Unfortunately, it presents a complex computational problem as the danger of overfitting is high and the individual optimization of every kernel in a learning system may be overly expensive due to the introduction of too many open learning parameters. Previous work has suggested gradient descent techniques or complex statistical hypothesis methods for local kernel shaping, typically requiring some amount of manual tuning of meta parameters. In this paper, we focus on nonparametric regression and introduce a Bayesian formulation that, with the help of variational approximations, results in an EM-like algorithm for simultaneous estimation of regression and kernel parameters. The algorithm is computationally efficient (suitable for large data sets), requires no sampling, automatically rejects outliers and has only one prior to be specified. It can be used for nonparametric regression with local polynomials or as a novel method to achieve nonstationary regression with Gaussian Processes. Our methods are particularly useful for learning control, where reliable estimation of local tangent planes is essential for adaptive controllers and reinforcement learning. We evaluate our methods on several synthetic data sets and on an actual robot which learns a task-level control law.',\n",
       "  'id': '3393',\n",
       "  'title': 'Bayesian Kernel Shaping for Learning Control',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Learning graphical models with hidden variables can offer semantic insights to complex data and lead to salient structured predictors without relying on expensive, sometime unattainable fully annotated training data. While likelihood-based methods have been extensively explored, to our knowledge, learning structured prediction models with latent variables based on the max-margin principle remains largely an open problem. In this paper, we present a partially observed Maximum Entropy Discrimination Markov Network (PoMEN) model that attempts to combine the advantages of Bayesian and margin based paradigms for learning Markov networks from partially labeled data. PoMEN leads to an averaging prediction rule that resembles a Bayes predictor that is more robust to overfitting, but is also built on the desirable discriminative laws resemble those of the M$^3$N. We develop an EM-style algorithm utilizing existing convex optimization algorithms for M$^3$N as a subroutine. We demonstrate competent performance of PoMEN over existing methods on a real-world web data extraction task.',\n",
       "  'id': '3399',\n",
       "  'title': 'Partially Observed Maximum Entropy Discrimination Markov Networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"This paper studies global ranking problem by learning to rank methods. Conventional learning to rank methods are usually designed for `local ranking', in the sense that the ranking model is defined on a single object, for example, a document in information retrieval. For many applications, this is a very loose approximation. Relations always exist between objects and it is better to define the ranking model as a function on all the objects to be ranked (i.e., the relations are also included). This paper refers to the problem as global ranking and proposes employing a Continuous Conditional Random Fields (CRF) for conducting the learning task. The Continuous CRF model is defined as a conditional probability distribution over ranking scores of objects conditioned on the objects. It can naturally represent the content information of objects as well as the relation information between objects, necessary for global ranking. Taking two specific information retrieval tasks as examples, the paper shows how the Continuous CRF method can perform global ranking better than baselines.\",\n",
       "  'id': '3402',\n",
       "  'title': 'Global Ranking Using Continuous Conditional Random Fields',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Accurate and efficient inference in evolutionary trees is a central problem in computational biology. Realistic models require tracking insertions and deletions along the phylogenetic tree, making inference challenging. We propose new sampling techniques that speed up inference and improve the quality of the samples. We compare our method to previous approaches and show performance improvement on metrics evaluating multiple sequence alignment and reconstruction of ancestral sequences.',\n",
       "  'id': '3406',\n",
       "  'title': 'Efficient Inference in Phylogenetic InDel Trees',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We describe an application of probabilistic modeling and inference technology to the problem of analyzing sensor data in the setting of an intensive care unit (ICU). In particular, we consider the arterial-line blood pressure sensor, which is subject to frequent data artifacts that cause false alarms in the ICU and make the raw data almost useless for automated decision making. The problem is complicated by the fact that the sensor data are acquired at fixed intervals whereas the events causing data artifacts may occur at any time and have durations that may be significantly shorter than the data collection interval. We show that careful modeling of the sensor, combined with a general technique for detecting sub-interval events and estimating their duration, enables effective detection of artifacts and accurate estimation of the underlying blood pressure values.',\n",
       "  'id': '3434',\n",
       "  'title': 'Probabilistic detection of short events, with application to critical care monitoring',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Clustering stability is an increasingly popular family of methods for performing model selection in data clustering. The basic idea is that the chosen model should be stable under perturbation or resampling of the data. Despite being reasonably effective in practice, these methods are not well understood theoretically, and present some difficulties. In particular, when the data is assumed to be sampled from an underlying distribution, the solutions returned by the clustering algorithm will usually become more and more stable as the sample size increases. This raises a potentially serious practical difficulty with these methods, because it means there might be some hard-to-compute sample size, beyond which clustering stability estimators 'break down' and become unreliable in detecting the most stable model. Namely, all models will be relatively stable, with differences in their stability measures depending mostly on random and meaningless sampling artifacts. In this paper, we provide a set of general sufficient conditions, which ensure the reliability of clustering stability estimators in the large sample regime. In contrast to previous work, which concentrated on specific toy distributions or specific idealized clustering frameworks, here we make no such assumptions. We then exemplify how these conditions apply to several important families of clustering algorithms, such as maximum likelihood clustering, certain types of kernel clustering, and centroid-based clustering with any Bregman divergence. In addition, we explicitly derive the non-trivial asymptotic behavior of these estimators, for any framework satisfying our conditions. This can help us understand what is considered a 'stable' model by these estimators, at least for large enough samples.\",\n",
       "  'id': '3438',\n",
       "  'title': 'On the Reliability of Clustering Stability in the Large Sample Regime',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a new family of linear time algorithms based on sufficient statistics for string comparison with mismatches under the string kernels framework. Our algorithms improve theoretical complexity bounds of existing approaches while scaling well with respect to the sequence alphabet size, the number of allowed mismatches and the size of the dataset. In particular, on large alphabets with loose mismatch constraints our algorithms are several orders of magnitude faster than the existing algorithms for string comparison under the mismatch similarity measure. We evaluate our algorithms on synthetic data and real applications in music genre classification, protein remote homology detection and protein fold prediction. The scalability of the algorithms allows us to consider complex sequence transformations, modeled using longer string features and larger numbers of mismatches, leading to a state-of-the-art performance with significantly reduced running times.',\n",
       "  'id': '3441',\n",
       "  'title': 'Scalable Algorithms for String Kernels with Inexact Matching',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In partially observable worlds with many agents, nested beliefs are formed when agents simultaneously reason about the unknown state of the world and the beliefs of the other agents. The multi-agent filtering problem is to efficiently represent and update these beliefs through time as the agents act in the world. In this paper, we formally define an infinite sequence of nested beliefs about the state of the world at the current time $t$ and present a filtering algorithm that maintains a finite representation which can be used to generate these beliefs. In some cases, this representation can be updated exactly in constant time; we also present a simple approximation scheme to compact beliefs if they become too complex. In experiments, we demonstrate efficient filtering in a range of multi-agent domains.',\n",
       "  'id': '3459',\n",
       "  'title': 'Multi-Agent Filtering with Infinitely Nested Beliefs',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper lower and upper bounds for the number of support vectors are derived for support vector machines (SVMs) based on the epsilon-insensitive loss function. It turns out that these bounds are asymptotically tight under mild assumptions on the data generating distribution. Finally, we briefly discuss a trade-off in epsilon between sparsity and accuracy if the SVM is used to estimate the conditional median.',\n",
       "  'id': '3466',\n",
       "  'title': 'Sparsity of SVMs that use the epsilon-insensitive loss',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Current on-line learning algorithms for predicting the labelling of a graph have an important limitation in the case of large diameter graphs; the number of mistakes made by such algorithms may be proportional to the square root of the number of vertices, even when tackling simple problems. We overcome this problem with an efficient algorithm which achieves a logarithmic mistake bound. Furthermore, current algorithms are optimised for data which exhibits cluster-structure; we give an additional algorithm which performs well locally in the presence of cluster structure and on large diameter graphs.',\n",
       "  'id': '3475',\n",
       "  'title': 'Online Prediction on Large Diameter Graphs',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose a novel hierarchical, nonlinear model that predicts brain activity in area V1 evoked by natural images. In the study reported here brain activity was measured by means of functional magnetic resonance imaging (fMRI), a noninvasive technique that provides an indirect measure of neural activity pooled over a small volume (~ 2mm cube) of brain tissue. Our model, which we call the SpAM V1 model, is based on the reasonable assumption that fMRI measurements reflect the (possibly nonlinearly) pooled, rectified output of a large population of simple and complex cells in V1. It has a hierarchical filtering stage that consists of three layers: model simple cells, model complex cells, and a third layer in which the complex cells are linearly pooled (called ???pooled-complex??? cells). The pooling stage then obtains the measured fMRI signals as a sparse additive model (SpAM) in which a sparse nonparametric (nonlinear) combination of model complex cell and model pooled-complex cell outputs are summed. Our results show that the SpAM V1 model predicts fMRI responses evoked by natural images better than a benchmark model that only provides linear pooling of model complex cells. Furthermore, the spatial receptive fields, frequency tuning and orientation tuning curves of the SpAM V1 model estimated for each voxel appears to be consistent with the known properties of V1, and with previous analyses of this data set. A visualization procedure applied to the SpAM V1 model shows that most of the nonlinear pooling consists of simple compressive or saturating nonlinearities.',\n",
       "  'id': '3481',\n",
       "  'title': 'Nonparametric sparse hierarchical models describe V1 fMRI responses to natural images',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in HazanKaKaAg06. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions.',\n",
       "  'id': '3484',\n",
       "  'title': 'Mind the Duality Gap: Logarithmic regret algorithms for online optimization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper presents the first data-dependent generalization bounds for non-i.i.d. settings based on the notion of Rademacher complexity. Our bounds extend to the non-i.i.d. case existing Rademacher complexity bounds derived for the i.i.d. setting. These bounds provide a strict generalization of the ones found in the i.i.d. case, and can also be used within the standard i.i.d. scenario. They apply to the standard scenario of beta-mixing stationary sequences examined in many previous studies of non-i.i.d. settings and benefit form the crucial advantages of Rademacher complexity over other measures of the complexity of hypothesis classes. In particular, they are data-dependent and measure the complexity of a class of hypotheses based on the training sample. The empirical Rademacher complexity can be estimated from finite samples and lead to tighter bounds.',\n",
       "  'id': '3489',\n",
       "  'title': 'Rademacher Complexity Bounds for Non-I.I.D. Processes',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"EEG connectivity measures could provide a new type of feature space for inferring a subject's intention in Brain-Computer Interfaces (BCIs). However, very little is known on EEG connectivity patterns for BCIs. In this study, EEG connectivity during motor imagery (MI) of the left and right is investigated in a broad frequency range across the whole scalp by combining Beamforming with Transfer Entropy and taking into account possible volume conduction effects. Observed connectivity patterns indicate that modulation intentionally induced by MI is strongest in the gamma-band, i.e., above 35 Hz. Furthermore, modulation between MI and rest is found to be more pronounced than between MI of different hands. This is in contrast to results on MI obtained with bandpower features, and might provide an explanation for the so far only moderate success of connectivity features in BCIs. It is concluded that future studies on connectivity based BCIs should focus on high frequency bands and consider experimental paradigms that maximally vary cognitive demands between conditions.\",\n",
       "  'id': '3505',\n",
       "  'title': 'Understanding Brain Connectivity Patterns during Motor Imagery for Brain-Computer Interfacing',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present an approach to low-level vision that combines two main ideas: the use of convolutional networks as an image processing architecture and an unsupervised learning procedure that synthesizes training samples from specific noise models. We demonstrate this approach on the challenging problem of natural image denoising. Using a test set with a hundred natural images, we find that convolutional networks provide comparable and in some cases superior performance to state of the art wavelet and Markov random field (MRF) methods. Moreover, we find that a convolutional network offers similar performance in the blind denoising setting as compared to other techniques in the non-blind setting. We also show how convolutional networks are mathematically related to MRF approaches by presenting a mean field theory for an MRF specially designed for image denoising. Although these approaches are related, convolutional networks avoid computational difficulties in MRF approaches that arise from probabilistic learning and inference. This makes it possible to learn image processing architectures that have a high degree of representational power (we train models with over 15,000 parameters), but whose computational expense is significantly less than that associated with inference in MRF approaches with even hundreds of parameters.',\n",
       "  'id': '3506',\n",
       "  'title': 'Natural Image Denoising with Convolutional Networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider the problem of multiple kernel learning (MKL), which can be formulated as a convex-concave problem. In the past, two efficient methods, i.e., Semi-Infinite Linear Programming (SILP) and Subgradient Descent (SD), have been proposed for large-scale multiple kernel learning. Despite their success, both methods have their own shortcomings: (a) the SD method utilizes the gradient of only the current solution, and (b) the SILP method does not regularize the approximate solution obtained from the cutting plane model. In this work, we extend the level method, which was originally designed for optimizing non-smooth objective functions, to convex-concave optimization, and apply it to multiple kernel learning. The extended level method overcomes the drawbacks of SILP and SD by exploiting all the gradients computed in past iterations and by regularizing the solution via a projection to a level set. Empirical study with eight UCI datasets shows that the extended level method can significantly improve efficiency by saving on average 91.9% of computational time over the SILP method and 70.3% over the SD method.',\n",
       "  'id': '3520',\n",
       "  'title': 'An Extended Level Method for Efficient Multiple Kernel Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Causal structure-discovery techniques usually assume that all causes of more than one variable are observed. This is the so-called causal sufficiency assumption. In practice, it is untestable, and often violated. In this paper, we present an efficient causal structure-learning algorithm, suited for causally insufficient data. Similar to algorithms such as IC* and FCI, the proposed approach drops the causal sufficiency assumption and learns a structure that indicates (potential) latent causes for pairs of observed variables. Assuming a constant local density of the data-generating graph, our algorithm makes a quadratic number of conditional-independence tests w.r.t. the number of variables. We show with experiments that our algorithm is comparable to the state-of-the-art FCI algorithm in accuracy, while being several orders of magnitude faster on large problems. We conclude that MBCS* makes a new range of causally insufficient problems computationally tractable.',\n",
       "  'id': '3525',\n",
       "  'title': 'Finding Latent Causes in Causal Networks: an Efficient Approach Based on Markov Blankets',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We study learning formulations with non-convex regularizaton that are natural for sparse linear models. There are two approaches to this problem: (1) Heuristic methods such as gradient descent that only find a local minimum. A drawback of this approach is the lack of theoretical guarantee showing that the local minimum gives a good solution. (2) Convex relaxation such as $L_1$-regularization that solves the problem under some conditions. However it often leads to sub-optimal sparsity in reality. This paper tries to remedy the above gap between theory and practice. In particular, we investigate a multi-stage convex relaxation scheme for solving problems with non-convex regularization. Theoretically, we analyze the behavior of a resulting two-stage relaxation scheme for the capped-$L_1$ regularization. Our performance bound shows that the procedure is superior to the standard $L_1$ convex relaxation for learning sparse targets. Experiments confirm the effectiveness of this method on some simulation and real data.',\n",
       "  'id': '3526',\n",
       "  'title': 'Multi-stage Convex Relaxation for Learning with Sparse Regularization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a new, massively parallel architecture for accelerating machine learning algorithms, based on arrays of variable-resolution arithmetic vector processing elements (VPE). Groups of VPEs operate in SIMD (single instruction multiple data) mode, and each group is connected to an independent memory bank. In this way memory bandwidth scales with the number of VPE, and the main data flows are local, keeping power dissipation low. With 256 VPEs, implemented on two FPGA (field programmable gate array) chips, we obtain a sustained speed of 19 GMACS (billion multiply-accumulate per sec.) for SVM training, and 86 GMACS for SVM classification. This performance is more than an order of magnitude higher than that of any FPGA implementation reported so far. The speed on one FPGA is similar to the fastest speeds published on a Graphics Processor for the MNIST problem, despite a clock rate of the FPGA that is six times lower. High performance at low clock rates makes this massively parallel architecture particularly attractive for embedded applications, where low power dissipation is critical. Tests with Convolutional Neural Networks and other learning algorithms are under way now.',\n",
       "  'id': '3527',\n",
       "  'title': 'A Massively Parallel Digital Learning Processor',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Accounts of how people learn functional relationships between continuous variables have tended to focus on two possibilities: that people are estimating explicit functions, or that they are simply performing associative learning supported by similarity. We provide a rational analysis of function learning, drawing on work on regression in machine learning and statistics. Using the equivalence of Bayesian linear regression and Gaussian processes, we show that learning explicit rules and using similarity can be seen as two views of one solution to this problem. We use this insight to define a Gaussian process model of human function learning that combines the strengths of both approaches.',\n",
       "  'id': '3529',\n",
       "  'title': 'Modeling human function learning with Gaussian processes',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a mixture model whose components are Restricted Boltzmann Machines (RBMs). This possibility has not been considered before because computing the partition function of an RBM is intractable, which appears to make learning a mixture of RBMs intractable as well. Surprisingly, when formulated as a third-order Boltzmann machine, such a mixture model can be learned tractably using contrastive divergence. The energy function of the model captures three-way interactions among visible units, hidden units, and a single hidden multinomial unit that represents the cluster labels. The distinguishing feature of this model is that, unlike other mixture models, the mixing proportions are not explicitly parameterized. Instead, they are defined implicitly via the energy function and depend on all the parameters in the model. We present results for the MNIST and NORB datasets showing that the implicit mixture of RBMs learns clusters that reflect the class structure in the data.',\n",
       "  'id': '3536',\n",
       "  'title': 'Implicit Mixtures of Restricted Boltzmann Machines',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The discovery of causal relationships between a set of observed variables is a fundamental problem in science. For continuous-valued data linear acyclic causal models are often used because these models are well understood and there are well-known methods to fit them to data. In reality, of course, many causal relationships are more or less nonlinear, raising some doubts as to the applicability and usefulness of purely linear methods. In this contribution we show that in fact the basic linear framework can be generalized to nonlinear models with additive noise. In this extended framework, nonlinearities in the data-generating process are in fact a blessing rather than a curse, as they typically provide information on the underlying causal system and allow more aspects of the true data-generating mechanisms to be identified. In addition to theoretical results we show simulations and some simple real data experiments illustrating the identification power provided by nonlinearities.',\n",
       "  'id': '3548',\n",
       "  'title': 'Nonlinear causal discovery with additive noise models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a sparse approximation approach for dependent output Gaussian processes (GP). Employing a latent function framework, we apply the convolution process formalism to establish dependencies between output variables, where each latent function is represented as a GP. Based on these latent functions, we establish an approximation scheme using a conditional independence assumption between the output processes, leading to an approximation of the full covariance which is determined by the locations at which the latent functions are evaluated. We show results of the proposed methodology for synthetic data and real world applications on pollution prediction and a sensor network.',\n",
       "  'id': '3553',\n",
       "  'title': 'Sparse Convolved Gaussian Processes for Multi-output Regression',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'By attempting to simultaneously partition both the rows (examples) and columns (features) of a data matrix, Co-clustering algorithms often demonstrate surpris- ingly impressive performance improvements over traditional one-sided (row) clustering techniques. A good clustering of features may be seen as a combinatorial transformation of the data matrix, effectively enforcing a form of regularization that may lead to a better clustering of examples (and vice-versa). In many applications, partial supervision in the form of a few row labels as well as column labels may be available to potentially assist co-clustering. In this paper, we develop two novel semi-supervised multi-class classification algorithms motivated respectively by spectral bipartite graph partitioning and matrix approximation (e.g., non-negative matrix factorization) formulations for co-clustering. These algorithms (i) support dual supervision in the form of labels for both examples and/or features, (ii) provide principled predictive capability on out-of-sample test data, and (iii) arise naturally from the classical Representer theorem applied to regularization problems posed on a collection of Reproducing Kernel Hilbert Spaces. Empirical results demonstrate the effectiveness and utility of our algorithms.',\n",
       "  'id': '3562',\n",
       "  'title': 'Regularized Co-Clustering with Dual Supervision',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The Temporal Restricted Boltzmann Machine (TRBM) is a probabilistic model for sequences that is able to successfully model (i.e., generate nice-looking samples of) several very high dimensional sequences, such as motion capture data and the pixels of low resolution videos of balls bouncing in a box. The major disadvantage of the TRBM is that exact inference is extremely hard, since even computing a Gibbs update for a single variable of the posterior is exponentially expensive. This difficulty has necessitated the use of a heuristic inference procedure, that nonetheless was accurate enough for successful learning. In this paper we introduce the Recurrent TRBM, which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable. We demonstrate that the RTRBM is better than an analogous TRBM at generating motion capture and videos of bouncing balls.',\n",
       "  'id': '3567',\n",
       "  'title': 'The Recurrent Temporal Restricted Boltzmann Machine',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"With the increased availability of data for complex domains, it is desirable to learn Bayesian network structures that are sufficiently expressive for generalization while also allowing for tractable inference. While the method of thin junction trees can, in principle, be used for this purpose, its fully greedy nature makes it prone to overfitting, particularly when data is scarce. In this work we present a novel method for learning Bayesian networks of bounded treewidth that employs global structure modifications and that is polynomial in the size of the graph and the treewidth bound. At the heart of our method is a triangulated graph that we dynamically update in a way that facilitates the addition of chain structures that increase the bound on the model's treewidth by at most one. We demonstrate the effectiveness of our ``treewidth-friendly'' method on several real-life datasets. Importantly, we also show that by using global operators, we are able to achieve better generalization even when learning Bayesian networks of unbounded treewidth.\",\n",
       "  'id': '3568',\n",
       "  'title': 'Learning Bounded Treewidth Bayesian Networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We report a compact realization of short-term depression (STD) in a VLSI stochastic synapse. The behavior of the circuit is based on a subtractive single release model of STD. Experimental results agree well with simulation and exhibit expected STD behavior: the transmitted spike train has negative autocorrelation and lower power spectral density at low frequencies which can remove redundancy in the input spike train, and the mean transmission probability is inversely proportional to the input spike rate which has been suggested as an automatic gain control mechanism in neural systems. The dynamic stochastic synapse could potentially be a powerful addition to existing deterministic VLSI spiking neural systems.',\n",
       "  'id': '3570',\n",
       "  'title': 'Short-Term Depression in VLSI Stochastic Synapse',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Conditional Random Sampling (CRS) was originally proposed for efficiently computing pairwise ($l_2$, $l_1$) distances, in static, large-scale, and sparse data sets such as text and Web data. It was previously presented using a heuristic argument. This study extends CRS to handle dynamic or streaming data, which much better reflect the real-world situation than assuming static data. Compared with other known sketching algorithms for dimension reductions such as stable random projections, CRS exhibits a significant advantage in that it is ``one-sketch-for-all.'' In particular, we demonstrate that CRS can be applied to efficiently compute the $l_p$ distance and the Hilbertian metrics, both are popular in machine learning. Although a fully rigorous analysis of CRS is difficult, we prove that, with a simple modification, CRS is rigorous at least for an important application of computing Hamming norms. A generic estimator and an approximate variance formula are provided and tested on various applications, for computing Hamming norms, Hamming distances, and $\\\\chi^2$ distances.\",\n",
       "  'id': '3572',\n",
       "  'title': 'One sketch for all: Theory and Application of Conditional Random Sampling',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Consider linear prediction models where the target function is a sparse linear combination of a set of basis functions. We are interested in the problem of identifying those basis functions with non-zero coefficients and reconstructing the target function from noisy observations. Two heuristics that are widely used in practice are forward and backward greedy algorithms. First, we show that neither idea is adequate. Second, we propose a novel combination that is based on the forward greedy algorithm but takes backward steps adaptively whenever beneficial. We prove strong theoretical results showing that this procedure is effective in learning sparse representations. Experimental results support our theory.',\n",
       "  'id': '3586',\n",
       "  'title': 'Adaptive Forward-Backward Greedy Algorithm for Sparse Learning with Linear Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Adaptation of visually guided reaching movements in novel visuomotor environments (e.g. wearing prism goggles) comprises not only motor adaptation but also substantial sensory adaptation, corresponding to shifts in the perceived spatial location of visual and proprioceptive cues. Previous computational models of the sensory component of visuomotor adaptation have assumed that it is driven purely by the discrepancy introduced between visual and proprioceptive estimates of hand position and is independent of any motor component of adaptation. We instead propose a unified model in which sensory and motor adaptation are jointly driven by optimal Bayesian estimation of the sensory and motor contributions to perceived errors. Our model is able to account for patterns of performance errors during visuomotor adaptation as well as the subsequent perceptual aftereffects. This unified model also makes the surprising prediction that force field adaptation will elicit similar perceptual shifts, even though there is never any discrepancy between visual and proprioceptive observations. We confirm this prediction with an experiment.',\n",
       "  'id': '3587',\n",
       "  'title': 'Unifying the Sensory and Motor Components of Sensorimotor Adaptation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Classical Game Theoretic approaches that make strong rationality assumptions have difficulty modeling observed behaviour in Economic games of human subjects. We investigate the role of finite levels of iterated reasoning and non-selfish utility functions in a Partially Observable Markov Decision Process model that incorporates Game Theoretic notions of interactivity. Our generative model captures a broad class of characteristic behaviours in a multi-round Investment game. We invert the generative process for a recognition model that is used to classify 200 subjects playing an Investor-Trustee game against randomly matched opponents.',\n",
       "  'id': '3589',\n",
       "  'title': 'Bayesian Model of Behaviour in Economic Games',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The machine learning problem of classifier design is studied from the perspective of probability elicitation, in statistics. This shows that the standard approach of proceeding from the specification of a loss, to the minimization of conditional risk is overly restrictive. It is shown that a better alternative is to start from the specification of a functional form for the minimum conditional risk, and derive the loss function. This has various consequences of practical interest, such as showing that 1) the widely adopted practice of relying on convex loss functions is unnecessary, and 2) many new losses can be derived for classification problems. These points are illustrated by the derivation of a new loss which is not convex, but does not compromise the computational tractability of classifier design, and is robust to the contamination of data with outliers. A new boosting algorithm, SavageBoost, is derived for the minimization of this loss. Experimental results show that it is indeed less sensitive to outliers than conventional methods, such as Ada, Real, or LogitBoost, and converges in fewer iterations.',\n",
       "  'id': '3591',\n",
       "  'title': 'On the Design of Loss Functions for Classification: theory, robustness to outliers, and SavageBoost',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"We consider the problem of binary classification where the classifier may abstain instead of classifying each observation. The Bayes decision rule for this setup, known as Chow's rule, is defined by two thresholds on posterior probabilities. From simple desiderata, namely the consistency and the sparsity of the classifier, we derive the double hinge loss function that focuses on estimating conditional probabilities only in the vicinity of the threshold points of the optimal decision rule. We show that, for suitable kernel machines, our approach is universally consistent. We cast the problem of minimizing the double hinge loss as a quadratic program akin to the standard SVM optimization problem and propose an active set method to solve it efficiently. We finally provide preliminary experimental results illustrating the interest of our constructive approach to devising loss functions.\",\n",
       "  'id': '3594',\n",
       "  'title': 'Support Vector Machines with a Reject Option',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider a generalization of stochastic bandit problems where the set of arms, X, is allowed to be a generic topological space. We constraint the mean-payoff function with a dissimilarity function over X in a way that is more general than Lipschitz. We construct an arm selection policy whose regret improves upon previous result for a large class of problems. In particular, our results imply that if X is the unit hypercube in a Euclidean space and the mean-payoff function has a finite number of global maxima around which the behavior of the function is locally H?lder with a known exponent, then the expected regret is bounded up to a logarithmic factor by $n$, i.e., the rate of the growth of the regret is independent of the dimension of the space. Moreover, we prove the minimax optimality of our algorithm for the class of mean-payoff functions we consider.',\n",
       "  'id': '3605',\n",
       "  'title': 'Online Optimization in X-Armed Bandits',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Cell assemblies exhibiting episodes of recurrent coherent activity have been observed in several brain regions including the striatum and hippocampus CA3. Here we address the question of how coherent dynamically switching assemblies appear in large networks of biologically realistic spiking neurons interacting deterministically. We show by numerical simulations of large asymmetric inhibitory networks with fixed external excitatory drive that if the network has intermediate to sparse connectivity, the individual cells are in the vicinity of a bifurcation between a quiescent and firing state and the network inhibition varies slowly on the spiking timescale, then cells form assemblies whose members show strong positive correlation, while members of different assemblies show strong negative correlation. We show that cells and assemblies switch between firing and quiescent states with time durations consistent with a power-law. Our results are in good qualitative agreement with the experimental studies. The deterministic dynamical behaviour is related to winner-less competition shown in small closed loop inhibitory networks with heteroclinic cycles connecting saddle-points.',\n",
       "  'id': '3610',\n",
       "  'title': 'Cell Assemblies in Large Sparse Inhibitory Networks of Biologically Realistic Spiking Neurons',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The stochastic approximation method is behind the solution to many important, actively-studied problems in machine learning. Despite its far-reaching application, there is almost no work on applying stochastic approximation to learning problems with constraints. The reason for this, we hypothesize, is that no robust, widely-applicable stochastic approximation method exists for handling such problems. We propose that interior-point methods are a natural solution. We establish the stability of a stochastic interior-point approximation method both analytically and empirically, and demonstrate its utility by deriving an on-line learning algorithm that also performs feature selection via L1 regularization.',\n",
       "  'id': '3614',\n",
       "  'title': 'An interior-point stochastic approximation method and an L1-regularized delta rule',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduce the first temporal-difference learning algorithm that is stable with linear function approximation and off-policy training, for any finite Markov decision process, target policy, and exciting behavior policy, and whose complexity scales linearly in the number of parameters. We consider an i.i.d.\\\\ policy-evaluation setting in which the data need not come from on-policy experience. The gradient temporal-difference (GTD) algorithm estimates the expected update vector of the TD(0) algorithm and performs stochastic gradient descent on its L_2 norm. Our analysis proves that its expected update is in the direction of the gradient, assuring convergence under the usual stochastic approximation conditions to the same least-squares solution as found by the LSTD, but without its quadratic computational complexity. GTD is online and incremental, and does not involve multiplying by products of likelihood ratios as in importance-sampling methods.',\n",
       "  'id': '3626',\n",
       "  'title': 'A Convergent ',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a generative model for performing sparse probabilistic projections, which includes sparse principal component analysis and sparse canonical correlation analysis as special cases. Sparsity is enforced by means of automatic relevance determination or by imposing appropriate prior distributions, such as generalised hyperbolic distributions. We derive a variational Expectation-Maximisation algorithm for the estimation of the hyperparameters and show that our novel probabilistic approach compares favourably to existing techniques. We illustrate how the proposed method can be applied in the context of cryptoanalysis as a pre-processing tool for the construction of template attacks.',\n",
       "  'id': '3380',\n",
       "  'title': 'Sparse probabilistic projections',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We derive risk bounds for the randomized classifiers in Sample Compressions settings where the classifier-specification utilizes two sources of information viz. the compression set and the message string. By extending the recently proposed Occam???s Hammer principle to the data-dependent settings, we derive point-wise versions of the bounds on the stochastic sample compressed classifiers and also recover the corresponding classical PAC-Bayes bound. We further show how these compare favorably to the existing results.',\n",
       "  'id': '3388',\n",
       "  'title': 'Risk Bounds for Randomized Sample Compressed Classifiers',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Mixture of Gaussian processes models extended a single Gaussian process with ability of modeling multi-modal data and reduction of training complexity. Previous inference algorithms for these models are mostly based on Gibbs sampling, which can be very slow, particularly for large-scale data sets. We present a new generative mixture of experts model. Each expert is still a Gaussian process but is reformulated by a linear model. This breaks the dependency among training outputs and enables us to use a much faster variational Bayesian algorithm for training. Our gating network is more flexible than previous generative approaches as inputs for each expert are modeled by a Gaussian mixture model. The number of experts and number of Gaussian components for an expert are inferred automatically. A variety of tests show the advantages of our method.',\n",
       "  'id': '3395',\n",
       "  'title': 'Variational Mixture of Gaussian Process Experts',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Embeddings of random variables in reproducing kernel Hilbert spaces (RKHSs) may be used to conduct statistical inference based on higher order moments. For sufficiently rich (characteristic) RKHSs, each probability distribution has a unique embedding, allowing all statistical properties of the distribution to be taken into consideration. Necessary and sufficient conditions for an RKHS to be characteristic exist for $\\\\R^n$. In the present work, conditions are established for an RKHS to be characteristic on groups and semigroups. Illustrative examples are provided, including characteristic kernels on periodic domains, rotation matrices, and $\\\\R^n_+$.',\n",
       "  'id': '3396',\n",
       "  'title': 'Characteristic Kernels on Groups and Semigroups',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'For undiscounted reinforcement learning in Markov decision processes (MDPs) we consider the total regret of a learning algorithm with respect to an optimal policy. In order to describe the transition structure of an MDP we propose a new parameter: An MDP has diameter D if for any pair of states s1,s2 there is a policy which moves from s1 to s2 in at most D steps (on average). We present a reinforcement learning algorithm with total regret O(DSAT) after T steps for any unknown MDP with S states, A actions per state, and diameter D. This bound holds with high probability. We also present a corresponding lower bound of Omega(DSAT) on the total regret of any learning algorithm. Both bounds demonstrate the utility of the diameter as structural parameter of the MDP.',\n",
       "  'id': '3401',\n",
       "  'title': 'Near-optimal Regret Bounds for Reinforcement Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Learning in real-time applications, e.g., online approximation of the inverse dynamics model for model-based robot control, requires fast online regression techniques. Inspired by local learning, we propose a method to speed up standard Gaussian Process regression (GPR) with local GP models (LGP). The training data is partitioned in local regions, for each an individual GP model is trained. The prediction for a query point is performed by weighted estimation using nearby local models. Unlike other GP approximations, such as mixtures of experts, we use a distance based measure for partitioning of the data and weighted prediction. The proposed method achieves online learning and prediction in real-time. Comparisons with other nonparametric regression methods show that LGP has higher accuracy than LWPR and close to the performance of standard GPR and nu-SVR.',\n",
       "  'id': '3403',\n",
       "  'title': 'Local Gaussian Process Regression for Real Time Online Model Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper is devoted to thoroughly investigating how to bootstrap the ROC curve, a widely used visual tool for evaluating the accuracy of test/scoring statistics in the bipartite setup. The issue of confidence bands for the ROC curve is considered and a resampling procedure based on a smooth version of the empirical distribution called the smoothed bootstrap\" is introduced. Theoretical arguments and simulation results are presented to show that the \"smoothed bootstrap\" is preferable to a \"naive\" bootstrap in order to construct accurate confidence bands.\"',\n",
       "  'id': '3404',\n",
       "  'title': 'On Bootstrapping the ROC Curve',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Covariance estimation for high dimensional vectors is a classically difficult problem in statistical analysis and machine learning due to limited sample size. In this paper, we propose a new approach to covariance estimation, which is based on constrained maximum likelihood (ML) estimation of the covariance. Specifically, the covariance is constrained to have an eigen decomposition which can be represented as a sparse matrix transform (SMT). The SMT is formed by a product of pairwise coordinate rotations known as Givens rotations. Using this framework, the covariance can be efficiently estimated using greedy minimization of the log likelihood function, and the number of Givens rotations can be efficiently computed using a cross-validation procedure. The estimator obtained using this method is always positive definite and well-conditioned even with limited sample size. Experiments on hyperspectral data show that SMT covariance estimation results in consistently better estimates of the covariance for a variety of different classes and sample sizes compared to traditional shrinkage estimators.',\n",
       "  'id': '3409',\n",
       "  'title': 'Covariance Estimation for High Dimensional Data Vectors Using the Sparse Matrix Transform',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present the Gaussian Process Density Sampler (GPDS), an exchangeable generative model for use in nonparametric Bayesian density estimation. Samples drawn from the GPDS are consistent with exact, independent samples from a fixed density function that is a transformation of a function drawn from a Gaussian process prior. Our formulation allows us to infer an unknown density from data using Markov chain Monte Carlo, which gives samples from the posterior distribution over density functions and from the predictive distribution on data space. We can also infer the hyperparameters of the Gaussian process. We compare this density modeling technique to several existing techniques on a toy problem and a skull-reconstruction task.',\n",
       "  'id': '3410',\n",
       "  'title': 'The Gaussian Process Density Sampler',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"We present a characterization of a useful class of skills based on a graphical representation of an agent's interaction with its environment. Our characterization uses betweenness, a measure of centrality on graphs. It may be used directly to form a set of skills suitable for a given environment. More importantly, it serves as a useful guide for developing online, incremental skill discovery algorithms that do not rely on knowing or representing the environment graph in its entirety.\",\n",
       "  'id': '3411',\n",
       "  'title': 'Skill Characterization Based on Betweenness',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Detecting underlying clusters from large-scale data plays a central role in machine learning research. In this paper, we attempt to tackle clustering problems for complex data of multiple distributions and large multi-scales. To this end, we develop an algorithm named Zeta $l$-links, or Zell which consists of two parts: Zeta merging with a similarity graph and an initial set of small clusters derived from local $l$-links of the graph. More specifically, we propose to structurize a cluster using cycles in the associated subgraph. A mathematical tool, Zeta function of a graph, is introduced for the integration of all cycles, leading to a structural descriptor of the cluster in determinantal form. The popularity character of the cluster is conceptualized as the global fusion of variations of the structural descriptor by means of the leave-one-out strategy in the cluster. Zeta merging proceeds, in the agglomerative fashion, according to the maximum incremental popularity among all pairwise clusters. Experiments on toy data, real imagery data, and real sensory data show the promising performance of Zell. The $98.1\\\\%$ accuracy, in the sense of the normalized mutual information, is obtained on the FRGC face data of 16028 samples and 466 facial clusters. The MATLAB codes of Zell will be made publicly available for peer evaluation.',\n",
       "  'id': '3412',\n",
       "  'title': 'Cyclizing Clusters via Zeta Function of a Graph',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Query expansion is a long-studied approach for improving retrieval effectiveness by enhancing the user???s original query with additional related terms. Current algorithms for automatic query expansion have been shown to consistently improve retrieval accuracy on average, but are highly unstable and have bad worst-case performance for individual queries. We introduce a novel risk framework that formulates query model estimation as a constrained metric labeling problem on a graph of term relations. Themodel combines assignment costs based on a baseline feedback algorithm, edge weights based on term similarity, and simple constraints to enforce aspect balance, aspect coverage, and term centrality. Results across multiple standard test collections show consistent and dramatic reductions in the number and magnitude of expansion failures, while retaining the strong positive gains of the baseline algorithm.',\n",
       "  'id': '3413',\n",
       "  'title': 'Estimating Robust Query Models with Convex Optimization',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"We propose a novel bound on single-variable marginal probability distributions in factor graphs with discrete variables. The bound is obtained by propagating bounds (convex sets of probability distributions) over a subtree of the factor graph, rooted in the variable of interest. By construction, the method not only bounds the exact marginal probability distribution of a variable, but also its approximate Belief Propagation marginal (``belief''). Thus, apart from providing a practical means to calculate bounds on marginals, our contribution also lies in providing a better understanding of the error made by Belief Propagation. We show that our bound outperforms the state-of-the-art on some inference problems arising in medical diagnosis.\",\n",
       "  'id': '3415',\n",
       "  'title': 'Bounds on marginal probability distributions',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We analyze the estimation of information theoretic measures of continuous random variables such as: differential entropy, mutual information or Kullback-Leibler divergence. The objective of this paper is two-fold. First, we prove that the information theoretic measure estimates using the k-nearest-neighbor density estimation with fixed k converge almost surely, even though the k-nearest-neighbor density estimation with fixed k does not converge to its true measure. Second, we show that the information theoretic measure estimates do not converge for k growing linearly with the number of samples. Nevertheless, these nonconvergent estimates can be used for solving the two-sample problem and assessing if two random variables are independent. We show that the two-sample and independence tests based on these nonconvergent estimates compare favorably with the maximum mean discrepancy test and the Hilbert Schmidt independence criterion, respectively.',\n",
       "  'id': '3417',\n",
       "  'title': 'Estimation of Information Theoretic Measures for Continuous Random Variables',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper describes a recursive estimation procedure for multivariate binary densities using orthogonal expansions. For $d$ covariates, there are $2^d$ basis coefficients to estimate, which renders conventional approaches computationally prohibitive when $d$ is large. However, for a wide class of densities that satisfy a certain sparsity condition, our estimator runs in probabilistic polynomial time and adapts to the unknown sparsity of the underlying density in two key ways: (1) it attains near-minimax mean-squared error, and (2) the computational complexity is lower for sparser densities. Our method also allows for flexible control of the trade-off between mean-squared error and computational complexity.',\n",
       "  'id': '3424',\n",
       "  'title': 'Near-minimax recursive density estimation on the binary hypercube',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We formulate the problem of bipartite graph inference as a supervised learning problem, and propose a new method to solve it from the viewpoint of distance metric learning. The method involves the learning of two mappings of the heterogeneous objects to a unified Euclidean space representing the network topology of the bipartite graph, where the graph is easy to infer. The algorithm can be formulated as an optimization problem in a reproducing kernel Hilbert space. We report encouraging results on the problem of compound-protein interaction network reconstruction from chemical structure data and genomic sequence data.',\n",
       "  'id': '3428',\n",
       "  'title': 'Supervised Bipartite Graph Inference',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The visual and auditory map alignment in the Superior Colliculus (SC) of barn owl is important for its accurate localization for prey behavior. Prism learning or Blindness may interfere this alignment and cause loss of the capability of accurate prey. However, juvenile barn owl could recover its sensory map alignment by shifting its auditory map. The adaptation of this map alignment is believed based on activity dependent axon developing in Inferior Colliculus (IC). A model is built to explore this mechanism. In this model, axon growing process is instructed by an inhibitory network in SC while the strength of the inhibition adjusted by Spike Timing Dependent Plasticity (STDP). We test and analyze this mechanism by application of the neural structures involved in spatial localization in a robotic system.',\n",
       "  'id': '3439',\n",
       "  'title': 'Bio-inspired Real Time Sensory Map Realignment in a Robotic Barn Owl',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many machine learning algorithms can be formulated in the framework of statistical independence such as the Hilbert Schmidt Independence Criterion. In this paper, we extend this criterion to deal with with structured and interdependent observations. This is achieved by modeling the structures using undirected graphical models and comparing the Hilbert space embeddings of distributions. We apply this new criterion to independent component analysis and sequence clustering.',\n",
       "  'id': '3440',\n",
       "  'title': 'Kernel Measures of Independence for non-iid Data',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper we consider approximate policy-iteration-based reinforcement learning algorithms. In order to implement a flexible function approximation scheme we propose the use of non-parametric methods with regularization, providing a convenient way to control the complexity of the function approximator. We propose two novel regularized policy iteration algorithms by adding L2-regularization to two widely-used policy evaluation methods: Bellman residual minimization (BRM) and least-squares temporal difference learning (LSTD). We derive efficient implementation for our algorithms when the approximate value-functions belong to a reproducing kernel Hilbert space. We also provide finite-sample performance bounds for our algorithms and show that they are able to achieve optimal rates of convergence under the studied conditions.',\n",
       "  'id': '3445',\n",
       "  'title': 'Regularized Policy Iteration',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Recent research suggests that neural systems employ sparse coding. However, there is limited theoretical understanding of fundamental resolution limits in such sparse coding. This paper considers a general sparse estimation problem of detecting the sparsity pattern of a $k$-sparse vector in $\\\\R^n$ from $m$ random noisy measurements. Our main results provide necessary and sufficient conditions on the problem dimensions, $m$, $n$ and $k$, and the signal-to-noise ratio (SNR) for asymptotically-reliable detection. We show a necessary condition for perfect recovery at any given SNR for all algorithms, regardless of complexity, is $m = \\\\Omega(k\\\\log(n-k))$ measurements. This is considerably stronger than all previous necessary conditions. We also show that the scaling of $\\\\Omega(k\\\\log(n-k))$ measurements is sufficient for a trivial ``maximum correlation'' estimator to succeed. Hence this scaling is optimal and does not require lasso, matching pursuit, or more sophisticated methods, and the optimal scaling can thus be biologically plausible.\",\n",
       "  'id': '3447',\n",
       "  'title': 'Resolution Limits of Sparse Coding in High Dimensions',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a novel method for inducing synchronous context free grammars (SCFGs) from a corpus of parallel string pairs. SCFGs can model equivalence between strings in terms of substitutions, insertions and deletions, and the reordering of sub-strings. We develop a non-parametric Bayesian model and apply it to a machine translation task, using priors to replace the various heuristics commonly used in this field. Using a variational Bayes training procedure, we learn the latent structure of translation equivalence through the induction of synchronous grammar categories for phrasal translations, showing improvements in translation performance over previously proposed maximum likelihood models.',\n",
       "  'id': '3453',\n",
       "  'title': 'Bayesian Synchronous Grammar Induction',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Psychophysical experiments show that humans are better at perceiving rotation and expansion than translation. These findings are inconsistent with standard models of motion integration which predict best performance for translation [6]. To explain this discrepancy, our theory formulates motion perception at two levels of inference: we first perform model selection between the competing models (e.g. translation, rotation, and expansion) and then estimate the velocity using the selected model. We define novel prior models for smooth rotation and expansion using techniques similar to those in the slow-and-smooth model [17] (e.g. Green functions of differential operators). The theory gives good agreement with the trends observed in human experiments.',\n",
       "  'id': '3458',\n",
       "  'title': 'Model selection and velocity estimation using novel priors for motion patterns',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Kernel supervised learning methods can be unified by utilizing the tools from regularization theory. The duality between regularization and prior leads to interpreting regularization methods in terms of maximum a posteriori estimation and has motivated Bayesian interpretations of kernel methods. In this paper we pursue a Bayesian interpretation of sparsity in the kernel setting by making use of a mixture of a point-mass distribution and prior that we refer to as ``Silverman's g-prior.'' We provide a theoretical analysis of the posterior consistency of a Bayesian model choice procedure based on this prior. We also establish the asymptotic relationship between this procedure and the Bayesian information criterion.\",\n",
       "  'id': '3462',\n",
       "  'title': 'Posterior Consistency of the Silverman g-prior in Bayesian Model Choice',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by almost isometric\" transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times.\"',\n",
       "  'id': '3464',\n",
       "  'title': 'Robust Near-Isometric Matching via Structured Learning of Graphical Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Cognitive control refers to the flexible deployment of memory and attention in response to task demands and current goals. Control is often studied experimentally by presenting sequences of stimuli, some demanding a response, and others modulating the stimulus-response mapping. In these tasks, participants must maintain information about the current stimulus-response mapping in working memory. Prominent theories of cognitive control use recurrent neural nets to implement working memory, and optimize memory utilization via reinforcement learning. We present a novel perspective on cognitive control in which working memory representations are intrinsically probabilistic, and control operations that maintain and update working memory are dynamically determined via probabilistic inference. We show that our model provides a parsimonious account of behavioral and neuroimaging data, and suggest that it offers an elegant conceptualization of control in which behavior can be cast as optimal, subject to limitations on learning and the rate of information processing. Moreover, our model provides insight into how task instructions can be directly translated into appropriate behavior and then efficiently refined with subsequent task experience.',\n",
       "  'id': '3474',\n",
       "  'title': 'Temporal Dynamics of Cognitive Control',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'From an information-theoretic perspective, a noisy transmission system such as a visual Brain-Computer Interface (BCI) speller could benefit from the use of error-correcting codes. However, optimizing the code solely according to the maximal minimum-Hamming-distance criterion tends to lead to an overall increase in target frequency of target stimuli, and hence a significantly reduced average target-to-target interval (TTI), leading to difficulties in classifying the individual event-related potentials (ERPs) due to overlap and refractory effects. Clearly any change to the stimulus setup must also respect the possible psychophysiological consequences. Here we report new EEG data from experiments in which we explore stimulus types and codebooks in a within-subject design, finding an interaction between the two factors. Our data demonstrate that the traditional, row-column code has particular spatial properties that lead to better performance than one would expect from its TTIs and Hamming-distances alone, but nonetheless error-correcting codes can improve performance provided the right stimulus type is used.',\n",
       "  'id': '3476',\n",
       "  'title': 'Effects of Stimulus Type and of Error-Correcting Code Design on BCI Speller Performance',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Identification and comparison of nonlinear dynamical systems using noisy and sparse experimental data is a vital task in many fields, however current methods are computationally expensive and prone to error due in part to the nonlinear nature of the likelihood surfaces induced. We present an accelerated sampling procedure which enables Bayesian inference of parameters in nonlinear ordinary and delay differential equations via the novel use of Gaussian processes (GP). Our method involves GP regression over time-series data, and the resulting derivative and time delay estimates make parameter inference possible without solving the dynamical system explicitly, resulting in dramatic savings of computational time. We demonstrate the speed and statistical accuracy of our approach using examples of both ordinary and delay differential equations, and provide a comprehensive comparison with current state of the art methods.',\n",
       "  'id': '3497',\n",
       "  'title': 'Accelerating Bayesian Inference over Nonlinear Differential Equations with Gaussian Processes',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the iedb MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non convex methods dedicated to the same problem.',\n",
       "  'id': '3499',\n",
       "  'title': 'Clustered Multi-Task Learning: A Convex Formulation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Markov Decision Processes (MDPs) have been extensively studied and used in the context of planning and decision-making, and many methods exist to find the optimal policy for problems modelled as MDPs. Although finding the optimal policy is sufficient in many domains, in certain applications such as decision support systems where the policy is executed by a human (rather than a machine), finding all possible near-optimal policies might be useful as it provides more flexibility to the person executing the policy. In this paper we introduce the new concept of non-deterministic MDP policies, and address the question of finding near-optimal non-deterministic policies. We propose two solutions to this problem, one based on a Mixed Integer Program and the other one based on a search algorithm. We include experimental results obtained from applying this framework to optimize treatment choices in the context of a medical decision support system.',\n",
       "  'id': '3504',\n",
       "  'title': 'MDPs with Non-Deterministic Policies',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Actor-critic algorithms for reinforcement learning are achieving renewed popularity due to their good convergence properties in situations where other approaches often fail (e.g., when function approximation is involved). Interestingly, there is growing evidence that actor-critic approaches based on phasic dopamine signals play a key role in biological learning through the cortical and basal ganglia. We derive a temporal difference based actor critic learning algorithm, for which convergence can be proved without assuming separate time scales for the actor and the critic. The approach is demonstrated by applying it to networks of spiking neurons. The established relation between phasic dopamine and the temporal difference signal lends support to the biological relevance of such algorithms.',\n",
       "  'id': '3517',\n",
       "  'title': 'Temporal Difference Based Actor Critic Learning - Convergence and Neural Implementation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider the problem of efficiently encoding a signal by transforming it to a new representation whose components are statistically independent. A widely studied linear solution, independent components analysis (ICA), exists for the case when the signal is generated as a linear transformation of independent non- Gaussian sources. Here, we examine a complementary case, in which the source is non-Gaussian but elliptically symmetric. In this case, no linear transform suffices to properly decompose the signal into independent components, but we show that a simple nonlinear transformation, which we call radial Gaussianization (RG), is able to remove all dependencies. We then demonstrate this methodology in the context of natural signal statistics. We first show that the joint distributions of bandpass filter responses, for both sound and images, are better described as elliptical than linearly transformed independent sources. Consistent with this, we demonstrate that the reduction in dependency achieved by applying RG to either pairs or blocks of bandpass filter responses is significantly greater than that achieved by PCA or ICA.',\n",
       "  'id': '3521',\n",
       "  'title': 'Reducing statistical dependencies in natural signals using radial Gaussianization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Bandpass filtering, orientation selectivity, and contrast gain control are prominent features of sensory coding at the level of V1 simple cells. While the effect of bandpass filtering and orientation selectivity can be assessed within a linear model, contrast gain control is an inherently nonlinear computation. Here we employ the class of $L_p$ elliptically contoured distributions to investigate the extent to which the two features---orientation selectivity and contrast gain control---are suited to model the statistics of natural images. Within this framework we find that contrast gain control can play a significant role for the removal of redundancies in natural images. Orientation selectivity, in contrast, has only a very limited potential for redundancy reduction.',\n",
       "  'id': '3530',\n",
       "  'title': 'The Conjoint Effect of Divisive Normalization and Orientation Selectivity on Redundancy Reduction',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Principal Components Analysis (PCA) has become established as one of the key tools for dimensionality reduction when dealing with real valued data. Approaches such as exponential family PCA and non-negative matrix factorisation have successfully extended PCA to non-Gaussian data types, but these techniques fail to take advantage of Bayesian inference and can suffer from problems of overfitting and poor generalisation. This paper presents a fully probabilistic approach to PCA, which is generalised to the exponential family, based on Hybrid Monte Carlo sampling. We describe the model which is based on a factorisation of the observed data matrix, and show performance of the model on both synthetic and real data.',\n",
       "  'id': '3532',\n",
       "  'title': 'Bayesian Exponential Family PCA',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Integrating semantic and syntactic analysis is essential for document analysis. Using an analogous reasoning, we present an approach that combines bag-of-words and spatial models to perform semantic and syntactic analysis for recognition of an object based on its internal appearance and its context. We argue that while object recognition requires modeling relative spatial locations of image features within the object, a bag-of-word is sufficient for representing context. Learning such a model from weakly labeled data involves labeling of features into two classes: foreground(object) or ''informative'' background(context). labeling. We present a ''shape-aware'' model which utilizes contour information for efficient and accurate labeling of features in the image. Our approach iterates between an MCMC-based labeling and contour based labeling of features to integrate co-occurrence of features and shape similarity.\",\n",
       "  'id': '3533',\n",
       "  'title': \"A ``Shape Aware'' Model for semi-supervised Learning of Objects and its Context\",\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In classification problems, Support Vector Machines maximize the margin of separation between two classes. While the paradigm has been successful, the solution obtained by SVMs is dominated by the directions with large data spread and biased to separate the classes by cutting along large spread directions. This article proposes a novel formulation to overcome such sensitivity and maximizes the margin relative to the spread of the data. The proposed formulation can be efficiently solved and experiments on digit datasets show drastic performance improvements over SVMs.',\n",
       "  'id': '3534',\n",
       "  'title': 'Relative Margin Machines',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper we focus on training deep neural networks for visual recognition tasks. One challenge is the lack of an informative regularization on the network parameters, to imply a meaningful control on the computed function. We propose a training strategy that takes advantage of kernel methods, where an existing kernel function represents useful prior knowledge about the learning task of interest. We derive an efficient algorithm using stochastic gradient descent, and demonstrate very positive results in a wide range of visual recognition tasks.',\n",
       "  'id': '3541',\n",
       "  'title': 'Deep Learning with Kernel Regularization for Visual Recognition',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"The essence of exploration is acting to try to decrease uncertainty. We propose a new methodology for representing uncertainty in continuous-state control problems. Our approach, multi-resolution exploration (MRE), uses a hierarchical mapping to identify regions of the state space that would benefit from additional samples. We demonstrate MRE's broad utility by using it to speed up learning in a prototypical model-based and value-based reinforcement-learning method. Empirical results show that MRE improves upon state-of-the-art exploration approaches.\",\n",
       "  'id': '3557',\n",
       "  'title': 'Multi-resolution Exploration in Continuous Spaces',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Language comprehension in humans is significantly constrained by memory, yet rapid, highly incremental, and capable of utilizing a wide range of contextual information to resolve ambiguity and form expectations about future input. In contrast, most of the leading psycholinguistic models and fielded algorithms for natural language parsing are non-incremental, have run time superlinear in input length, and/or enforce structural locality constraints on probabilistic dependencies between events. We present a new limited-memory model of sentence comprehension which involves an adaptation of the particle filter, a sequential Monte Carlo method, to the problem of incremental parsing. We show that this model can reproduce classic results in online sentence comprehension, and that it naturally provides the first rational account of an outstanding problem in psycholinguistics, in which the preferred alternative in a syntactic ambiguity seems to grow more attractive over time even in the absence of strong disambiguating information.',\n",
       "  'id': '3573',\n",
       "  'title': 'Modeling the effects of memory on human online sentence processing with particle filters',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Contours have been established in the biological and computer vision literatures as a compact yet descriptive representation of object shape. While individual contours provide structure, they lack the large spatial support of region segments (which lack internal structure). We present a method for further grouping of contours in an image using their relationship to the contours of a second, related image. Stereo, motion, and similarity all provide cues that can aid this task; contours that have similar transformations relating them to their matching contours in the second image likely belong to a single group. To find matches for contours, we rely only on shape, which applies directly to all three modalities without modification, in constrant to the specialized approaches developed for each independently. Visually salient contours are extracted in each image, along with a set of candidate transformations for aligning subsets of them. For each transformation, groups of contours with matching shape across the two images are identified to provide a context for evaluating matches of individual contour points across the images. The resulting contexts of contours are used to perform a final grouping on contours in the original image while simultaneously finding matches in the related image, again by shape matching. We demonstrate grouping results on image pairs consisting of stereo, motion, and similar images. Our method also produces qualitatively better results against a baseline method that does not use the inferred contexts.',\n",
       "  'id': '3576',\n",
       "  'title': 'Grouping Contours Via a Related Image',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Unexpected stimuli are a challenge to any machine learning algorithm. Here we identify distinct types of unexpected events, focusing on 'incongruent events' - when 'general level' and 'specific level' classifiers give conflicting predictions. We define a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy . An incongruent event is an event where the probability computed based on some more specific level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conflicting predictions. We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. Respectively, we show promising results with real data on two specific problems: Out Of Vocabulary words in speech recognition, and the identification of a new sub-class (e.g., the face of a new individual) in audio-visual facial object recognition.\",\n",
       "  'id': '3581',\n",
       "  'title': 'Beyond Novelty Detection: Incongruent Events, when General and Specific Classifiers Disagree',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"``How is information decoded in the brain?'' is one of the most difficult and important questions in neuroscience. Whether neural correlation is important or not in decoding neural activities is of special interest. We have developed a general framework for investigating how far the decoding process in the brain can be simplified. First, we hierarchically construct simplified probabilistic models of neural responses that ignore more than $K$th-order correlations by using a maximum entropy principle. Then, we compute how much information is lost when information is decoded using the simplified models, i.e., ``mismatched decoders''. We introduce an information theoretically correct quantity for evaluating the information obtained by mismatched decoders. We applied our proposed framework to spike data for vertebrate retina. We used 100-ms natural movies as stimuli and computed the information contained in neural activities about these movies. We found that the information loss is negligibly small in population activities of ganglion cells even if all orders of correlation are ignored in decoding. We also found that if we assume stationarity for long durations in the information analysis of dynamically changing stimuli like natural movies, pseudo correlations seem to carry a large portion of the information.\",\n",
       "  'id': '3582',\n",
       "  'title': 'A general framework for investigating how far the decoding process in the brain can be simplified',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a simple new Monte Carlo algorithm for evaluating probabilities of observations in complex latent variable models, such as Deep Belief Networks. While the method is based on Markov chains, estimates based on short runs are formally unbiased. In expectation, the log probability of a test set will be underestimated, and this could form the basis of a probabilistic bound. The method is much cheaper than gold-standard annealing-based methods and only slightly more expensive than the cheapest Monte Carlo methods. We give examples of the new method substantially improving simple variational bounds at modest extra cost.',\n",
       "  'id': '3584',\n",
       "  'title': 'Evaluating probabilities under high-dimensional latent variable models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose a general method called truncated gradient to induce sparsity in the weights of online-learning algorithms with convex loss. This method has several essential properties. First, the degree of sparsity is continuous---a parameter controls the rate of sparsification from no sparsification to total sparsification. Second, the approach is theoretically motivated, and an instance of it can be regarded as an online counterpart of the popular $L_1$-regularization method in the batch setting. We prove that small rates of sparsification result in only small additional regret with respect to typical online-learning guarantees. Finally, the approach works well empirically. We apply it to several datasets and find that for datasets with large numbers of features, substantial sparsity is discoverable.',\n",
       "  'id': '3585',\n",
       "  'title': 'Sparse Online Learning via Truncated Gradient',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many human interactions involve pieces of information being passed from one person to another, raising the question of how this process of information transmission is affected by the capacities of the agents involved. In the 1930s, Sir Frederic Bartlett explored the influence of memory biases in ???serial reproduction??? of information, in which one person???s reconstruction of a stimulus from memory becomes the stimulus seen by the next person. These experiments were done using relatively uncontrolled stimuli such as pictures and stories, but suggested that serial reproduction would transform information in a way that reflected the biases inherent in memory. We formally analyze serial reproduction using a Bayesian model of reconstruction from memory, giving a general result characterizing the effect of memory biases on information transmission. We then test the predictions of this account in two experiments using simple one-dimensional stimuli. Our results provide theoretical and empirical justification for the idea that serial reproduction reflects memory biases.',\n",
       "  'id': '3588',\n",
       "  'title': 'How memory biases affect information transmission: A rational analysis of serial reproduction',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The coding of information by neural populations depends critically on the statistical dependencies between neuronal responses. However, there is no simple model that combines the observations that (1) marginal distributions over single-neuron spike counts are often approximately Poisson; and (2) joint distributions over the responses of multiple neurons are often strongly dependent. Here, we show that both marginal and joint properties of neural responses can be captured using Poisson copula models. Copulas are joint distributions that allow random variables with arbitrary marginals to be combined while incorporating arbitrary dependencies between them. Different copulas capture different kinds of dependencies, allowing for a richer and more detailed description of dependencies than traditional summary statistics, such as correlation coefficients. We explore a variety of Poisson copula models for joint neural response distributions, and derive an efficient maximum likelihood procedure for estimating them. We apply these models to neuronal data collected in and macaque motor cortex, and quantify the improvement in coding accuracy afforded by incorporating the dependency structure between pairs of neurons.',\n",
       "  'id': '3593',\n",
       "  'title': 'Characterizing neural dependencies with copula models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider robust least-squares regression with feature-wise disturbance. We show that this formulation leads to tractable convex optimization problems, and we exhibit a particular uncertainty set for which the robust problem is equivalent to $\\\\ell_1$ regularized regression (Lasso). This provides an interpretation of Lasso from a robust optimization perspective. We generalize this robust formulation to consider more general uncertainty sets, which all lead to tractable convex optimization problems. Therefore, we provide a new methodology for designing regression algorithms, which generalize known formulations. The advantage is that robustness to disturbance is a physical property that can be exploited: in addition to obtaining new formulations, we use it directly to show sparsity properties of Lasso, as well as to prove a general consistency result for robust regression problems, including Lasso, from a unified robustness perspective.',\n",
       "  'id': '3596',\n",
       "  'title': 'Robust Regression and Lasso',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Applications of multi-class classification, such as document categorization, often appear in cost-sensitive settings. Recent work has significantly improved the state of the art by moving beyond ``flat'' classification through incorporation of class hierarchies [Cai and Hoffman 04]. We present a novel algorithm that goes beyond hierarchical classification and estimates the latent semantic space that underlies the class hierarchy. In this space, each class is represented by a prototype and classification is done with the simple nearest neighbor rule. The optimization of the semantic space incorporates large margin constraints that ensure that for each instance the correct class prototype is closer than any other. We show that our optimization is convex and can be solved efficiently for large data sets. Experiments on the OHSUMED medical journal data base yield state-of-the-art results on topic categorization.\",\n",
       "  'id': '3597',\n",
       "  'title': 'Large Margin Taxonomy Embedding for Document Categorization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We analyse matching pursuit for kernel principal components analysis by proving that the sparse subspace it produces is a sample compression scheme. We show that this bound is tighter than the KPCA bound of Shawe-Taylor et al swck-05 and highly predictive of the size of the subspace needed to capture most of the variance in the data. We analyse a second matching pursuit algorithm called kernel matching pursuit (KMP) which does not correspond to a sample compression scheme. However, we give a novel bound that views the choice of subspace of the KMP algorithm as a compression scheme and hence provide a VC bound to upper bound its future loss. Finally we describe how the same bound can be applied to other matching pursuit related algorithms.',\n",
       "  'id': '3612',\n",
       "  'title': 'Theory of matching pursuit',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We use graphical models and structure learning to explore how people learn policies in sequential decision making tasks. Studies of sequential decision-making in humans frequently find suboptimal performance relative to an ideal actor that knows the graph model that generates reward in the environment. We argue that the learning problem humans face also involves learning the graph structure for reward generation in the environment. We formulate the structure learning problem using mixtures of reward models, and solve the optimal action selection problem using Bayesian Reinforcement Learning. We show that structure learning in one and two armed bandit problems produces many of the qualitative behaviors deemed suboptimal in previous studies. Our argument is supported by the results of experiments that demonstrate humans rapidly learn and exploit new reward structure.',\n",
       "  'id': '3615',\n",
       "  'title': 'Structure Learning in Human Sequential Decision-Making',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Extensive labeled data for image annotation systems, which learn to assign class labels to image regions, is difficult to obtain. We explore a hybrid model framework for utilizing partially labeled data that integrates a generative topic model for image appearance with discriminative label prediction. We propose three alternative formulations for imposing a spatial smoothness prior on the image labels. Tests of the new models and some baseline approaches on two real image datasets demonstrate the effectiveness of incorporating the latent structure.',\n",
       "  'id': '3620',\n",
       "  'title': 'Learning Hybrid Models for Image Annotation with Partially Labeled Data',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We describe a novel stochastic process that can be used to construct a multidimensional generalization of the stick-breaking process and which is related to the classic stick breaking process described by Sethuraman1994 in one dimension. We describe how the process can be applied to relational data modeling using the de Finetti representation for infinitely and partially exchangeable arrays.',\n",
       "  'id': '3622',\n",
       "  'title': 'The Mondrian Process',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Stochastic relational models provide a rich family of choices for learning and predicting dyadic data between two sets of entities. It generalizes matrix factorization to a supervised learning problem that utilizes attributes of objects in a hierarchical Bayesian framework. Previously empirical Bayesian inference was applied, which is however not scalable when the size of either object sets becomes tens of thousands. In this paper, we introduce a Markov chain Monte Carlo (MCMC) algorithm to scale the model to very large-scale dyadic data. Both superior scalability and predictive accuracy are demonstrated on a collaborative filtering problem, which involves tens of thousands users and a half million items.',\n",
       "  'id': '3625',\n",
       "  'title': 'Stochastic Relational Models for Large-scale Dyadic Data using MCMC',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Before the age of 4 months, infants make inductive inferences about the motions of physical objects. Developmental psychologists have provided verbal accounts of the knowledge that supports these inferences, but often these accounts focus on categorical rather than probabilistic principles. We propose that infant object perception is guided in part by probabilistic principles like persistence: things tend to remain the same, and when they change they do so gradually. To illustrate this idea, we develop an ideal observer model that includes probabilistic formulations of rigidity and inertia. Like previous researchers, we suggest that rigid motions are expected from an early age, but we challenge the previous claim that expectations consistent with inertia are relatively slow to develop (Spelke et al., 1992). We support these arguments by modeling four experiments from the developmental literature.',\n",
       "  'id': '3382',\n",
       "  'title': 'An ideal observer model of infant object perception',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Semantic hashing seeks compact binary codes of datapoints so that the Hamming distance between codewords correlates with semantic similarity. Hinton et al. used a clever implementation of autoencoders to find such codes. In this paper, we show that the problem of finding a best code for a given dataset is closely related to the problem of graph partitioning and can be shown to be NP hard. By relaxing the original problem, we obtain a spectral method whose solutions are simply a subset of thresh- olded eigenvectors of the graph Laplacian. By utilizing recent results on convergence of graph Laplacian eigenvectors to the Laplace-Beltrami eigen- functions of manifolds, we show how to efficiently calculate the code of a novel datapoint. Taken together, both learning the code and applying it to a novel point are extremely simple. Our experiments show that our codes significantly outperform the state-of-the art.',\n",
       "  'id': '3383',\n",
       "  'title': 'Spectral Hashing',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many popular optimization algorithms, like the Levenberg-Marquardt algorithm (LMA), use heuristic-based controllers\\'\\' that modulate the behavior of the optimizer during the optimization process. For example, in the LMA a damping parameter is dynamically modified based on a set rules that were developed using various heuristic arguments. Reinforcement learning (RL) is a machine learning approach to learn optimal controllers by examples and thus is an obvious candidate to improve the heuristic-based controllers implicit in the most popular and heavily used optimization algorithms. Improving the performance of off-the-shelf optimizers is particularly important for time-constrained optimization problems. For example the LMA algorithm has become popular for many real-time computer vision problems, including object tracking from video, where only a small amount of time can be allocated to the optimizer on each incoming video frame. Here we show that a popular modern reinforcement learning technique using a very simply state space can dramatically improve the performance of general purpose optimizers, like the LMA. Most surprisingly the controllers learned for a particular domain appear to work very well also on very different optimization domains. For example we used RL methods to train a new controller for the damping parameter of the LMA. This controller was trained on a collection of classic, relatively small, non-linear regression problems. The modified LMA performed better than the standard LMA on these problems. Most surprisingly, it also dramatically outperformed the standard LMA on a difficult large scale computer vision problem for which it had not been trained before. Thus the controller appeared to have extracted control rules that were not just domain specific but generalized across a wide range of optimization domains.\"',\n",
       "  'id': '3386',\n",
       "  'title': 'Optimization on a Budget: A Reinforcement Learning Approach',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present polynomial-time algorithms for the exact computation of lowest- energy states, worst margin violators, partition functions, and marginals in binary undirected graphical models. Our approach provides an interesting alternative to the well-known graph cut paradigm in that it does not impose any submodularity constraints; instead we require planarity to establish a correspondence with perfect matchings in an expanded dual graph. Maximum-margin parameter estimation for a boundary detection task shows our approach to be ef&#64257;cient and effective.',\n",
       "  'id': '3390',\n",
       "  'title': 'Efficient Exact Inference in Planar Ising Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Our setting is a Partially Observable Markov Decision Process with continuous state, observation and action spaces. Decisions are based on a Particle Filter for estimating the belief state given past observations. We consider a policy gradient approach for parameterized policy optimization. For that purpose, we investigate sensitivity analysis of the performance measure with respect to the parameters of the policy, focusing on Finite Difference (FD) techniques. We show that the naive FD is subject to variance explosion because of the non-smoothness of the resampling procedure. We propose a more sophisticated FD method which overcomes this problem and establish its consistency.',\n",
       "  'id': '3397',\n",
       "  'title': 'Particle Filter-based Policy Gradient in POMDPs',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We show that the empirical minimizer of a stochastic strongly convex objective, where the stochastic component is linear, converges to the population minimizer with rate $O(1/n)$. The result applies, in particular, to the SVM objective. Thus, we get a rate of $O(1/n)$ on the convergence of the SVM objective to its infinite data limit. We demonstrate how this is essential for obtaining tight oracle inequalities for SVMs. The results extend also to strong convexity with respect to other $\\\\ellnorm_p$ norms, and so also to objectives regularized using other norms.',\n",
       "  'id': '3400',\n",
       "  'title': 'Fast Rates for Regularized Objectives',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Sampling functions in Gaussian process (GP) models is challenging because of the highly correlated posterior distribution. We describe an efficient Markov chain Monte Carlo algorithm for sampling from the posterior process of the GP model. This algorithm uses control variables which are auxiliary function values that provide a low dimensional representation of the function. At each iteration, the algorithm proposes new values for the control variables and generates the function from the conditional GP prior. The control variable input locations are found by continuously minimizing an objective function. We demonstrate the algorithm on regression and classification problems and we use it to estimate the parameters of a differential equation model of gene regulation.',\n",
       "  'id': '3414',\n",
       "  'title': 'Efficient Sampling for Gaussian Process Inference using Control Variables',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose a novel application of Formal Concept Analysis (FCA) to neural decoding: instead of just trying to figure out which stimulus was presented, we demonstrate how to explore the semantic relationships between the neural representation of large sets of stimuli. FCA provides a way of displaying and interpreting such relationships via concept lattices. We explore the effects of neural code sparsity on the lattice. We then analyze neurophysiological data from high-level visual cortical area STSa, using an exact Bayesian approach to construct the formal context needed by FCA. Prominent features of the resulting concept lattices are discussed, including indications for a product-of-experts code in real neurons.',\n",
       "  'id': '3421',\n",
       "  'title': 'Interpreting the neural code with Formal Concept Analysis',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"For many supervised learning problems, we possess prior knowledge about which features yield similar information about the target variable.  In predicting the topic of a document, we might know that two words are synonyms, or when performing image recognition, we know which pixels are adjacent.  Such synonymous or neighboring features are near-duplicates and should therefore be expected to have similar weights in a good model.  Here we present a framework for regularized learning in settings where one has prior knowledge about which features are expected to have similar and dissimilar weights.  This prior knowledge is encoded as a graph whose vertices represent features and whose edges represent similarities and dissimilarities between them.  During learning, each feature's weight is penalized by the amount it differs from the average weight of its neighbors.  For text classification, regularization using graphs of word co-occurrences outperforms manifold learning and compares favorably to other recently proposed semi-supervised learning methods.  For sentiment analysis, feature graphs constructed from declarative human knowledge, as well as from auxiliary task learning, significantly improve prediction accuracy.\",\n",
       "  'id': '3427',\n",
       "  'title': 'Regularized Learning with Networks of Features',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We develop a statistical framework for the simultaneous, unsupervised segmentation and discovery of visual object categories from image databases. Examining a large set of manually segmented scenes, we use chi--square tests to show that object frequencies and segment sizes both follow power law distributions, which are well modeled by the Pitman--Yor (PY) process. This nonparametric prior distribution leads to learning algorithms which discover an unknown set of objects, and segmentation methods which automatically adapt their resolution to each image. Generalizing previous applications of PY processes, we use Gaussian processes to discover spatially contiguous segments which respect image boundaries. Using a novel family of variational approximations, our approach produces segmentations which compare favorably to state--of--the--art methods, while simultaneously discovering categories shared among natural scenes.',\n",
       "  'id': '3435',\n",
       "  'title': 'Shared Segmentation of Natural Scenes Using Dependent Pitman-Yor Processes',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The ROC curve is known to be the golden standard for measuring performance of a test/scoring statistic regarding its capacity of discrimination between two populations in a wide variety of applications, ranging from anomaly detection in signal processing to information retrieval, through medical diagnosis. Most practical performance measures used in scoring applications such as the AUC, the local AUC, the p-norm push, the DCG and others, can be seen as summaries of the ROC curve. This paper highlights the fact that many of these empirical criteria can be expressed as (conditional) linear rank statistics. We investigate the properties of empirical maximizers of such performance criteria and provide preliminary results for the concentration properties of a novel class of random variables that we will call a linear rank process.',\n",
       "  'id': '3437',\n",
       "  'title': 'Empirical performance maximization for linear rank statistics',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Recently, supervised dimensionality reduction has been gaining attention, owing to the realization that data labels are often available and strongly suggest important underlying structures in the data. In this paper, we present a novel convex supervised dimensionality reduction approach based on exponential family PCA and provide a simple but novel form to project new testing data into the embedded space. This convex approach successfully avoids the local optima of the EM learning. Moreover, by introducing a sample-based multinomial approximation to exponential family models, it avoids the limitation of the prevailing Gaussian assumptions of standard PCA, and produces a kernelized formulation for nonlinear supervised dimensionality reduction. A training algorithm is then devised based on a subgradient bundle method, whose scalability can be gained through a coordinate descent procedure. The advantage of our global optimization approach is demonstrated by empirical results over both synthetic and real data.',\n",
       "  'id': '3442',\n",
       "  'title': 'Supervised Exponential Family Principal Component Analysis via Convex Optimization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper we present two transductive bounds on the risk of the majority vote estimated over partially labeled training sets. Our first bound is tight when the additional unlabeled training data are used in the cases where the voted classifier makes its errors on low margin observations and where the errors of the associated Gibbs classifier can accurately be estimated. In semi-supervised learning, considering the margin as an indicator of confidence constitutes the working hypothesis of algorithms which search the decision boundary on low density regions. In this case, we propose a second bound on the joint probability that the voted classifier makes an error over an example having its margin over a fixed threshold. As an application we are interested on self-learning algorithms which assign iteratively pseudo-labels to unlabeled training examples having margin above a threshold obtained from this bound. Empirical results on different datasets show the effectiveness of our approach compared to the same algorithm and the TSVM in which the threshold is fixed manually.',\n",
       "  'id': '3444',\n",
       "  'title': 'A Transductive Bound for the Voted Classifier with an Application to Semi-supervised Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Metric learning algorithms can provide useful distance functions for a variety of domains, and recent work has shown good accuracy for problems where the learner can access all distance constraints at once. However, in many real applications, constraints are only available incrementally, thus necessitating methods that can perform online updates to the learned metric. Existing online algorithms offer bounds on worst-case performance, but typically do not perform well in practice as compared to their offline counterparts. We present a new online metric learning algorithm that updates a learned Mahalanobis metric based on LogDet regularization and gradient descent. We prove theoretical worst-case performance bounds, and empirically compare the proposed method against existing online metric learning algorithms. To further boost the practicality of our approach, we develop an online locality-sensitive hashing scheme which leads to efficient updates for approximate similarity search data structures. We demonstrate our algorithm on multiple datasets and show that it outperforms relevant baselines.',\n",
       "  'id': '3446',\n",
       "  'title': 'Online Metric Learning and Fast Similarity Search',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Offline handwriting recognition---the transcription of images of handwritten text---is an interesting task, in that it combines computer vision with sequence learning. In most systems the two elements are handled separately, with sophisticated preprocessing techniques used to extract the image features and sequential models such as HMMs used to provide the transcriptions. By combining two recent innovations in neural networks---multidimensional recurrent neural networks and connectionist temporal classification---this paper introduces a globally trained offline handwriting recogniser that takes raw pixel data as input. Unlike competing systems, it does not require any alphabet specific preprocessing, and can therefore be used unchanged for any language. Evidence of its generality and power is provided by data from a recent international Arabic recognition competition, where it outperformed all entries (91.4% accuracy compared to 87.2% for the competition winner) despite the fact that neither author understands a word of Arabic.',\n",
       "  'id': '3449',\n",
       "  'title': 'Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We consider multi-armed bandit problems where the number of arms is larger than the possible number of experiments. We make a stochastic assumption on the mean-reward of a new selected arm which characterizes its probability of being a near-optimal arm. Our assumption is weaker than in previous works. We describe algorithms based on upper-confidence-bounds applied to a restricted set of randomly selected arms and provide upper-bounds on the resulting expected regret. We also derive a lower-bound which matchs (up to logarithmic factors) the upper-bound in some cases.',\n",
       "  'id': '3452',\n",
       "  'title': 'Algorithms for Infinitely Many-Armed Bandits',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We tackle the computational problem of query-conditioned search. Given a machine-learned scoring rule and a query distribution, we build a predictive index by precomputing lists of potential results sorted based on an expected score of the result over future queries. The predictive index datastructure supports an anytime algorithm for approximate retrieval of the top elements. The general approach is applicable to webpage ranking, internet advertisement, and approximate nearest neighbor search. It is particularly effective in settings where standard techniques (e.g., inverted indices) are intractable. We experimentally find substantial improvement over existing methods for internet advertisement and approximate nearest neighbors.',\n",
       "  'id': '3454',\n",
       "  'title': 'Predictive Indexing for Fast Search',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We investigate a topic at the interface of machine learning and cognitive science. Human active learning, where learners can actively query the world for information, is contrasted with passive learning from random examples. Furthermore, we compare human active learning performance with predictions from statistical learning theory. We conduct a series of human category learning experiments inspired by a machine learning task for which active and passive learning error bounds are well understood, and dramatically distinct. Our results indicate that humans are capable of actively selecting informative queries, and in doing so learn better and faster than if they are given random training data, as predicted by learning theory. However, the improvement over passive learning is not as dramatic as that achieved by machine active learning algorithms. To the best of our knowledge, this is the first quantitative study comparing human category learning in active versus passive settings.',\n",
       "  'id': '3456',\n",
       "  'title': 'Human Active Learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper examines the generalization properties of online convex programming algorithms when the loss function is Lipschitz and strongly convex. Our main result is a sharp bound, that holds with high probability, on the excess risk of the output of an online algorithm in terms of the average regret. This allows one to use recent algorithms with logarithmic cumulative regret guarantees to achieve fast convergence rates for the excess risk with high probability. The bound also solves an open problem regarding the convergence rate of {\\\\pegasos}, a recently proposed method for solving the SVM optimization problem.',\n",
       "  'id': '3457',\n",
       "  'title': 'On the Generalization Ability of Online Strongly Convex Programming Algorithms',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Regularized Least Squares (RLS) algorithms have the ability to avoid over-fitting problems and to express solutions as kernel expansions. However, we observe that the current RLS algorithms cannot provide a satisfactory interpretation even on a constant function. On the other hand, while kernel-based algorithms have been developed in such a tendency that almost all learning algorithms are kernelized or being kernelized, a basic fact is often ignored: The learned function from the data and the kernel fits the data well, but may not be consistent with the kernel. Based on these considerations and on the intuition that a good kernel-based inductive function should be consistent with both the data and the kernel, a novel learning scheme is proposed. The advantages of this scheme lie in its corresponding Representer Theorem, its strong interpretation ability about what kind of functions should not be penalized, and its promising accuracy improvements shown in a number of experiments. Furthermore, we provide a detailed technical description about heat kernels, which serves as an example for the readers to apply similar techniques for other kernels. Our work provides a preliminary step in a new direction to explore the varying consistency between inductive functions and kernels under various distributions.',\n",
       "  'id': '3460',\n",
       "  'title': 'Learning with Consistency between Inductive Functions and Kernels',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'A crucial part of developing mathematical models of how the brain works is the quantification of their success. One of the most widely-used metrics yields the percentage of the variance in the data that is explained by the model. Unfortunately, this metric is biased due to the intrinsic variability in the data. This variability is in principle unexplainable by the model. We derive a simple analytical modification of the traditional formula that significantly improves its accuracy (as measured by bias) with similar or better precision (as measured by mean-square error) in estimating the true underlying Variance Explained by the model class. Our estimator advances on previous work by a) accounting for the uncertainty in the noise estimate, b) accounting for overfitting due to free model parameters mitigating the need for a separate validation data set and c) adding a conditioning term. We apply our new estimator to binocular disparity tuning curves of a set of macaque V1 neurons and find that on a population level almost all of the variance unexplained by Gabor functions is attributable to noise.',\n",
       "  'id': '3461',\n",
       "  'title': 'An improved estimator of Variance Explained in the presence of noise',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In most cognitive and motor tasks, speed-accuracy tradeoffs are observed: Individuals can respond slowly and accurately, or quickly yet be prone to errors. Control mechanisms governing the initiation of behavioral responses are sensitive not only to task instructions and the stimulus being processed, but also to the recent stimulus history. When stimuli can be characterized on an easy-hard dimension (e.g., word frequency in a naming task), items preceded by easy trials are responded to more quickly, and with more errors, than items preceded by hard trials. We propose a rationally motivated mathematical model of this sequential adaptation of control, based on a diffusion model of the decision process in which difficulty corresponds to the drift rate for the correct response. The model assumes that responding is based on the posterior distribution over which response is correct, conditioned on the accumulated evidence. We derive this posterior as a function of the drift rate, and show that higher estimates of the drift rate lead to (normatively) faster responding. Trial-by-trial tracking of difficulty thus leads to sequential effects in speed and accuracy. Simulations show the model explains a variety of phenomena in human speeded decision making. We argue this passive statistical mechanism provides a more elegant and parsimonious account than extant theories based on elaborate control structures.',\n",
       "  'id': '3465',\n",
       "  'title': 'Optimal Response Initiation: Why Recent Experience Matters',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'ROC curves are one of the most widely used displays to evaluate performance of scoring functions. In the paper, we propose a statistical method for directly optimizing the ROC curve. The target is known to be the regression function up to an increasing transformation and this boils down to recovering the level sets of the latter. We propose to use classifiers obtained by empirical risk minimization of a weighted classification error and then to construct a scoring rule by overlaying these classifiers. We show the consistency and rate of convergence to the optimal ROC curve of this procedure in terms of supremum norm and also, as a byproduct of the analysis, we derive an empirical estimate of the optimal ROC curve.',\n",
       "  'id': '3469',\n",
       "  'title': 'Overlaying classifiers: a practical approach for optimal ranking',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The Singular Value Decomposition is a key operation in many machine learning methods. Its computational cost, however, makes it unscalable and impractical for the massive-sized datasets becoming common in applications. We present a new method, QUIC-SVD, for fast approximation of the full SVD with automatic sample size minimization and empirical relative error control. Previous Monte Carlo approaches have not addressed the full SVD nor benefited from the efficiency of automatic, empirically-driven sample sizing. Our empirical tests show speedups of several orders of magnitude over exact SVD. Such scalability should enable QUIC-SVD to meet the needs of a wide array of methods and applications.',\n",
       "  'id': '3473',\n",
       "  'title': 'QUIC-SVD: Fast SVD Using Cosine Trees',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"A novel center-based clustering algorithm is proposed in this paper. We first formulate clustering as an NP-hard linear integer program and we then use linear programming and the duality theory to derive the solution of this optimization problem. This leads to an efficient and very general algorithm, which works in the dual domain, and can cluster data based on an arbitrary set of distances. Despite its generality, it is independent of initialization (unlike EM-like methods such as K-means), has guaranteed convergence, and can also provide online optimality bounds about the quality of the estimated clustering solutions. To deal with the most critical issue in a center-based clustering algorithm (selection of cluster centers), we also introduce the notion of stability of a cluster center, which is a well defined LP-based quantity that plays a key role to our algorithm's success. Furthermore, we also introduce, what we call, the margins (another key ingredient in our algorithm), which can be roughly thought of as dual counterparts to stabilities and allow us to obtain computationally efficient approximations to the latter. Promising experimental results demonstrate the potentials of our method.\",\n",
       "  'id': '3478',\n",
       "  'title': 'Clustering via LP-based Stabilities',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Spectral clustering is useful for a wide-ranging set of applications in areas such as biological data analysis, image processing and data mining. However, the computational and/or communication resources required by the method in processing large-scale data sets are often prohibitively high, and practitioners are often required to perturb the original data in various ways (quantization, downsampling, etc) before invoking a spectral algorithm. In this paper, we use stochastic perturbation theory to study the effects of data perturbation on the performance of spectral clustering. We show that the error under perturbation of spectral clustering is closely related to the perturbation of the eigenvectors of the Laplacian matrix. From this result we derive approximate upper bounds on the clustering error. We show that this bound is tight empirically across a wide range of problems, suggesting that it can be used in practical settings to determine the amount of data reduction allowed in order to meet a specification of permitted loss in clustering performance.',\n",
       "  'id': '3480',\n",
       "  'title': 'Spectral Clustering with Perturbed Data',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a new co-clustering problem of images and visual features. The problem involves a set of non-object images in addition to a set of object images and features to be co-clustered. Co-clustering is performed in a way of maximising discrimination of object images from non-object images, thus emphasizing discriminative features. This provides a way of obtaining perceptual joint-clusters of object images and features. We tackle the problem by simultaneously boosting multiple strong classifiers which compete for images by their expertise. Each boosting classifier is an aggregation of weak-learners, i.e. simple visual features. The obtained classifiers are useful for multi-category and multi-view object detection tasks. Experiments on a set of pedestrian images and a face data set demonstrate that the method yields intuitive image clusters with associated features and is much superior to conventional boosting classifiers in object detection tasks.',\n",
       "  'id': '3483',\n",
       "  'title': 'MCBoost: Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Bartlett et al (2006) recently proved that a ground condition for convex surrogates, classification calibration, ties up the minimization of the surrogates and classification risks, and left as an important problem the algorithmic questions about the minimization of these surrogates. In this paper, we propose an algorithm which provably minimizes any classification calibrated surrogate strictly convex and differentiable --- a set whose losses span the exponential, logistic and squared losses ---, with boosting-type guaranteed convergence rates under a weak learning assumption. A particular subclass of these surrogates, that we call balanced convex surrogates, has a key rationale that ties it to maximum likelihood estimation, zero-sum games and the set of losses that satisfy some of the most common requirements for losses in supervised learning. We report experiments on more than 50 readily available domains of 11 flavors of the algorithm, that shed light on new surrogates, and the potential of data dependent strategies to tune surrogates.',\n",
       "  'id': '3485',\n",
       "  'title': 'On the Efficient Minimization of Classification Calibrated Surrogates',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper addresses the important tradeoff between privacy and learnability, when designing algorithms for learning from private databases. First we apply an idea of Dwork et al. to design a specific privacy-preserving machine learning algorithm, logistic regression. This involves bounding the sensitivity of logistic regression, and perturbing the learned classifier with noise proportional to the sensitivity. Noting that the approach of Dwork et al. has limitations when applied to other machine learning algorithms, we then present another privacy-preserving logistic regression algorithm. The algorithm is based on solving a perturbed objective, and does not depend on the sensitivity. We prove that our algorithm preserves privacy in the model due to Dwork et al., and we provide a learning performance guarantee. Our work also reveals an interesting connection between regularization and privacy.',\n",
       "  'id': '3486',\n",
       "  'title': 'Privacy-preserving logistic regression',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Compressive Sensing (CS) combines sampling and compression into a single sub-Nyquist linear measurement process for sparse and compressible signals. In this paper, we extend the theory of CS to include signals that are concisely represented in terms of a graphical model. In particular, we use Markov Random Fields (MRFs) to represent sparse signals whose nonzero coefficients are clustered. Our new model-based reconstruction algorithm, dubbed Lattice Matching Pursuit (LaMP), stably recovers MRF-modeled signals using many fewer measurements and computations than the current state-of-the-art algorithms.',\n",
       "  'id': '3487',\n",
       "  'title': 'Sparse Signal Recovery Using Markov Random Fields',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The cluster assumption is exploited by most semi-supervised learning (SSL) methods. However, if the unlabeled data is merely weakly related to the target classes, it becomes questionable whether driving the decision boundary to the low density regions of the unlabeled data will help the classification. In such case, the cluster assumption may not be valid; and consequently how to leverage this type of unlabeled data to enhance the classification accuracy becomes a challenge. We introduce Semi-supervised Learning with Weakly-Related Unlabeled Data\" (SSLW), an inductive method that builds upon the maximum-margin approach, towards a better usage of weakly-related unlabeled information. Although the SSLW could improve a wide range of classification tasks, in this paper, we focus on text categorization with a small training pool. The key assumption behind this work is that, even with different topics, the word usage patterns across different corpora tends to be consistent. To this end, SSLW estimates the optimal word-correlation matrix that is consistent with both the co-occurrence information derived from the weakly-related unlabeled documents and the labeled documents. For empirical evaluation, we present a direct comparison with a number of state-of-the-art methods for inductive semi-supervised learning and text categorization; and we show that SSLW results in a significant improvement in categorization accuracy, equipped with a small training set and an unlabeled resource that is weakly related to the test beds.\"',\n",
       "  'id': '3488',\n",
       "  'title': 'Semi-supervised Learning with Weakly-Related Unlabeled Data : Towards Better Text Categorization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Existing approaches to nonrigid structure from motion assume that the instantaneous 3D shape of a deforming object is a linear combination of basis shapes, which have to be estimated anew for each video sequence. In contrast, we propose that the evolving 3D structure be described by a linear combination of basis trajectories. The principal advantage of this lateral approach is that we do not need to estimate any basis vectors during computation. Instead, we show that generic bases over trajectories, such as the Discrete Cosine Transform (DCT) bases, can be used to effectively describe most real motions. This results in a significant reduction in unknowns, and corresponding stability, in estimation. We report empirical performance, quantitatively using motion capture data and qualitatively on several video sequences exhibiting nonrigid motions including piece-wise rigid motion, articulated motion, partially nonrigid motion (such as a facial expression), and highly nonrigid motion (such as a person dancing).',\n",
       "  'id': '3493',\n",
       "  'title': 'Nonrigid Structure from Motion in Trajectory Space',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Randomized neural networks are immortalized in this AI Koan: In the days when Sussman was a novice, Minsky once came to him as he sat hacking at the PDP-6. ``What are you doing?'' asked Minsky. ``I am training a randomly wired neural net to play tic-tac-toe,'' Sussman replied. ``Why is the net wired randomly?'' asked Minsky. Sussman replied, ``I do not want it to have any preconceptions of how to play.'' Minsky then shut his eyes. ``Why do you close your eyes?'' Sussman asked his teacher. ``So that the room will be empty,'' replied Minsky. At that moment, Sussman was enlightened. We analyze shallow random networks with the help of concentration of measure inequalities. Specifically, we consider architectures that compute a weighted sum of their inputs after passing them through a bank of arbitrary randomized nonlinearities. We identify conditions under which these networks exhibit good classification performance, and bound their test error in terms of the size of the dataset and the number of random nonlinearities.\",\n",
       "  'id': '3495',\n",
       "  'title': 'Weighted Sums of Random Kitchen Sinks: Replacing minimization with randomization in learning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Metal binding is important for the structural and functional characterization of proteins. Previous prediction efforts have only focused on bonding state, i.e. deciding which protein residues act as metal ligands in some binding site. Identifying the geometry of metal-binding sites, i.e. deciding which residues are jointly involved in the coordination of a metal ion is a new prediction problem that has been never attempted before from protein sequence alone. In this paper, we formulate it in the framework of learning with structured outputs. Our solution relies on the fact that, from a graph theoretical perspective, metal binding has the algebraic properties of a matroid, enabling the application of greedy algorithms for learning structured outputs. On a data set of 199 non-redundant metalloproteins, we obtained precision/recall levels of 75\\\\%/46\\\\% correct ligand-ion assignments, which improves to 88\\\\%/88\\\\% in the setting where the metal binding state is known.',\n",
       "  'id': '3498',\n",
       "  'title': 'Predicting the Geometry of Metal Binding Sites from Protein Sequence',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'In this paper we introduce the MeanNN approach for estimation of main information theoretic measures such as differential entropy, mutual information and divergence. As opposed to other nonparametric approaches the MeanNN results in smooth differentiable functions of the data samples with clear geometrical interpretation. Then we apply the proposed estimators to the ICA problem and obtain a smooth expression for the mutual information that can be analytically optimized by gradient descent methods. The improved performance on the proposed ICA algorithm is demonstrated on standard tests in comparison with state-of-the-art techniques.',\n",
       "  'id': '3500',\n",
       "  'title': 'ICA based on a Smooth Estimation of the Differential Entropy',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Policy gradient (PG) reinforcement learning algorithms have strong (local) convergence guarantees, but their learning performance is typically limited by a large variance in the estimate of the gradient. In this paper, we formulate the variance reduction problem by describing a signal-to-noise ratio (SNR) for policy gradient algorithms, and evaluate this SNR carefully for the popular Weight Perturbation (WP) algorithm. We confirm that SNR is a good predictor of long-term learning performance, and that in our episodic formulation, the cost-to-go function is indeed the optimal baseline. We then propose two modifications to traditional model-free policy gradient algorithms in order to optimize the SNR. First, we examine WP using anisotropic sampling distributions, which introduces a bias into the update but increases the SNR; this bias can be interpretted as following the natural gradient of the cost function. Second, we show that non-Gaussian distributions can also increase the SNR, and argue that the optimal isotropic distribution is a ???shell??? distribution with a constant magnitude and uniform distribution in direction. We demonstrate that both modifications produce substantial improvements in learning performance in challenging policy gradient experiments.',\n",
       "  'id': '3511',\n",
       "  'title': 'Signal-to-Noise Ratio Analysis of Policy Gradient Algorithms',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"Selective attention is a most intensively studied psychological phenomenon, rife with theoretical suggestions and schisms. A critical idea is that of limited capacity, the allocation of which has produced half a century's worth of conflict about such phenomena as early and late selection. An influential resolution of this debate is based on the notion of perceptual load (Lavie, 2005, TICS, 9: 75), which suggests that low-load, easy tasks, because they underuse the total capacity of attention, mandatorily lead to the processing of stimuli that are irrelevant to the current attentional set; whereas high-load, difficult tasks grab all resources for themselves, leaving distractors high and dry. We argue that this theory presents a challenge to Bayesian theories of attention, and suggest an alternative, statistical, account of key supporting data.\",\n",
       "  'id': '3516',\n",
       "  'title': 'Load and Attentional Bayes',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Distributed learning is a problem of fundamental interest in machine learning and cognitive science. In this paper, we present asynchronous distributed learning algorithms for two well-known unsupervised learning frameworks: Latent Dirichlet Allocation (LDA) and Hierarchical Dirichlet Processes (HDP). In the proposed approach, the data are distributed across P processors, and processors independently perform Gibbs sampling on their local data and communicate their information in a local asynchronous manner with other processors. We demonstrate that our asynchronous algorithms are able to learn global topic models that are statistically as accurate as those learned by the standard LDA and HDP samplers, but with significant improvements in computation time and memory. We show speedup results on a 730-million-word text corpus using 32 processors, and we provide perplexity results for up to 1500 virtual processors. As a stepping stone in the development of asynchronous HDP, a parallel HDP sampler is also introduced.',\n",
       "  'id': '3524',\n",
       "  'title': 'Asynchronous Distributed Learning of Topic Models',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose a new class of consistency constraints for Linear Programming (LP) relaxations for finding the most probable (MAP) configuration in graphical models. Usual cluster-based LP relaxations enforce joint consistency of the beliefs of a cluster of variables, with computational cost increasing exponentially with the size of the clusters. By partitioning the state space of a cluster and enforcing consistency only across partitions, we obtain a class of constraints which, although less tight, are computationally feasible for large clusters. We show how to solve the cluster selection and partitioning problem monotonically in the dual LP, using the current beliefs to guide these choices. We obtain a dual message-passing algorithm and apply it to protein design problems where the variables have large state spaces and the usual cluster-based relaxations are very costly.',\n",
       "  'id': '3537',\n",
       "  'title': 'Clusters and Coarse Partitions in LP Relaxations',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose a new fast Gaussian summation algorithm for high-dimensional datasets with high accuracy. First, we extend the original fast multipole-type methods to use approximation schemes with both hard and probabilistic error. Second, we utilize a new data structure called subspace tree which maps each data point in the node to its lower dimensional mapping as determined by any linear dimension reduction method such as PCA. This new data structure is suitable for reducing the cost of each pairwise distance computation, the most dominant cost in many kernel methods. Our algorithm guarantees probabilistic relative error on each kernel sum, and can be applied to high-dimensional Gaussian summations which are ubiquitous inside many kernel methods as the key computational bottleneck. We provide empirical speedup results on low to high-dimensional datasets up to 89 dimensions.',\n",
       "  'id': '3539',\n",
       "  'title': 'Fast High-dimensional Kernel Summations Using the Monte Carlo Multipole Method',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper introduces a new approach to constructing meaningful lower dimensional representations of sets of data points. We argue that constraining the mapping between the high and low dimensional spaces to be a diffeomorphism is a natural way of ensuring that pairwise distances are approximately preserved. Accordingly we develop an algorithm which diffeomorphically maps the data near to a lower dimensional subspace and then projects onto that subspace. The problem of solving for the mapping is transformed into one of solving for an Eulerian flow field which we compute using ideas from kernel methods. We demonstrate the efficacy of our approach on various real world data sets.',\n",
       "  'id': '3542',\n",
       "  'title': 'Diffeomorphic Dimensionality Reduction',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Many interesting problems, including Bayesian network structure-search, can be cast in terms of finding the optimum value of a function over the space of graphs. However, this function is often expensive to compute exactly. We here present a method derived from the study of reproducing-kernel Hilbert spaces which takes advantage of the regular structure of the space of all graphs on a fixed number of nodes to obtain approximations to the desired function quickly and with reasonable accuracy. We then test this method on both a small testing set and a real-world Bayesian network; the results suggest that not only is this method reasonably accurate, but that the BDe score itself varies quadratically over the space of all graphs.',\n",
       "  'id': '3543',\n",
       "  'title': 'Bayesian Network Score Approximation using a Metagraph Kernel',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Research in animal learning and behavioral neuroscience has distinguished between two forms of action control: a habit-based form, which relies on stored action values, and a goal-directed form, which forecasts and compares action outcomes based on a model of the environment. While habit-based control has been the subject of extensive computational research, the computational principles underlying goal-directed control in animals have so far received less attention. In the present paper, we advance a computational framework for goal-directed control in animals and humans. We take three empirically motivated points as founding premises: (1) Neurons in dorsolateral prefrontal cortex represent action policies, (2) Neurons in orbitofrontal cortex represent rewards, and (3) Neural computation, across domains, can be appropriately understood as performing structured probabilistic inference. On a purely computational level, the resulting account relates closely to previous work using Bayesian inference to solve Markov decision problems, but extends this work by introducing a new algorithm, which provably converges on optimal plans. On a cognitive and neuroscientific level, the theory provides a unifying framework for several different forms of goal-directed action selection, placing emphasis on a novel form, within which orbitofrontal reward representations directly drive policy selection.',\n",
       "  'id': '3547',\n",
       "  'title': 'Goal-directed decision making in prefrontal cortex: a computational framework',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Given an $n$-vertex weighted tree with structural diameter $S$ and a subset of $m$ vertices, we present a technique to compute a corresponding $m \\\\times m$ Gram matrix of the pseudoinverse of the graph Laplacian in $O(n+ m^2 + m S)$ time. We discuss the application of this technique to fast label prediction on a generic graph. We approximate the graph with a spanning tree and then we predict with the kernel perceptron. We address the approximation of the graph with either a minimum spanning tree or a shortest path tree. The fast computation of the pseudoinverse enables us to address prediction problems on large graphs. To this end we present experiments on two web-spam classification tasks, one of which includes a graph with 400,000 nodes and more than 10,000,000 edges. The results indicate that the accuracy of our technique is competitive with previous methods using the full graph information.',\n",
       "  'id': '3549',\n",
       "  'title': 'Fast Prediction on a Tree',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'The odor transduction process has a large time constant and is susceptible to various types of noise. Therefore, the olfactory code at the sensor/receptor level is in general a slow and highly variable indicator of the input odor in both natural and artificial situations. Insects overcome this problem by using a neuronal device in their Antennal Lobe (AL), which transforms the identity code of olfactory receptors to a spatio-temporal code. This transformation improves the decision of the Mushroom Bodies (MBs), the subsequent classifier, in both speed and accuracy.Here we propose a rate model based on two intrinsic mechanisms in the insect AL, namely integration and inhibition. Then we present a MB classifier model that resembles the sparse and random structure of insect MB. A local Hebbian learning procedure governs the plasticity in the model. These formulations not only help to understand the signal conditioning and classification methods of insect olfactory systems, but also can be leveraged in synthetic problems. Among them, we consider here the discrimination of odor mixtures from pure odors. We show on a set of records from metal-oxide gas sensors that the cascade of these two new models facilitates fast and accurate discrimination of even highly imbalanced mixtures from pure odors.',\n",
       "  'id': '3555',\n",
       "  'title': 'Artificial Olfactory Brain for Mixture Identification',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We show how improved sequences for magnetic resonance imaging can be found through automated optimization of Bayesian design scores. Combining recent advances in approximate Bayesian inference and natural image statistics with high-performance numerical computation, we propose the first scalable Bayesian experimental design framework for this problem of high relevance to clinical and brain research. Our solution requires approximate inference for dense, non-Gaussian models on a scale seldom addressed before. We propose a novel scalable variational inference algorithm, and show how powerful methods of numerical mathematics can be modified to compute primitives in our framework. Our approach is evaluated on a realistic setup with raw data from a 3T MR scanner.',\n",
       "  'id': '3558',\n",
       "  'title': 'Bayesian Experimental Design of Magnetic Resonance Imaging Sequences',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper discusses non-parametric regression between Riemannian manifolds. This learning problem arises frequently in many application areas ranging from signal processing, computer vision, over robotics to computer graphics. We present a new algorithmic scheme for the solution of this general learning problem based on regularized empirical risk minimization. The regularization functional takes into account the geometry of input and output manifold, and we show that it implements a prior which is particularly natural. Moreover, we demonstrate that our algorithm performs well in a difficult surface registration problem.',\n",
       "  'id': '3561',\n",
       "  'title': 'Non-parametric Regression Between Manifolds',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose using correlated bigram LSA for unsupervised LM adaptation for automatic speech recognition. The model is trained using efficient variational EM and smoothed using the proposed fractional Kneser-Ney smoothing which handles fractional counts. Our approach can be scalable to large training corpora via bootstrapping of bigram LSA from unigram LSA. For LM adaptation, unigram and bigram LSA are integrated into the background N-gram LM via marginal adaptation and linear interpolation respectively. Experimental results show that applying unigram and bigram LSA together yields 6%--8% relative perplexity reduction and 0.6% absolute character error rates (CER) reduction compared to applying only unigram LSA on the Mandarin RT04 test set. Comparing with the unadapted baseline, our approach reduces the absolute CER by 1.2%.',\n",
       "  'id': '3564',\n",
       "  'title': 'Correlated Bigram LSA for Unsupervised Language Model Adaptation',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a discriminative part-based approach for human action recognition from video sequences using motion features. Our model is based on the recently proposed hidden conditional random field~(hCRF) for object recognition. Similar to hCRF for object recognition, we model a human action by a flexible constellation of parts conditioned on image observations. Different from object recognition, our model combines both large-scale global features and local patch features to distinguish various actions. Our experimental results show that our model is comparable to other state-of-the-art approaches in action recognition. In particular, our experimental results demonstrate that combining large-scale global features and local patch features performs significantly better than directly applying hCRF on local patches alone.',\n",
       "  'id': '3565',\n",
       "  'title': 'Learning a discriminative hidden part model for human action recognition',\n",
       "  'year': '2008'},\n",
       " {'abstract': \"We formulate and study a new variant of the $k$-armed bandit problem, motivated by e-commerce applications. In our model, arms have (stochastic) lifetime after which they expire. In this setting an algorithm needs to continuously explore new arms, in contrast to the standard $k$-armed bandit model in which arms are available indefinitely and exploration is reduced once an optimal arm is identified with near-certainty. The main motivation for our setting is online-advertising, where ads have limited lifetime due to, for example, the nature of their content and their campaign budget. An algorithm needs to choose among a large collection of ads, more than can be fully explored within the ads' lifetime. We present an optimal algorithm for the state-aware (deterministic reward function) case, and build on this technique to obtain an algorithm for the state-oblivious (stochastic reward function) case. Empirical studies on various reward distributions, including one derived from a real-world ad serving application, show that the proposed algorithms significantly outperform the standard multi-armed bandit approaches applied to these settings.\",\n",
       "  'id': '3580',\n",
       "  'title': 'Mortal Multi-Armed Bandits',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'Continuously-Adaptive Discretization for Message-Passing (CAD-MP) is a new message-passing algorithm employing adaptive discretization. Most previous message-passing algorithms approximated arbitrary continuous probability distributions using either: a family of continuous distributions such as the exponential family; a particle-set of discrete samples; or a fixed, uniform discretization. In contrast, CAD-MP uses a discretization that is (i) non-uniform, and (ii) adaptive. The non-uniformity allows CAD-MP to localize interesting features (such as sharp peaks) in the marginal belief distributions with time complexity that scales logarithmically with precision, as opposed to uniform discretization which scales at best linearly. We give a principled method for altering the non-uniform discretization according to information-based measures. CAD-MP is shown in experiments on simulated data to estimate marginal beliefs much more precisely than competing approaches for the same computational expense.',\n",
       "  'id': '3590',\n",
       "  'title': 'Continuously-adaptive discretization for message-passing algorithms',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduce a family of unsupervised algorithms, numerical taxonomy clustering, to simultaneously cluster data, and to learn a taxonomy that encodes the relationship between the clusters. The algorithms work by maximizing the dependence between the taxonomy and the original data. The resulting taxonomy is a more informative visualization of complex data than simple clustering; in addition, taking into account the relations between different clusters is shown to substantially improve the quality of the clustering, when compared with state-of-the-art algorithms in the literature (both spectral clustering and a previous dependence maximization approach). We demonstrate our algorithm on image and text data.',\n",
       "  'id': '3592',\n",
       "  'title': 'Learning Taxonomies by Dependence Maximization',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We introduce a framework for actively learning visual categories from a mixture of weakly and strongly labeled image examples. We propose to allow the category-learner to strategically choose what annotations it receives---based on both the expected reduction in uncertainty as well as the relative costs of obtaining each annotation. We construct a multiple-instance discriminative classifier based on the initial training data. Then all remaining unlabeled and weakly labeled examples are surveyed to actively determine which annotation ought to be requested next. After each request, the current classifier is incrementally updated. Unlike previous work, our approach accounts for the fact that the optimal use of manual annotation may call for a combination of labels at multiple levels of granularity (e.g., a full segmentation on some images and a present/absent flag on others). As a result, it is possible to learn more accurate category models with a lower total expenditure of manual annotation effort.',\n",
       "  'id': '3598',\n",
       "  'title': 'Multi-Level Active Prediction of Useful Image Annotations for Recognition',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We propose new families of models and algorithms for high-dimensional nonparametric learning with joint sparsity constraints. Our approach is based on a regularization method that enforces common sparsity patterns across different function components in a nonparametric additive model. The algorithms employ a coordinate descent approach that is based on a functional soft-thresholding operator. The framework yields several new models, including multi-task sparse additive models, multi-response sparse additive models, and sparse additive multi-category logistic regression. The methods are illustrated with experiments on synthetic data and gene microarray data.',\n",
       "  'id': '3616',\n",
       "  'title': 'Nonparametric regression and classification with joint sparsity constraints',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'We present a new reinforcement-learning model for the role of the hippocampus in classical conditioning, focusing on the differences between trace and delay conditioning. In the model, all stimuli are represented both as unindividuated wholes and as a series of temporal elements with varying delays. These two stimulus representations interact, producing different patterns of learning in trace and delay conditioning. The model proposes that hippocampal lesions eliminate long-latency temporal elements, but preserve short-latency temporal elements. For trace conditioning, with no contiguity between stimulus and reward, these long-latency temporal elements are vital to learning adaptively timed responses. For delay conditioning, in contrast, the continued presence of the stimulus supports conditioned responding, and the short-latency elements suppress responding early in the stimulus. In accord with the empirical data, simulated hippocampal damage impairs trace conditioning, but not delay conditioning, at medium-length intervals. With longer intervals, learning is impaired in both procedures, and, with shorter intervals, in neither. In addition, the model makes novel predictions about the response topography with extended stimuli or post-training lesions. These results demonstrate how temporal contiguity, as in delay conditioning, changes the timing problem faced by animals, rendering it both easier and less susceptible to disruption by hippocampal lesions.',\n",
       "  'id': '3619',\n",
       "  'title': 'A computational model of hippocampal function in trace conditioning',\n",
       "  'year': '2008'},\n",
       " {'abstract': 'This paper addresses the problem of noisy Generalized Binary Search (GBS).  GBS is a well-known greedy algorithm for determining a binary-valued hypothesis through a sequence of strategically selected queries.  At each step, a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets, a natural generalization of the idea underlying classic binary search.  GBS is used in many applications, including fault testing, machine diagnostics, disease diagnosis, job scheduling, image processing, computer vision, and active learning. In most of these cases, the responses to queries can be noisy.  Past work has provided a partial characterization of GBS, but existing noise-tolerant versions of GBS are suboptimal in terms of sample complexity.  This paper presents the first optimal algorithm for noisy GBS and demonstrates its application to learning multidimensional threshold functions.',\n",
       "  'id': '3721',\n",
       "  'title': 'Noisy Generalized Binary Search',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We prove an oracle inequality for generic regularized empirical risk minimization algorithms learning from  $\\\\a$-mixing processes. To illustrate this oracle inequality, we use it to derive learning rates for some learning methods including least squares SVMs. Since the proof of the oracle inequality uses recent localization ideas developed for independent and identically distributed (i.i.d.) processes, it turns out that these learning rates are close to the optimal rates known in the i.i.d. case.',\n",
       "  'id': '3736',\n",
       "  'title': 'Fast Learning from Non-i.i.d. Observations',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Recent work on the statistical modeling of neural responses has focused on modulated renewal processes in which the spike rate is a function of the stimulus and recent spiking history. Typically, these models incorporate spike-history dependencies via either: (A) a conditionally-Poisson process with rate dependent on a linear projection of the spike train history (e.g., generalized linear model); or (B) a modulated non-Poisson renewal process (e.g., inhomogeneous gamma process). Here we show that the two approaches can be combined, resulting in a {\\\\it conditional renewal} (CR) model for neural spike trains. This model captures both real and rescaled-time effects, and can be fit by maximum likelihood using a simple application of the time-rescaling theorem [1]. We show that for any modulated renewal process model, the log-likelihood is concave in the linear filter parameters only under certain restrictive conditions on the renewal density (ruling out many popular choices, e.g. gamma with $\\\\kappa \\\\neq1$), suggesting that real-time history effects are easier to estimate than non-Poisson renewal properties. Moreover, we show that goodness-of-fit tests based on the time-rescaling theorem [1] quantify relative-time effects, but do not reliably assess accuracy in spike prediction or stimulus-response modeling. We illustrate the CR model with applications to both real and simulated neural data.',\n",
       "  'id': '3740',\n",
       "  'title': 'Time-rescaling methods for the estimation and assessment of non-Poisson neural encoding models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper addresses the problem of designing binary codes for high-dimensional data such that vectors that are similar in the original space map to similar binary strings. We introduce a simple distribution-free encoding scheme based on random projections, such that the expected Hamming distance between the binary codes of two vectors is related to the value of a shift-invariant kernel (e.g., a Gaussian kernel) between the vectors. We present a full theoretical analysis of the convergence properties of the proposed scheme, and report favorable experimental performance as compared to a recent state-of-the-art method, spectral hashing.',\n",
       "  'id': '3749',\n",
       "  'title': 'Locality-sensitive binary codes from shift-invariant kernels',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'An algorithm is presented for online learning of rotations. The proposed algorithm involves matrix exponentiated gradient updates and is motivated by the Von Neumann divergence. The additive updates are skew-symmetric matrices with trace zero which comprise the Lie algebra of the rotation group. The orthogonality and unit determinant of the matrix  parameter are preserved using matrix logarithms and exponentials and the algorithm lends itself to interesting interpretations in terms of the computational topology of the compact Lie groups. The stability and the computational complexity of the algorithm are discussed.',\n",
       "  'id': '3753',\n",
       "  'title': 'On Learning Rotations',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The standard assumption of identically distributed training and test data can be violated when an adversary can exercise some control over the generation of the test data. In a prediction game, a learner produces a predictive model while an adversary may alter the distribution of input data. We study single-shot prediction games in which the cost functions of learner and adversary are not necessarily antagonistic. We identify conditions under which the prediction game has a unique Nash equilibrium, and derive algorithms that will find the equilibrial prediction models. In a case study, we explore properties of Nash-equilibrial prediction models for email spam filtering empirically.',\n",
       "  'id': '3755',\n",
       "  'title': 'Nash Equilibria of Static Prediction Games',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The estimation of high-dimensional parametric models requires imposing some structure on the models, for instance that they be sparse, or that matrix structured parameters have low rank. A general approach for such structured parametric model estimation is to use regularized M-estimation procedures, which regularize a loss function that measures goodness of fit of the parameters to the data with some regularization function that encourages the assumed structure. In this paper, we aim to provide a unified analysis of such regularized M-estimation procedures. In particular, we report the convergence rates of such estimators in any metric norm. Using just our main theorem, we are able to rederive some of the many existing results, but also obtain a wide range of novel convergence rates results. Our analysis also identifies key properties of loss and regularization functions such as restricted strong convexity, and decomposability, that ensure the corresponding regularized M-estimators have good convergence rates.',\n",
       "  'id': '3765',\n",
       "  'title': 'A unified framework for high-dimensional analysis of ',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose to use Rademacher complexity, originally developed in computational learning theory, as a measure of human learning capacity.  Rademacher complexity measures a learners ability to fit random data, and can be used to bound the learners true error based on the observed training sample error.  We first review the definition of Rademacher complexity and its generalization bound.  We then describe a learning the noise\" procedure to experimentally measure human Rademacher complexities.  The results from empirical studies showed that: (i) human Rademacher complexity can be successfully measured, (ii) the complexity depends on the domain and training sample size in intuitive ways, (iii) human learning respects the generalization bounds, (iv) the bounds can be useful in predicting the danger of overfitting in human learning.  Finally, we discuss the potential applications of human Rademacher complexity in cognitive science.\"',\n",
       "  'id': '3771',\n",
       "  'title': 'Human Rademacher Complexity',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The proposal that cortical activity in the visual cortex is optimized for sparse neural activity is one of the most established ideas in computational neuroscience. However, direct experimental evidence for optimal sparse coding remains inconclusive, mostly due to the lack of reference values on which to judge the measured sparseness. Here we analyze neural responses to natural movies in the primary visual cortex of ferrets at different stages of development, and of rats while awake and under different levels of anesthesia. In contrast with prediction from a sparse coding model, our data shows that population and lifetime sparseness decrease with visual experience, and increase from the awake to anesthetized state. These results suggest that the representation in the primary visual cortex is not actively optimized to maximize sparseness.',\n",
       "  'id': '3774',\n",
       "  'title': 'No evidence for active sparsification in the visual cortex',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The recent emergence of Graphics Processing Units (GPUs) as general-purpose parallel computing devices provides us with new opportunities to develop scalable learning methods for massive data. In this work, we consider the problem of parallelizing two inference methods on GPUs for latent Dirichlet Allocation (LDA) models, collapsed Gibbs sampling (CGS) and collapsed variational Bayesian (CVB). To address limited memory constraints on GPUs, we propose a novel data partitioning scheme that effectively reduces the memory cost. Furthermore, the partitioning scheme balances the computational cost on each multiprocessor and enables us to easily avoid memory access conflicts. We also use data streaming to handle extremely large datasets. Extensive experiments showed that our parallel inference methods consistently produced LDA models with the same predictive power as sequential training methods did but with 26x speedup for CGS and 196x speedup for CVB on a GPU with 30 multiprocessors; actually the speedup is almost linearly scalable with the number of multiprocessors available. The proposed partitioning scheme and data streaming can be easily ported to many other models in machine learning.',\n",
       "  'id': '3788',\n",
       "  'title': 'Parallel Inference for Latent Dirichlet Allocation on Graphics Processing Units',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We describe an algorithm for learning bilinear SVMs. Bilinear classifiers are a discriminative variant of bilinear models, which capture the dependence of data on multiple factors. Such models are particularly appropriate for visual data that is better represented as a matrix or tensor, rather than a vector. Matrix encodings allow for more natural regularization through rank restriction. For example, a rank-one scanning-window classifier yields a separable filter. Low-rank models have fewer parameters and so are easier to regularize and faster to score at run-time. We learn low-rank models with bilinear classifiers. We also use bilinear classifiers for transfer learning by sharing linear factors between different classification tasks. Bilinear classifiers are trained with biconvex programs. Such programs are optimized with coordinate descent, where each coordinate step requires solving a convex program - in our case, we use a standard off-the-shelf SVM solver. We demonstrate bilinear SVMs on difficult problems of people detection in video sequences and action classification of video sequences, achieving state-of-the-art results in both.',\n",
       "  'id': '3789',\n",
       "  'title': 'Bilinear classifiers for visual recognition',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We devise a graphical model that supports the process of debugging software by guiding developers to code that is likely to contain defects. The model is trained using execution traces of passing test runs; it reflects the distribution over transitional patterns of code positions. Given a failing test case, the model determines the least likely transitional pattern in the execution trace. The model is designed such that Bayesian inference has a closed-form solution. We evaluate the  Bernoulli graph model on data of the software projects AspectJ and Rhino.',\n",
       "  'id': '3792',\n",
       "  'title': 'Localizing Bugs in Program Executions with Graphical Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a novel linear program for the approximation of the dynamic programming cost-to-go function in high-dimensional stochastic control problems. LP approaches to approximate DP naturally restrict attention to approximations that are lower bounds to the optimal cost-to-go function. Our program -- the `smoothed approximate linear program -- relaxes this restriction in an appropriate fashion while remaining computationally tractable. Doing so appears to have several advantages: First, we demonstrate superior bounds on the quality of approximation to the optimal cost-to-go function afforded by our approach. Second, experiments with our approach on a challenging problem (the game of Tetris) show that the approach outperforms the existing LP approach (which has previously been shown to be competitive with several ADP algorithms) by an order of magnitude.',\n",
       "  'id': '3799',\n",
       "  'title': 'A Smoothed Approximate Linear Program',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Dependencies among neighbouring labels in a sequence is an important source of information for sequence labeling problems. However, only dependencies between adjacent labels are commonly exploited in practice because of the high computational complexity of typical inference algorithms when longer distance dependencies are taken into account. In this paper, we show that it is possible to design efficient inference algorithms for a conditional random field using features that depend on long consecutive label sequences (high-order features), as long as the number of distinct label sequences in the features used is small. This leads to efficient learning algorithms for these conditional random fields. We show experimentally that exploiting dependencies using high-order features can lead to substantial performance improvements for some problems and discuss conditions under which high-order features can be effective.',\n",
       "  'id': '3815',\n",
       "  'title': 'Conditional Random Fields with High-Order Features for Sequence Labeling',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Regularized risk minimization often involves non-smooth optimization, either because of the loss function (e.g., hinge loss) or the regularizer (e.g., $\\\\ell_1$-regularizer). Gradient descent methods, though highly scalable and easy to implement, are known to converge slowly on these problems. In this paper, we develop novel accelerated gradient methods for stochastic optimization while still preserving their computational simplicity and scalability. The proposed algorithm, called SAGE (Stochastic Accelerated GradiEnt), exhibits fast convergence rates on stochastic optimization with both convex and strongly convex objectives. Experimental results show that SAGE is faster than recent (sub)gradient methods including FOLOS, SMIDAS and SCD. Moreover, SAGE can also be extended for online learning, resulting in a simple but powerful algorithm.',\n",
       "  'id': '3817',\n",
       "  'title': 'Accelerated Gradient Methods for Stochastic Optimization and Online Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We show that convex KL-regularized objective functions are obtained from a PAC-Bayes risk bound when using convex loss functions for the stochastic Gibbs classifier that upper-bound the standard zero-one loss used for the weighted majority vote. By restricting ourselves to a class of posteriors, that we call quasi uniform, we propose a simple coordinate descent learning algorithm to minimize the proposed KL-regularized cost function. We show that standard ell_p-regularized objective functions currently used, such as ridge regression and ell_p-regularized boosting, are obtained from a relaxation of the KL divergence between the quasi uniform posterior and the uniform prior. We present numerical experiments where the proposed learning algorithm generally outperforms ridge regression and AdaBoost.',\n",
       "  'id': '3821',\n",
       "  'title': 'From PAC-Bayes Bounds to KL Regularization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Solving multi-agent reinforcement learning problems has proven difficult because of the lack of tractable algorithms.  We provide the first approximation algorithm which solves stochastic games to within $\\\\epsilon$ relative error of the optimal game-theoretic solution, in time polynomial in $1/\\\\epsilon$. Our algorithm extends Murrays and Gordon?s (2007) modified Bellman equation which determines the \\\\emph{set} of all possible achievable utilities; this provides us a truly general framework for multi-agent learning. Further, we empirically validate our algorithm and find the computational cost to be orders of magnitude less than what the theory predicts.',\n",
       "  'id': '3825',\n",
       "  'title': 'Solving Stochastic Games',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Score functions induced by generative models extract fixed-dimension feature vectors from different-length data observations by subsuming the process of data generation, projecting them in highly informative spaces called score spaces. In this way, standard discriminative classifiers are proved to achieve higher performances than a solely generative or discriminative approach. In this paper, we present a novel score space that exploits the free energy associated to a generative model through a score function. This function aims at capturing both the uncertainty of the model learning and ``local compliance  of data observations with respect to the generative process. Theoretical justifications and convincing comparative classification results on various generative models prove the goodness of the proposed strategy.',\n",
       "  'id': '3830',\n",
       "  'title': 'Free energy score space',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The Indian Buffet Process is a Bayesian nonparametric approach that models objects as arising from an infinite number of latent factors. Here we extend the latent factor model framework to two or more unbounded layers of latent factors. From a generative perspective, each layer defines a conditional \\\\emph{factorial} prior distribution over the binary latent variables of the layer below via a noisy-or mechanism. We explore the properties of the model with two empirical studies, one digit recognition task and one music tag data experiment.',\n",
       "  'id': '3833',\n",
       "  'title': 'An Infinite Factor Model Hierarchy Via a Noisy-Or Mechanism',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we study the problem of learning a low-dimensional (sparse)  distance matrix.  We propose a novel metric learning model which can simultaneously conduct dimension reduction and learn a distance matrix. The sparse representation involves a mixed-norm regularization which is  non-convex.  We then show that it can be equivalently formulated  as a convex saddle (min-max) problem. From this saddle representation, we develop an efficient smooth optimization approach for sparse metric learning although the learning model is based on a non-differential loss function. This smooth optimization approach has an optimal convergence rate of $O(1 /\\\\ell^2)$ for smooth problems where $\\\\ell$ is the iteration number. Finally, we run experiments to validate the effectiveness and efficiency of our sparse metric learning model on various datasets.',\n",
       "  'id': '3847',\n",
       "  'title': 'Sparse Metric Learning via Smooth Optimization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Existing models of categorization typically represent to-be-classified items as points in a multidimensional space. While from a mathematical point of view, an infinite number of basis sets can be used to represent points in this space, the choice of basis set is psychologically crucial. People generally choose the same basis dimensions, and have a strong preference to generalize along the axes of these dimensions, but not diagonally\". What makes some choices of dimension special? We explore the idea that the dimensions used by people echo the natural variation in the environment. Specifically, we present a rational model that does not assume dimensions, but learns the same type of dimensional generalizations that people display. This bias is shaped by exposing the model to many categories with a structure hypothesized to be like those which children encounter. Our model can be viewed as a type of transformed Dirichlet process mixture model, where it is the learning of the base distribution of the Dirichlet process which allows dimensional generalization.The learning behaviour of our model captures the developmental shift from roughly \"isotropic\" for children to the axis-aligned generalization that adults show.\"',\n",
       "  'id': '3849',\n",
       "  'title': 'Hierarchical Learning of Dimensional Biases in Human Categorization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a new framework for semi-supervised learning with sparse eigenfunction bases of kernel matrices.  It turns out that  when the \\\\emph{cluster assumption} holds, that is, when the high density regions are sufficiently separated by  low density valleys, each high density area corresponds to a unique representative eigenvector. Linear combination of such eigenvectors (or, more precisely, of their Nystrom extensions) provide good candidates for good classification functions. By first choosing an appropriate basis of these eigenvectors from unlabeled data and then using labeled data  with Lasso to select a classifier in the span of these eigenvectors, we obtain a classifier, which has a very sparse representation in this basis. Importantly, the sparsity appears naturally from the  cluster assumption. Experimental results on a number  of real-world data-sets show that our method is competitive with the state of the art semi-supervised learning algorithms and outperforms the natural base-line algorithm (Lasso in the Kernel PCA basis).',\n",
       "  'id': '3852',\n",
       "  'title': 'Semi-supervised Learning using Sparse Eigenfunction Bases',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper, we develop an efficient moments-based permutation test approach to improve the system?s efficiency by approximating the permutation distribution of the test statistic with Pearson distribution series. This approach involves the calculation of the first four moments of the permutation distribution. We propose a novel recursive method to derive these moments theoretically and analytically without any permutation.  Experimental results using different test statistics are demonstrated using simulated data and real data. The proposed strategy takes advantage of nonparametric permutation tests and parametric Pearson distribution approximation to achieve both accuracy and efficiency.',\n",
       "  'id': '3858',\n",
       "  'title': 'Efficient Moments-based Permutation Tests',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the problem of learning probabilistic models for complex relational structures between various types of objects.  A model can help us ``understand a dataset of relational facts in at least two ways, by finding interpretable structure in the data, and by supporting predictions, or inferences about whether particular unobserved relations are likely to be true.  Often there is a tradeoff between these two aims: cluster-based models yield more easily interpretable representations, while factorization-based approaches have better predictive performance on large data sets.  We introduce the Bayesian Clustered Tensor Factorization (BCTF) model, which embeds a factorized representation of relations in a nonparametric Bayesian clustering framework.  Inference is fully Bayesian but scales well to large data sets.  The model simultaneously discovers interpretable clusters and yields predictive performance that matches or beats previous probabilistic models for relational data.',\n",
       "  'id': '3863',\n",
       "  'title': 'Modelling Relational Data using Bayesian Clustered Tensor Factorization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we present a novel approach to learn directed acyclic graphs (DAG) and factor models within the same framework while also allowing for model comparison between them. For this purpose, we exploit the connection between factor models and DAGs to propose Bayesian hierarchies based on spike and slab priors to promote sparsity, heavy-tailed priors to ensure identifiability and predictive densities to perform the model comparison. We require identifiability to be able to produce variable orderings leading to valid DAGs and sparsity to learn the structures. The effectiveness of our approach is demonstrated through extensive experiments on artificial and biological data showing that our approach outperform a number of state of the art methods.',\n",
       "  'id': '3867',\n",
       "  'title': 'Bayesian Sparse Factor Models and DAGs Inference and Comparison',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a new type of neural network activation function based on recent physiological rate models for complex cells in visual area V1.  A single-hidden-layer neural network of this kind of model achieves 1.5% error on MNIST.  We also introduce an existing criterion for learning slow, decorrelated features as a pretraining strategy for image models.  This pretraining strategy results in orientation-selective features, similar to the receptive fields of complex cells.  With this pretraining, the same single-hidden-layer model achieves better generalization error, even though the pretraining sample distribution is very different from the fine-tuning distribution.  To implement this pretraining strategy, we derive a fast algorithm for online learning of decorrelated features such that each iteration of the algorithm runs in linear time with respect to the number of features.',\n",
       "  'id': '3868',\n",
       "  'title': 'Slow, Decorrelated Features for Pretraining Complex Cell-like Networks',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Across a wide range of cognitive tasks, recent experience in?uences behavior. For example, when individuals repeatedly perform a simple two-alternative forced-choice task (2AFC), response latencies vary dramatically based on the immediately preceding trial sequence. These sequential effects have been interpreted as adaptation to the statistical structure of an uncertain, changing environment (e.g. Jones & Sieck, 2003; Mozer, Kinoshita, & Shettel, 2007; Yu & Cohen, 2008). The Dynamic Belief Model (DBM) (Yu & Cohen, 2008) explains sequential effects in 2AFC tasks as a rational consequence of a dynamic internal representation that tracks second-order statistics of the trial sequence (repetition rates) and predicts whether the upcoming trial will be a repetition or an alternation of the previous trial. Experimental results suggest that ?rst-order statistics (base rates) also in?uence sequential effects. We propose a model that learns both ?rst- and second-order sequence properties, each according to the basic principles of the DBM but under a uni?ed inferential framework. This model, the Dynamic Belief Mixture Model (DBM2), obtains precise, parsimonious ?ts to data. Furthermore, the model predicts dissociations in behavioral (Maloney, Dal Martello, Sahm, & Spillmann, 2005) and electrophysiological studies (Jentzsch & Sommer, 2002), supporting the psychological and neurobiological reality of its two components.',\n",
       "  'id': '3870',\n",
       "  'title': 'Sequential effects reflect parallel learning of multiple environmental regularities',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We adapt a probabilistic latent variable model, namely GaP (Gamma-Poisson), to ad targeting in the contexts of sponsored search (SS) and behaviorally targeted (BT) display advertising. We also approach the important problem of ad positional bias by formulating a one-latent-dimension GaP factorization. Learning from click-through data is intrinsically large scale, even more so for ads. We scale up the algorithm to terabytes of real-world SS and BT data that contains hundreds of millions of users and hundreds of thousands of features, by leveraging the scalability characteristics of the algorithm and the inherent structure of the problem including data sparsity and locality. Specifically, we demonstrate two somewhat orthogonal philosophies of scaling algorithms to large-scale problems, through the SS and BT implementations, respectively. Finally, we report the experimental results using Yahoos vast datasets, and show that our approach substantially outperform the state-of-the-art methods in prediction accuracy. For BT in particular, the ROC area achieved by GaP is exceeding 0.95, while one prior approach using Poisson regression yielded 0.83. For computational performance, we compare a single-node sparse implementation with a parallel implementation using Hadoop MapReduce, the results are counterintuitive yet quite interesting. We therefore provide insights into the underlying principles of large-scale learning.',\n",
       "  'id': '3873',\n",
       "  'title': 'Factor Modeling for Advertisement Targeting',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper is concerned with the consistency analysis on listwise ranking methods. Among various ranking methods, the listwise methods have competitive performances on benchmark datasets and are regarded as one of the state-of-the-art approaches. Most listwise ranking methods manage to optimize ranking on the whole list (permutation) of objects, however, in practical applications such as information retrieval, correct ranking at the top k positions is much more important. This paper aims to analyze whether existing listwise ranking methods are statistically consistent in the top-k setting. For this purpose, we define a top-k ranking framework, where the true loss (and thus the risks) are defined on the basis of top-k subgroup of permutations. This framework can include the permutation-level ranking framework proposed in previous work as a special case. Based on the new framework, we derive sufficient conditions for a listwise ranking method to be consistent with the top-k true loss, and show an effective way of modifying the surrogate loss functions in existing methods to satisfy these conditions. Experimental results show that after the modifications, the methods can work significantly better than their original versions.',\n",
       "  'id': '3879',\n",
       "  'title': 'Statistical Consistency of Top-k Ranking',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Online learning algorithms have impressive convergence properties   when it comes to risk minimization and convex games on very large   problems. However, they are inherently sequential in their design   which prevents them from taking advantage of modern multi-core   architectures. In this paper we prove that online learning with   delayed updates converges well, thereby facilitating parallel online   learning.',\n",
       "  'id': '3888',\n",
       "  'title': 'Slow Learners are Fast',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'While many advances have already been made on the topic of hierarchical classi-  ?cation learning, we take a step back and examine how a hierarchical classi?ca-  tion problem should be formally de?ned. We pay particular attention to the fact  that many arbitrary decisions go into the design of the the label taxonomy that  is provided with the training data, and that this taxonomy is often unbalanced.  We correct this problem by using the data distribution to calibrate the hierarchical  classi?cation loss function. This distribution-based correction must be done with  care, to avoid introducing unmanagable statstical dependencies into the learning  problem. This leads us off the beaten path of binomial-type estimation and into  the uncharted waters of geometric-type estimation. We present a new calibrated  de?nition of statistical risk for hierarchical classi?cation, an unbiased geometric  estimator for this risk, and a new algorithmic reduction from hierarchical classi?-  cation to cost-sensitive classi?cation.',\n",
       "  'id': '3629',\n",
       "  'title': 'Distribution-Calibrated Hierarchical Classification',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The relative merits of different population coding schemes have mostly been analyzed in the framework of stimulus reconstruction using Fisher Information. Here, we consider the case of stimulus discrimination in a two alternative forced choice paradigm and compute neurometric functions in terms of the minimal discrimination error and the Jensen-Shannon information to study neural population codes. We first explore the relationship between minimum discrimination error, Jensen-Shannon Information and Fisher Information and show that the discrimination framework is more informative about the coding accuracy than Fisher Information as it defines an error for any pair of possible stimuli. In particular, it includes Fisher Information as a special case. Second, we use the framework to study population codes of angular variables. Specifically, we assess the impact of different noise correlations structures on coding accuracy in long versus short decoding time windows. That is, for long time window we use the common Gaussian noise approximation. To address the case of short time windows we analyze the Ising model with identical noise correlation structure. In this way, we provide a new rigorous framework for assessing the functional consequences of noise correlation structures for the representational accuracy of neural population codes that is in particular applicable to short-time population coding.',\n",
       "  'id': '3631',\n",
       "  'title': 'Neurometric function analysis of population codes',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We study an encoding/decoding mechanism accounting for the relative spike timing of the signals propagating from peripheral nerve fibers to second-order somatosensory neurons in the cuneate nucleus (CN). The CN is modeled as a population of spiking neurons receiving as inputs the spatiotemporal responses of real mechanoreceptors obtained via microneurography recordings in humans. The efficiency of the haptic discrimination process is quantified by a novel definition of entropy that takes into full account the metrical properties of the spike train space. This measure proves to be a suitable decoding scheme for generalizing the classical Shannon entropy to spike-based neural codes. It permits an assessment of neurotransmission in the presence of a large output space (i.e. hundreds of spike trains) with 1 ms temporal precision. It is shown that the CN population code performs a complete discrimination of 81 distinct stimuli already within 35 ms of the first afferent spike, whereas a partial discrimination (80% of the maximum information transmission) is possible as rapidly as 15 ms. This study suggests that the CN may not constitute a mere synaptic relay along the somatosensory pathway but, rather, it may convey optimal contextual accounts (in terms of fast and reliable information transfer) of peripheral tactile inputs to downstream structures of the central nervous system.',\n",
       "  'id': '3636',\n",
       "  'title': 'Optimal context separation of spiking haptic signals by second-order somatosensory neurons',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Interesting real-world datasets often exhibit nonlinear, noisy, continuous-valued states that are unexplorable, are poorly described by first principles, and are only partially observable. If partial observability can be overcome, these constraints suggest the use of model-based reinforcement learning.  We experiment with manifold embeddings as the reconstructed observable state-space of an off-line, model-based reinforcement learning approach to control. We demonstrate the embedding of a system changes as a result of learning and that the best performing embeddings well-represent the dynamics of both the uncontrolled and adaptively controlled system.  We apply this approach in simulation to learn a neurostimulation policy that is more efficient in treating epilepsy than conventional policies.  We then demonstrate the learned policy completely suppressing seizures in real-world neurostimulation experiments on actual animal brain slices.',\n",
       "  'id': '3640',\n",
       "  'title': 'Manifold Embeddings for Model-Based Reinforcement Learning under Partial Observability',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Modern machine learning-based approaches to computer vision require very large databases of labeled images. Some contemporary vision systems already require on the order of millions of images for training (e.g., Omron face detector). While the collection of these large databases is becoming a bottleneck, new Internet-based services that allow labelers from around the world to be easily hired and managed provide a promising solution.  However, using these services to label large databases brings with it new theoretical and practical challenges: (1) The labelers may have wide ranging levels of expertise which are unknown a priori, and in some cases may be adversarial; (2) images may vary in their level of difficulty; and (3) multiple labels for the same image must be combined to provide an estimate of the actual label of the image. Probabilistic approaches provide a principled way to approach these problems. In this paper we present a probabilistic model and use it to simultaneously infer the label of each image, the expertise of each labeler, and the difficulty of each image. On both simulated and real data, we demonstrate that the model outperforms the commonly used ``Majority Vote heuristic for inferring image labels, and is robust to both adversarial and noisy labelers.',\n",
       "  'id': '3644',\n",
       "  'title': 'Whose Vote Should Count More: Optimal Integration of Labels from Labelers of Unknown Expertise',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Imaging techniques such as optical imaging of intrinsic signals, 2-photon calcium imaging and voltage sensitive dye imaging can be used to measure the functional organization of visual cortex across different spatial scales. Here, we present Bayesian methods based on Gaussian processes for extracting topographic maps from functional imaging data.  In particular, we focus on the estimation of orientation preference maps (OPMs) from intrinsic signal imaging data.  We model the underlying map as a bivariate Gaussian process, with a prior covariance function that reflects known properties of OPMs, and a noise covariance adjusted to the data.  The posterior mean can be interpreted as an optimally smoothed estimate of the map, and can be used for model based interpolations of the map from sparse measurements.  By sampling from the posterior distribution, we can get error bars on statistical properties such as preferred orientations,  pinwheel locations or -counts.  Finally, the use of an explicit probabilistic model facilitates interpretation of parameters and provides the basis for decoding studies.  We demonstrate our model both on simulated data and on intrinsic signaling data from ferret visual cortex.',\n",
       "  'id': '3645',\n",
       "  'title': 'Bayesian estimation of orientation preference maps',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We study the behavior of the popular Laplacian Regularization method for Semi-Supervised Learning at the regime of a fixed number of labeled points but a large number of unlabeled points.  We show that in $\\\\R^d$, $d \\\\geq 2$, the method is actually not well-posed, and as the number of unlabeled points increases the solution degenerates to a noninformative function.  We also contrast the method with the Laplacian Eigenvector method, and discuss the ``smoothness assumptions associated with this alternate method.',\n",
       "  'id': '3652',\n",
       "  'title': 'Statistical Analysis of Semi-Supervised Learning: The Limit of Infinite Unlabelled Data',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We extend Dyna planning architecture for policy evaluation and control in two significant aspects. First, we introduce a multi-step Dyna planning that projects the simulated state/feature many steps into the future. Our multi-step Dyna is based on a multi-step model, which we call the {\\\\em $\\\\lambda$-model}. The $\\\\lambda$-model interpolates between the one-step model and an infinite-step model, and can be learned efficiently online. Second, we use for Dyna control a dynamic multi-step model that is able to predict the results of a sequence of greedy actions and track the optimal policy in the long run. Experimental results show that Dyna using the multi-step model evaluates a policy faster than using single-step models; Dyna control algorithms using the dynamic tracking model are much faster than model-free algorithms; further, multi-step Dyna control algorithms enable the policy and value function to converge much faster to their optima than single-step Dyna algorithms.',\n",
       "  'id': '3670',\n",
       "  'title': 'Multi-Step Dyna Planning for Policy Evaluation and Control',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Finding maximally sparse representations from overcomplete feature dictionaries frequently involves minimizing a cost function composed of a likelihood (or data fit) term and a prior (or penalty function) that favors sparsity.  While typically the prior is factorial, here we examine non-factorial alternatives that have a number of desirable properties relevant to sparse estimation and are easily implemented using an efficient, globally-convergent reweighted $\\\\ell_1$ minimization procedure.  The first method under consideration arises from the sparse Bayesian learning (SBL) framework.  Although based on a highly non-convex underlying cost function, in the context of canonical sparse estimation problems, we prove uniform superiority of this method over the Lasso in that, (i) it can never do worse, and (ii) for any dictionary and sparsity profile, there will always exist cases where it does better.  These results challenge the prevailing reliance on strictly convex penalty functions for finding sparse solutions.  We then derive a new non-factorial variant with similar properties that exhibits further performance improvements in empirical tests.  For both of these methods, as well as traditional factorial analogs, we demonstrate the effectiveness of reweighted $\\\\ell_1$-norm algorithms in handling more general sparse estimation problems involving classification, group feature selection, and non-negativity constraints.  As a byproduct of this development, a rigorous reformulation of sparse Bayesian classification (e.g., the relevance vector machine) is derived that, unlike the original, involves no approximation steps and descends a well-defined objective function.',\n",
       "  'id': '3681',\n",
       "  'title': 'Sparse Estimation Using General Likelihoods and Non-Factorial Priors',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper, we study the manifold regularization for the Sliced Inverse Regression (SIR). The manifold regularization improves the standard SIR in two aspects: 1) it encodes the local geometry for SIR and 2) it enables SIR to deal with transductive and semi-supervised learning problems. We prove that the proposed graph Laplacian based regularization is convergent at rate root-n. The projection directions of the regularized SIR are optimized by using a conjugate gradient method on the Grassmann manifold. Experimental results support our theory.',\n",
       "  'id': '3684',\n",
       "  'title': 'Manifold Regularization for SIR with Rate Root-n Convergence',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a Bayesian nonparametric approach to relating multiple time series via a set of latent, dynamical behaviors.  Using a beta process prior, we allow data-driven selection of the size of this set, as well as the pattern with which behaviors are shared among time series.  Via the Indian buffet process representation of the beta process predictive distributions, we develop an exact Markov chain Monte Carlo inference method.  In particular, our approach uses the sum-product algorithm to efficiently compute Metropolis-Hastings acceptance probabilities, and explores new dynamical behaviors via birth/death proposals.  We validate our sampling algorithm using several synthetic datasets, and also demonstrate promising unsupervised segmentation of visual motion capture data.',\n",
       "  'id': '3685',\n",
       "  'title': 'Sharing Features among Dynamical Systems with Beta Processes',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'When used to guide decisions, linear regression analysis typically involves estimation of regression coefficients via ordinary least squares and their subsequent use to make decisions. When there are multiple response variables and features do not perfectly capture their relationships, it is beneficial to account for the decision objective when computing regression coefficients. Empirical optimization does so but sacrifices performance when features are well-chosen or training data are insufficient. We propose directed regression, an efficient algorithm that combines merits of ordinary least squares and empirical optimization. We demonstrate through a computational study that directed regression can generate significant performance gains over either alternative. We also develop a theory that motivates the algorithm.',\n",
       "  'id': '3686',\n",
       "  'title': 'Directed Regression',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper studies the general problem of learning kernels based on a polynomial combination of base kernels. It analyzes this problem in the case of regression and the kernel ridge regression algorithm. It examines the corresponding learning kernel optimization problem, shows how that minimax problem can be reduced to a simpler minimization problem, and proves that the global solution of this problem always lies on the boundary. We give a projection-based gradient descent algorithm for solving the optimization problem, shown empirically to converge in few iterations. Finally, we report the results of extensive experiments with this algorithm using several publicly available datasets demonstrating the effectiveness of our technique.',\n",
       "  'id': '3692',\n",
       "  'title': 'Learning Non-Linear Combinations of Kernels',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Given $n$ noisy samples with $p$ dimensions, where $n \\\\ll p$, we show that the multi-stage thresholding procedures can accurately estimate a sparse vector $\\\\beta \\\\in \\\\R^p$ in a linear model, under the restricted eigenvalue conditions (Bickel-Ritov-Tsybakov 09). Thus our conditions for model selection consistency are considerably weaker than what has been achieved in previous works. More importantly, this method allows very significant values of $s$, which is the number of non-zero elements in the true parameter $\\\\beta$. For example, it works for cases where the ordinary Lasso would have failed. Finally, we show that if $X$ obeys a uniform uncertainty principle and if the true parameter is sufficiently sparse, the Gauss-Dantzig selector (Cand\\\\{e}s-Tao 07) achieves the $\\\\ell_2$ loss within a logarithmic factor of the ideal mean square error one would achieve with an oracle which would supply perfect information about which coordinates are non-zero and which are above the noise level, while selecting a sufficiently sparse model.',\n",
       "  'id': '3697',\n",
       "  'title': 'Thresholding Procedures for High Dimensional Variable Selection and Statistical Estimation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'It has been established that the second-order stochastic gradient descent (2SGD) method can potentially achieve generalization performance as well as empirical optimum in a single pass (i.e., epoch) through the training examples. However, 2SGD requires computing the inverse of the Hessian matrix of the loss function, which is prohibitively expensive. This paper presents Periodic Step-size Adaptation (PSA), which approximates the Jacobian matrix of the mapping function and explores a linear relation between the Jacobian and Hessian to approximate the Hessian periodically and achieve near-optimal results in experiments on a wide variety of models and tasks.',\n",
       "  'id': '3702',\n",
       "  'title': 'Periodic Step Size Adaptation for Single Pass On-line Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'With the advent of the Internet it is now possible to collect   hundreds of millions of images. These images come with varying   degrees of label information. ``Clean labels can be manually obtained on a   small fraction, ``noisy labels may be extracted automatically from  surrounding text, while for most images there are no labels at all. Semi-supervised learning is a principled framework for combining these different label sources. However, it scales polynomially with the  number of images, making it impractical for use on gigantic  collections with hundreds of millions of images and thousands of classes.   In this paper we show how to utilize recent results in machine   learning to obtain highly efficient approximations for   semi-supervised learning that are linear in the number of images.? Specifically, we use the convergence of the eigenvectors of the normalized graph Laplacian to eigenfunctions of weighted Laplace-Beltrami operators. We combine this with a label sharing framework obtained from Wordnet to propagate label information to classes lacking manual annotations. Our algorithm enables us to apply semi-supervised learning to a  database of 80 million images with 74 thousand classes.',\n",
       "  'id': '3633',\n",
       "  'title': 'Semi-Supervised Learning in Gigantic Image Collections',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The replica method is a non-rigorous but widely-used technique from statistical physics used in the asymptotic analysis of many large random nonlinear problems.  This paper applies the replica method to non-Gaussian MAP estimation.  It is shown that with large random linear measurements and Gaussian noise, the asymptotic behavior of the MAP estimate of an n-dimensional vector ``decouples as n scalar MAP estimators.  The result is a counterpart to Guo and Verdus replica analysis on MMSE estimation. The replica MAP analysis can be readily applied to many estimators used in compressed sensing, including basis pursuit, lasso, linear estimation with thresholding and zero-norm estimation.  In the case of lasso estimation, the scalar estimator reduces to a soft-thresholding operator and for zero-norm estimation it reduces to a hard-threshold.  Among other benefits, the replica method provides a computationally tractable method for exactly computing various performance metrics including MSE and sparsity recovery.',\n",
       "  'id': '3635',\n",
       "  'title': 'Asymptotic Analysis of MAP Estimation via the Replica Method and Compressed Sensing',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The human brain can be described as containing a number of functional regions. For a given task, these regions, as well as the connections between them, play a key role in information processing in the brain. However, most existing multi-voxel pattern analysis approaches either treat multiple functional regions as one large uniform region or several independent regions, ignoring the connections between regions. In this paper, we propose to model such connections in an Hidden Conditional Random Field (HCRF) framework, where the classifier of one region of interest (ROI) makes predictions based on not only its voxels but also the classifier predictions from ROIs that it connects to. Furthermore, we propose a structural learning method in the HCRF framework to automatically uncover the connections between ROIs. Experiments on fMRI data acquired while human subjects viewing images of natural scenes show that our model can improve the top-level (the classifier combining information from all ROIs) and ROI-level prediction accuracy, as well as uncover some meaningful connections between ROIs.',\n",
       "  'id': '3641',\n",
       "  'title': 'Hierarchical Mixture of Classification Experts Uncovers Interactions between Brain Regions',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The recent introduction of indefinite SVM by Luss and dAspremont [15] has effectively demonstrated SVM classification with a non-positive semi-definite  kernel (indefinite kernel).  This paper studies the properties of the objective function introduced there. In particular, we show that the objective function  is continuously differentiable and its gradient can be explicitly computed. Indeed, we further show that its gradient is Lipschitz continuous.  The main idea behind our analysis is that the objective function is smoothed by the penalty term, in its saddle (min-max) representation, measuring the distance between the indefinite kernel matrix and the proxy positive semi-definite one. Our elementary result greatly facilitates the application of gradient-based algorithms. Based on our analysis,  we further develop  Nesterovs smooth optimization approach [16,17] for indefinite SVM which has an optimal convergence rate for smooth problems. Experiments on various benchmark datasets validate our analysis and demonstrate the efficiency of our proposed algorithms.',\n",
       "  'id': '3661',\n",
       "  'title': 'Analysis of SVM with Indefinite Kernels',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'There is a growing body of experimental evidence to suggest that the brain is capable of approximating optimal Bayesian inference in the face of noisy input stimuli.  Despite this progress, the neural underpinnings of this computation are still poorly  understood.  In this paper we focus on the problem of Bayesian filtering of stochastic time series.  In particular we introduce a novel neural network, derived from a line attractor architecture, whose dynamics map directly onto those of the Kalman Filter in the limit where the prediction error is small.  When the prediction error is large we show that the network responds robustly to change-points in a way that is qualitatively compatible with the optimal Bayesian model.  The model suggests ways in which probability distributions are encoded in the brain and makes a number of testable experimental predictions.',\n",
       "  'id': '3665',\n",
       "  'title': 'A Neural Implementation of the Kalman Filter',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we present an algorithm for separating mixed sounds from  a monophonic recording. Our approach makes use of training data which  allows us to learn representations of the types of sounds that compose the  mixture. In contrast to popular methods that attempt to extract com-  pact generalizable models for each sound from training data, we employ  the training data itself as a representation of the sources in the mixture.  We show that mixtures of known sounds can be described as sparse com-  binations of the training data itself, and in doing so produce signi?cantly  better separation results as compared to similar systems based on compact  statistical models.',\n",
       "  'id': '3668',\n",
       "  'title': 'A Sparse Non-Parametric Approach for Single Channel Separation of Known Sounds',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Many models for computations in recurrent networks of neurons assume that the network state moves from some initial state to some fixed point attractor or limit cycle that represents the output of the computation. However experimental data show that in response to a sensory stimulus the network state moves from its initial state through a trajectory of network states and eventually returns to the initial state, without reaching an attractor or limit cycle in between. This type of network response, where salient information about external stimuli is encoded in characteristic trajectories of continuously varying network states, raises the question how a neural system could compute with such code, and arrive for example at a temporally stable classification of the external stimulus. We show that a known unsupervised learning algorithm, Slow Feature Analysis (SFA), could be an important ingredient for extracting stable information from these network trajectories. In fact, if sensory stimuli are more often followed by another stimulus from the same class than by a stimulus from another class, SFA approaches the classification capability of Fishers Linear Discriminant (FLD), a powerful algorithm for supervised learning. We apply this principle to simulated cortical microcircuits, and show that it enables readout neurons to learn discrimination of spoken digits and detection of repeating firing patterns within a stream of spike trains with the same firing statistics, without requiring any supervision for learning.',\n",
       "  'id': '3672',\n",
       "  'title': 'Replacing supervised classification learning by Slow Feature Analysis in spiking neural networks',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We prove strong noise-tolerance properties of a potential-based boosting algorithm, similar to MadaBoost (Domingo and Watanabe, 2000) and SmoothBoost (Servedio, 2003). Our analysis is in the agnostic framework of Kearns, Schapire and Sellie (1994), giving polynomial-time guarantees in presence of arbitrary noise. A remarkable feature of our algorithm is that it can be implemented without reweighting examples, by randomly relabeling them instead. Our boosting theorem gives, as easy corollaries, alternative derivations of two recent non-trivial results in computational learning theory: agnostically learning decision trees (Gopalan et al, 2008) and agnostically learning halfspaces (Kalai et al, 2005). Experiments suggest that the algorithm performs similarly to Madaboost.',\n",
       "  'id': '3676',\n",
       "  'title': 'Potential-Based Agnostic Boosting',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper uses information-theoretic techniques to determine minimax rates for estimating nonparametric sparse additive regression models under high-dimensional scaling.  We assume an additive decomposition of the form $f^*(X_1, \\\\ldots, X_p) = \\\\sum_{j \\\\in S} h_j(X_j)$, where each component function $h_j$ lies in some Hilbert Space $\\\\Hilb$ and $S \\\\subset \\\\{1, \\\\ldots, \\\\pdim \\\\}$ is an unknown subset with cardinality $\\\\s = |S$.  Given $\\\\numobs$ i.i.d. observations of $f^*(X)$ corrupted with white Gaussian noise where the covariate vectors $(X_1, X_2, X_3,...,X_{\\\\pdim})$ are drawn with i.i.d. components from some distribution $\\\\mP$, we determine tight lower bounds on the minimax rate for estimating the regression function with respect to squared $\\\\LTP$ error. The main result shows that the minimax rates are $\\\\max{\\\\big(\\\\frac{\\\\s \\\\log \\\\pdim / \\\\s}{n}, \\\\LowerRateSq \\\\big)}$.  The first term reflects the difficulty of performing \\\\emph{subset selection} and is independent of the Hilbert space $\\\\Hilb$; the second term $\\\\LowerRateSq$ is an \\\\emph{\\\\s-dimensional estimation} term, depending only on the low dimension $\\\\s$ but not the ambient dimension $\\\\pdim$, that captures the difficulty of estimating a sum of $\\\\s$ univariate functions in the Hilbert space $\\\\Hilb$.  As a special case, if $\\\\Hilb$ corresponds to the $\\\\m$-th order Sobolev space $\\\\SobM$ of functions that are $m$-times differentiable, the $\\\\s$-dimensional estimation term takes the form $\\\\LowerRateSq \\\\asymp \\\\s \\\\; n^{-2\\\\m/(2\\\\m+1)}$. The minimax rates are compared with rates achieved by an $\\\\ell_1$-penalty based approach, it can be shown that a certain $\\\\ell_1$-based approach achieves the minimax optimal rate.',\n",
       "  'id': '3688',\n",
       "  'title': 'Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Despite the large amount of literature on upper bounds on complexity of convex analysis, surprisingly little is known about the fundamental hardness of these problems. The extensive use of convex optimization in machine learning and statistics makes such an understanding critical to understand fundamental computational limits of learning and estimation. In this paper, we study the complexity of stochastic convex optimization in an oracle model of computation. We improve upon known results and obtain tight minimax complexity estimates for some function classes. We also discuss implications of these results to the understanding the inherent complexity of large-scale learning and estimation problems.',\n",
       "  'id': '3689',\n",
       "  'title': 'Information-theoretic lower bounds on the oracle complexity of convex optimization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Many types of regularization schemes have been employed in statistical learning, each one motivated by some assumption about the problem domain.  In this paper, we present a unified asymptotic analysis of smooth regularizers, which allows us to see how the validity of these assumptions impacts the success of a particular regularizer.  In addition, our analysis motivates an algorithm for optimizing regularization parameters, which in turn can be analyzed within our framework.  We apply our analysis to several examples, including hybrid generative-discriminative learning and multi-task learning.',\n",
       "  'id': '3693',\n",
       "  'title': 'Asymptotically Optimal Regularization in Smooth Parametric Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We study unsupervised learning in a probabilistic generative model for occlusion. The model uses two types of latent variables: one indicates which objects are present in the image, and the other how they are ordered in depth. This depth order then determines how the positions and appearances of the objects present, specified in the model parameters, combine to form the image. We show that the object parameters can be learnt from an unlabelled set of images in which objects occlude one another. Exact maximum-likelihood learning is intractable. However, we show that tractable approximations to Expectation Maximization (EM) can be found if the training images each contain only a small number of objects on average. In numerical experiments it is shown that these approximations recover the correct set of object parameters. Experiments on a novel version of the bars test using colored bars, and experiments on more realistic data, show that the algorithm performs well in extracting the generating causes. Experiments based on the standard bars benchmark test for object learning show that the algorithm performs well in comparison to other recent component extraction approaches. The model and the learning algorithm thus connect research on occlusion with the research field of multiple-cause component extraction methods.',\n",
       "  'id': '3701',\n",
       "  'title': 'Occlusive Components Analysis',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper, we examine the generalization error of regularized distance metric learning. We show that with appropriate constraints, the generalization error of regularized distance metric learning could be independent from the dimensionality, making it suitable for handling high dimensional data. In addition, we present an efficient online learning algorithm for regularized distance metric learning. Our empirical studies with data classification and face recognition show that the proposed algorithm is (i) effective for distance metric learning when compared to the state-of-the-art methods, and (ii) efficient and robust for high dimensional data.',\n",
       "  'id': '3703',\n",
       "  'title': 'Regularized Distance Metric Learning:Theory and Algorithm',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Kernel learning is a powerful framework for nonlinear data modeling. Using the kernel trick, a number of problems have been formulated as semidefinite programs (SDPs). These include Maximum Variance Unfolding (MVU) (Weinberger et al., 2004) in nonlinear dimensionality reduction, and Pairwise Constraint Propagation (PCP) (Li et al., 2008) in constrained clustering. Although in theory SDPs can be efficiently solved, the high computational complexity incurred in numerically processing the huge linear matrix inequality constraints has rendered the SDP approach unscalable. In this paper, we show that a large class of kernel learning problems can be reformulated as semidefinite-quadratic-linear programs (SQLPs), which only contain a simple positive semidefinite constraint, a second-order cone constraint and a number of linear constraints. These constraints are much easier to process numerically, and the gain in speedup over previous approaches is at least of the order $m^{2.5}$, where m is the matrix dimension. Experimental results are also presented to show the superb computational efficiency of our approach.',\n",
       "  'id': '3709',\n",
       "  'title': 'Fast Graph Laplacian Regularized Kernel Learning via Semidefinite?Quadratic?Linear Programming',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Which ads should we display in sponsored search in order to maximize our revenue?  How should we dynamically rank information sources to maximize value of information?  These applications exhibit strong diminishing returns: Selection of redundant ads and information sources decreases their marginal utility.  We show that these and other problems can be formalized as repeatedly selecting an assignment of items to positions to maximize a sequence of monotone submodular functions that arrive one by one.  We present an efficient algorithm for this general problem and analyze it in the no-regret model.  Our algorithm is equipped with strong theoretical guarantees, with a performance ratio that converges to the optimal constant of 1-1/e.  We empirically evaluate our algorithms on two real-world online optimization problems on the web: ad allocation with submodular utilities, and dynamically ranking blogs to detect information cascades.',\n",
       "  'id': '3719',\n",
       "  'title': 'Online Learning of Assignments',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a novel feature selection algorithm for the $k$-means clustering problem. Our algorithm is randomized and, assuming an accuracy parameter $\\\\epsilon \\\\in (0,1)$, selects and appropriately rescales in an unsupervised manner $\\\\Theta(k \\\\log(k / \\\\epsilon) / \\\\epsilon^2)$ features from a dataset of arbitrary dimensions. We prove that, if we run any $\\\\gamma$-approximate $k$-means algorithm ($\\\\gamma \\\\geq 1$) on the features selected using our method, we can find a $(1+(1+\\\\epsilon)\\\\gamma)$-approximate partition with high probability.',\n",
       "  'id': '3724',\n",
       "  'title': 'Unsupervised Feature Selection for the ',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Recent work has led to the ability to perform space ef?cient, approximate counting  over large vocabularies in a streaming context. Motivated by the existence of data  structures of this type, we explore the computation of associativity scores, other-  wise known as pointwise mutual information (PMI), in a streaming context. We  give theoretical bounds showing the impracticality of perfect online PMI compu-  tation, and detail an algorithm with high expected accuracy. Experiments on news  articles show our approach gives high accuracy on real world data.',\n",
       "  'id': '3730',\n",
       "  'title': 'Streaming Pointwise Mutual Information',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Although it is widely believed that reinforcement learning is a suitable tool for describing behavioral learning, the mechanisms by which it can be implemented in networks of spiking neurons are not fully understood. Here, we show that different learning rules emerge from a policy gradient approach depending on which features of the spike trains are assumed to influence the reward signals, i.e., depending on which neural code is in effect. We use the framework of Williams (1992) to derive learning rules for arbitrary neural codes. For illustration, we present policy-gradient rules for  three different example codes - a spike count code, a spike timing code and the most general ``full spike train code - and test them on simple model problems. In addition to classical synaptic learning, we derive learning rules for intrinsic parameters that control the excitability of the neuron. The spike count learning rule has structural similarities with established Bienenstock-Cooper-Munro rules. If the distribution of the relevant spike train features  belongs to the natural exponential family, the learning rules have a characteristic shape that raises interesting prediction problems.',\n",
       "  'id': '3733',\n",
       "  'title': 'Code-specific policy gradient rules for spiking neurons',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A kernel embedding of probability distributions into reproducing kernel Hilbert spaces (RKHS) has recently been proposed, which  allows the comparison of two probability measures P and Q based on the distance between their respective embeddings: for a sufficiently rich RKHS, this distance is zero if and only if P and Q coincide. In using this distance as a statistic for a  test of whether two samples are from different distributions, a major difficulty arises in computing the significance threshold, since the empirical statistic has as its null distribution (where P=Q)  an infinite weighted sum of $\\\\chi^2$ random variables. The main result of the present work is a  novel, consistent estimate of this null distribution, computed from  the eigenspectrum of the Gram matrix on the aggregate sample from P and Q. This estimate may be computed faster than a previous consistent estimate based on the bootstrap.  Another prior approach was to compute the null distribution based on fitting a parametric family with the low order moments of the test statistic: unlike the present work, this heuristic has no guarantee of being accurate or consistent. We verify the performance of our null distribution estimate on both   an artificial example and on high dimensional multivariate data.',\n",
       "  'id': '3738',\n",
       "  'title': 'A Fast, Consistent Kernel Two-Sample Test',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Semi-supervised regression based on the graph Laplacian suffers from the fact that the solution is biased towards a constant and the lack of extrapolating power. Outgoing from these observations we propose to use the second-order Hessian energy for semi-supervised regression which overcomes both of these problems, in particular, if the data lies on or close to a low-dimensional submanifold in the feature space, the Hessian energy prefers functions which vary ``linearly with respect to the natural parameters in the data. This property makes it also particularly suited for the task of semi-supervised dimensionality reduction where the goal is to find the natural parameters in the data based on a few labeled points. The experimental result suggest that our method is superior to semi-supervised regression using Laplacian regularization and standard supervised methods and is particularly suited for semi-supervised dimensionality reduction.',\n",
       "  'id': '3741',\n",
       "  'title': 'Semi-supervised Regression using Hessian energy with an application to semi-supervised dimensionality reduction',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a class of nonlinear (polynomial) models that are discriminatively trained to directly map from the word content in a query-document or document-document pair to a ranking score. Dealing with polynomial models on word features is computationally challenging. We propose a low rank (but diagonal preserving) representation of our polynomial models to induce feasible memory and computation requirements. We provide an empirical study on retrieval tasks based on Wikipedia documents, where we obtain state-of-the-art performance while providing realistically scalable methods.',\n",
       "  'id': '3742',\n",
       "  'title': 'Polynomial Semantic Indexing',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Several key problems in machine learning, such as feature selection and active learning, can be formulated as submodular set function maximization.  We present herein a novel algorithm for maximizing a submodular set function under a cardinality constraint --- the algorithm is based on a cutting-plane method and is implemented as an iterative small-scale binary-integer linear programming procedure. It is well known that this problem is NP-hard, and the approximation factor achieved by the greedy algorithm is the theoretical limit for polynomial time. As for (non-polynomial time) exact algorithms that perform reasonably in practice, there has been very little in the literature although the problem is quite important for many applications. Our algorithm is guaranteed to find the exact solution in finite iterations, and it converges fast in practice due to the efficiency of the cutting-plane mechanism. Moreover, we also provide a method that produces successively decreasing upper-bounds of the optimal solution, while our algorithm provides successively increasing lower-bounds.  Thus, the accuracy of the current solution can be estimated at any point, and the algorithm can be stopped early once a desired degree of tolerance is met.  We evaluate our algorithm on sensor placement and feature selection applications showing good performance.',\n",
       "  'id': '3762',\n",
       "  'title': 'Submodularity Cuts and Applications',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Stochastic Neighbor Embedding (SNE) has shown to be quite promising for data visualization.  Currently, the most popular implementation, t-SNE, is restricted to a particular Student t-distribution as its embedding distribution. Moreover, it uses a gradient descent algorithm that may require users to tune parameters such as the learning step size, momentum, etc., in finding its optimum. In this paper, we propose the Heavy-tailed Symmetric Stochastic Neighbor Embedding (HSSNE) method, which is a generalization of the t-SNE to accommodate various heavy-tailed embedding similarity functions. With this generalization, we are presented with two difficulties.  The first is how to select the best embedding similarity among all heavy-tailed functions and the second is how to optimize the objective function once the heave-tailed function has been selected. Our contributions then are: (1) we point out that various heavy-tailed embedding similarities can be characterized by their negative score functions. Based on this finding, we present a parameterized subset of similarity functions for choosing the best tail-heaviness for HSSNE; (2) we present a fixed-point optimization algorithm that can be applied to all heavy-tailed functions and does not require the user to set any parameters; and (3) we present two empirical studies, one for unsupervised visualization showing that our optimization algorithm runs as fast and as good as the best known t-SNE implementation and the other for semi-supervised visualization showing quantitative superiority using the homogeneity measure as well as qualitative advantage in cluster separation over t-SNE.',\n",
       "  'id': '3770',\n",
       "  'title': 'Heavy-Tailed Symmetric Stochastic Neighbor Embedding',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Humans are typically able to infer how many objects their environment contains and to recognize when the same object is encountered twice.  We present a simple statistical model that helps to explain these abilities and evaluate it in three behavioral experiments.  Our first experiment suggests that humans rely on prior knowledge when deciding whether an object token has been previously encountered. Our second and third experiments suggest that humans can infer how many objects they have seen and can learn about categories and their properties even when they are uncertain about which tokens are instances of the same object.',\n",
       "  'id': '3776',\n",
       "  'title': 'Individuation, Identification and Object Discovery',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The Partially Observable Markov Decision Process (POMDP) framework has proven useful in planning domains that require balancing actions that increase an agents knowledge and actions that increase an agents reward.  Unfortunately, most POMDPs are complex structures with a large number of parameters.  In many realworld problems, both the structure and the parameters are difficult to specify from domain knowledge alone.  Recent work in Bayesian reinforcement learning has made headway in learning POMDP models; however, this work has largely focused on learning the parameters of the POMDP model.  We define an infinite POMDP (iPOMDP) model that does not require knowledge of the size of the state space; instead, it assumes that the number of visited states will grow as the agent explores its world and explicitly models only visited states.  We demonstrate the iPOMDP utility on several standard problems.',\n",
       "  'id': '3780',\n",
       "  'title': 'The Infinite Partially Observable Markov Decision Process',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We provide some insights into how task correlations in multi-task Gaussian process (GP) regression affect the generalization error and the learning curve.  We analyze the asymmetric two-task case, where a secondary task is to help the learning of a primary task. Within this setting, we give bounds on the generalization error and the learning curve of the primary task. Our approach admits intuitive understandings of the multi-task GP by relating it to single-task GPs. For the case of one-dimensional input-space under optimal sampling with data only for the secondary task, the limitations of multi-task GP can be quantified explicitly.',\n",
       "  'id': '3786',\n",
       "  'title': 'Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'For many computer vision applications, the ideal image feature would be invariant to multiple confounding image properties, such as illumination and viewing angle. Recently, deep architectures trained in an unsupervised manner have been proposed as an automatic method for extracting useful features. However, outside of using these learning algorithms in a classi?er, they can be sometimes dif?cult to evaluate. In this paper, we propose a number of empirical tests that directly measure the degree to which these learned features are invariant to different image transforms. We ?nd that deep autoencoders become invariant to increasingly complex image transformations with depth. This further justi?es the use of ?deep? vs. ?shallower? representations. Our performance metrics agree with existing measures of invariance. Our evaluation metrics can also be used to evaluate future work in unsupervised deep learning, and thus help the development of future algorithms.',\n",
       "  'id': '3790',\n",
       "  'title': 'Measuring Invariances in Deep Networks',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In practice, most investing is done assuming a probabilistic model of stock price returns known as the Geometric Brownian Motion (GBM). While it is often an acceptable approximation, the GBM model is not always valid empirically. This motivates a worst-case approach to investing, called universal portfolio management, where the objective is to maximize wealth relative to the wealth earned by the best fixed portfolio in hindsight.  In this paper we tie the two approaches, and design an investment strategy which is universal in the worst-case, and yet capable of exploiting the mostly valid GBM model. Our method is based on new and improved regret bounds for online convex optimization with exp-concave loss functions.',\n",
       "  'id': '3795',\n",
       "  'title': 'On Stochastic and Worst-case Models for Investing',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a probabilistic latent factor model which can be used for studying spatio-temporal datasets. The spatial and temporal structure is modeled by using Gaussian process priors both for the loading matrix and the factors. The posterior distributions are approximated using the variational Bayesian framework. High computational cost of Gaussian process modeling is reduced by using sparse approximations. The model is used to compute the reconstructions of the global sea surface temperatures from a historical dataset. The results suggest that the proposed model can outperform the state-of-the-art reconstruction systems.',\n",
       "  'id': '3805',\n",
       "  'title': 'Variational Gaussian-process factor analysis for modeling spatio-temporal data',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We formulate and address the problem of discovering dynamic malicious regions on the Internet. We model this problem as one of adaptively pruning a known decision tree, but with additional challenges: (1) severe space requirements, since the underlying decision tree has over 4 billion leaves, and (2) a changing target function, since malicious activity on the Internet is dynamic. We present a novel algorithm that addresses this problem, by putting together a number of different ``experts algorithms and online paging algorithms. We prove guarantees on our algorithms performance as a function of the best possible pruning of a similar size, and our experiments show that our algorithm achieves high accuracy on large real-world data sets, with significant improvements over existing approaches.',\n",
       "  'id': '3807',\n",
       "  'title': 'Tracking Dynamic Sources of Malicious Activity at Internet Scale',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce the first  temporal-difference  learning algorithms that converge  with smooth value function approximators, such as neural networks. Conventional temporal-difference (TD) methods, such as TD($\\\\lambda$), Q-learning and Sarsa have been used successfully with function approximation in many applications.  However, it is well known that off-policy sampling, as well as nonlinear function approximation, can cause these algorithms to become unstable (i.e., the parameters of the approximator may diverge). Sutton et al (2009a,b) solved the problem of off-policy learning with linear TD algorithms by introducing a new objective function, related to the Bellman-error, and algorithms that perform stochastic gradient-descent on this function. In this paper, we generalize their work to nonlinear function approximation. We present a Bellman error objective function and two gradient-descent TD algorithms that optimize it. We prove the  asymptotic almost-sure convergence  of both algorithms for any finite Markov decision process and any smooth value function approximator, under usual stochastic approximation conditions. The computational complexity per iteration scales linearly with the number of parameters of the approximator. The algorithms are incremental and are guaranteed to converge to locally optimal solutions.',\n",
       "  'id': '3809',\n",
       "  'title': 'Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We describe a new algorithmic framework for inference in probabilistic models, and apply it to inference for latent Dirichlet allocation. Our framework adopts the methodology of variational inference, but unlike existing variational methods such as mean field and expectation propagation it is not restricted to tractable classes of approximating distributions. Our approach can also be viewed as a sequential Monte Carlo (SMC) method, but unlike existing SMC methods there is no need to design the artificial sequence of distributions. Notably, our framework offers a principled means to exchange the variance of an importance sampling estimate for the bias incurred through variational approximation. Experiments on a challenging inference problem in population genetics demonstrate improvements in stability and accuracy over existing methods, and at a comparable cost.',\n",
       "  'id': '3823',\n",
       "  'title': 'A Stochastic approximation method for inference in probabilistic graphical models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Kernel density estimation is the most widely-used practical method for accurate nonparametric density estimation. However, long-standing worst-case theoretical results showing that its performance worsens exponentially with the dimension of the data have quashed its application to modern high-dimensional datasets for decades. In practice, it has been recognized that often such data have a much lower-dimensional intrinsic structure. We propose a small modification to kernel density estimation for estimating probability density functions on Riemannian submanifolds of Euclidean space. Using ideas from Riemannian geometry, we prove the consistency of this modified estimator and show that the convergence rate is determined by the intrinsic dimension of the submanifold. We conclude with empirical results demonstrating the behavior predicted by our theory.',\n",
       "  'id': '3826',\n",
       "  'title': 'Submanifold density estimation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we make several contributions towards accelerating approximate Bayesian structural inference for non-decomposable GGMs. Our first contribution is to show how to efficiently compute a BIC or Laplace approximation to the marginal likelihood of non-decomposable graphs using convex methods for precision matrix estimation. This optimization technique can be used as a fast scoring function inside standard Stochastic Local Search (SLS) for generating posterior samples. Our second contribution is a novel framework for efficiently generating large sets of high-quality graph topologies without performing local search. This graph proposal method, which we call Neighborhood Fusion\" (NF), samples candidate Markov blankets at each node using sparse regression techniques. Our final contribution is a hybrid method combining the complementary strengths of NF and SLS. Experimental results in structural recovery and prediction tasks demonstrate that NF and hybrid NF/SLS out-perform state-of-the-art local search methods, on both synthetic and real-world datasets, when realistic computational limits are imposed.\"',\n",
       "  'id': '3827',\n",
       "  'title': 'Accelerating Bayesian Structural Inference for Non-Decomposable Gaussian Graphical Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Multiple object tracking is a task commonly used to investigate the architecture of human visual attention. Human participants show a distinctive pattern of successes and failures in tracking experiments that is often attributed to limits on an object system, a tracking module, or other specialized cognitive structures. Here we use a computational analysis of the task of object tracking to ask which human failures arise from cognitive limitations and which are consequences of inevitable perceptual uncertainty in the tracking task. We find that many human performance phenomena, measured through novel behavioral experiments, are naturally produced by the operation of our ideal observer model (a Rao-Blackwelized particle filter). The tradeoff between the speed and number of objects being tracked, however, can only arise from the allocation of a flexible cognitive resource, which can be formalized as either memory or attention.',\n",
       "  'id': '3828',\n",
       "  'title': 'Explaining human multiple object tracking as resource-constrained approximate inference in a dynamic probabilistic model',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Second-order maximum-entropy models have recently gained much interest for describing the statistics of binary spike trains. Here, we extend this approach to take continuous stimuli into account as well. By constraining  the joint second-order statistics, we obtain a joint Gaussian-Boltzmann distribution of continuous stimuli and binary neural firing patterns, for which we also compute marginal and conditional distributions. This model has the same computational complexity as pure binary models and fitting it to data is a convex problem. We show that the model can be seen as an extension to the classical spike-triggered average/covariance analysis and can be used as a non-linear method for extracting features which a neural population is sensitive to. Further, by calculating the posterior distribution of stimuli given an observed neural response, the model can be used to decode stimuli and yields a natural spike-train metric. Therefore, extending the framework of maximum-entropy models to continuous variables allows us to gain novel insights into the relationship between the firing patterns of neural ensembles and the stimuli they are processing.',\n",
       "  'id': '3831',\n",
       "  'title': 'A joint maximum-entropy model for binary neural population patterns and continuous signals',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Synapses exhibit an extraordinary degree of short-term malleability, with release probabilities and effective synaptic strengths changing markedly over multiple timescales. From the perspective of a fixed computational operation in a network, this seems like a most unacceptable degree of added noise. We suggest an alternative theory according to which short term synaptic plasticity plays a normatively-justifiable role. This theory starts from the commonplace observation that the spiking of a neuron is an incomplete, digital, report of the analog quantity that contains all the critical information, namely its membrane potential. We suggest that one key task for a synapse is to solve the inverse problem of estimating the pre-synaptic membrane potential from the spikes it receives and prior  expectations, as in a recursive filter. We show that short-term synaptic depression has canonical dynamics which closely resemble those required for optimal estimation, and that it indeed supports high quality estimation. Under this account, the local postsynaptic potential and the level of synaptic resources track the (scaled) mean and variance of the estimated presynaptic membrane potential. We make  experimentally testable predictions for how the statistics of subthreshold membrane potential fluctuations and the form of spiking non-linearity should be related to the properties of short-term plasticity in any particular cell type.',\n",
       "  'id': '3841',\n",
       "  'title': 'Know Thy Neighbour: A Normative Theory of Synaptic Depression',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present AROW, a new online learning algorithm that combines several properties of successful : large margin training, confidence weighting, and the capacity to handle non-separable data. AROW performs adaptive regularization of the prediction function upon seeing each new instance, allowing it to perform especially well in the presence of label noise.  We derive a mistake bound, similar in form to the second order perceptron bound, which does not assume separability. We also relate our algorithm to recent confidence-weighted online learning techniques and empirically show that AROW achieves state-of-the-art performance and notable robustness in the case of non-separable data.',\n",
       "  'id': '3848',\n",
       "  'title': 'Adaptive Regularization of Weight Vectors',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Over recent years Dirichlet processes and the associated Chinese restaurant process (CRP) have found many applications in clustering while the Indian buffet process (IBP) is increasingly used to describe latent feature models. In the clustering case, we associate to each data point a latent allocation variable. These latent variables can share the same value and this induces a partition of the data set. The CRP is a prior distribution on such partitions.  In latent feature models, we associate to each data point a potentially infinite number of binary latent variables indicating the possession of some features and the IBP is a prior distribution on the associated infinite binary matrix. These prior distributions are attractive because they ensure exchangeability (over samples). We propose here extensions of these models to decomposable graphs. These models have appealing properties and can be easily learned using Monte Carlo techniques.',\n",
       "  'id': '3853',\n",
       "  'title': 'Bayesian Nonparametric Models on Decomposable Graphs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Continuous-time Markov chains are used to model systems in which transitions between states as well as the time the system spends in each state are random.  Many computational problems related to such chains have been solved, including determining state distributions as a function of time, parameter estimation, and control.  However, the problem of inferring most likely trajectories, where a trajectory is a sequence of states as well as the amount of time spent in each state, appears unsolved.  We study three versions of this problem: (i) an initial value problem, in which an initial state is given and we seek the most likely trajectory until a given final time, (ii) a boundary value problem, in which initial and final states and times are given, and we seek the most likely trajectory connecting them, and (iii) trajectory inference under partial observability, analogous to finding maximum likelihood trajectories for hidden Markov models.  We show that maximum likelihood trajectories are not always well-defined, and describe a polynomial time test for well-definedness.  When well-definedness holds, we show that each of the three problems can be solved in polynomial time, and we develop efficient dynamic programming algorithms for doing so.',\n",
       "  'id': '3859',\n",
       "  'title': 'Maximum likelihood trajectories for continuous-time Markov chains',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In visual recognition, the images are frequently modeled as sets of local features (bags). We show that bag of words, a common method to handle such cases, can be viewed as a special match kernel, which counts 1 if two local features fall into the same regions partitioned by visual words and 0 otherwise. Despite its simplicity, this quantization is too coarse. It is, therefore, appealing to design match kernels that more accurately measure the similarity between local features. However, it is impractical to use such kernels on large datasets due to their significant computational cost. To address this problem, we propose an efficient match kernel (EMK), which maps local features to a low dimensional feature space, average the resulting feature vectors to form a set-level feature, then apply a linear classifier. The local feature maps are learned so that their inner products preserve, to the best possible, the values of the specified kernel function. EMK is linear both in the number of images and in the number of local features. We demonstrate that EMK is extremely efficient and achieves the current state of the art performance on three difficult real world datasets: Scene-15, Caltech-101 and Caltech-256.',\n",
       "  'id': '3874',\n",
       "  'title': 'Efficient Match Kernel between Sets of Features for Visual Recognition',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a general inference framework for inter-domain Gaussian Processes (GPs), focusing on its usefulness to build sparse GP models. The state-of-the-art sparse GP model introduced by Snelson and Ghahramani in [1] relies on finding a small, representative pseudo data set of m elements (from the same domain as the n available data elements) which is able to explain existing data well, and then uses it to perform inference. This reduces inference and model selection computation time from O(n^3) to O(m^2n), where m << n. Inter-domain GPs can be used to find a (possibly more compact) representative set of features lying in a different domain, at the same computational cost. Being able to specify a different domain for the representative features allows to incorporate prior knowledge about relevant characteristics of data and detaches the functional form of the covariance and basis functions. We will show how previously existing models fit into this framework and will use it to develop two new sparse GP models. Tests on large, representative regression data sets suggest that significant improvement can be achieved, while retaining computational efficiency.',\n",
       "  'id': '3876',\n",
       "  'title': 'Inter-domain Gaussian Processes for Sparse Inference using Inducing Features',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Motivated from real world problems, like object categorization, we study a particular mixed-norm regularization for Multiple Kernel Learning (MKL). It is assumed that the given set of kernels are grouped into distinct components where each component is crucial for the learning task at hand. The formulation hence employs $l_\\\\infty$ regularization for promoting combinations at the component level and $l_1$ regularization for promoting sparsity among kernels in each component. While previous attempts have formulated this as a non-convex problem, the formulation given here is an instance of non-smooth convex optimization problem which admits an efficient Mirror-Descent (MD) based procedure. The MD procedure optimizes over product of simplexes, which is not a well-studied case in literature. Results on real-world datasets show that the new MKL formulation is well-suited for object categorization tasks and that the MD based algorithm outperforms state-of-the-art MKL solvers like \\\\texttt{simpleMKL} in terms of computational effort.',\n",
       "  'id': '3880',\n",
       "  'title': 'On the Algorithmics and Applications of a Mixed-norm based Kernel Learning Formulation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We study the problem of decision-theoretic online learning (DTOL). Motivated by practical applications, we focus on DTOL when the number of actions is very large. Previous algorithms for learning in this framework have a tunable learning rate parameter, and a major barrier to using online-learning in practical applications is that it is not understood how to set this parameter optimally, particularly when the number of actions is large. In this paper, we offer a clean solution by proposing a novel and completely parameter-free algorithm for DTOL.   In addition, we introduce a new notion of regret, which is more natural for applications with a large number of actions. We show that our algorithm achieves good performance with respect to this new notion of regret; in addition, it also achieves performance close to that of the best bounds achieved by previous algorithms with optimally-tuned parameters, according to previous notions of regret.',\n",
       "  'id': '3883',\n",
       "  'title': 'A Parameter-free Hedging Algorithm',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We develop an algorithm for efficient range search when the notion of dissimilarity is given by a Bregman divergence.  The range search task is to return all points in a potentially large database that are within some specified distance of a query.  It arises in many learning algorithms such as locally-weighted regression, kernel density estimation, neighborhood graph-based algorithms, and in tasks like outlier detection and information retrieval.  In metric spaces, efficient range search-like algorithms based on spatial data structures have been deployed on a variety of statistical tasks.  Here we describe the first algorithm for range search for an arbitrary Bregman divergence.   This broad class of dissimilarity measures includes the relative entropy,  Mahalanobis distance, Itakura-Saito divergence, and a variety of matrix divergences.  Metric methods cannot be directly applied since Bregman divergences do not in general satisfy the triangle inequality.  We derive geometric properties of Bregman divergences that yield an efficient algorithm for range search based on a recently proposed space decomposition for Bregman divergences.',\n",
       "  'id': '3884',\n",
       "  'title': 'Efficient Bregman Range Search',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Dependent Dirichlet processes (DPs) are dependent sets of random measures, each being marginally Dirichlet process distributed. They are used in Bayesian nonparametric models when the usual exchangebility assumption does not hold. We propose a simple and general framework to construct dependent DPs by marginalizing and normalizing a single gamma process over an extended space. The result is a set of DPs, each located at a point in a space such that  neighboring DPs are more dependent. We describe Markov chain Monte Carlo inference, involving the typical Gibbs sampling and three different Metropolis-Hastings proposals to speed up convergence. We report an empirical study of convergence speeds on a synthetic dataset and demonstrate an application of the model to topic modeling through time.',\n",
       "  'id': '3630',\n",
       "  'title': 'Spatial Normalized Gamma Processes',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a sequence of unsupervised, nonparametric Bayesian models for clustering  complex linguistic objects. In this approach, we consider a potentially infinite number of features and categorical outcomes. We evaluate these models for the task  of within- and cross-document event coreference on two corpora.  All the models we investigated show significant improvements when compared against an existing baseline for this task.',\n",
       "  'id': '3637',\n",
       "  'title': 'Nonparametric Bayesian Models for Unsupervised Event Coreference Resolution',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The concave-convex procedure (CCCP) is a majorization-minimization algorithm that solves d.c. (difference of convex functions) programs as a sequence of convex programs. In machine learning, CCCP is extensively used in many learning algorithms like sparse support vector machines (SVMs), transductive SVMs, sparse principal component analysis, etc. Though widely used in many applications, the convergence behavior of CCCP has not gotten a lot of specific attention. Yuille and Rangarajan analyzed its convergence in their original paper, however, we believe the analysis is not complete. Although the convergence of CCCP can be derived from the convergence of the d.c. algorithm (DCA), their proof is more specialized and technical than actually required for the specific case of CCCP. In this paper, we follow a different reasoning and show how Zangwills global convergence theory of iterative algorithms provides a natural framework to prove the convergence of CCCP, allowing a more elegant and simple proof. This underlines Zangwills theory as a powerful and general framework to deal with the convergence issues of iterative algorithms, after also being used to prove the convergence of algorithms like expectation-maximization, generalized alternating minimization, etc. In this paper, we provide a rigorous analysis of the convergence of CCCP by addressing these questions: (i) When does CCCP find a local minimum or a stationary point of the d.c. program under consideration? (ii) When does the sequence generated by CCCP converge? We also present an open problem on the issue of local convergence of CCCP.',\n",
       "  'id': '3646',\n",
       "  'title': 'On the Convergence of the Concave-Convex Procedure',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper considers a sensitivity analysis in Hidden Markov Models with continuous state and observation spaces. We propose an Infinitesimal Perturbation Analysis (IPA) on the filtering distribution with respect to some parameters of the model. We describe a methodology for using any algorithm that estimates the filtering density, such as Sequential Monte Carlo methods, to design an algorithm that estimates its gradient. The resulting IPA estimator is proven to be asymptotically unbiased, consistent and has computational complexity linear in the number of particles. We consider an application of this analysis to the problem of identifying unknown parameters of the model given a sequence of observations. We derive an IPA estimator for the gradient of the log-likelihood, which may be used in a gradient method for the purpose of likelihood maximization. We illustrate the method with several numerical experiments.',\n",
       "  'id': '3648',\n",
       "  'title': 'Sensitivity analysis in HMMs with application to likelihood maximization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Motivated by recent developments in manifold-valued regression we propose a family of nonparametric kernel-smoothing estimators with metric-space valued output including a robust median type estimator and the classical Frechet mean. Depending on the choice of the output space and the chosen metric the estimator reduces to partially well-known procedures for multi-class classification, multivariate regression in Euclidean space, regression with manifold-valued output and even some cases of structured output learning. In this paper we focus on the case of regression with manifold-valued input and output. We show pointwise and Bayes consistency for all estimators in the family for the case of manifold-valued output and illustrate the robustness properties of the estimator with experiments.',\n",
       "  'id': '3649',\n",
       "  'title': 'Robust Nonparametric Regression with Metric-Space Valued Output',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Recent advances in neuroimaging techniques provide great potentials for effective diagnosis of Alzheimer?s disease (AD), the most common form of dementia. Previous studies have shown that AD is closely related to alternation in the functional brain network, i.e., the functional connectivity among different brain regions. In this paper, we consider the problem of learning functional brain connectivity from neuroimaging, which holds great promise for identifying image-based markers used to distinguish Normal Controls (NC), patients with Mild Cognitive Impairment (MCI), and patients with AD.  More specifically, we study sparse inverse covariance estimation (SICE), also known as exploratory Gaussian graphical models, for brain connectivity modeling. In particular, we apply SICE to learn and analyze functional brain connectivity patterns from different subject groups, based on a key property of SICE, called the ?monotone property? we established in this paper. Our experimental results on neuroimaging PET data of 42 AD, 116 MCI, and 67 NC subjects reveal several interesting connectivity patterns consistent with literature findings, and also some new patterns that can help the knowledge discovery of AD.',\n",
       "  'id': '3651',\n",
       "  'title': \"Learning Brain Connectivity of Alzheimer's Disease from Neuroimaging Data\",\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The control of neuroprosthetic devices from the activity of motor cortex neurons benefits from learning effects where the function of these neurons is adapted to the control task. It was recently shown that tuning properties of neurons in monkey motor cortex are adapted selectively in order to compensate for an erroneous interpretation of their activity. In particular, it was shown that the tuning curves of those neurons whose preferred directions had been misinterpreted changed more than those of other neurons. In this article, we show that the experimentally observed self-tuning properties of the system can be explained on the basis of a simple learning rule. This learning rule utilizes neuronal noise for exploration and performs Hebbian weight updates that are modulated by a global reward signal. In contrast to most previously proposed reward-modulated Hebbian learning rules, this rule does not require extraneous knowledge about what is noise and what is signal. The learning rule is able to optimize the performance of the model system within biologically realistic periods of time and under high noise levels. When the neuronal noise is fitted to experimental data, the model produces learning effects similar to those found in monkey experiments.',\n",
       "  'id': '3656',\n",
       "  'title': 'Functional network reorganization in motor cortex can be explained by reward-modulated Hebbian learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The nested Chinese restaurant process (nCRP) is a powerful nonparametric Bayesian model for learning tree-based hierarchies from data. Since its posterior distribution is intractable, current inference methods have all relied on MCMC sampling. In this paper, we develop an alternative inference technique based on variational methods. To employ variational methods, we derive a tree-based stick-breaking construction of the nCRP mixture model, and a novel variational algorithm that efficiently explores a posterior over a large set of combinatorial structures. We demonstrate the use of this approach for text and hand written digits modeling, where we show we can adapt the nCRP to continuous data as well.',\n",
       "  'id': '3662',\n",
       "  'title': 'Variational Inference for the Nested Chinese Restaurant Process',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In the quest to make Brain Computer Interfacing (BCI) more usable, dry electrodes have emerged that get rid of the initial 30 minutes required for placing an electrode cap.  Another time consuming step is the required individualized adaptation to the BCI user, which involves another 30 minutes calibration for assessing a subjects brain signature. In this paper we aim to also remove this calibration proceedure from BCI setup time by means of machine learning. In particular, we harvest a large database of EEG BCI motor imagination recordings (83 subjects) for constructing a library of subject-specific spatio-temporal filters and derive a subject independent BCI classifier. Our offline results indicate that BCI-na\\\\{i}ve users could start real-time BCI use with no prior calibration at only a very moderate performance loss.\"',\n",
       "  'id': '3671',\n",
       "  'title': 'Subject independent EEG-based BCI decoding',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Canonical Correlation Analysis (CCA) is a useful technique for modeling dependencies between two (or more) sets of variables. Building upon the recently suggested probabilistic interpretation of CCA, we propose a nonparametric, fully Bayesian framework that can automatically select the number of correlation components, and effectively capture the sparsity underlying the projections. In addition, given (partially) labeled data, our algorithm can also be used as a (semi)supervised dimensionality reduction technique, and can be applied to learn useful predictive features in the context of learning a set of related tasks. Experimental results demonstrate the efficacy of the proposed approach for both CCA as a stand-alone problem, and when applied to multi-label prediction.',\n",
       "  'id': '3673',\n",
       "  'title': 'Multi-Label Prediction via Sparse Infinite CCA',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a new approach to the problem of robust estimation in multiview geometry. Inspired by recent  advances in the sparse recovery problem of statistics, our estimator is defined as a Bayesian maximum a posteriori  with multivariate Laplace prior on the vector describing the outliers. This leads to an estimator in which  the fidelity to the data is measured by the $L_\\\\infty$-norm while the regularization is done by the $L_1$-norm.  The proposed procedure is fairly fast since the outlier removal is done by solving one linear program (LP).  An important difference compared to existing algorithms is that for our estimator it is not necessary  to specify neither the number nor the proportion of the outliers. The theoretical results, as well as  the numerical example reported in this work, confirm the efficiency of the proposed approach.',\n",
       "  'id': '3677',\n",
       "  'title': '<var>L_1</var>',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Since the development of loopy belief propagation, there has been considerable work on advancing the state of the art for approximate inference over distributions defined on discrete random variables. Improvements include guarantees of convergence, approximations that are provably more accurate, and bounds on the results of exact inference.  However, extending these methods  to continuous-valued systems has lagged behind.  While several methods have been developed to use belief propagation on systems with continuous values, they have not as yet incorporated the recent advances for discrete variables. In this context we extend a recently proposed particle-based belief propagation algorithm to provide a general framework for adapting discrete message-passing algorithms to perform inference in continuous systems.  The resulting algorithms behave similarly to their purely discrete counterparts, extending the benefits of these more advanced inference techniques to the continuous domain.',\n",
       "  'id': '3682',\n",
       "  'title': 'Particle-based Variational Inference for Continuous Systems',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Bag-of-words document representations are often used in text, image and video processing. While it is relatively easy to determine a suitable word dictionary for text documents, there is no simple mapping from raw images or videos to dictionary terms. The classical approach builds a dictionary using vector quantization over a large set of useful visual descriptors extracted from a training set, and uses a nearest-neighbor algorithm to count the number of occurrences of each dictionary word in documents to be encoded. More robust approaches have been proposed recently that represent each visual descriptor as a sparse weighted combination of dictionary words. While favoring a sparse representation at the level of visual descriptors, those methods however do not ensure that images have sparse representation. In this work, we use mixed-norm regularization to achieve sparsity at the image level as well as a small overall dictionary. This approach can also be used to encourage using the same dictionary words for all the images in a class, providing a discriminative signal in the construction of image representations. Experimental results on a benchmark image classification dataset show that when compact image or dictionary representations are needed for computational efficiency, the proposed approach yields better mean average precision in classification.',\n",
       "  'id': '3691',\n",
       "  'title': 'Group Sparse Coding',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'By adding a spatial regularization kernel to a standard loss function formulation of the boosting problem, we develop a framework for spatially informed boosting.  From this regularized loss framework we derive an efficient boosting algorithm that uses additional weights/priors on the base classifiers.  We prove that the proposed algorithm exhibits a ``grouping effect, which encourages the selection of all spatially local, discriminative base classifiers.  The algorithms primary advantage is in applications where the trained classifier is used to identify the spatial pattern of discriminative information, e.g. the voxel selection problem in fMRI.  We demonstrate the algorithms performance on various data sets.',\n",
       "  'id': '3696',\n",
       "  'title': 'Boosting with Spatial Regularization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Principal component analysis is a fundamental operation in computational data analysis, with myriad applications ranging from web search to bioinformatics to computer vision and image analysis. However, its performance and applicability in real scenarios are limited by a lack of robustness to outlying or corrupted observations. This paper considers the idealized ?robust principal component analysis? problem of recovering a low rank matrix A from corrupted observations D = A + E. Here, the error entries E can be arbitrarily large (modeling grossly corrupted observations common in visual and bioinformatic data), but are assumed to be sparse. We prove that most matrices A can be efficiently and exactly recovered from most error sign-and-support patterns, by solving a simple convex program. Our result holds even when the rank of A grows nearly proportionally (up to a logarithmic factor) to the dimensionality of the observation space and the number of errors E grows in proportion to the total number of entries in the matrix. A by-product of our analysis is the first proportional growth results for the related problem of completing a low-rank matrix from a small fraction of its entries. Simulations and real-data examples corroborate the theoretical results, and suggest potential applications in computer vision.',\n",
       "  'id': '3704',\n",
       "  'title': 'Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning. It stands in the core of classification methods like kernel machines, and is particularly useful for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video. In these tasks, users look for objects that are not only visually similar but also semantically related to a given object. Unfortunately, current approaches for learning similarity may not scale to large datasets with high dimensionality, especially when imposing metric constraints on the learned similarity. We describe OASIS, a method for learning pairwise similarity that is fast and scales linearly with the number of objects and the number of non-zero features. Scalability is achieved through online learning of a bilinear model over sparse representations using a large margin criterion and an efficient hinge loss cost. OASIS is accurate at a wide range of scales: on a standard benchmark with thousands of images, it is more precise than state-of-the-art methods, and faster by orders of magnitude. On 2 million images collected from the web, OASIS can be trained within 3 days on a single CPU. The non-metric similarities learned by OASIS can be transformed into metric similarities, achieving higher precisions than similarities that are learned as metrics in the first place. This suggests an approach for learning a metric from data that is larger by an order of magnitude than was handled before.',\n",
       "  'id': '3705',\n",
       "  'title': 'An Online Algorithm for Large Scale Image Similarity Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Multitask learning addressed the problem of learning related tasks whose information can be shared each other. Traditional problem usually deal with homogeneous tasks such as regression, classification individually. In this paper we consider the problem learning multiple related tasks where tasks consist of both continuous and discrete outputs from a common set of input variables that lie in a high-dimensional space. All of the tasks are related in the sense that they share the same set of relevant input variables, but the amount of influence of each input on different outputs may vary. We formulate this problem as a combination of linear regression and logistic regression and model the joint sparsity as L1/Linf and L1/L2-norm of the model parameters. Among several possible applications, our approach addresses an important open problem in genetic association mapping, where we are interested in discovering genetic markers that influence multiple correlated traits jointly. In our experiments, we demonstrate our method in the scenario of association mapping, using simulated and asthma data, and show that the algorithm can effectively recover the relevant inputs with respect to all of the tasks.',\n",
       "  'id': '3706',\n",
       "  'title': 'Heterogeneous multitask learning with joint sparsity constraints',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'While many perceptual and cognitive phenomena are well described in terms of Bayesian inference, the necessary computations are intractable at the scale of real-world tasks, and it remains unclear how the human mind approximates Bayesian inference algorithmically. We explore the proposal that for some tasks, humans use a form of Markov Chain Monte Carlo to approximate the posterior distribution over hidden variables.  As a case study, we show how several phenomena of perceptual multistability can be explained as MCMC inference in simple graphical models for low-level vision.',\n",
       "  'id': '3711',\n",
       "  'title': 'Perceptual Multistability as Markov Chain Monte Carlo Inference',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Markov random fields (MRFs), or undirected graphical models, provide a powerful framework for modeling complex dependencies among random variables. Maximum likelihood learning in MRFs is hard due to the presence of the global normalizing constant. In this paper we consider a class of stochastic approximation algorithms of Robbins-Monro type that uses Markov chain Monte Carlo to do approximate maximum likelihood learning. We show that using MCMC operators based on tempered transitions enables the stochastic approximation algorithm to better explore highly multimodal distributions, which considerably improves parameter estimates in large densely-connected MRFs. Our results on MNIST and NORB datasets demonstrate that we can successfully learn good generative models of high-dimensional, richly structured data and perform well on digit and object recognition tasks.',\n",
       "  'id': '3717',\n",
       "  'title': 'Learning in Markov Random Fields using Tempered Transitions',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper, we investigate how similar images sharing the same global description can help with unsupervised scene segmentation in an image.  In contrast to recent work in semantic alignment of scenes, we allow an input image to be explained by partial matches of similar scenes.  This allows for a better explanation of the input scenes.  We perform MRF-based segmentation that optimizes over matches, while respecting boundary information.  The recovered segments are then used to re-query a large database of images to retrieve better matches for the target region. We show improved performance in detecting occluding boundaries over previous methods on data gathered from the LabelMe database.',\n",
       "  'id': '3718',\n",
       "  'title': 'Segmenting Scenes by Matching Image Composites',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a novel non-parametric adaptive anomaly detection algorithm for high dimensional data based on score functions derived from nearest neighbor graphs on n-point nominal data. Anomalies are declared whenever the score of a test sample falls below q, which is supposed to be the desired false alarm level. The resulting anomaly detector is shown to be asymptotically optimal in that it is uniformly most powerful for the specified false alarm level, q, for the case when the anomaly density is a mixture of the nominal and a known density. Our algorithm is computationally efficient, being linear in dimension and quadratic in data size. It does not require choosing complicated tuning parameters or function approximation classes and it can adapt to local structure such as local change in dimensionality. We demonstrate the algorithm on both artificial and real data sets in high dimensional feature spaces.',\n",
       "  'id': '3723',\n",
       "  'title': 'Anomaly Detection with Score functions based on Nearest Neighbor Graphs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a novel multivariate Laplace (MVL) distribution as a sparsity promoting prior for Bayesian source localization that allows the specification of constraints between and within sources. We represent the MVL distribution as a scale mixture that induces a coupling between source variances instead of their means. Approximation of the posterior marginals using expectation propagation is shown to be very efficient due to properties of the scale mixture representation. The computational bottleneck amounts to computing the diagonal elements of a sparse matrix inverse. Our approach is illustrated using a mismatch negativity paradigm for which MEG data and a structural MRI have been acquired. We show that spatial coupling leads to sources which are active over larger cortical areas as compared with an uncoupled prior.',\n",
       "  'id': '3751',\n",
       "  'title': 'Bayesian Source Localization with the Multivariate Laplace Prior',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We investigate methods for selecting sets of labeled vertices for use in predicting the labels of vertices on a graph.  We specifically study methods which choose a single batch of labeled vertices (i.e. offline, non sequential methods).  In this setting, we find common graph smoothness assumptions directly motivate simple label selection methods with interesting theoretical guarantees. These methods bound prediction error in terms of the smoothness of the true labels with respect to the graph.  Some of these bounds give new motivations for previously proposed algorithms, and some suggest new algorithms which we evaluate.  We show improved performance over baseline methods on several real world data sets.',\n",
       "  'id': '3752',\n",
       "  'title': 'Label Selection on Graphs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a novel information theoretic approach for semi-supervised learning of conditional random fields. Our approach defines a training objective that combines the conditional likelihood on labeled data and the mutual information on unlabeled data. Different from previous minimum conditional entropy semi-supervised discriminative learning methods, our approach can be naturally cast into the rate distortion theory framework in information theory. We analyze the tractability of the framework for structured prediction and present a convergent variational training algorithm to defy the combinatorial explosion of terms in the sum over label configurations. Our experimental results show that the rate distortion approach outperforms standard $l_2$ regularization and minimum conditional entropy regularization on both multi-class classification and sequence labeling problems.',\n",
       "  'id': '3754',\n",
       "  'title': 'A Rate Distortion Approach for Semi-Supervised Conditional Random Fields',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Learning to rank is a relatively new field of study, aiming to learn a ranking function from a set of training data with relevancy labels. The ranking algorithms are often evaluated using Information Retrieval measures, such as Normalized Discounted Cumulative Gain [1] and Mean Average Precision [2]. Until recently, most learning to rank algorithms were not using a loss function related to the above mentioned evaluation measures. The main difficulty in direct optimization of these measures is that they depend on the ranks of documents, not the numerical values output by the ranking function. We propose a probabilistic framework that addresses this challenge by optimizing the expectation of NDCG over all the possible permutations of documents. A relaxation strategy is used to approximate the average of NDCG over the space of permutation, and a bound optimization approach is proposed to make the computation efficient. Extensive experiments show that the proposed algorithm outperforms state-of-the-art ranking algorithms on several benchmark data sets.',\n",
       "  'id': '3758',\n",
       "  'title': 'Learning to Rank by Optimizing NDCG Measure',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Given a corpus of news items consisting of images accompanied by text captions, we want to find out ``whos doing what, i.e. associate names and action verbs in the captions to the face and body pose of the persons in the images. We present a joint model for simultaneously solving the image-caption correspondences and learning visual appearance models for the face and pose classes occurring in the corpus. These models can then be used to recognize people and actions in novel images without captions. We demonstrate experimentally that our joint `face and pose model solves the correspondence problem better than earlier models covering only the face, and that it can perform recognition of new uncaptioned images.',\n",
       "  'id': '3759',\n",
       "  'title': 'Who?s Doing What: Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A classic debate in cognitive science revolves around understanding how children learn complex linguistic rules, such as those governing  restrictions on verb alternations, without negative  evidence. Traditionally, formal learnability arguments have been used to claim that such learning is impossible without the aid of innate  language-specific knowledge. However, recently, researchers have shown  that statistical models are capable of learning complex rules from only  positive evidence. These two kinds of learnability analyses differ in their assumptions about the role of the distribution from which linguistic  input is generated.  The former analyses assume that learners seek to identify grammatical sentences in a way that is robust to the distribution  from which the sentences are generated, analogous to discriminative  approaches in machine learning. The latter assume that learners are trying  to estimate a generative model, with sentences being sampled from that  model. We show that these two learning approaches differ in their use of implicit negative evidence -- the absence of a sentence -- when learning  verb alternations, and demonstrate that human learners can produce results  consistent with the predictions of both approaches, depending on the  context in which the learning problem is presented.',\n",
       "  'id': '3760',\n",
       "  'title': 'Differential Use of Implicit Negative Evidence in Generative and Discriminative Language Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Existing value function approximation methods have been successfully used in many applications, but they often lack useful a priori error bounds. We propose approximate bilinear programming, a new formulation of value function approximation that provides strong a priori guarantees. In particular, it provably finds an approximate value function that minimizes the Bellman residual. Solving a bilinear program optimally is NP hard, but this is unavoidable because the Bellman-residual minimization itself is NP hard. We, therefore, employ and analyze a common approximate algorithm for bilinear programs. The analysis shows that this algorithm offers a convergent generalization of approximate policy iteration. Finally, we demonstrate that the proposed approach can consistently minimize the Bellman residual on a simple benchmark problem.',\n",
       "  'id': '3761',\n",
       "  'title': 'Robust Value Function Approximation Using Bilinear Programming',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Object detection and multi-class image segmentation are two closely related tasks that can be greatly improved when solved jointly by feeding information from one task to the other. However, current state-of-the-art models use a separate representation for each task making joint inference clumsy and leaving classification of many parts of the scene ambiguous. In this work, we propose a hierarchical region-based approach to joint object detection and image segmentation. Our approach reasons about pixels, regions and objects in a coherent probabilistic model. Importantly, our model gives a single unified description of the scene. We explain every pixel in the image and enforce global consistency between all variables in our model. We run experiments on challenging vision datasets and show significant improvement over state-of-the-art object detection accuracy.',\n",
       "  'id': '3766',\n",
       "  'title': 'Region-based Segmentation and Object Detection',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Representing distributions over permutations can be a daunting task due to the fact that the number of permutations of n objects scales factorially in n. One recent way that has been used to reduce storage complexity has been to exploit probabilistic independence, but as we argue, full independence assumptions impose strong sparsity constraints on distributions and are unsuitable for modeling rankings. We identify a novel class of independence structures, called riffled independence, which encompasses a more expressive family of distributions while retaining many of the properties necessary for performing efficient inference and reducing sample complexity. In riffled independence, one draws two permutations independently, then performs the riffle shuffle, common in card games, to combine the two permutations to form a single permutation. In ranking, riffled independence corresponds to ranking disjoint sets of objects independently, then interleaving those rankings. We provide a formal introduction and present algorithms for using riffled independence within Fourier-theoretic frameworks which have been explored by a number of recent papers.',\n",
       "  'id': '3775',\n",
       "  'title': 'Riffled Independence for Ranked Data',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'One crucial assumption made by both principal component analysis (PCA) and probabilistic PCA (PPCA) is that the instances are independent and identically distributed (i.i.d.). However, this common i.i.d. assumption is unreasonable for relational data. In this paper, by explicitly modeling covariance between instances as derived from the relational information, we propose a novel probabilistic dimensionality reduction method, called probabilistic relational PCA (PRPCA), for relational data analysis. Although the i.i.d. assumption is no longer adopted in PRPCA, the learning algorithms for PRPCA can still be devised easily like those for PPCA which makes explicit use of the i.i.d. assumption. Experiments on real-world data sets show that PRPCA can effectively utilize the relational information to dramatically outperform PCA and achieve state-of-the-art performance.',\n",
       "  'id': '3778',\n",
       "  'title': 'Probabilistic Relational PCA',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a new approach to the analysis of Loopy Belief Propagation (LBP) by establishing a formula that connects the Hessian of the Bethe free energy with the edge zeta function. The formula has a number of theoretical implications on LBP. It is applied to give a sufficient condition that the Hessian of the Bethe free energy is positive definite, which shows non-convexity for graphs with multiple cycles. The formula clarifies the relation between the local stability of a fixed point of LBP and local minima of the Bethe free energy. We also propose a new approach to the uniqueness of LBP fixed point, and show various conditions of uniqueness.',\n",
       "  'id': '3779',\n",
       "  'title': 'Graph Zeta Function in the Bethe Free Energy and Loopy Belief Propagation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In most online learning algorithms, the weights assigned to the misclassified examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufficient since when a new misclassified example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning\", or \"DUOL\" for short. Instead of only assigning a fixed weight to the misclassified example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be significantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms.\"',\n",
       "  'id': '3787',\n",
       "  'title': 'DUOL: A Double Updating Approach for Online Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Several key computational bottlenecks in machine learning involve pairwise distance computations, including all-nearest-neighbors (finding the nearest neighbor(s) for each point, e.g.  in manifold learning) and kernel summations (e.g. in kernel density estimation or kernel machines).  We consider the general, bichromatic case for these problems, in addition to the scientific problem of N-body potential calculation.  In this paper we show for the first time O(N) worst case runtimes for practical algorithms for these problems based on the cover tree data structure (Beygelzimer, Kakade, Langford, 2006).',\n",
       "  'id': '3796',\n",
       "  'title': 'Linear-time Algorithms for Pairwise Statistical Problems',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a method for learning max-weight matching predictors in bipartite graphs. The method consists of performing maximum a posteriori estimation in exponential families with sufficient statistics that encode permutations and data features. Although inference is in general hard, we show that for one very relevant application - document ranking - exact inference is efficient. For general model instances, an appropriate sampler is readily available. Contrary to existing max-margin matching models, our approach is statistically consistent and, in addition, experiments with increasing sample sizes indicate superior improvement over such models. We apply the method to graph matching in computer vision as well as to a standard benchmark dataset for learning document ranking, in which we obtain state-of-the-art results, in particular improving on max-margin variants. The drawback of this method with respect to max-margin alternatives is its runtime for large graphs, which is high comparatively.',\n",
       "  'id': '3800',\n",
       "  'title': 'Exponential Family Graph Matching and Ranking',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We prove that linear projections between distribution families with fixed first and second moments are surjective, regardless of dimension. We further extend this result to families that respect additional constraints, such as symmetry, unimodality and log-concavity. By combining our results with classic univariate inequalities, we provide new worst-case analyses for natural risk criteria arising in different fields. One discovery is that portfolio selection under the worst-case value-at-risk and conditional value-at-risk criteria yields identical portfolios.',\n",
       "  'id': '3811',\n",
       "  'title': 'A General Projection Property for Distribution Families',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A fundamental objective in reinforcement learning is the maintenance of a proper balance between exploration and exploitation. This problem becomes more challenging when the agent can only partially observe the states of its environment. In this paper we propose a dual-policy method for jointly learning the agent behavior and the balance between exploration exploitation, in partially observable environments. The method subsumes traditional exploration, in which the agent takes actions to gather information about the environment, and active learning, in which the agent queries an oracle for optimal actions (with an associated cost for employing the oracle). The form of the employed exploration is dictated by the specific problem. Theoretical guarantees are provided concerning the optimality of the balancing of exploration and exploitation. The effectiveness of the method is demonstrated by experimental results on benchmark problems.',\n",
       "  'id': '3814',\n",
       "  'title': 'Learning to Explore and Exploit in POMDPs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the problem of learning the structure of Ising models (pairwise binary Markov random fields) from i.i.d. samples. While several methods have been proposed to accomplish this task, their relative merits and limitations remain somewhat obscure. By analyzing a number of concrete examples, we show that low-complexity  algorithms systematically fail when the Markov random field  develops long-range correlations. More precisely, this phenomenon  appears to be related to the Ising model phase transition  (although it does not coincide with it).',\n",
       "  'id': '3819',\n",
       "  'title': 'Which graphical models are difficult to learn?',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Large, relational factor graphs with structure defined by   first-order logic or other languages give rise to notoriously   difficult inference problems.  Because unrolling the structure   necessary to represent distributions over all hypotheses has   exponential blow-up, solutions are often derived from MCMC. However,   because of limitations in the design and parameterization of the   jump function, these sampling-based methods suffer from local   minima|the system must transition through lower-scoring   configurations before arriving at a better MAP solution. This paper   presents a new method of explicitly selecting fruitful downward   jumps by leveraging reinforcement learning (RL). Rather than setting   parameters to maximize the likelihood of the training data,   parameters of the factor graph are treated as a log-linear function   approximator and learned with temporal difference (TD); MAP   inference is performed by executing the resulting policy on held out   test data. Our method allows efficient gradient updates since only   factors in the neighborhood of variables affected by an action need   to be computed|we bypass the need to compute marginals entirely.   Our method provides dramatic empirical success, producing new   state-of-the-art results on a complex joint model of ontology   alignment, with a 48\\\\% reduction in error over state-of-the-art in   that domain.',\n",
       "  'id': '3832',\n",
       "  'title': 'Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The purpose of the paper is to explore the connection between multivariate homogeneity tests and $\\\\auc$ optimization. The latter problem has recently received much attention in the statistical learning literature. From the elementary observation that, in the two-sample problem setup, the null assumption corresponds to the situation where the area under the optimal ROC curve is equal to 1/2, we propose a two-stage testing method based on data splitting. A nearly optimal scoring function in the AUC sense is first learnt from one of the two half-samples. Data from the remaining half-sample are then projected onto the real line and eventually ranked according to the scoring function computed at the first stage. The last step amounts to performing a standard Mann-Whitney Wilcoxon  test in the one-dimensional framework. We show that the learning step of the procedure does not affect the consistency of the test as well as its properties in terms of power, provided the ranking produced is accurate enough in the AUC sense. The results of a numerical experiment are eventually displayed in order to show the efficiency of the method.',\n",
       "  'id': '3838',\n",
       "  'title': 'AUC optimization and the two-sample problem',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We investigate how well Gaussian process regression can learn functions defined on graphs, using large regular random graphs as a paradigmatic example. Random-walk based kernels are shown to have some surprising properties: within the standard approximation of a locally tree-like graph structure, the kernel does not become constant, i.e.neighbouring function values do not become fully correlated, when the lengthscale $\\\\sigma$ of the kernel is made large. Instead the kernel attains a non-trivial limiting form, which we calculate. The fully correlated limit is reached only once loops become relevant, and we estimate where the crossover to this regime occurs. Our main subject are learning curves of Bayes error versus training set size. We show that these are qualitatively well predicted by a simple approximation using only the spectrum of a large tree as input, and generically scale with $n/V$, the number of training examples per vertex. We also explore how this behaviour changes once kernel lengthscales are large enough for loops to become important.',\n",
       "  'id': '3840',\n",
       "  'title': 'Kernels and learning curves for Gaussian process regression on random graphs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We discuss the framework of Transductive Support Vector Machine (TSVM) from the perspective of the regularization strength induced by the unlabeled data. In this framework, SVM and TSVM can be regarded as a learning machine without regularization and one with full regularization from the unlabeled data, respectively. Therefore, to supplement this framework of the regularization strength, it is necessary to introduce data-dependant partial regularization. To this end, we reformulate TSVM into a form with controllable regularization strength, which includes SVM and TSVM as special cases. Furthermore, we introduce a method of adaptive regularization that is data dependant and is based on the smoothness assumption. Experiments on a set of benchmark data sets indicate the promising results of the proposed work compared with state-of-the-art TSVM algorithms.',\n",
       "  'id': '3843',\n",
       "  'title': 'Adaptive Regularization for Transductive Support Vector Machine',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'As the availability and importance of relational data -- such as the friendships summarized on a social networking website -- increases, it becomes increasingly important to have good models for such data.  The kinds of latent structure that have been considered for use in predicting links in such networks have been relatively limited. In particular, the machine learning community has focused on latent class models, adapting nonparametric Bayesian methods to jointly infer how many latent classes there are while learning which entities belong to each class. We pursue a similar approach with a richer kind of latent variable -- latent features -- using a nonparametric Bayesian technique to simultaneously infer the number of features at the same time we learn which entities have each feature. The greater expressiveness of this approach allows us to improve link prediction on three datasets.',\n",
       "  'id': '3846',\n",
       "  'title': 'Nonparametric Latent Feature Models for Link Prediction',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The worst-case complexity of general decentralized POMDPs, which are equivalent to partially observable stochastic games (POSGs) is very high, both for the cooperative and competitive cases.  Some reductions in complexity have been achieved by exploiting independence relations in some models.  We show that these results are somewhat limited:  when these independence assumptions are relaxed in very small ways, complexity returns to that of the general case.',\n",
       "  'id': '3857',\n",
       "  'title': 'Complexity of Decentralized Control: Special Cases',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We visit the following fundamental problem: For a `generic model of consumer choice (namely, distributions over preference lists) and a limited amount of data on how consumers actually make decisions (such as marginal preference information), how may one predict revenues from offering a particular assortment of choices? This problem is central to areas within operations research, marketing and econometrics. We present a framework to answer such questions and design a number of tractable algorithms (from a data and computational standpoint) for the same.',\n",
       "  'id': '3862',\n",
       "  'title': 'A Data-Driven Approach to Modeling Choice',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we explore the problem of biasing unsupervised models to favor sparsity. We extend the posterior regularization framework [8] to encourage the  model to achieve posterior sparsity on the unlabeled training data. We apply this new method to learn ?rst-order HMMs for unsupervised part-of-speech (POS) tagging, and show that HMMs learned this way consistently and signi?cantly out-performs both EM-trained HMMs, and HMMs with a sparsity-inducing Dirichlet prior trained by variational EM. We evaluate these HMMs on three languages ? English, Bulgarian and Portuguese ? under four conditions. We ?nd that our  method always improves performance with respect to both baselines, while variational Bayes actually degrades performance in most cases. We increase accuracy with respect to EM by 2.5%-8.7% absolute and we see improvements even in a semisupervised condition where a limited dictionary is provided.',\n",
       "  'id': '3865',\n",
       "  'title': 'Posterior vs Parameter Sparsity in Latent Variable Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Conditional random fields (CRF) are quite successful on sequence labeling tasks such as natural language processing and biological sequence analysis. CRF models use linear potential functions to represent the relationship between input features and outputs. However, in many real-world applications such as protein structure prediction and handwriting recognition, the relationship between input features and outputs is highly complex and nonlinear, which cannot be accurately modeled by a linear function. To model the nonlinear relationship between input features and outputs we propose Conditional Neural Fields (CNF), a new conditional probabilistic graphical model for sequence labeling. Our CNF model extends CRF by adding one (or possibly several) middle layer between input features and outputs. The middle layer consists of a number of hidden parameterized gates, each acting as a local neural network node or feature extractor to capture the nonlinear relationship between input features and outputs. Therefore, conceptually this CNF model is much more expressive than the linear CRF model. To better control the complexity of the CNF model, we also present a hyperparameter optimization procedure within the evidence framework. Experiments on two widely-used benchmarks indicate that this CNF model performs significantly better than a number of popular methods. In particular, our CNF model is the best among about ten machine learning methods for protein secondary tructure prediction and also among a few of the best methods for handwriting recognition.',\n",
       "  'id': '3869',\n",
       "  'title': 'Conditional Neural Fields',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efficient and are Hannan-consistent in both the full information and bandit settings.',\n",
       "  'id': '3871',\n",
       "  'title': 'Beyond Convexity: Online Submodular Minimization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a new type of Deep Belief Net and evaluate it on a 3D object recognition task. The top-level model is a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients. Performance is evaluated on the NORB database(normalized-uniform version), which contains stereo-pair images of objects under different lighting conditions and viewpoints. Our model achieves 6.5% error on the test set, which is close to the best published result for NORB (5.9%) using a convolutional neural net that has built-in knowledge of translation invariance. It substantially outperforms shallow models such as SVMs (11.6%). DBNs are especially suited for semi-supervised learning, and to demonstrate this we consider a modified version of the NORB recognition task in which additional unlabeled images are created by applying small translations to the images in the database. With the extra unlabeled data (and the same amount of labeled data as before), our model achieves 5.2% error, making it the current best result for NORB.',\n",
       "  'id': '3872',\n",
       "  'title': '3D Object Recognition with Deep Belief Nets',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the problem of variable group selection for least squares regression, namely, that of selecting groups of variables for best regression performance, leveraging and adhering to a natural grouping structure within the explanatory variables. We show that this problem can be efficiently addressed by using a certain greedy style algorithm. More precisely, we propose the Group Orthogonal Matching Pursuit algorithm (Group-OMP), which extends the standard OMP procedure (also referred to as ``forward greedy feature selection algorithm for least squares regression) to perform stage-wise group variable selection. We prove that under certain conditions Group-OMP can identify the correct (groups of) variables. We also provide an upperbound on the $l_\\\\infty$ norm of the difference between the estimated regression coefficients and the true coefficients. Experimental results on simulated and real world datasets indicate that Group-OMP compares favorably to Group Lasso, OMP and Lasso, both in terms of variable selection and prediction accuracy.',\n",
       "  'id': '3878',\n",
       "  'title': 'Grouped Orthogonal Matching Pursuit for Variable Selection and Prediction',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph. We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure. The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning. Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity.',\n",
       "  'id': '3887',\n",
       "  'title': 'Maximin affinity learning of image segmentation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a new family of positive-definite kernel functions that mimic the computation in large, multilayer neural nets.  These kernel functions can be used in shallow architectures, such as support vector machines (SVMs), or in deep kernel-based architectures that we call multilayer kernel machines (MKMs).  We evaluate SVMs and MKMs with these kernel functions on problems designed to illustrate the advantages of deep architectures.  On several problems, we obtain better results than previous, leading benchmarks from both SVMs with Gaussian kernels as well as deep belief nets.',\n",
       "  'id': '3628',\n",
       "  'title': 'Kernel Methods for Deep Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose new methodologies to detect anomalies in discrete-time processes taking values in a set. The method is based on the inference of functionals whose evaluations on successive states visited by the process have low autocorrelations. Deviations from this behavior are used to flag anomalies. The candidate functionals are estimated in a subset of a reproducing kernel Hilbert space associated with the set where the process takes values. We provide experimental results which show that these techniques compare favorably with other algorithms.',\n",
       "  'id': '3632',\n",
       "  'title': 'White Functionals for Anomaly Detection in Dynamical Systems',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a new family of distributions, called $L_p${\\\\em -nested symmetric distributions}, whose densities access the data exclusively through a hierarchical cascade of $L_p$-norms. This class generalizes the family of spherically and $L_p$-spherically symmetric distributions which have recently been successfully used for natural image modeling. Similar to those distributions it allows for a nonlinear mechanism to reduce the dependencies between its variables. With suitable choices of the parameters and norms, this family also includes the Independent Subspace Analysis (ISA) model, which has been proposed as a means of deriving filters that mimic complex cells found in mammalian primary visual cortex. $L_p$-nested distributions are easy to estimate and allow us to explore the variety of models between ISA and the $L_p$-spherically symmetric models. Our main findings are that, without a preprocessing step of contrast gain control, the independent subspaces of ISA are in fact more dependent than the individual filter coefficients within a subspace and, with contrast gain control, where ISA finds more than one subspace, the filter responses were almost independent anyway.',\n",
       "  'id': '3642',\n",
       "  'title': 'Hierarchical Modeling of Local Image Features through ',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We develop a Bayesian sequential model for category learning. The sequential model updates two category parameters, the mean and the variance, over time. We define conjugate temporal priors to enable closed form solutions to be obtained. This model can be easily extended to supervised and unsupervised learning involving multiple categories. To model the spacing effect, we introduce a generic prior in the temporal updating stage to capture a learning preference, namely, less change for repetition and more change for variation. Finally, we show how this approach can be generalized to efficiently performmodel selection to decide whether observations are from one or multiple categories.',\n",
       "  'id': '3643',\n",
       "  'title': 'Modeling the spacing effect in sequential category learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the problem of zero-shot learning, where the goal is to learn a classifier $f: X \\\\rightarrow Y$ that must predict novel values of $Y$ that were omitted from the training set. To achieve this, we define the notion of a semantic output code classifier (SOC) which utilizes a knowledge base of semantic properties of $Y$ to extrapolate to novel classes. We provide a formalism for this type of classifier and study its theoretical properties in a PAC framework, showing conditions under which the classifier can accurately predict novel classes.  As a case study, we build a SOC classifier for a neural decoding task and show that it can often predict words that people are thinking about from functional magnetic resonance images (fMRI) of their neural activity, even without training examples for those words.',\n",
       "  'id': '3650',\n",
       "  'title': 'Zero-shot Learning with Semantic Output Codes',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'There has been a clear distinction between induction or training time and diagnosis time active information acquisition. While active learning during induction focuses on acquiring data that promises to provide the best classification model, the goal at diagnosis time focuses completely on next features to observe about the test case at hand in order to make better predictions about the case. We introduce a model and inferential methods that breaks this distinction. The methods can be used to extend case libraries under a budget but, more fundamentally, provide a framework for guiding agents to collect data under scarce resources, focused by diagnostic challenges. This extension to active learning leads to a new class of policies for real-time diagnosis, where recommended information-gathering sequences include actions that simultaneously seek new data for the case at hand and for cases in the training set.',\n",
       "  'id': '3653',\n",
       "  'title': 'Breaking Boundaries Between Induction Time and Diagnosis Time Active Information Acquisition',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Discriminatively trained undirected graphical models have had wide empirical success, and there has been increasing interest in toolkits that ease their application to complex relational data.  The power in relational models is in their repeated structure and tied parameters; at issue is how to define these structures in a powerful and flexible way. Rather than using a declarative language, such as SQL or first-order logic, we advocate using an imperative language to express various aspects of model structure, inference, and learning.  By combining the traditional, declarative, statistical semantics of factor graphs with imperative definitions of their construction and operation, we allow the user to mix declarative and procedural domain knowledge, and also gain significant efficiencies.  We have implemented such imperatively defined factor graphs in a system we call Factorie, a software library for an object-oriented, strongly-typed, functional language.  In experimental comparisons to Markov Logic Networks on joint segmentation and coreference, we find our approach to be 3-15 times faster while reducing error by 20-25%-achieving a new state of the art.',\n",
       "  'id': '3654',\n",
       "  'title': 'FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose Dirichlet-Bernoulli Alignment (DBA), a generative model for corpora in which each pattern (e.g., a document) contains a set of instances (e.g., paragraphs in the document) and belongs to multiple classes. By casting predefined classes as latent Dirichlet variables (i.e., instance level labels), and modeling the multi-label of each pattern as Bernoulli variables conditioned on the weighted empirical average of topic assignments, DBA automatically aligns the latent topics discovered from data to human-defined classes. DBA is useful for both pattern classification and instance disambiguation, which are tested on text classification and named entity disambiguation for web search queries respectively.',\n",
       "  'id': '3657',\n",
       "  'title': 'Dirichlet-Bernoulli Alignment: A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In many domains, humans appear to combine perceptual cues in a near-optimal, probabilistic fashion: two noisy pieces of information tend to be combined linearly with weights proportional to the precision of each cue. Here we present a case where structural information plays an important role. The presence of a background cue gives rise to the possibility of occlusion, and places a soft constraint on the location of a target ? in effect propelling it forward. We present an ideal observer model of depth estimation for this situation where structural or ordinal information is important and then fit the model to human data from a stereo-matching task. To test whether subjects are truly using ordinal cues in a probabilistic manner we then vary the uncertainty of the task. We find that the model accurately predicts shifts in subject?s behavior. Our results indicate that the nervous system estimates depth ordering in a probabilistic fashion and estimates the structure of the visual scene during depth perception.',\n",
       "  'id': '3663',\n",
       "  'title': 'Structural inference affects depth perception in the context of potential occlusion',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the reconstruction of sparse signals in the multiple measurement vector (MMV) model,in which the signal, represented as a matrix, consists of a set of jointly sparse vectors. MMV is an extension of the single measurement vector (SMV) model employed in standard compressive sensing (CS). Recent theoretical studies focus on the convex relaxation of the MMV problem based on the $(2,1)$-norm minimization, which is an extension of the well-known $1$-norm minimization employed in SMV. However, the resulting convex optimization problem in MMV is significantly much more difficult to solve than the one in SMV. Existing algorithms reformulate it as a second-order cone programming (SOCP) or semidefinite programming (SDP), which is computationally expensive to solve for problems of moderate size. In this paper, we propose a new (dual) reformulation of the convex optimization problem in MMV and develop an efficient algorithm based on the prox-method. Interestingly, our theoretical analysis reveals the close connection between the proposed reformulation and multiple kernel learning. Our simulation studies demonstrate the scalability of the proposed algorithm.',\n",
       "  'id': '3664',\n",
       "  'title': 'Efficient Recovery of Jointly Sparse Vectors',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Many transductive inference algorithms assume that distributions over training and test estimates should be related, e.g. by providing a large margin of separation on both sets. We use this idea to design a transduction algorithm which can be used without modification for classification, regression, and structured estimation. At its heart we exploit the fact that for a good learner the distributions over the outputs on training and test sets should match. This is a classical two-sample problem which can be solved efficiently in its most general form by using distance measures in Hilbert Space. It turns out that a number of existing heuristics can be viewed as special cases of our approach.',\n",
       "  'id': '3666',\n",
       "  'title': 'Distribution Matching for Transduction',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Nonparametric Bayesian models provide a framework for flexible probabilistic modelling of complex datasets. Unfortunately, Bayesian inference methods often require high-dimensional averages and can be slow to compute, especially with the potentially unbounded representations associated with nonparametric models. We address the challenge of scaling nonparametric Bayesian inference to the increasingly large datasets found in real-world applications, focusing on the case of parallelising inference in the Indian Buffet Process (IBP).  Our approach divides a large data set between multiple processors.  The processors use message passing to compute likelihoods in an asynchronous, distributed fashion and to propagate statistics about the global Bayesian posterior.  This novel MCMC sampler is the first parallel inference scheme for IBP-based models, scaling to datasets orders of magnitude larger than had previously been possible.',\n",
       "  'id': '3669',\n",
       "  'title': 'Large Scale Nonparametric Bayesian Inference: Data Parallelisation in the Indian Buffet Process',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Learning linear combinations of multiple kernels is an appealing strategy when the right choice of features is unknown. Previous approaches to multiple kernel learning (MKL) promote sparse kernel combinations and hence support interpretability. Unfortunately, L1-norm MKL is hardly observed to outperform trivial baselines in practical applications. To allow for robust kernel mixtures, we generalize MKL to arbitrary Lp-norms. We devise new insights on the connection between  several existing MKL formulations and develop two efficient interleaved optimization strategies for arbitrary p>1. Empirically, we demonstrate that the interleaved optimization strategies are much faster compared to the traditionally used wrapper approaches. Finally, we apply Lp-norm MKL to real-world problems from computational biology, showing that non-sparse MKL achieves accuracies that go beyond the state-of-the-art.',\n",
       "  'id': '3675',\n",
       "  'title': 'Efficient and Accurate Lp-Norm Multiple Kernel Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper proposes a fast and scalable alternating optimization technique to detect regions of interest (ROIs) in cluttered Web images without labels. The proposed approach discovers highly probable regions of  object instances by iteratively repeating the following two functions: (1) choose the exemplar set (i.e. small number of high ranked reference ROIs) across the dataset and (2) refine the ROIs of each image with respect to the exemplar set. These two subproblems are formulated as ranking in two different similarity networks of ROI hypotheses by link analysis. The experiments with the PASCAL 06 dataset show that our unsupervised localization performance is better than one of state-of-the-art techniques and comparable to supervised methods. Also, we test the scalability of our approach with five objects in Flickr dataset consisting of more than 200,000 images.',\n",
       "  'id': '3680',\n",
       "  'title': 'Unsupervised Detection of Regions of Interest Using Iterative Link Analysis',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Dynamic Bayesian networks have been applied widely to reconstruct the structure of regulatory processes from time series data. The standard approach is based on the assumption of a homogeneous Markov chain, which is not valid in many real-world scenarios. Recent research efforts addressing this shortcoming have considered undirected graphs, directed graphs for discretized data, or over-flexible models that lack any information sharing between time series segments. In the present article, we propose a non-stationary dynamic Bayesian network for continuous data, in which parameters are allowed to vary between segments, and in which a common network structure provides essential information sharing across segments.  Our model is based on a Bayesian change-point process, and we apply a variant of the allocation sampler of Nobile and Fearnside to infer the number and location of the change-points.',\n",
       "  'id': '3687',\n",
       "  'title': 'Non-stationary continuous dynamic Bayesian networks',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a new empirical risk minimization framework for approximating functions from training samples for low-dimensional regression applications where a lattice (look-up table) is stored and interpolated at run-time for an efficient hardware implementation. Rather than evaluating a fitted function at the lattice nodes without regard to the fact that samples will be interpolated, the proposed lattice regression approach estimates the lattice to minimize the interpolation error on the given training samples. Experiments show that lattice regression can reduce mean test error  compared to Gaussian process regression for digital color management of printers, an application for which linearly interpolating a look-up table (LUT) is standard. Simulations confirm that lattice regression performs consistently better than the naive approach to learning the lattice, particularly when the density of training samples is low.',\n",
       "  'id': '3694',\n",
       "  'title': 'Lattice Regression',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The recently proposed \\\\emph{additive noise model} has advantages over previous structure learning algorithms, when attempting to recover some true data generating mechanism, since it (i) does not assume linearity or Gaussianity and (ii) can recover a unique DAG rather than an equivalence class. However, its original extension to the multivariate case required enumerating all possible DAGs, and for some special distributions, e.g. linear Gaussian, the model is invertible and thus cannot be used for structure learning. We present a new approach which combines a PC style search using recent advances in kernel measures of conditional dependence with local searches for additive noise models in substructures of the equivalence class. This results in a more computationally efficient approach that is useful for arbitrary distributions even when additive noise models are invertible. Experiments with synthetic and real data show that this method is more accurate than previous methods when data are nonlinear and/or non-Gaussian.',\n",
       "  'id': '3699',\n",
       "  'title': 'Nonlinear directed acyclic structure learning with weakly additive noise models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The heavy-tailed distribution of gradients in natural scenes have proven effective priors for a range of problems such as denoising, deblurring and super-resolution. However, the use of sparse distributions makes the problem non-convex and impractically slow to solve for multi-megapixel images. In this paper we describe a deconvolution approach that is several orders of magnitude faster than existing techniques that use hyper-Laplacian priors. We adopt an alternating minimization scheme where one of the two phases is a non-convex problem that is separable over pixels. This per-pixel sub-problem may be solved with a lookup table (LUT). Alternatively, for two specific values of ?, 1/2 and 2/3 an analytic solution can be found, by finding the roots of a cubic and quartic polynomial, respectively. Our approach (using either LUTs or analytic formulae) is able to deconvolve a 1 megapixel image in less than ?3 seconds, achieving comparable quality to existing methods such as iteratively reweighted least squares (IRLS) that take ?20 minutes. Furthermore, our method is quite general and can easily be extended to related image processing problems, beyond the deconvolution application demonstrated.',\n",
       "  'id': '3707',\n",
       "  'title': 'Fast Image Deconvolution using Hyper-Laplacian Priors',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Pruning can massively accelerate the computation of feature expectations in large models.  However, any single pruning mask will introduce bias.  We present a novel approach which employs a randomized sequence of pruning masks. Formally, we apply auxiliary variable MCMC sampling to generate this sequence of masks, thereby gaining theoretical guarantees about convergence. Because each mask is generally able to skip large portions of an underlying dynamic program, our approach is particularly compelling for high-degree algorithms.  Empirically, we demonstrate our method on bilingual parsing, showing decreasing bias as more masks are incorporated, and outperforming fixed tic-tac-toe pruning.',\n",
       "  'id': '3710',\n",
       "  'title': 'Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Hypergraph clustering refers to the process of extracting maximally coherent groups from a set of objects using high-order (rather than pairwise) similarities. Traditional approaches to this problem are based on the idea of partitioning the input data into a user-defined number of classes, thereby obtaining the clusters as a by-product of the partitioning process. In this paper, we provide a radically different perspective to the problem. In contrast to the classical approach, we attempt to provide a meaningful formalization of the very notion of a cluster and we show that game theory offers an attractive and unexplored perspective that serves well our purpose. Specifically, we show that the hypergraph clustering problem can be naturally cast into a non-cooperative multi-player ``clustering game, whereby the notion of a cluster is equivalent to a classical game-theoretic equilibrium concept. From the computational viewpoint, we show that the problem of finding the equilibria of our clustering game is equivalent to locally optimizing a polynomial function over the standard simplex, and we provide a discrete-time dynamics to perform this optimization. Experiments are presented which show the superiority of our approach over state-of-the-art hypergraph clustering techniques.',\n",
       "  'id': '3714',\n",
       "  'title': 'A Game-Theoretic Approach to Hypergraph Clustering',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We develop a structured output model for object category detection that explicitly accounts for alignment, multiple aspects and partial truncation in both training and inference. The model is formulated as large margin learning with latent variables and slack rescaling, and both training and inference are computationally efficient. We make the following contributions: (i) we note that extending the Structured Output Regression formulation of Blaschko and Lampert (ECCV 2008) to include a bias term significantly improves performance; (ii) that alignment (to account for small rotations and anisotropic scalings) can be included as a latent variable and efficiently determined and implemented; (iii) that the latent variable extends to multiple aspects (e.g. left facing, right facing, front) with the same formulation; and (iv), most significantly for performance, that truncated and truncated instances can be included in both training and inference with an explicit truncation mask. We demonstrate the method by training and testing on the PASCAL VOC 2007 data set -- training includes the truncated examples, and in testing object instances are detected at multiple scales, alignments, and with significant truncations.',\n",
       "  'id': '3715',\n",
       "  'title': 'Structured output regression for detection with partial truncation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We develop a probabilistic model of human memory performance in free recall experiments. In these experiments, a subject first studies a list of words and then tries to recall them.  To model these data, we draw on both previous psychological research and statistical topic models of text documents.  We assume that memories are formed by assimilating the semantic meaning of studied words (represented as a distribution over topics) into a slowly changing latent context (represented in the same space).  During recall, this context is reinstated and used as a cue for retrieving studied words.  By conceptualizing memory retrieval as a dynamic latent variable model, we are able to use Bayesian inference to represent uncertainty and reason about the cognitive processes underlying memory.  We present a particle filter algorithm for performing approximate posterior inference, and evaluate our model on the prediction of recalled words in experimental data. By specifying the model hierarchically, we are also able to capture inter-subject variability.',\n",
       "  'id': '3720',\n",
       "  'title': 'A Bayesian Analysis of Dynamics in Free Recall',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we introduce a new algorithm for updating the parameters of a heuristic evaluation function, by updating the heuristic towards the values computed by an alpha-beta search. Our algorithm differs from previous approaches to learning from search, such as Samuels checkers player and the TD-Leaf algorithm, in two key ways. First, we update all nodes in the search tree, rather than a single node. Second, we use the outcome of a deep search, instead of the outcome of a subsequent search, as the training signal for the evaluation function. We implemented our algorithm in a chess program Meep, using a linear heuristic function. After initialising its weight vector to small random values, Meep was able to learn high quality weights from self-play alone. When tested online against human opponents, Meep played at a master level, the best performance of any chess program with a heuristic learned entirely from self-play.',\n",
       "  'id': '3722',\n",
       "  'title': 'Bootstrapping from Game Tree Search',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Situations in which people with opposing prior beliefs observe the same evidence and then strengthen those existing beliefs are frequently offered as evidence of human irrationality. This phenomenon, termed belief polarization, is typically assumed to be non-normative. We demonstrate, however, that a variety of cases of belief polarization are consistent with a Bayesian approach to belief revision. Simulation results indicate that belief polarization is not only possible but relatively common within the class of Bayesian models that we consider.',\n",
       "  'id': '3725',\n",
       "  'title': 'Bayesian Belief Polarization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We extend the concept of phase tuning, a ubiquitous mechanism in sensory neurons including motion and disparity detection neurons, to the motion contrast detection.  We demonstrate that motion contrast can be detected by phase shifts between motion neuronal responses in different spatial regions. By constructing the differential motion opponency in response to motions in two different spatial regions, varying motion contrasts can be detected, where similar motion is detected by zero phase shifts and differences in motion by non-zero phase shifts.  The model can exhibit either enhancement or suppression of responses by either different or similar motion in the surrounding.  A primary advantage of the model is that the responses are selective to relative motion instead of absolute motion, which could model neurons found in neurophysiological experiments responsible for motion pop-out detection.',\n",
       "  'id': '3726',\n",
       "  'title': 'Extending Phase Mechanism to Differential Motion Opponency for Motion Pop-out',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Alignment of time series is an important problem to solve in many scientific disciplines. In particular, temporal alignment of two or more subjects performing similar activities is a challenging problem due to the large temporal scale difference between human actions as well as the inter/intra subject variability. In this paper we present canonical time warping (CTW), an extension of canonical correlation analysis (CCA) for spatio-temporal alignment of the behavior between two subjects. CTW extends previous work on CCA in two ways: (i) it combines CCA with dynamic time warping for temporal alignment; and (ii) it extends CCA to allow local spatial deformations. We show CTWs effectiveness in three experiments: alignment of synthetic data, alignment of motion capture data of two subjects performing similar actions, and alignment of two people with similar facial expressions. Our results demonstrate that CTW provides both visually and qualitatively better alignment than state-of-the-art techniques based on dynamic time warping.',\n",
       "  'id': '3728',\n",
       "  'title': 'Canonical Time Warping for Alignment of Human Behavior',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a novel and highly effective approach for multi-body motion segmentation. Drawing inspiration from robust statistical model fitting, we estimate putative subspace hypotheses from the data. However, instead of ranking them we encapsulate the hypotheses in a novel Mercer kernel which elicits the potential of two point trajectories to have emerged from the same subspace. The kernel permits the application of well-established statistical learning methods for effective outlier rejection, automatic recovery of the number of motions and accurate segmentation of the point trajectories. The method operates well under severe outliers arising from spurious trajectories or mistracks. Detailed experiments on a recent benchmark dataset (Hopkins 155) show that our method is superior to other state-of-the-art approaches in terms of recovering the number of motions, segmentation accuracy, robustness against gross outliers and computational efficiency.',\n",
       "  'id': '3734',\n",
       "  'title': 'The Ordered Residual Kernel for Robust Motion Subspace Clustering',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the general problem of constructing nonparametric   Bayesian models on infinite-dimensional random objects, such   as functions, infinite graphs or infinite permutations.   The problem has generated much interest in machine learning,   where it is treated heuristically, but has not been    studied in full generality in nonparametric Bayesian statistics, which tends to   focus on models over probability distributions.    Our approach applies a standard tool of stochastic process   theory, the construction of stochastic processes from their   finite-dimensional marginal distributions.    The main contribution of the paper is a generalization   of the classic Kolmogorov extension theorem to conditional   probabilities.   This extension allows a rigorous construction of nonparametric Bayesian models   from systems of finite-dimensional, parametric Bayes equations.   Using this approach, we show (i)   how existence of a conjugate posterior for    the nonparametric model can be guaranteed by choosing   conjugate finite-dimensional models in the construction, (ii) how the   mapping to the posterior parameters of the nonparametric   model can be explicitly determined, and (iii) that   the construction of conjugate models in essence requires the   finite-dimensional models to be in the exponential family.   As an application of our constructive framework,    we derive a model on infinite   permutations, the nonparametric Bayesian analogue of a model   recently proposed for the analysis of rank data.',\n",
       "  'id': '3737',\n",
       "  'title': 'Construction of Nonparametric Bayesian Models from Parametric Bayes Equations',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We prove certain theoretical properties of a graph-regularized transductive learning objective that is based on minimizing a Kullback-Leibler divergence based loss. These include showing that the iterative alternating minimization procedure used to minimize the objective converges to the correct solution and deriving a test for convergence. We also propose a graph node ordering algorithm that is cache cognizant and leads to a linear speedup in parallel computations. This ensures that the algorithm scales to large data sets. By making use of empirical evaluation on the TIMIT and Switchboard I corpora, we show this approach is able to out-perform other state-of-the-art SSL approaches. In one instance, we solve a problem on a 120 million node graph.',\n",
       "  'id': '3739',\n",
       "  'title': 'Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The principles by which spiking neurons contribute to the astounding computational power of generic cortical microcircuits, and how spike-timing-dependent plasticity (STDP) of synaptic weights could generate and maintain  this computational function, are unknown. We show here that STDP, in conjunction with a stochastic soft winner-take-all (WTA) circuit, induces spiking neurons to generate through their synaptic weights implicit internal models for subclasses (or causes\") of the high-dimensional spike patterns of hundreds of pre-synaptic neurons. Hence these  neurons will fire after learning whenever the current input best matches their internal model. The resulting computational function of soft WTA circuits, a common network motif of cortical microcircuits, could therefore be a drastic dimensionality reduction of information streams, together with the autonomous creation of internal models for the probability distributions of their input patterns. We show that the autonomous generation and maintenance of this computational function can be explained on the basis of rigorous mathematical principles. In particular, we show that STDP is able to approximate a stochastic online Expectation-Maximization (EM) algorithm for modeling the input data. A corresponding result is shown for Hebbian learning in artificial neural networks.\"',\n",
       "  'id': '3744',\n",
       "  'title': 'STDP enables spiking neurons to detect hidden causes of their inputs',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The Minimum Description Length (MDL) principle selects the model that has the shortest code for data plus model. We show that for a countable class of models, MDL predictions are close to the true distribution in a strong sense. The result is completely general. No independence, ergodicity, stationarity, identifiability, or other assumption on the model class need to be made. More formally, we show that for any countable class of models, the distributions selected by MDL (or MAP) asymptotically predict (merge with) the true measure in the class in total variation distance. Implications for non-i.i.d. domains like time-series forecasting, discriminative learning, and reinforcement learning are discussed.',\n",
       "  'id': '3746',\n",
       "  'title': 'Discrete MDL Predicts in Total Variation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Policy gradient Reinforcement Learning (RL) algorithms have received much attention in seeking stochastic policies that maximize the average rewards.  In addition, extensions based on the concept of the Natural Gradient (NG) show promising learning efficiency because these regard metrics for the task. Though there are two candidate metrics, Kakades Fisher Information Matrix (FIM) and Morimuras FIM, all RL algorithms with NG have followed the Kakades approach. In this paper, we describe a generalized Natural Gradient (gNG) by linearly interpolating the two FIMs and propose an efficient implementation for the gNG learning based on a theory of the estimating function, generalized Natural Actor-Critic (gNAC). The gNAC algorithm involves a near optimal auxiliary function to reduce the variance of the gNG estimates. Interestingly, the gNAC can be regarded as a natural extension of the current state-of-the-art NAC algorithm, as long as the interpolating parameter is appropriately selected. Numerical experiments showed that the proposed gNAC algorithm can estimate gNG efficiently and outperformed the NAC algorithm.',\n",
       "  'id': '3767',\n",
       "  'title': 'A Generalized Natural Actor-Critic Algorithm',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a probabilistic topic model for analyzing and extracting content-related annotations from noisy annotated discrete data such as web pages stored in social bookmarking services. In these services, since users can attach annotations freely, some annotations do not describe the semantics of the content, thus they are noisy,  i.e.  not content-related. The extraction of content-related annotations can be used as a preprocessing step in machine learning tasks such as text classification and image recognition, or can improve information retrieval performance. The proposed model is a generative model for content and annotations, in which the annotations are assumed to originate either from topics that generated the content or from a general distribution unrelated to the content. We demonstrate the effectiveness of the proposed method by using synthetic data and real social annotation data for text and images.',\n",
       "  'id': '3773',\n",
       "  'title': 'Modeling Social Annotation Data with Content Relevance using a Topic Model',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Orthogonal matching pursuit (OMP) is a widely used greedy algorithm for recovering sparse vectors from linear measurements.  A well-known analysis of Tropp and Gilbert shows that OMP can recover a k-sparse n-dimensional real vector from m = 4k log(n) noise-free random linear measurements with a probability that goes to one as n goes to infinity. This work shows strengthens this result by showing that a lower number of measurements, m = 2k log(n-k), is in fact sufficient for asymptotic recovery. Moreover, this number of measurements is also sufficient for detection of the sparsity pattern (support) of the vector with measurement errors provided the signal-to-noise ratio (SNR) scales to infinity. The scaling m = 2k log(n-k) exactly matches the number of measurements required by the more complex lasso for signal recovery.',\n",
       "  'id': '3784',\n",
       "  'title': 'Orthogonal Matching Pursuit From Noisy Random Measurements: A New Analysis',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Contrast statistics of the majority of natural images conform to a Weibull distribution. This property of natural images may facilitate efficient and very rapid extraction of a scenes visual gist. Here we investigate whether a neural response model based on the Weibull contrast distribution captures visual information that humans use to rapidly identify natural scenes. In a learning phase, we measure EEG activity  of 32 subjects viewing brief flashes of 800 natural scenes. From these neural measurements and the contrast statistics of the natural image stimuli,  we  derive an across subject  Weibull response model. We use this model to predict the responses to a large set of new scenes and estimate which scene the subject viewed by finding the best match between the model predictions and the observed EEG responses. In almost 90 percent of the cases our model accurately predicts the observed scene. Moreover, in most failed cases, the scene mistaken for the observed scene is visually similar to the observed scene itself. These results suggest that Weibull contrast statistics of natural images contain a considerable amount of scene gist information to warrant rapid identification of natural images.',\n",
       "  'id': '3785',\n",
       "  'title': 'A Biologically Plausible Model for Rapid Natural Scene Identification',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We describe a method for learning a group of continuous transformation operators  to traverse smooth nonlinear manifolds. The method is applied to model how  natural images change over time and scale. The group of continuous transform  operators is represented by a basis that is adapted to the statistics of the data so  that the in?nitesimal generator for a measurement orbit can be produced by a  linear combination of a few basis elements. We illustrate how the method can be  used to ef?ciently code time-varying images by describing changes across time  and scale in terms of the learned operators.',\n",
       "  'id': '3791',\n",
       "  'title': 'Learning transport operators for image manifolds',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We describe, analyze, and experiment with a new framework for empirical loss minimization with regularization. Our algorithmic framework alternates between two phases. On each iteration we first perform an {\\\\em unconstrained} gradient descent step. We then cast and solve an instantaneous optimization problem that trades off minimization of a regularization term while keeping close proximity to the result of the first phase. This yields a simple yet effective algorithm for both batch penalized risk minimization and online learning. Furthermore, the two phase approach enables sparse solutions when used in conjunction with regularization functions that promote sparsity, such as $\\\\ell_1$. We derive concrete and very simple algorithms for minimization of loss functions with $\\\\ell_1$, $\\\\ell_2$, $\\\\ell_2^2$, and $\\\\ell_\\\\infty$ regularization. We also show how to construct efficient algorithms for mixed-norm $\\\\ell_1/\\\\ell_q$ regularization. We further extend the algorithms and give efficient implementations for very high-dimensional data with sparsity. We demonstrate the potential of the proposed framework in experiments with synthetic and natural datasets.',\n",
       "  'id': '3793',\n",
       "  'title': 'Efficient Learning using Forward-Backward Splitting',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A central hypothesis about early visual processing is that it represents inputs in a coordinate system matched to the statistics of natural scenes. Simple versions of this lead to Gabor-like receptive fields and divisive gain modulation from local surrounds; these have led to influential neural and psychological models of visual processing. However, these accounts are based on an incomplete view of the visual context surrounding each point. Here, we consider an approximate model of linear and non-linear correlations between the responses of spatially distributed Gabor-like receptive fields, which, when trained on an ensemble of natural scenes, unifies a range of spatial context effects. The full model accounts for neural surround data in primary visual cortex (V1), provides a statistical foundation for perceptual phenomena associated with Lis (2002) hypothesis that V1 builds a saliency map, and fits data on the tilt illusion.',\n",
       "  'id': '3794',\n",
       "  'title': 'Statistical Models of Linear and Nonlinear Contextual Interactions in Early Visual Processing',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Multiple object class learning and detection is a challenging problem due to the large number of object classes and their high visual variability. Specialized detectors usually excel in performance, while joint representations optimize sharing and reduce inference time --- but are complex to train. Conveniently, sequential learning of categories cuts down training time by transferring existing knowledge to novel classes, but cannot fully exploit the richness of shareability and might depend on ordering in learning. In hierarchical frameworks these issues have been little explored. In this paper, we show how different types of multi-class learning can be done within one generative hierarchical framework and provide a rigorous experimental analysis of various object class learning strategies as the number of classes grows. Specifically, we propose, evaluate and compare three important types of multi-class learning: 1.) independent training of individual categories, 2.) joint training of classes, 3.) sequential learning of classes. We explore and compare their computational behavior (space and time) and detection performance as a function of the number of learned classes on several recognition data sets.',\n",
       "  'id': '3798',\n",
       "  'title': 'Evaluating multi-class learning strategies in a generative hierarchical framework for object detection',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We are often interested in casting classification and clustering problems in a regression framework, because it is feasible to achieve some statistical properties in this framework by imposing some penalty criteria. In this paper we illustrate optimal scoring, which was originally proposed for performing Fisher linear discriminant analysis by regression, in the application of unsupervised learning. In particular, we devise a novel clustering algorithm that we call optimal discriminant clustering (ODC). We associate our algorithm with the existing unsupervised learning algorithms such as spectral clustering, discriminative clustering and sparse principal component analysis. Thus, our work shows that optimal scoring  provides a new approach to the implementation of  unsupervised learning. This approach facilitates the development of new unsupervised learning algorithms.',\n",
       "  'id': '3803',\n",
       "  'title': 'Optimal Scoring for Unsupervised Learning',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In the Gaussian process regression the observation model is commonly assumed to be Gaussian, which is convenient in computational perspective. However, the drawback is that the predictive accuracy of the model can be significantly compromised if the observations are contaminated by outliers. A robust observation model, such as the Student-t distribution, reduces the influence of outlying observations and improves the predictions. The problem, however, is the analytically intractable inference. In this work, we discuss the properties of a Gaussian process regression model with the Student-t likelihood and utilize the Laplace approximation for approximate inference. We compare our approach to a variational approximation and a Markov chain Monte Carlo scheme, which utilize the commonly used scale mixture representation of the Student-t distribution.',\n",
       "  'id': '3806',\n",
       "  'title': 'Gaussian process regression with Student-t likelihood',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Existing methods for recognition of object instances and categories based on quantized local features can perform poorly when local features exist on transparent surfaces, such as glass or plastic objects. There are characteristic patterns to the local appearance of transparent objects, but they may not be well captured by distances to individual examples or by a local pattern codebook obtained by vector quantization.  The appearance of a transparent patch is determined in part by the refraction of a background pattern through a transparent medium: the energy from the background usually dominates the patch appearance.  We model transparent local patch appearance using an additive  model of latent factors: background factors due to scene content,  and factors which capture a local edge energy distribution characteristic of the refraction.  We implement our method using a novel LDA-SIFT formulation which performs LDA prior to any vector quantization step; we discover latent topics which are characteristic of particular transparent patches and quantize the SIFT space into transparent visual words according to the latent topic dimensions. No knowledge of the background scene is required at test time; we show examples recognizing transparent glasses in a domestic environment.',\n",
       "  'id': '3808',\n",
       "  'title': 'An Additive Latent Feature Model for Transparent Object Recognition',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the question of computing Maximum A Posteriori (MAP) assignment in an arbitrary pair-wise Markov Random Field (MRF). We present a randomized iterative algorithm based on simple local updates. The algorithm, starting with an arbitrary initial assignment, updates it in each iteration by first, picking a random node, then selecting an (appropriately chosen) random local neighborhood and optimizing over this local neighborhood. Somewhat surprisingly, we show that this algorithm finds a near optimal assignment within $2n\\\\ln n$ iterations on average and with high probability for {\\\\em any} $n$ node pair-wise MRF with {\\\\em geometry} (i.e. MRF graph with polynomial growth) with the approximation error depending on (in a reasonable manner) the geometric growth rate of the graph and the average radius of the local neighborhood -- this allows for a graceful tradeoff between the complexity of the algorithm and the approximation error. Through extensive simulations, we show that our algorithm finds extremely good approximate solutions for various kinds of MRFs with geometry.',\n",
       "  'id': '3810',\n",
       "  'title': 'Local Rules for Global MAP: When Do They Work ?',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper proposes a new algorithm for the linear least squares problem where the unknown variables are constrained to be in a finite set.  The factor graph that corresponds to this problem is very loopy; in fact, it is a complete graph. Hence, applying the Belief Propagation (BP) algorithm yields very poor results. The algorithm described here is based on  an optimal  tree approximation of the Gaussian density of the unconstrained linear system. It is shown that even though the approximation is not directly applied to the exact discrete distribution, applying the BP algorithm to the modified factor graph outperforms current methods in terms of both performance and complexity. The improved performance of the proposed algorithm is demonstrated  on the problem of MIMO detection.',\n",
       "  'id': '3829',\n",
       "  'title': 'A Gaussian Tree Approximation for Integer Least-Squares',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a nonparametric hierarchical Bayesian model of document collections that decouples sparsity and smoothness in the component distributions (i.e., the ``topics). In the sparse topic model (STM), each topic is represented by a bank of selector variables that determine which terms appear in the topic. Thus each topic is associated with a subset of the vocabulary, and topic smoothness is modeled on this subset. We develop an efficient Gibbs sampler for the STM that includes a general-purpose method for sampling from a Dirichlet mixture with a combinatorial number of components. We demonstrate the STM on four real-world datasets. Compared to traditional approaches, the empirical results show that STMs give better predictive performance with simpler inferred models.',\n",
       "  'id': '3835',\n",
       "  'title': 'Decoupling Sparsity and Smoothness in the Discrete Hierarchical Dirichlet Process',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The method of common spatio-spectral patterns (CSSPs) is an extension of common spatial patterns (CSPs) by utilizing the technique of delay embedding to alleviate the adverse effects of noises and artifacts on the electroencephalogram (EEG) classification. Although the CSSPs method has shown to be more powerful than the CSPs method in the EEG classification, this method is only suitable for two-class EEG classification problems. In this paper, we generalize the two-class CSSPs method to multi-class cases. To this end, we first develop a novel theory of multi-class Bayes error estimation and then present the multi-class CSSPs (MCSSPs) method based on this Bayes error theoretical framework. By minimizing the estimated closed-form Bayes error, we obtain the optimal spatio-spectral filters of MCSSPs. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on the data set of BCI competition 2005. The experimental results show that our method significantly outperforms the previous multi-class CSPs (MCSPs) methods in the EEG classification.',\n",
       "  'id': '3837',\n",
       "  'title': 'Optimizing Multi-Class Spatio-Spectral Filters via Bayes Error Estimation for EEG Classification',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The linear correlation coefficient is typically used to characterize and analyze dependencies of neural spike counts. Here, we show that the correlation coefficient is in general insufficient to characterize these dependencies. We construct two neuron spike count models with Poisson-like marginals and vary their dependence structure using copulas. To this end, we construct a copula that allows to keep the spike counts uncorrelated while varying their dependence strength. Moreover, we employ a network of leaky integrate-and-fire neurons to investigate whether weakly correlated spike counts with strong dependencies are likely to occur in real networks. We find that the entropy of uncorrelated but dependent spike count distributions can deviate from the corresponding distribution with independent components by more than 25% and that weakly correlated but strongly dependent spike counts are very likely to occur in biological networks. Finally, we introduce a test for deciding whether the dependence structure of distributions with Poisson-like marginals is well characterized by the linear correlation coefficient and verify it for different copula-based models.',\n",
       "  'id': '3839',\n",
       "  'title': 'Correlation Coefficients are Insufficient for Analyzing Spike Count Dependencies',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a theory of compositionality in stochastic optimal control, showing how task-optimal controllers can be constructed from certain primitives. The primitives are themselves feedback controllers pursuing their own agendas. They are mixed in proportion to how much progress they are making towards their agendas and how compatible their agendas are with the present task. The resulting composite control law is provably optimal when the problem belongs to a certain class. This class is rather general and yet has a number of unique properties - one of which is that the Bellman equation can be made linear even for non-linear or discrete dynamics. This gives rise to the compositionality developed here. In the special case of linear dynamics and Gaussian noise our framework yields analytical solutions (i.e. non-linear mixtures of linear-quadratic regulators) without requiring the final cost to be quadratic. More generally, a natural set of control primitives can be constructed by applying SVD to Greens function of the Bellman equation. We illustrate the theory in the context of human arm movements. The ideas of optimality and compositionality are both very prominent in the field of motor control, yet they are hard to reconcile. Our work makes this possible.',\n",
       "  'id': '3842',\n",
       "  'title': 'Compositionality of optimal control laws',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the problem of using nearest neighbor methods to provide a conditional probability estimate, P(y|a), when the number of labels y is large and the labels share some underlying structure. We propose a method for learning error-correcting output codes (ECOCs) to model the similarity between labels within a nearest neighbor framework. The learned ECOCs and nearest neighbor information are used to provide conditional probability estimates. We apply these estimates to the problem of acoustic modeling for speech recognition. We demonstrate an absolute reduction in word error rate (WER) of 0.9% (a 2.5% relative reduction in WER) on a lecture recognition task over a state-of-the-art baseline GMM model.',\n",
       "  'id': '3845',\n",
       "  'title': 'Learning Label Embeddings for Nearest-Neighbor Multi-class Classification with an Application to Speech Recognition',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Implementations of topic models typically use symmetric Dirichlet priors with fixed concentration parameters, with the implicit assumption that such smoothing parameters\" have little practical effect. In this paper, we explore several classes of structured priors for topic models. We find that an asymmetric Dirichlet prior over the document-topic distributions has substantial advantages over a symmetric prior, while an asymmetric prior over the topic-word distributions provides no real benefit. Approximation of this prior structure through simple, efficient hyperparameter optimization steps is sufficient to achieve these performance gains. The prior structure we advocate substantially increases the robustness of topic models to variations in the number of topics and to the highly skewed word frequency distributions common in natural language. Since this prior structure can be implemented using efficient algorithms that add negligible cost beyond standard inference techniques, we recommend it as a new standard for topic modeling.\"',\n",
       "  'id': '3854',\n",
       "  'title': 'Rethinking LDA: Why Priors Matter',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Little work has been done to directly combine the outputs of multiple supervised and unsupervised models. However, it can increase the accuracy and applicability of ensemble methods. First, we can boost the diversity of classification ensemble by incorporating multiple clustering outputs, each of which provides grouping constraints for the joint label predictions of a set of related objects. Secondly, ensemble of supervised models is limited in applications which have no access to raw data but to the meta-level model outputs. In this paper, we aim at calculating a consolidated classification solution for a set of objects by maximizing the consensus among both supervised predictions and unsupervised grouping constraints. We seek a global optimal label assignment for the target objects, which is different from the result of traditional majority voting and model combination approaches. We cast the problem into an optimization problem on a bipartite graph, where the objective function favors smoothness in the conditional probability estimates over the graph, as well as penalizes deviation from initial labeling of supervised models. We solve the problem through iterative propagation of conditional probability estimates among neighboring nodes, and interpret the method as conducting a constrained embedding in a transformed space, as well as a ranking on the graph. Experimental results on three real applications demonstrate the benefits of the proposed method over existing alternatives.',\n",
       "  'id': '3855',\n",
       "  'title': 'Graph-based Consensus Maximization among Multiple Supervised and Unsupervised Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a system which constructs a topological map of an environment given a sequence of images. This system includes a novel image similarity score which uses dynamic programming to match images using both the appearance and relative positions of local features simultaneously. Additionally an MRF is constructed to model the probability of loop-closures. A locally optimal labeling is found using Loopy-BP. Finally we outline a method to generate a topological map from loop closure data. Results are presented on four urban sequences and one indoor sequence.',\n",
       "  'id': '3861',\n",
       "  'title': 'Constructing Topological Maps using Markov Random Fields and Loop-Closure Detection',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The long-standing problem of efficient nearest-neighbor (NN) search has ubiquitous applications ranging from astrophysics to MP3 fingerprinting to bioinformatics to movie recommendations.  As the dimensionality of the dataset increases, exact NN search becomes computationally prohibitive; (1+eps)-distance-approximate NN search can provide large speedups but risks losing the meaning of NN search present in the ranks (ordering) of the distances. This paper presents a simple, practical algorithm allowing the user to, for the first time, directly control the true accuracy of NN search (in terms of ranks) while still achieving the large speedups over exact NN.  Experiments with high-dimensional datasets show that it often achieves faster and more accurate results than the best-known distance-approximate method, with much more stable behavior.',\n",
       "  'id': '3864',\n",
       "  'title': 'Rank-Approximate Nearest Neighbor Search: Retaining Meaning and Speed in High Dimensions',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as L1-norm for sparsity. We develop a new online algorithm, the regularized dual averaging method, that can explicitly exploit the regularization structure in an online setting. In particular, at each iteration, the learning variables are adjusted by solving a simple optimization problem that involves the running average of all past subgradients of the loss functions and the whole regularization term, not just its subgradient. This method achieves the optimal convergence rate and often enjoys a low complexity per iteration similar as the standard stochastic gradient method. Computational experiments are presented for the special case of sparse online learning using L1-regularization.',\n",
       "  'id': '3882',\n",
       "  'title': 'Dual Averaging Method for Regularized Stochastic Learning and Online Optimization',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'When individuals independently recollect events or retrieve facts from memory, how can we aggregate these retrieved memories to reconstruct the actual set of events or facts? In this research, we report the performance of individuals in a series of general knowledge tasks, where the goal is to reconstruct from memory the order of historic events, or the order of items along some physical dimension. We introduce two Bayesian models for aggregating order information based on a Thurstonian approach and Mallows model. Both models assume that each individuals reconstruction is based on either a random permutation of the unobserved ground truth, or by a pure guessing strategy. We apply MCMC to make inferences about the underlying truth and the strategies employed by individuals. The models demonstrate a wisdom of crowds\" effect, where the aggregated orderings are closer to the true ordering than the orderings of the best individual.\"',\n",
       "  'id': '3727',\n",
       "  'title': 'The Wisdom of Crowds in the Recollection of Order Information',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a nonparametric Bayesian method for texture learning and synthesis.  A texture image is represented by a 2D-Hidden Markov Model (2D-HMM) where the hidden states correspond to the cluster labeling of textons and the transition matrix encodes their spatial layout (the compatibility between adjacent textons). 2D-HMM is coupled with the Hierarchical Dirichlet process (HDP) which allows the number of textons and the complexity of transition matrix grow as the input texture becomes irregular. The HDP makes use of Dirichlet process prior which favors regular textures by penalizing the model complexity. This framework (HDP-2D-HMM) learns the texton vocabulary and their spatial layout jointly and automatically.  The HDP-2D-HMM results in a compact  representation of textures which allows fast texture synthesis with comparable rendering quality over the state-of-the-art image-based rendering methods. We also show that HDP-2D-HMM can be applied to perform image segmentation and synthesis.',\n",
       "  'id': '3729',\n",
       "  'title': 'Nonparametric Bayesian Texture Learning and Synthesis',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'When individuals learn facts (e.g., foreign language vocabulary) over multiple study sessions, the temporal spacing of study has a significant impact on memory retention.  Behavioral experiments have shown a nonmonotonic relationship between spacing and retention:  short or long intervals between study sessions yield lower cued-recall accuracy than intermediate intervals.  Appropriate spacing of study can double retention on educationally relevant time scales.  We introduce a Multiscale Context Model (MCM) that is able to predict the influence of a particular study schedule on retention for specific material.  MCMs prediction is based on empirical data characterizing forgetting of the material following a single study session.  MCM is a synthesis of two existing memory models (Staddon, Chelaru, & Higa, 2002; Raaijmakers, 2003).  On the surface, these  models are unrelated and incompatible, but we show they share a core feature  that allows them to be integrated.  MCM can determine study schedules that  maximize the durability of learning, and has implications for education  and training.  MCM can be cast either as a neural network with inputs that  fluctuate over time, or as a cascade of leaky integrators.  MCM is  intriguingly similar to a Bayesian multiscale model of memory (Kording, Tenenbaum, Shadmehr, 2007), yet MCM is better able to account for human  declarative memory.',\n",
       "  'id': '3731',\n",
       "  'title': 'Predicting the Optimal Spacing of Study: A Multiscale Context Model of Memory',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A goal of central importance in the study of hierarchical models for object recognition -- and indeed the visual cortex -- is that of understanding quantitatively the trade-off between invariance and selectivity, and how invariance and discrimination properties contribute towards providing an improved representation useful for learning from data. In this work we provide a general group-theoretic framework for characterizing and understanding invariance in a family of hierarchical models.  We show that by taking an algebraic perspective, one can provide a concise set of conditions which must be met to establish invariance, as well as a constructive prescription for meeting those conditions. Analyses in specific cases of particular relevance to computer vision and text processing are given, yielding insight into how and when invariance can be achieved. We find that the minimal sets of transformations intrinsic to the hierarchical model needed to support a particular invariance can be clearly described, thereby encouraging efficient computational implementations.',\n",
       "  'id': '3732',\n",
       "  'title': 'On Invariance in Hierarchical Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In cognitive science, empirical data collected from participants are the arbiters in model selection. Model discrimination thus depends on designing maximally informative experiments.  It has been shown that adaptive design optimization (ADO) allows one to discriminate models as efficiently as possible in simulation experiments.  In this paper we use ADO in a series of experiments with people to discriminate the Power, Exponential, and Hyperbolic models of memory retention, which has been a long-standing problem in cognitive science, providing an ideal setting in which to test the application of ADO for addressing questions about human cognition. Using an optimality criterion based on mutual information, ADO is able to find designs that are maximally likely to increase our certainty about the true model upon observation of the experiment outcomes.  Results demonstrate the usefulness of ADO and also reveal some challenges in its implementation.',\n",
       "  'id': '3735',\n",
       "  'title': 'Adaptive Design Optimization in Experiments with People',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Most of existing methods for DNA motif discovery consider only a single set of sequences to find an over-represented motif. In contrast, we consider multiple sets of sequences where we group sets associated with the same motif into a cluster, assuming that each set involves a single motif. Clustering sets of sequences yields clusters of coherent motifs, improving signal-to-noise ratio or enabling us to identify multiple motifs. We present a probabilistic model for DNA motif discovery where we identify multiple motifs through searching for patterns which are shared across multiple sets of sequences. Our model infers cluster-indicating latent variables and learns motifs simultaneously, where these two tasks interact with each other. We show that our model can handle various motif discovery problems, depending on how to construct multiple sets of sequences. Experiments on three different problems for discovering DNA motifs emphasize the useful behavior and confirm the substantial gains over existing methods where only single set of sequences is considered.',\n",
       "  'id': '3743',\n",
       "  'title': 'Clustering sequence sets for motif discovery',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Everyday social interactions are heavily influenced by our snap judgments about others goals.  Even young infants can infer the goals of intentional agents from observing how they interact with objects and other agents in their environment: e.g., that one agent is `helping or `hindering anothers attempt to get up a hill or open a box. We propose a model for how people can infer these social goals from actions, based on inverse planning in multiagent Markov decision problems (MDPs).  The model infers the goal most likely to be driving an agents behavior by assuming the agent acts approximately rationally given environmental constraints and its model of other agents present.  We also present behavioral evidence in support of this model over a simpler, perceptual cue-based alternative.',\n",
       "  'id': '3747',\n",
       "  'title': 'Help or Hinder: Bayesian Models of Social Goal Inference',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Resting state activity is brain activation that arises in the absence of any task, and is usually measured in awake subjects during prolonged fMRI scanning sessions where the only instruction given is to close the eyes and do nothing.  It has been recognized in recent years that resting state activity is implicated in a wide variety of brain function.  While certain networks of brain areas have different levels of activation at rest and during a task, there is nevertheless significant similarity between activations in the two cases.  This suggests that recordings of resting state activity can be used as a source of unlabeled data to augment discriminative regression techniques in a semi-supervised setting.  We evaluate this setting empirically yielding three main results: (i) regression tends to be improved by the use of Laplacian regularization even when no additional unlabeled data are available, (ii) resting state data may have a similar marginal distribution to that recorded during the execution of a visual processing task reinforcing the hypothesis that these conditions have similar types of activation, and (iii) this source of information can be broadly exploited to improve the robustness of empirical inference in fMRI studies, an inherently data poor domain.',\n",
       "  'id': '3748',\n",
       "  'title': 'Augmenting Feature-driven fMRI Analyses: Semi-supervised learning and resting state activity',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Graph matching and MAP inference are essential problems in computer vision and machine learning. We introduce a novel algorithm that can accommodate both problems and solve them efficiently. Recent graph matching algorithms are based on a general quadratic programming formulation, that takes in consideration both unary and second-order terms reflecting the similarities in local appearance as well as in the pairwise geometric relationships between the matched features. In this case the problem is NP-hard and a lot of effort has been spent in finding efficiently approximate solutions by relaxing the constraints of the original problem. Most algorithms find optimal continuous solutions of the modified problem, ignoring during the optimization the original discrete constraints. The continuous solution is quickly binarized at the end, but very little attention is put into this final discretization step. In this paper we argue that the stage in which a discrete solution is found is crucial for good performance. We propose an efficient algorithm, with climbing and convergence properties, that optimizes in the discrete domain the quadratic score, and it gives excellent results either by itself or by starting from the solution returned by any graph matching algorithm. In practice it outperforms state-or-the art algorithms and it also significantly improves their performance if used in combination. When applied to MAP inference, the algorithm is a parallel extension of Iterated Conditional Modes (ICM) with climbing and convergence properties that make it a compelling alternative to the sequential ICM. In our experiments on MAP inference our algorithm proved its effectiveness by outperforming ICM and Max-Product Belief Propagation.',\n",
       "  'id': '3756',\n",
       "  'title': 'An Integer Projected Fixed Point Method for Graph Matching and MAP Inference',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Image representation based on image bases provides a framework for understanding neural representation of visual perception. A recent fMRI study has shown that arbitrary contrast-defined visual images can be reconstructed from fMRI activity patterns using a combination of multi-scale local image bases. In the reconstruction model, the mapping from an fMRI activity pattern to the contrasts of the image bases was learned from measured fMRI responses to visual images. But the shapes of the images bases were fixed, and thus may not be optimal for reconstruction. Here, we propose a method to build a reconstruction model in which image bases are automatically extracted from the measured data. We constructed a probabilistic model that relates the fMRI activity space to the visual image space via a set of latent variables. The mapping from the latent variables to the visual image space can be regarded as a set of image bases. We found that spatially localized, multi-scale image bases were estimated near the fovea, and that the model using the estimated image bases was able to accurately reconstruct novel visual images. The proposed method provides a means to discover a novel functional mapping between stimuli and brain activity patterns.',\n",
       "  'id': '3757',\n",
       "  'title': 'Estimating image bases for visual image reconstruction from human brain activity',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The low-rank matrix completion problem is a fundamental problem with many important applications. Recently, Candes & Recht, Keshavan et al. and Candes & Tao obtained the first non-trivial theoretical results for the problem assuming that the observed entries are sampled uniformly at random. Unfortunately, most real-world datasets do not satisfy this assumption, but instead exhibit power-law distributed samples. In this paper, we propose a graph theoretic approach to matrix completion that solves the problem for more realistic sampling models. Our method is easier to analyze than previous methods with the analysis reducing to computing the threshold for complete cascades in random graphs, a problem of independent interest. By analyzing the graph theoretic problem, we show that our method achieves exact recovery when the observed entries are sampled from the Chung-Lu-Vu model, which can generate power-law distributed graphs. We also hypothesize that our algorithm solves the matrix completion problem from an optimal number of entries for the popular preferential attachment model and provide strong empirical evidence for the claim. Furthermore, our method is easier to implement and is substantially faster than existing methods. We demonstrate the effectiveness of our method on examples when the low-rank matrix is sampled according to the prevalent random graph models for complex networks and also on the Netflix challenge dataset.',\n",
       "  'id': '3763',\n",
       "  'title': 'Matrix Completion from Power-Law Distributed Samples',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The inter-subject alignment of functional MRI (fMRI) data is important for improving the statistical power of fMRI group analyses. In contrast to existing anatomically-based methods, we propose a novel multi-subject algorithm that derives a functional correspondence by aligning spatial patterns of functional connectivity across a set of subjects. We test our method on fMRI data collected during a movie viewing experiment. By cross-validating the results of our algorithm, we show that the correspondence successfully generalizes to a secondary movie dataset not used to derive the alignment.',\n",
       "  'id': '3764',\n",
       "  'title': 'fMRI-Based Inter-Subject Cortical Alignment Using Functional Connectivity',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a new perspective on approximations to the maximum a posteriori (MAP) task in probabilistic graphical models, that is based on simplifying a given instance, and then tightening the approximation.  First, we start with a structural relaxation of the original model.  We then infer from the relaxation its deficiencies, and compensate for them.  This perspective allows us to identify two distinct classes of approximations.  First, we find that max-product belief propagation can be viewed as a way to compensate for a relaxation, based on a particular idealized case for exactness.  We identify a second approach to compensation that is based on a more refined idealized case, resulting in a new approximation with distinct properties.  We go on to propose a new class of algorithms that, starting with a relaxation, iteratively yields tighter approximations.',\n",
       "  'id': '3768',\n",
       "  'title': 'Approximating MAP by Compensating for Structural Relaxations',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'It was recently shown that certain nonparametric regressors can escape the curse of dimensionality in the sense that their convergence rates adapt to the intrinsic dimension of data (\\\\cite{BL:65, SK:77}). We prove some stronger results in more general settings. In particular, we consider a regressor which, by combining aspects of both tree-based regression and kernel regression, operates on a general metric space, yields a smooth function, and evaluates in time $O(\\\\log n)$. We derive a tight convergence rate of the form $n^{-2/(2+d)}$ where $d$ is the Assouad dimension of the input space.',\n",
       "  'id': '3769',\n",
       "  'title': 'Fast, smooth and adaptive regression in metric spaces',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'One of the central problems in neuroscience is reconstructing synaptic connectivity in neural circuits. Synapses onto a neuron can be probed by sequentially stimulating potentially pre-synaptic neurons while monitoring the membrane voltage of the post-synaptic neuron. Reconstructing a large neural circuit using such a ?brute force? approach is rather time-consuming and inefficient because the connectivity in neural circuits is sparse. Instead, we propose to measure a post-synaptic neuron?s voltage while stimulating simultaneously multiple randomly chosen potentially pre-synaptic neurons. To extract the weights of individual synaptic connections we apply a decoding algorithm recently developed for compressive sensing. Compared to the brute force approach, our method promises significant time savings that grow with the size of the circuit. We use computer simulations to find optimal stimulation parameters and explore the feasibility of our reconstruction method under realistic experimental conditions including noise and non-linear synaptic integration. Multiple-neuron stimulation allows reconstructing synaptic connectivity just from the spiking activity of post-synaptic neurons, even when sub-threshold voltage is unavailable. By using calcium indicators, voltage-sensitive dyes, or multi-electrode arrays one could monitor activity of multiple post-synaptic neurons simultaneously, thus mapping their synaptic inputs in parallel, potentially reconstructing a complete neural circuit.',\n",
       "  'id': '3772',\n",
       "  'title': 'Reconstruction of Sparse Circuits Using Multi-neuronal Excitation (RESCUME)',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Given a matrix M of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries. The problem arises in a variety of applications, from collaborative filtering (the ?Netflix problem?) to structure-from-motion and positioning. We study a low complexity algorithm introduced in [1], based on a combination of spectral techniques and manifold optimization, that we call here OPTSPACE. We prove performance guarantees that are order-optimal in a number of circumstances.',\n",
       "  'id': '3777',\n",
       "  'title': 'Matrix Completion from Noisy Entries',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Search engines today present results that are often oblivious to recent shifts in intent. For example, the meaning of the query independence day shifts in early July to a US holiday and to a movie around the time of the box office release.  While no studies exactly quantify the magnitude of intent-shifting traffic, studies suggest that news events, seasonal topics, pop culture, etc account for 1/2 the search queries.  This paper shows that the signals a search engine receives can be used to both determine that a shift in intent happened, as well as find a result that is now more relevant. We present a meta-algorithm that marries a classifier with a bandit algorithm to achieve regret that depends logarithmically on the number of query impressions, under certain assumptions.  We provide strong evidence that this regret is close to the best achievable. Finally, via a series of experiments, we demonstrate that our algorithm outperforms prior approaches, particularly as the amount of intent-shifting traffic increases.',\n",
       "  'id': '3781',\n",
       "  'title': 'Adapting to the Shifting Intent of Search Queries',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The goal of perception is to infer the hidden states in the hierarchical process by which sensory data are generated. Human behavior is consistent with the optimal statistical solution to this problem in many tasks, including cue combination and orientation detection. Understanding the neural mechanisms underlying this behavior is of particular importance, since probabilistic computations are notoriously challenging. Here we propose a simple mechanism for Bayesian inference which involves averaging over a few feature detection neurons which fire at a rate determined by their similarity to a sensory stimulus. This mechanism is based on a Monte Carlo method known as importance sampling, commonly used in computer science and statistics. Moreover, a simple extension to recursive importance sampling can be used to perform hierarchical Bayesian inference. We identify a scheme for implementing importance sampling with spiking neurons, and show that this scheme can account for human behavior in cue combination and oblique effect.',\n",
       "  'id': '3782',\n",
       "  'title': 'Neural Implementation of Hierarchical Bayesian Inference by Importance Sampling',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present a general Bayesian approach to probabilistic matrix factorization subject to linear constraints. The approach is based on a Gaussian observation model and Gaussian priors with bilinear equality and inequality constraints. We present an efficient Markov chain Monte Carlo inference procedure based on Gibbs sampling. Special cases of the proposed model are Bayesian formulations of non-negative matrix factorization and factor analysis.  The method is evaluated on a blind source separation problem. We demonstrate that our algorithm can be used to extract meaningful and interpretable features that are remarkably different from features extracted using existing related matrix factorization techniques.',\n",
       "  'id': '3783',\n",
       "  'title': 'Linearly constrained Bayesian matrix factorization for blind source separation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this study, we present a method for estimating the mutual information for a localized pattern of fMRI data. We show that taking a multivariate information approach to voxel selection leads to a decoding accuracy that surpasses an univariate inforamtion approach and other standard voxel selection methods. Furthermore,we extend the multivariate mutual information theory to measure the functional connectivity between distributed brain regions. By jointly estimating the information shared by two sets of voxels we can reliably map out the connectivities in the human brain during experiment conditions. We validated our approach on a 6-way scene categorization fMRI experiment. The multivariate information analysis is able to ?nd strong information ?ow between PPA and RSC, which con?rms existing neuroscience studies on scenes. Furthermore, by exploring over the whole brain, our method identifies other interesting ROIs that share information with the PPA, RSC scene network,suggesting interesting future work for neuroscientists.',\n",
       "  'id': '3797',\n",
       "  'title': 'Exploring Functional Connectivities of the Human Brain using Multivariate Information Analysis',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Locality information is crucial in datasets where each variable corresponds to a measurement in a manifold (silhouettes, motion trajectories, 2D and 3D images). Although these datasets are typically under-sampled and high-dimensional, they often need to be represented with low-complexity statistical models, which are comprised of only the important probabilistic dependencies in the datasets. Most methods attempt to reduce model complexity by enforcing structure sparseness. However, sparseness cannot describe inherent regularities in the structure. Hence, in this paper we first propose a new class of Gaussian graphical models which, together with sparseness, imposes local constancy through ${\\\\ell}_1$-norm penalization. Second, we propose an efficient algorithm which decomposes the strictly convex maximum likelihood estimation into a sequence of problems with closed form solutions. Through synthetic experiments, we evaluate the closeness of the recovered models to the ground truth. We also test the generalization performance of our method in a wide range of complex real-world datasets and demonstrate that it can capture useful structures such as the rotation and shrinking of a beating heart, motion correlations between body parts during walking and functional interactions of brain regions. Our method outperforms the state-of-the-art structure learning techniques for Gaussian graphical models both for small and large datasets.',\n",
       "  'id': '3801',\n",
       "  'title': 'Sparse and Locally Constant Gaussian Graphical Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Speaker comparison, the process of finding the speaker similarity between two speech signals, occupies a central role in a variety of applications---speaker verification, clustering, and identification. Speaker comparison can be placed in a geometric framework by casting the problem as a model comparison process.  For a given speech signal, feature vectors are produced and used to adapt a Gaussian mixture model (GMM).  Speaker comparison can then be viewed as the process of compensating and finding metrics on the space of adapted models.  We propose a framework, inner product discriminant functions (IPDFs), which extends many common techniques for speaker comparison: support vector machines, joint factor analysis, and linear scoring.  The framework uses inner products between the parameter vectors of GMM models motivated by several statistical methods.  Compensation of nuisances is performed via linear transforms on GMM parameter vectors.  Using the IPDF framework, we show that many current techniques are simple variations of each other.  We demonstrate, on a 2006 NIST speaker recognition evaluation task, new scoring methods using IPDFs which produce excellent error rates and require significantly less computation than current techniques.',\n",
       "  'id': '3802',\n",
       "  'title': 'Speaker Comparison with Inner Product Discriminant Functions',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a multiple incremental decremental algorithm  of Support Vector Machine (SVM). Conventional single  cremental decremental SVM can update the trained model  efficiently when single data point is added to or removed  from the training set. When we add and/or remove multiple  data points, this algorithm is time-consuming because we  need to repeatedly apply it to each data point. The roposed  algorithm is computationally more efficient when multiple  data points are added and/or removed simultaneously. The  single incremental decremental algorithm is built on an  optimization technique called parametric programming.  We extend the idea and introduce multi-parametric  programming for developing the proposed algorithm.  Experimental results on synthetic and real data sets indicate that the proposed algorithm can significantly  reduce the computational cost of multiple incremental  decremental operation. Our approach is especially useful  for online SVM learning in which we need to remove old  data points and add new data points in a short amount of  time.',\n",
       "  'id': '3804',\n",
       "  'title': 'Multiple Incremental Decremental Learning of Support Vector Machines',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We provide a clustering algorithm that approximately optimizes the k-means objective, in the one-pass streaming setting. We make no assumptions about the data, and  our algorithm is very light-weight in terms of memory, and computation. This setting is applicable to unsupervised learning on massive data sets, or resource-constrained devices. The two main ingredients of our theoretical work are:  a derivation of an extremely simple pseudo-approximation batch algorithm for k-means, in which the algorithm is allowed to output more than k centers (based on the recent k-means++\"), and a streaming clustering algorithm in which batch clustering algorithms are performed on small inputs (fitting in memory) and combined in a hierarchical manner.  Empirical evaluations on real and simulated data reveal the practical utility of our method.\"',\n",
       "  'id': '3812',\n",
       "  'title': 'Streaming k-means approximation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Many researchers have suggested that the psychological complexity of a concept is related to the length of its representation in a language of thought.  As yet, however, there are few concrete proposals about the nature of this language. This paper makes one such proposal: the language of thought allows first order quantification (quantification over objects) more readily than second-order quantification (quantification over features). To support this proposal we present behavioral results from a concept learning study inspired by the work of Shepard, Hovland and Jenkins.\"',\n",
       "  'id': '3816',\n",
       "  'title': 'Quantification and the language of thought',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We study pool-based active learning in the presence of noise, i.e. the agnostic setting. Previous works have shown that the effectiveness of agnostic active learning depends on the learning problem and the hypothesis space. Although there are many cases on which active learning is very useful, it is also easy to construct examples that no active learning algorithm can have advantage. In this paper, we propose intuitively reasonable sufficient conditions under which agnostic active learning algorithm is strictly superior to passive supervised learning. We show that under some noise condition, if the classification boundary and the underlying distribution are smooth to a finite order, active learning achieves polynomial improvement in the label complexity; if the boundary and the distribution are infinitely smooth, the improvement is exponential.',\n",
       "  'id': '3818',\n",
       "  'title': 'Sufficient Conditions for Agnostic Active Learnable',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We present an approach for learning stochastic geometric models of object categories from single view images. We focus here on models expressible as a spatially contiguous assemblage of blocks. Model topologies are learned across groups of images, and one or more such topologies is linked to an object category (e.g.  chairs). Fitting learned topologies to an image can be used to identify the object class, as well as detail its geometry. The latter goes beyond labeling objects, as it provides the geometric structure of particular instances.  We learn the models using joint statistical inference over structure parameters, camera parameters, and instance parameters. These produce an image likelihood through a statistical imaging model. We use trans-dimensional sampling to explore topology hypotheses, and alternate between Metropolis-Hastings and stochastic dynamics to explore instance parameters. Experiments on images of furniture objects such as tables and chairs suggest that this is an effective approach for learning models that encode simple representations of category geometry and the statistics thereof, and support inferring both category and geometry on held out single view images.',\n",
       "  'id': '3820',\n",
       "  'title': 'Learning models of object structure',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We develop a convex relaxation of maximum a posteriori estimation of a mixture of regression models. Although our relaxation involves a semidefinite matrix variable, we reformulate the problem to eliminate the need for general semidefinite programming. In particular, we provide two reformulations that admit fast algorithms. The first is a max-min spectral reformulation exploiting quasi-Newton descent. The second is a min-min reformulation consisting of fast alternating steps of closed-form updates. We evaluate the methods against Expectation-Maximization in a real problem of motion segmentation from video data.',\n",
       "  'id': '3822',\n",
       "  'title': 'Convex Relaxation of Mixture Regression with Efficient Algorithms',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a new model for natural image statistics. Instead of minimizing dependency between components of natural images, we maximize a simple form of dependency in the form of tree-dependency. By learning filters and tree structures which are best suited for natural images we observe that the resulting filters are edge filters, similar to the famous ICA on natural images results. Calculating the likelihood of the model requires estimating the squared output of pairs of filters connected in the tree. We observe that after learning, these pairs of filters are predominantly of similar orientations but different phases, so their joint energy resembles models of complex cells.',\n",
       "  'id': '3834',\n",
       "  'title': \"The 'tree-dependent components' of natural scenes are edge filters\",\n",
       "  'year': '2009'},\n",
       " {'abstract': 'To estimate the changing structure of a varying-coefficient   varying-structure (VCVS) model remains an important and open problem   in dynamic system modelling, which includes learning trajectories of   stock prices, or uncovering the topology of an evolving gene   network. In this paper, we investigate sparsistent learning of a   sub-family of this model --- piecewise constant VCVS models. We   analyze two main issues in this problem: inferring time points where   structural changes occur and estimating model structure (i.e., model   selection) on each of the constant segments. We propose a two-stage   adaptive procedure, which first identifies jump points of structural   changes and then identifies relevant covariates to a response on   each of the segments. We provide an asymptotic analysis of the   procedure, showing that with the increasing sample size, number of   structural changes, and number of variables, the true model can be   consistently selected. We demonstrate the performance of the method   on synthetic data and apply it to the brain computer interface   dataset. We also consider how this applies to structure estimation   of time-varying probabilistic graphical models.',\n",
       "  'id': '3836',\n",
       "  'title': 'Sparsistent Learning of Varying-coefficient Models with Structural Changes',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The problem of approximating a given probability distribution using a simpler distribution plays an important role in several areas of machine learning, e.g. variational inference and classification. Within this context, we consider the task of learning a mixture of tree distributions. Although mixtures of trees can be learned by minimizing the KL-divergence using an EM algorithm, its success depends heavily on the initialization. We propose an efficient strategy for obtaining a good initial set of trees that attempts to cover the entire observed distribution by minimizing the $\\\\alpha$-divergence with $\\\\alpha = \\\\infty$. We formulate the problem using the fractional covering framework and present a convergent sequential algorithm that only relies on solving a convex program at each iteration. Compared to previous methods, our approach results in a significantly smaller mixture of trees that provides similar or better accuracies. We demonstrate the usefulness of our approach by learning pictorial structures for face recognition.',\n",
       "  'id': '3844',\n",
       "  'title': 'Learning a Small Mixture of Trees',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A crucial technique for scaling kernel methods to very large data sets reaching or exceeding millions of instances is based on low-rank approximation of kernel matrices. We introduce a new family of algorithms based on mixtures of Nystrom approximations, ensemble Nystrom algorithms, that yield more accurate low-rank approximations than the standard Nystrom method. We give a detailed study of multiple variants of these algorithms based on simple averaging, an exponential weight method, or regression-based methods. We also present a theoretical analysis of these algorithms, including novel error bounds guaranteeing a better convergence rate than the standard Nystrom method. Finally, we report the results of extensive experiments with several data sets containing up to 1M points demonstrating the signi?cant performance improvements gained over the standard Nystrom approximation.',\n",
       "  'id': '3850',\n",
       "  'title': 'Ensemble Nystrom Method',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations, with applications in denoising, inpainting and compressive sensing (CS). The beta process is employed as a prior for learning the dictionary, and this non-parametric method naturally infers an appropriate dictionary size. The Dirichlet process and a probit stick-breaking process are also considered to exploit structure within an image. The proposed method can learn a sparse dictionary in situ; training images may be exploited if available, but they are not required. Further, the noise variance need not be known, and can be non-stationary. Another virtue of the proposed method is that sequential inference can be readily employed, thereby allowing scaling to large images. Several example results are presented, using both Gibbs and variational Bayesian inference, with comparisons to other state-of-the-art approaches.',\n",
       "  'id': '3851',\n",
       "  'title': 'Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We show how to model documents as bags of words using family of two-layer, undirected graphical models. Each member of the family has the same number of binary hidden units but a different number of ``softmax visible units. All of the softmax units in all of the models in the family share the same weights to the binary hidden units. We describe efficient inference and learning procedures for such a family. Each member of the family models the probability distribution of documents of a specific length as a product of topic-specific distributions rather than as a mixture and this gives much better generalization than Latent Dirichlet Allocation for modeling the log probabilities of held-out documents. The low-dimensional topic vectors learned by the undirected family are also much better than LDA topic vectors for retrieving documents that are similar to a query document. The learned topics are more general than those found by LDA because precision is achieved by intersecting many general topics rather than by selecting a single precise topic to generate each word.',\n",
       "  'id': '3856',\n",
       "  'title': 'Replicated Softmax: an Undirected Topic Model',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We describe probability distributions, dubbed compressible priors, whose independent and identically distributed (iid) realizations result in compressible signals. A signal is compressible when sorted magnitudes of its coefficients exhibit a power-law decay so that the signal can be well-approximated by a sparse signal. Since compressible signals live close to sparse signals, their intrinsic information can be stably embedded via simple non-adaptive linear projections into a much lower dimensional space whose dimension grows logarithmically with the ambient signal dimension. By using order statistics, we show that N-sample iid realizations of generalized Pareto, Student?s t, log-normal, Frechet, and log-logistic distributions are compressible, i.e., they have a constant expected decay rate, which is independent of N. In contrast, we show that generalized Gaussian distribution with shape parameter q is compressible only in restricted cases since the expected decay rate of its N-sample iid realizations decreases with N as 1/[q log(N/q)]. We use compressible priors as a scaffold to build new iterative sparse signal recovery algorithms based on Bayesian inference arguments. We show how tuning of these algorithms explicitly depends on the parameters of the compressible prior of the signal, and how to learn the parameters of the signal?s compressible prior on the fly during recovery.',\n",
       "  'id': '3866',\n",
       "  'title': 'Learning with Compressible Priors',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper introduces a new method for semi-supervised learning on high dimensional nonlinear manifolds, which includes a phase of unsupervised basis learning and a phase of supervised function learning. The learned bases provide a set of anchor points to form a local coordinate system, such that each data point x on the manifold can be locally approximated by a linear combination of its nearby anchor points, and the linear weights become its local coordinate coding. We show that a high dimensional nonlinear function can be approximated by a global linear function with respect to this coding scheme, and the approximation quality is ensured by the locality of such coding. The method turns a difficult nonlinear learning problem into a simple global linear learning problem, which overcomes some drawbacks of traditional local learning methods.',\n",
       "  'id': '3875',\n",
       "  'title': 'Nonlinear Learning using Local Coordinate Coding',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Automated recovery from failures is a key component in the management of large data centers. Such systems typically employ a hand-made controller created by an expert. While such controllers capture many important aspects of the recovery process, they are often not systematically optimized to reduce costs such as server downtime. In this paper we explain how to use data gathered from the interactions of the hand-made controller with the system, to create an optimized controller. We suggest learning an indefinite horizon Partially Observable Markov Decision Process, a model for decision making under uncertainty, and solve it using a point-based algorithm. We describe the complete process, starting with data gathering, model learning, model checking procedures, and computing a policy. While our paper focuses on a specific domain, our method is applicable to other systems that use a hand-coded, imperfect controllers.',\n",
       "  'id': '3877',\n",
       "  'title': 'Improving Existing Fault Recovery Policies',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Training conditional maximum entropy models on massive data requires significant time and computational resources. In this paper, we investigate three common distributed training strategies: distributed gradient, majority voting ensembles, and parameter mixtures. We analyze the worst-case runtime and resource costs of each and present a theoretical foundation for the convergence of parameters under parameter mixtures, the most efficient strategy. We present large-scale experiments comparing the different strategies and demonstrate that parameter mixtures over independent models use fewer resources and achieve comparable loss as compared to standard approaches.',\n",
       "  'id': '3881',\n",
       "  'title': 'Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We propose a new sketch recognition framework that combines a rich representation of low level visual appearance with a graphical model for capturing high level relationships between symbols. This joint model of appearance and context allows our framework to be less sensitive to noise and drawing variations, improving accuracy and robustness. The result is a recognizer that is better able to handle the wide range of drawing styles found in messy freehand sketches. We evaluate our work on two real-world domains, molecular diagrams and electrical circuit diagrams, and show that our combined approach significantly improves recognition performance.',\n",
       "  'id': '3885',\n",
       "  'title': 'Learning from Neighboring Strokes: Combining Appearance and Context for Multi-Domain Sketch Recognition',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In the last few decades, model complexity has received a lot of press. While many methods have been proposed that jointly measure a model?s descriptive adequacy and its complexity, few measures exist that measure complexity in itself. Moreover, existing measures ignore the parameter prior, which is an inherent part of the model and affects the complexity. This paper presents a stand alone measure for model complexity, that takes the number of parameters, the functional form, the range of the parameters and the parameter prior into account. This Prior Predictive Complexity (PPC) is an intuitive and easy to compute measure. It starts from the observation that model complexity is the property of the model that enables it to fit a wide range of outcomes. The PPC then measures how wide this range exactly is.',\n",
       "  'id': '3886',\n",
       "  'title': 'Measuring model complexity with the prior predictive',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper studies the forward greedy strategy in sparse nonparametric regression. For additive models, we propose an algorithm called additive forward regression; for general multivariate regression, we propose an algorithm called generalized forward regression. Both of them simultaneously conduct estimation and variable selection in nonparametric settings for the high dimensional sparse learning problem. Our main emphasis is empirical: on both simulated and real data, these two simple greedy methods can clearly outperform several state-of-the-art competitors, including the LASSO, a nonparametric version of the LASSO called the sparse additive model (SpAM) and a recently proposed adaptive parametric forward-backward algorithm called the Foba. Some theoretical justifications are also provided.',\n",
       "  'id': '3889',\n",
       "  'title': 'Nonparametric Greedy Algorithms for the Sparse Learning Problem',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The Indian buffet process (IBP) is an exchangeable distribution over binary matrices used in Bayesian nonparametric featural models.  In this paper we propose a three-parameter generalization of the IBP exhibiting power-law behavior.  We achieve this by generalizing the beta process (the de Finetti measure of the IBP) to the \\\\emph{stable-beta process} and deriving the IBP corresponding to it.  We find interesting relationships between the stable-beta process and the Pitman-Yor process (another stochastic process used in Bayesian nonparametric models with interesting power-law properties).  We show that our power-law IBP is a good model for word occurrences in documents with improved performance over the normal IBP.',\n",
       "  'id': '3638',\n",
       "  'title': 'Indian Buffet Processes with Power-law Behavior',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'This paper tackles the problem of selecting among several linear estimators in non-parametric regression; this includes model selection for linear regression, the choice of a regularization parameter in kernel ridge regression or spline smoothing, and the choice of a kernel in multiple kernel learning. We propose a new algorithm which first estimates consistently the variance of the noise, based upon the concept of minimal penalty which was previously introduced in the context of model selection. Then, plugging our variance estimate in Mallows $C_L$ penalty is proved to lead to an algorithm satisfying an oracle inequality. Simulation experiments with kernel ridge regression and multiple kernel learning show that the proposed algorithm often improves significantly existing calibration procedures such as 10-fold cross-validation or generalized cross-validation.',\n",
       "  'id': '3639',\n",
       "  'title': 'Data-driven calibration of linear estimators with minimal penalties',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'A non-parametric Bayesian model is proposed for processing multiple images. The analysis employs image features and, when present, the words associated with accompanying annotations. The model clusters the images into classes, and each image is segmented into a set of objects, also allowing the opportunity to assign a word to each object (localized labeling). Each object is assumed to be represented as a heterogeneous mix of components, with this realized via mixture models linking image features to object types. The number of image classes, number of object types, and the characteristics of the object-feature mixture models are inferred non-parametrically. To constitute spatially contiguous objects, a new logistic stick-breaking process is developed. Inference is performed efficiently via variational Bayesian analysis, with example results presented on two image databases.',\n",
       "  'id': '3655',\n",
       "  'title': 'A Bayesian Model for Simultaneous Image Clustering, Annotation and Object Segmentation',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'The learning of appropriate distance metrics is a critical problem in classification. In this work, we propose a boosting-based technique, termed BoostMetric, for learning a Mahalanobis distance metric. One of the primary difficulties in learning such a metric is to ensure that the Mahalanobis matrix remains positive semidefinite. Semidefinite programming is sometimes used to enforce this constraint, but does not scale well. BoostMetric is instead based on a key observation that any positive semidefinite matrix can be decomposed into a linear positive combination of trace-one rank-one matrices.  BoostMetric thus uses rank-one positive semidefinite matrices as weak learners within an efficient and scalable boosting-based learning process. The resulting method is easy to implement, does not require tuning, and can accommodate various types of constraints.  Experiments on various datasets show that the proposed algorithm compares favorably to those state-of-the-art methods in terms of classification accuracy and running time.',\n",
       "  'id': '3658',\n",
       "  'title': 'Positive Semidefinite Metric Learning with Boosting',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Schizophrenia is a complex psychiatric disorder that has eluded a characterization in terms of local abnormalities of brain activity, and is hypothesized to affect the collective, ``emergent working of the brain. We propose a novel data-driven approach to capture emergent features using functional brain networks [Eguiluzet al] extracted from fMRI data, and demonstrate its advantage over traditional region-of-interest (ROI) and local, task-specific linear activation analyzes. Our results suggest that schizophrenia is indeed associated with disruption of global, emergent brain properties related to its functioning as a network, which cannot be explained by alteration of local activation patterns. Moreover, further exploitation of interactions by sparse Markov Random Field classifiers shows clear gain over linear methods, such as Gaussian Naive Bayes and SVM, allowing to reach 86% accuracy (over 50% baseline - random guess), which is quite remarkable given that it is based on a single fMRI experiment using a simple auditory task.',\n",
       "  'id': '3660',\n",
       "  'title': 'Discriminative Network Models of Schizophrenia',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Fast retrieval methods are increasingly critical for many large-scale analysis tasks, and there have been several recent methods that attempt to learn hash functions for fast and accurate nearest neighbor searches.  In this paper, we develop an algorithm for learning hash functions based on explicitly minimizing the reconstruction error between the original distances and the Hamming distances of the corresponding binary embeddings.  We develop a scalable coordinate-descent algorithm for our proposed hashing objective that is able to efficiently learn hash functions in a variety of settings.  Unlike existing methods such as semantic hashing and spectral hashing, our method is easily kernelized and does not require restrictive assumptions about the underlying distribution of the data.  We present results over several domains to demonstrate that our method outperforms existing state-of-the-art techniques.',\n",
       "  'id': '3667',\n",
       "  'title': 'Learning to Hash with Binary Reconstructive Embeddings',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In recent years, deep learning approaches have gained significant interest as a way of building hierarchical representations from unlabeled data. However, to our knowledge, these deep learning approaches have not been extensively studied for auditory data. In this paper, we apply convolutional deep belief networks to audio data and empirically evaluate them on various audio classification tasks. For the case of speech data, we show that the learned features correspond to phones/phonemes. In addition, our feature representations trained from unlabeled audio data show very good performance for multiple audio classification tasks. We hope that this paper will inspire more research on deep learning approaches applied to a wide range of audio recognition tasks.',\n",
       "  'id': '3674',\n",
       "  'title': 'Unsupervised feature learning for audio classification using convolutional deep belief networks',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Learning distance functions with side information plays a key role in many machine learning and data mining applications. Conventional approaches often assume a Mahalanobis distance function. These approaches are limited in two aspects: (i) they are computationally expensive (even infeasible) for high dimensional data because the size of the metric is in the square of dimensionality; (ii) they assume a fixed metric for the entire input space and therefore are unable to handle heterogeneous data. In this paper, we propose a novel scheme that learns nonlinear Bregman distance functions from side information using a non-parametric approach that is similar to support vector machines. The proposed scheme avoids the assumption of fixed metric because its local distance metric is implicitly derived from the Hessian matrix of a convex function that is used to generate the Bregman distance function. We present an efficient learning algorithm for the proposed scheme for distance function learning. The extensive experiments with semi-supervised clustering show the proposed technique (i) outperforms the state-of-the-art approaches for distance function learning, and (ii) is computationally efficient for high dimensional data.',\n",
       "  'id': '3678',\n",
       "  'title': 'Learning Bregman Distance Functions and Its Application for Semi-Supervised Clustering',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'In this paper we address the problem of provably correct feature selection in arbitrary domains.  An optimal solution to the problem is a Markov boundary, which is a minimal set of features that make the probability distribution of a target variable conditionally invariant to the state of all other features in the domain.  While numerous algorithms for this problem have been proposed, their theoretical correctness and practical behavior under arbitrary probability distributions is unclear.  We address this by introducing the Markov Boundary Theorem that precisely characterizes the properties of an ideal Markov boundary, and use it to develop algorithms that learn a more general boundary that can capture complex interactions that only appear when the values of multiple features are considered together.  We introduce two algorithms: an exact, provably correct one as well a more practical randomized anytime version, and show that they perform well on artificial as well as benchmark and real-world data sets.  Throughout the paper we make minimal assumptions that consist of only a general set of axioms that hold for every probability distribution, which gives these algorithms universal applicability.',\n",
       "  'id': '3679',\n",
       "  'title': 'Toward Provably Correct Feature Selection in Arbitrary Domains',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce skill chaining, a skill discovery method for reinforcement learning agents in continuous domains, that builds chains of skills leading to an end-of-task reward. We demonstrate experimentally that it creates skills that result in performance benefits in a challenging continuous domain.',\n",
       "  'id': '3683',\n",
       "  'title': 'Skill Discovery in Continuous Reinforcement Learning Domains using Skill Chaining',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Studying signal and noise properties of recorded neural data is critical in developing more efficient algorithms to recover the encoded information. Important issues exist in this research including the variant spectrum spans of neural spikes that make it difficult to choose a global optimal bandpass filter. Also, multiple sources produce aggregated noise that deviates from the conventional white Gaussian noise. In this work, the spectrum variability of spikes is addressed, based on which the concept of adaptive bandpass filter that fits the spectrum of individual spikes is proposed. Multiple noise sources have been studied through analytical models as well as empirical measurements. The dominant noise source is identified as neuron noise followed by interface noise of the electrode. This suggests that major efforts to reduce noise from electronics are not well spent. The measured noise from in vivo experiments shows a family of 1/f^{x} (x=1.5\\\\pm 0.5) spectrum that can be reduced using noise shaping techniques. In summary, the methods of adaptive bandpass filtering and noise shaping together result in several dB signal-to-noise ratio (SNR) enhancement.',\n",
       "  'id': '3695',\n",
       "  'title': 'Noise Characterization, Modeling, and Reduction for In Vivo Neural Recording',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We consider the problem of learning, from K input data, a regression function in a function space of high dimension N using projections onto a random subspace of lower dimension M. From any linear approximation algorithm using empirical risk minimization (possibly penalized), we provide bounds on the excess risk of the estimate computed in the projected subspace (compressed domain) in terms of the excess risk of the estimate built in the high-dimensional space (initial domain). We apply the analysis to the ordinary Least-Squares regression and show that by choosing M=O(\\\\sqrt{K}), the estimation error (for the quadratic loss) of the ``Compressed Least Squares Regression is O(1/\\\\sqrt{K}) up to logarithmic factors. We also discuss the numerical complexity of several algorithms (both in initial and compressed domains) as a function of N, K, and M.',\n",
       "  'id': '3698',\n",
       "  'title': 'Compressed Least-Squares Regression',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Learning to rank has become an important research topic in machine learning. While most learning-to-rank methods learn the ranking function by minimizing the loss functions, it is the ranking measures (such as NDCG and MAP) that are used to evaluate the performance of the learned ranking function. In this work, we reveal the relationship between ranking measures and loss functions in learning-to-rank methods, such as Ranking SVM, RankBoost, RankNet, and ListMLE. We show that these loss functions are upper bounds of the measure-based ranking errors. As a result, the minimization of these loss functions will lead to the maximization of the ranking measures. The key to obtaining this result is to model ranking as a sequence of classification tasks, and define a so-called essential loss as the weighted sum of the classification errors of individual tasks in the sequence. We have proved that the essential loss is both an upper bound of the measure-based ranking errors, and a lower bound of the loss functions in the aforementioned methods. Our proof technique also suggests a way to modify existing loss functions to make them tighter bounds of the measure-based ranking errors. Experimental results on benchmark datasets show that the modifications can lead to better ranking performance, demonstrating the correctness of our analysis.',\n",
       "  'id': '3708',\n",
       "  'title': 'Ranking Measures and Loss Functions in Learning to Rank',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We show how to sequentially optimize magnetic resonance imaging measurement designs over stacks of neighbouring image slices, by performing convex variational inference on a large scale non-Gaussian linear dynamical system, tracking dominating directions of posterior covariance without imposing any factorization constraints. Our approach can be scaled up to high-resolution images by reductions to numerical mathematics primitives and parallelization on several levels. In a first study, designs are found that improve significantly on others chosen independently for each slice or drawn at random.',\n",
       "  'id': '3712',\n",
       "  'title': 'Speeding up Magnetic Resonance Image Acquisition by Bayesian Multi-Slice Adaptive Compressed Sensing',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Sequential decision-making with multiple agents and imperfect information is commonly modeled as an extensive game.  One efficient method for computing Nash equilibria in large, zero-sum, imperfect information games is counterfactual regret minimization (CFR). In the domain of poker, CFR has proven effective, particularly when using a domain-specific augmentation involving chance outcome sampling.  In this paper, we describe a general family of domain independent CFR sample-based algorithms called Monte Carlo counterfactual regret minimization (MCCFR) of which the original and poker-specific versions are special cases. We start by showing that MCCFR performs the same regret updates as CFR on expectation. Then, we introduce two sampling schemes: {\\\\it outcome sampling} and {\\\\it external sampling}, showing that both have bounded overall regret with high  probability. Thus, they can compute an approximate equilibrium using self-play. Finally, we prove a new tighter bound on the regret for the original CFR algorithm and relate this new bound to MCCFRs bounds. We show empirically that, although the sample-based algorithms require more iterations, their lower cost per iteration can lead to dramatically faster convergence in various games.',\n",
       "  'id': '3713',\n",
       "  'title': 'Monte Carlo Sampling for Regret Minimization in Extensive Games',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'Directed graphical models such as Bayesian networks are a favored formalism to model the dependency structures in complex multivariate systems such as those encountered in biology and neural sciences. When the system is undergoing dynamic transformation, often a temporally rewiring network is needed for capturing the dynamic causal influences between covariates. In this paper, we propose a time-varying dynamic Bayesian network (TV-DBN) for modeling the structurally varying directed dependency structures underlying non-stationary biological/neural time series. This is a challenging problem due the non-stationarity and sample scarcity of the time series. We present a kernel reweighted $\\\\ell_1$ regularized auto-regressive procedure for learning the TV-DBN model. Our method enjoys nice properties such as computational efficiency and provable asymptotic consistency. Applying TV-DBN to time series measurements during yeast cell cycle and brain response to visual stimuli reveals interesting dynamics underlying the respective biological systems.',\n",
       "  'id': '3716',\n",
       "  'title': 'Time-Varying Dynamic Bayesian Networks',\n",
       "  'year': '2009'},\n",
       " {'abstract': 'We introduce a new Bayesian nonparametric approach to identification of sparse dynamic linear systems. The impulse responses are modeled as Gaussian processes whose autocovariances encode the BIBO stability constraint, as defined by the recently introduced ?Stable Spline kernel?. Sparse solutions are obtained by placing exponential hyperpriors on the scale factors of such kernels. Numerical experiments regarding estimation of ARMAX models show that this technique provides a definite advantage over a group LAR algorithm and state-of-the-art parametric identification techniques based on prediction error minimization.',\n",
       "  'id': '4174',\n",
       "  'title': 'Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Markov networks (MNs) can incorporate arbitrarily complex features in modeling relational data. However, this flexibility comes at a sharp price of training an exponentially complex model. To address this challenge, we propose a novel relational learning approach, which consists of a restricted class of relational MNs (RMNs) called relation tree-based RMN (treeRMN), and an efficient Hidden Variable Detection algorithm called Contrastive Variable Induction (CVI). On one hand, the restricted treeRMN only considers simple (e.g., unary and pairwise) features in relational data and thus achieves computational efficiency; and on the other hand, the CVI algorithm efficiently detects hidden variables which can capture long range dependencies. Therefore, the resultant approach is highly efficient yet does not sacrifice its expressive power. Empirical results on four real datasets show that the proposed relational learning method can achieve similar prediction quality as the state-of-the-art approaches, but is significantly more efficient in training; and the induced hidden variables are semantically meaningful and crucial to improve the training speed and prediction qualities of treeRMNs.',\n",
       "  'id': '4175',\n",
       "  'title': 'Efficient Relational Learning with Hidden Variable Detection',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Most active learning approaches select either informative or representative unlabeled instances to query their labels. Although several active learning algorithms have been proposed to combine the two criterions for query selection, they are usually ad hoc in finding unlabeled instances that are both informative and representative. We address this challenge by a principled approach, termed QUIRE, based on the min-max view of active learning. The proposed approach provides a systematic way for measuring and combining the informativeness and representativeness of an instance. Extensive experimental results show that the proposed QUIRE approach outperforms several state-of -the-art active learning approaches.',\n",
       "  'id': '4176',\n",
       "  'title': 'Active Learning by Querying Informative and Representative Examples',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Estimating 3D pose from monocular images is a highly ambiguous problem. Physical constraints can be exploited to restrict the space of feasible configurations. In this paper we propose an approach to constraining the prediction of a discriminative predictor. We first show that the mean prediction of a Gaussian process implicitly satisfies linear constraints if those constraints are satisfied by the training examples. We then show how, by performing a change of variables, a GP can be forced to satisfy quadratic constraints. As evidenced by the experiments, our method outperforms state-of-the-art approaches on the tasks of rigid and non-rigid pose estimation.',\n",
       "  'id': '4179',\n",
       "  'title': 'Implicitly Constrained Gaussian Process Regression for Monocular Non-Rigid Pose Estimation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We establish an excess risk bound of O(H R_n^2 + sqrt{H L*} R_n) for ERM with an H-smooth loss function and a hypothesis class with Rademacher complexity R_n, where L* is the best risk achievable by the hypothesis class. For typical hypothesis classes where R_n = sqrt{R/n}, this translates to a learning rate of ? O(RH/n) in the separable (L* = 0) case and O(RH/n + sqrt{L* RH/n}) more generally. We also provide similar guarantees for online and stochastic convex optimization of a smooth non-negative objective.',\n",
       "  'id': '3894',\n",
       "  'title': 'Smoothness, Low Noise and Fast Rates',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Given an ensemble of distinct, low-level segmentations of an image, our goal is to identify visually meaningful\" segments in the ensemble. Knowledge about any specific objects and surfaces present in the image is not available. The selection of image regions occupied by objects is formalized as the maximum-weight independent set (MWIS) problem. MWIS is the heaviest subset of mutually non-adjacent nodes of an attributed graph. We construct such a graph from all segments in the ensemble. Then, MWIS selects maximally distinctive segments that together partition the image. A new MWIS algorithm is presented. The algorithm seeks a solution directly in the discrete domain, instead of relaxing MWIS to a continuous problem, as common in previous work. It iteratively finds a candidate discrete solution of the Taylor series expansion of the original MWIS objective function around the previous solution. The algorithm is shown to converge to a maximum. Our empirical evaluation on the benchmark Berkeley segmentation dataset shows that the new algorithm eliminates the need for hand-picking optimal input parameters of the state-of-the-art segmenters, and outperforms their best, manually optimized results.\"',\n",
       "  'id': '3909',\n",
       "  'title': 'Segmentation as Maximum-Weight Independent Set',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The human vision system is able to effortlessly perceive both short-range and long-range motion patterns in complex dynamic scenes. Previous work has assumed that two different mechanisms are involved in processing these two types of motion. In this paper, we propose a hierarchical model as a unified framework for modeling both short-range and long-range motion perception. Our model consists of two key components: a data likelihood that proposes multiple motion hypotheses using nonlinear matching, and a hierarchical prior that imposes slowness and spatial smoothness constraints on the motion field at multiple scales. We tested our model on two types of stimuli, random dot kinematograms and multiple-aperture stimuli, both commonly used in human vision research. We demonstrate that the hierarchical model adequately accounts for human performance in psychophysical experiments.',\n",
       "  'id': '3910',\n",
       "  'title': 'A unified model of short-range and long-range motion perception',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider Markov decision processes where the values of the parameters are uncertain. This uncertainty is described by a sequence of nested sets (that is, each set contains the previous one), each of which corresponds to a probabilistic guarantee for a different confidence level so that a set of admissible probability distributions of the unknown parameters is specified. This formulation models the case where the decision maker is aware of and wants to exploit some (yet imprecise) a-priori information of the distribution of parameters, and arises naturally in practice where methods to estimate the confidence region of parameters abound. We propose a decision criterion based on *distributional robustness*: the optimal policy maximizes the expected total reward under the most adversarial probability distribution over realizations of the uncertain parameters that is admissible (i.e., it agrees with the a-priori information). We show that finding the optimal distributionally robust policy can be reduced to a standard robust MDP where the parameters belong to a single uncertainty set, hence it can be computed in polynomial time under mild technical conditions.',\n",
       "  'id': '3927',\n",
       "  'title': 'Distributionally Robust Markov Decision Processes',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Sparse coding has recently become a popular approach in computer vision to learn dictionaries of natural images. In this paper we extend sparse coding to learn interpretable spatio-temporal primitives of human motion.  We cast the problem of learning spatio-temporal primitives as a tensor factorization problem  and introduce constraints to learn interpretable primitives. In particular, we use group norms over those tensors, diagonal constraints on the activations as well as smoothness constraints that are inherent to human motion.   We demonstrate the effectiveness of our approach to learn interpretable representations  of human motion from motion capture data, and show that our approach outperforms  recently developed matching pursuit and  sparse coding algorithms.',\n",
       "  'id': '3930',\n",
       "  'title': 'Sparse Coding for Learning Interpretable Spatio-Temporal Primitives',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Sparse methods for supervised learning aim at finding good linear predictors from as few variables as possible, i.e., with small cardinality of their supports. This combinatorial selection problem is often turned into a convex optimization problem by replacing the cardinality function by its convex envelope (tightest convex lower bound), in this case the L1-norm. In this paper, we investigate more general set-functions than the cardinality, that may incorporate prior knowledge or structural constraints which are common in many applications: namely, we show that for nondecreasing submodular set-functions, the corresponding convex envelope can be obtained from its Lovasz extension, a common tool in submodular analysis. This defines a family of polyhedral norms, for which we provide generic algorithmic tools (subgradients and proximal operators) and theoretical results (conditions for support recovery or high-dimensional inference). By selecting specific submodular functions, we can give a new interpretation to known norms, such as those based on rank-statistics or grouped norms with potentially overlapping groups; we also define new norms, in particular ones that can be used as non-factorial priors for supervised learning.',\n",
       "  'id': '3933',\n",
       "  'title': 'Structured sparsity-inducing norms through submodular functions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper presents Bayesian non-parametric models that simultaneously learn to segment words from phoneme strings and learn the referents of some of those words, and shows that there is a synergistic interaction in the acquisition of these two kinds of linguistic information. The models themselves are novel kinds of Adaptor Grammars that are an extension of an embedding of topic models into PCFGs. These models simultaneously segment phoneme sequences into words and learn the relationship between non-linguistic objects to the words that refer to them. We show (i) that modelling inter-word dependencies not only improves the accuracy of the word segmentation but also of word-object relationships, and (ii) that a model that simultaneously learns word-object relationships and word segmentation segments more accurately than one that just learns word segmentation on its own. We argue that these results support an interactive view of language acquisition that can take advantage of synergies such as these.',\n",
       "  'id': '3946',\n",
       "  'title': 'Synergies in learning words and their referents',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a new approach to value function approximation which combines linear temporal difference reinforcement learning with subspace identification. In practical applications, reinforcement learning (RL) is complicated by the fact that state is either high-dimensional or partially observable. Therefore, RL methods are designed to work with features of state rather than state itself, and the success or failure of learning is often determined by the suitability of the selected features. By comparison, subspace identification (SSID) methods are designed to select a feature set which preserves as much information as possible about state. In this paper we connect the two approaches, looking at the problem of reinforcement learning with a large set of features, each of which may only be marginally useful for value function approximation. We introduce a new algorithm for this situation, called Predictive State Temporal Difference (PSTD) learning. As in SSID for predictive state representations, PSTD finds a linear compression operator that projects a large set of features down to a small set that preserves the maximum amount of predictive information. As in RL, PSTD then uses a Bellman recursion to estimate a value function. We discuss the connection between PSTD and prior approaches in RL and SSID. We prove that PSTD is statistically consistent, perform several experiments that illustrate its properties, and demonstrate its potential on a difficult optimal stopping problem.',\n",
       "  'id': '3952',\n",
       "  'title': 'Predictive State Temporal Difference Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A long-standing open research problem is how to use information from different experiments, including background knowledge, to infer causal relations. Recent developments have shown ways to use multiple data sets, provided they originate from identical experiments. We present the MCI-algorithm as the first method that can infer provably valid causal relations in the large sample limit from different experiments. It is fast, reliable and produces very clear and easily interpretable output. It is based on a result that shows that constraint-based causal discovery is decomposable into a candidate pair identification and subsequent elimination step that can be applied separately from different models. We test the algorithm on a variety of synthetic input model sets to assess its behavior and the quality of the output. The method shows promising signs that it can be adapted to suit causal discovery in real-world application areas as well, including large databases.',\n",
       "  'id': '3961',\n",
       "  'title': 'Causal discovery in multiple models from different experiments',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a generative probabilistic model for learning general graph structures, which we term concept graphs, from text. Concept graphs provide a visual summary of the thematic content of a collection of documents-a task that is difficult to accomplish using only keyword search. The proposed model can learn different types of concept graph structures and is capable of utilizing partial prior knowledge about graph structure as well as labeled documents. We describe a generative model that is based on a stick-breaking process for graphs, and a Markov Chain Monte Carlo inference procedure. Experiments on simulated data show that the model can recover known graph structure when learning in both unsupervised and semi-supervised modes. We also show that the proposed model is competitive in terms of empirical log likelihood with existing structure-based topic models (such as hPAM and hLDA) on real-world text data sets. Finally, we illustrate the application of the model to the problem of updating Wikipedia category graphs.',\n",
       "  'id': '3963',\n",
       "  'title': 'Learning concept graphs from text with stick-breaking priors',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A challenging problem in estimating high-dimensional graphical models is to choose the regularization parameter in a data-dependent way. The standard techniques include $K$-fold cross-validation ($K$-CV), Akaike information criterion (AIC), and Bayesian information criterion (BIC). Though these methods work well for low-dimensional problems, they are not suitable in high dimensional settings. In this paper, we present StARS: a new stability-based method for choosing the regularization parameter in high dimensional inference for undirected graphs. The method has a clear interpretation: we use the least amount of regularization that simultaneously makes a graph sparse and replicable under random sampling. This interpretation requires essentially no conditions. Under mild conditions, we show that StARS is partially sparsistent in terms of graph estimation: i.e. with high probability, all the true edges will be included in the selected model even when the graph size asymptotically increases with the sample size. Empirically, the performance of StARS is compared with the state-of-the-art model selection procedures, including $K$-CV, AIC, and BIC, on both synthetic data and a real microarray dataset. StARS outperforms all competing procedures.',\n",
       "  'id': '3966',\n",
       "  'title': 'Stability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study worst-case bounds on the quality of any fixed point assignment of the max-product algorithm for Markov Random Fields (MRF). We start proving a bound   independent of the MRF structure and parameters. Afterwards, we show how this bound can be improved for MRFs with particular structures such as bipartite graphs or grids.  Our results provide interesting insight into the behavior of max-product. For example, we prove that max-product provides very good results (at least 90% of the optimal) on MRFs  with large variable-disjoint cycles (MRFs in which all cycles are variable-disjoint, namely that they do not share any edge and in which each cycle contains at least 20 variables).',\n",
       "  'id': '3978',\n",
       "  'title': 'Worst-case bounds on the quality of max-product fixed-points',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Many statistical $M$-estimators are based on convex optimization problems formed by the weighted sum of a loss function with a norm-based regularizer.  We analyze the convergence rates of first-order gradient methods for solving such problems within a high-dimensional framework that allows the data dimension $d$ to grow with (and possibly exceed) the sample size $n$.  This high-dimensional structure precludes the usual global assumptions---namely, strong convexity and smoothness conditions---that underlie classical optimization analysis.  We define appropriately restricted versions of these conditions, and show that they are satisfied with high probability for various statistical models.  Under these conditions, our theory guarantees that Nesterov's first-order method~\\\\cite{Nesterov07} has a globally geometric rate of convergence up to the statistical precision of the model, meaning the typical Euclidean distance between the true unknown parameter $\\\\theta^*$ and the optimal solution $\\\\widehat{\\\\theta}$.  This globally linear rate is substantially faster than previous analyses of global convergence for specific methods that yielded only sublinear rates.  Our analysis applies to a wide range of $M$-estimators and statistical models, including sparse linear regression using Lasso ($\\\\ell_1$-regularized regression), group Lasso, block sparsity, and low-rank matrix recovery using nuclear norm regularization.  Overall, this result reveals an interesting connection between statistical precision and computational efficiency in high-dimensional estimation.\",\n",
       "  'id': '3984',\n",
       "  'title': 'Fast global convergence rates of gradient methods for high-dimensional statistical recovery',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a fast online solver for large scale maximum-flow problems as they occur in portfolio optimization, inventory management, computer vision, and logistics. Our algorithm solves an integer linear program in an online fashion. It exploits total unimodularity of the constraint matrix and a Lagrangian relaxation to solve the problem as a convex online game. The algorithm generates approximate solutions of max-flow problems by performing stochastic gradient descent on a set of flows. We apply the algorithm to optimize tier arrangement of over 80 Million web pages on a layered set of caches to serve an incoming query stream optimally. We provide an empirical demonstration of the effectiveness of our method on real query-pages data.',\n",
       "  'id': '3986',\n",
       "  'title': 'Optimal Web-Scale Tiering as a Flow Problem',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Feature selection is an important component of many machine learning applications. Especially in many bioinformatics tasks, efficient and robust feature selection methods are desired to extract meaningful features and eliminate noisy ones. In this paper, we propose a new robust feature selection method with emphasizing joint ?2,1-norm minimization on both loss function and regularization. The ?2,1-norm based loss function is robust to outliers in data points and the ?2,1-norm regularization selects features across all data points with joint sparsity. An efficient algorithm is introduced with proved convergence. Our regression based objective makes the feature selection process more efficient. Our method has been applied into both genomic and proteomic biomarkers discovery. Extensive empirical studies were performed on six data sets to demonstrate the effectiveness of our feature selection method.',\n",
       "  'id': '3988',\n",
       "  'title': 'Efficient and Robust Feature Selection via Joint ?2,1-Norms Minimization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Applications of Brain-Machine-Interfaces typically estimate user intent based on biological signals that are under voluntary control. For example, we might want to estimate how a patient with a paralyzed arm wants to move based on residual muscle activity. To solve such problems it is necessary to integrate obtained information over time. To do so, state of the art approaches typically use a probabilistic model of how the state, e.g. position and velocity of the arm, evolves over time ? a so-called trajectory model. We wanted to further develop this approach using two intuitive insights: (1) At any given point of time there may be a small set of likely movement targets, potentially identified by the location of objects in the workspace or by gaze information from the user. (2) The user may want to produce movements at varying speeds. We thus use a generative model with a trajectory model incorporating these insights. Approximate inference on that generative model is implemented using a mixture of extended Kalman filters. We find that the resulting algorithm allows us to decode arm movements dramatically better than when we use a trajectory model with linear dynamics.',\n",
       "  'id': '3989',\n",
       "  'title': 'Mixture of time-warped trajectory models for movement decoding',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose an algorithm to perform multitask learning where each task has potentially distinct label sets and label correspondences are not readily available. This is in contrast with existing methods which either assume that the label sets shared by different tasks are the same or that there exists a label mapping oracle. Our method directly maximizes the mutual information among the labels, and we show that the resulting objective function can be efficiently optimized using existing algorithms. Our proposed approach has a direct application for data integration with different label spaces for the purpose of classification, such as integrating Yahoo! and DMOZ web directories.',\n",
       "  'id': '3990',\n",
       "  'title': 'Multitask Learning without Label Correspondences',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider reinforcement learning in partially observable domains where the agent can query an expert for demonstrations. Our nonparametric Bayesian approach combines model knowledge, inferred from expert information and independent exploration, with policy knowledge inferred from expert trajectories. We introduce priors that bias the agent towards models with both simple representations and simple policies, resulting in improved policy and model learning.',\n",
       "  'id': '3992',\n",
       "  'title': 'Nonparametric Bayesian Policy Priors for Reinforcement Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider multivariate regression problems involving high-dimensional predictor and response spaces. To efficiently address such problems, we propose a variable selection method, Multivariate Group Orthogonal Matching Pursuit, which extends the standard Orthogonal Matching Pursuit technique to account for arbitrary sparsity patterns induced by domain-specific groupings over both input and output variables, while also taking advantage of the correlation that may exist between the multiple outputs. We illustrate the utility of this framework for inferring causal relationships over a collection of high-dimensional time series variables. When applied to time-evolving social media content, our models yield a new family of causality-based influence measures that may be seen as an alternative to PageRank. Theoretical guarantees, extensive simulations and empirical studies confirm the generality and value of our framework.',\n",
       "  'id': '3993',\n",
       "  'title': 'Block Variable Selection in Multivariate Regression and High-dimensional Causal Inference',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We describe an accelerated hardware neuron being capable of emulating the adap-tive exponential integrate-and-fire neuron model. Firing patterns of the membrane stimulated by a step current are analyzed in transistor level simulation and in silicon on a prototype chip. The neuron is destined to be the hardware neuron of a highly integrated wafer-scale system reaching out for new computational paradigms and opening new experimentation possibilities. As the neuron is dedicated as a universal device for neuroscientific experiments, the focus lays on parameterizability and reproduction of the analytical model.',\n",
       "  'id': '3995',\n",
       "  'title': 'A VLSI Implementation of the Adaptive Exponential Integrate-and-Fire Neuron Model',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a simple and effective approach to learning tractable conditional random fields with structure that depends on the evidence. Our approach retains the advantages of tractable discriminative models, namely efficient exact inference and exact parameter learning. At the same time, our algorithm does not suffer a large expressive power penalty inherent to fixed tractable structures. On real-life relational datasets, our approach matches or exceeds state of the art accuracy of the dense models, and at the same time provides an order of magnitude speedup',\n",
       "  'id': '4002',\n",
       "  'title': 'Evidence-Specific Structures for Rich Tractable CRFs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Modelling camera shake as a space-invariant convolution simplifies the problem of removing camera shake, but often insufficiently models actual motion blur such as those due to camera rotation and movements outside the sensor plane or when objects in the scene have different distances to the camera. In order to overcome such limitations we contribute threefold: (i) we introduce a taxonomy of camera shakes, (ii) we show how to combine a recently introduced framework for space-variant filtering based on overlap-add from Hirsch et al.~and a fast algorithm for single image blind deconvolution for space-invariant filters from Cho and Lee to introduce a method for blind deconvolution for space-variant blur. And (iii), we present an experimental setup for evaluation that allows us to take images with real camera shake while at the same time record the space-variant point spread function corresponding to that blur. Finally, we demonstrate that our method is able to deblur images degraded by spatially-varying blur originating from real camera shake.',\n",
       "  'id': '4007',\n",
       "  'title': 'Space-Variant Single-Image Blind Deconvolution for Removing Camera Shake',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Arithmetic circuits (ACs) exploit context-specific independence and determinism to allow exact inference even in networks with high treewidth. In this paper, we introduce the first ever approximate inference methods using ACs, for domains where exact inference remains intractable. We propose and evaluate a variety of techniques based on exact compilation, forward sampling, AC structure learning, Markov network parameter learning, variational inference, and Gibbs sampling. In experiments on eight challenging real-world domains, we find that the methods based on sampling and learning work best: one such method (AC2-F) is faster and usually more accurate than loopy belief propagation, mean field, and Gibbs sampling; another (AC2-G) has a running time similar to Gibbs sampling but is consistently more accurate than all baselines.',\n",
       "  'id': '4011',\n",
       "  'title': 'Approximate Inference by Compilation to Arithmetic Circuits',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a general framework to online learning for   classification problems with time-varying potential functions in the   adversarial setting. This framework allows to design and prove   relative mistake bounds for any generic loss function. The mistake   bounds can be specialized for the hinge loss, allowing to recover   and improve the bounds of known online classification   algorithms. By optimizing the general bound we derive a new online   classification algorithm, called NAROW, that hybridly uses adaptive- and fixed- second order   information. We analyze the properties of the algorithm and   illustrate its performance using synthetic dataset.',\n",
       "  'id': '4017',\n",
       "  'title': 'New Adaptive Algorithms for Online Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a novel approach to inference in conditionally Gaussian continuous time stochastic processes, where the latent process is a Markovian jump process. We first consider the case of jump-diffusion processes, where the drift of a linear stochastic differential equation can jump at arbitrary time points. We derive partial differential equations for exact inference and present a very efficient mean field approximation. By introducing a novel lower bound on the free energy, we then generalise our approach to Gaussian processes with arbitrary covariance, such as the non-Markovian RBF covariance. We present results on both simulated and real data, showing that the approach is very accurate in capturing latent dynamics and can be useful in a number of real data modelling tasks.',\n",
       "  'id': '4023',\n",
       "  'title': 'Approximate inference in continuous time Gaussian-Jump processes',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study a setting in which Poisson processes generate sequences of decision-making events. The optimization goal is allowed to depend on the rate of decision outcomes; the rate may depend on a potentially long backlog of events and decisions. We model the problem as a Poisson process with a throttling policy that enforces a data-dependent rate limit and reduce the learning problem to a convex optimization problem that can be solved efficiently. This problem setting matches applications in which damage caused by an attacker grows as a function of the rate of unsuppressed hostile events. We report on experiments on abuse detection for an email service.',\n",
       "  'id': '4025',\n",
       "  'title': 'Throttling Poisson Processes',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"This paper introduces a Monte-Carlo algorithm for online planning in large POMDPs. The algorithm combines a Monte-Carlo update of the agent's belief state with a Monte-Carlo tree search from the current belief state. The new algorithm, POMCP, has two important properties. First, Monte-Carlo sampling is used to break the curse of dimensionality both during belief state updates and during planning. Second, only a black box simulator of the POMDP is required, rather than explicit probability distributions. These properties enable POMCP to plan effectively in significantly larger POMDPs than has previously been possible. We demonstrate its effectiveness in three large POMDPs. We scale up a well-known benchmark problem, Rocksample, by several orders of magnitude. We also introduce two challenging new POMDPs: 10x10 Battleship and Partially Observable PacMan, with approximately 10^18 and 10^56 states respectively. Our Monte-Carlo planning algorithm achieved a high level of performance with no prior knowledge, and was also able to exploit simple domain knowledge to achieve better results with less search. POMCP is the first general purpose planner to achieve high performance in such large and unfactored POMDPs.\",\n",
       "  'id': '4031',\n",
       "  'title': 'Monte-Carlo Planning in Large POMDPs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Since the discovery of sophisticated fully polynomial randomized algorithms for a range of #P problems (Karzanov et al., 1991; Jerrum et al., 2001; Wilson, 2004), theoretical work on approximate inference in combinatorial spaces has focused on Markov chain Monte Carlo methods.  Despite their strong theoretical guarantees, the slow running time of many of these randomized algorithms and the restrictive assumptions on the potentials have hindered the applicability of these algorithms to machine learning.  Because of this, in applications to combinatorial spaces simple exact models are often preferred to more complex models that require approximate inference (Siepel et al., 2004).   Variational inference would appear to provide an appealing alternative, given the success of variational methods for graphical models (Wainwright et al., 2008); unfortunately, however, it is not obvious how to develop variational approximations for combinatorial objects such as matchings, partial orders, plane partitions and sequence alignments.   We propose a new framework that extends variational inference to a wide range of combinatorial spaces.  Our method is based on a simple assumption: the existence of a tractable measure factorization, which we show holds in many examples. Simulations on a range of matching models show that the algorithm is more general and empirically faster than a popular fully polynomial randomized algorithm.   We also apply the framework to the problem of multiple alignment of protein sequences, obtaining state-of-the-art results on the BAliBASE dataset (Thompson et al., 1999).',\n",
       "  'id': '4036',\n",
       "  'title': 'Variational Inference over Combinatorial Spaces',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Activity of a neuron, even in the early sensory areas, is not simply a function of its local receptive field or tuning properties, but depends on global context of the stimulus, as well as the neural context. This suggests the activity of the surrounding neurons and global brain states can exert considerable influence on the activity of a neuron. In this paper we implemented an L1 regularized point process model to assess the contribution of multiple factors to the firing rate of many individual units recorded simultaneously from V1 with a 96-electrode Utah\" array. We found that the spikes of surrounding neurons indeed provide strong predictions of a neuron\\'s response, in addition to the neuron\\'s receptive field transfer function. We also found that the same spikes could be accounted for with the local field potentials, a surrogate measure of global network states. This work shows that accounting for network fluctuations can improve estimates of single trial firing rate and stimulus-response transfer functions.\"',\n",
       "  'id': '4050',\n",
       "  'title': 'Accounting for network effects in neuronal responses using L1 regularized point process models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Energy disaggregation is the task of taking a whole-home energy signal and separating it into its component appliances. Studies have shown that having device-level energy information can cause users to conserve significant amounts of energy, but current electricity meters only report whole-home data. Thus, developing algorithmic methods for disaggregation presents a key technical challenge in the effort to maximize energy conservation. In this paper, we examine a large scale energy disaggregation task, and apply a novel extension of sparse coding to this problem. In particular, we develop a method, based upon structured prediction, for discriminatively training sparse coding algorithms specifically to maximize disaggregation performance. We show that this significantly improves the performance of sparse coding algorithms on the energy task and illustrate how these disaggregation results can provide useful information about energy usage.',\n",
       "  'id': '4054',\n",
       "  'title': 'Energy Disaggregation via Discriminative Sparse Coding',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Matching functional brain regions across individuals is a challenging task, largely due to the variability in their location and extent. It is particularly difficult, but highly relevant, for patients with pathologies such as brain tumors, which can cause substantial reorganization of functional systems. In such cases spatial registration based on anatomical data is only of limited value if the goal is to establish correspondences of functional areas among different individuals, or to localize potentially displaced active regions. Rather than rely on spatial alignment, we propose to perform registration in an alternative space whose geometry is governed by the functional interaction patterns in the brain. We first embed each brain into a functional map that reflects connectivity patterns during a fMRI experiment. The resulting functional maps are then registered, and the obtained correspondences are propagated back to the two brains. In application to a language fMRI experiment, our preliminary results suggest that the proposed method yields improved functional correspondences across subjects. This advantage is pronounced for subjects with tumors that affect the language areas and thus cause spatial reorganization of the functional regions.',\n",
       "  'id': '4059',\n",
       "  'title': 'Functional Geometry Alignment and Localization of Brain Areas',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Many data are naturally modeled by an unobserved hierarchical structure. In this paper we propose a flexible nonparametric prior over unknown data hierarchies. The approach uses nested stick-breaking processes to allow for trees of unbounded width and depth, where data can live at any node and are infinitely exchangeable. One can view our model as providing infinite mixtures where the components have a dependency structure corresponding to an evolutionary diffusion down a tree. By using a stick-breaking approach, we can apply Markov chain Monte Carlo methods based on slice sampling to perform Bayesian inference and simulate from the posterior distribution on trees. We apply our method to hierarchical clustering of images and topic modeling of text data.',\n",
       "  'id': '4108',\n",
       "  'title': 'Tree-Structured Stick Breaking for Hierarchical Data',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study the application of a strongly non-linear generative model to image patches. As in standard approaches such as Sparse Coding or Independent Component Analysis, the model assumes a sparse prior with independent hidden variables. However, in the place where standard approaches use the sum to combine basis functions we use the maximum. To derive tractable approximations for parameter estimation we apply a novel approach based on variational Expectation Maximization. The derived learning algorithm can be applied to large-scale problems with hundreds of observed and hidden variables. Furthermore, we can infer all model parameters including observation noise and the degree of sparseness. In applications to image patches we find that Gabor-like basis functions are obtained. Gabor-like functions are thus not a feature exclusive to approaches assuming linear superposition. Quantitatively, the inferred basis functions show a large diversity of shapes with many strongly elongated and many circular symmetric functions. The distribution of basis function shapes reflects properties of simple cell receptive fields that are not reproduced by standard linear approaches. In the study of natural image statistics, the implications of using different superposition assumptions have so far not been investigated systematically because models with strong non-linearities have been found analytically and computationally challenging. The presented algorithm represents the first large-scale application of such an approach.',\n",
       "  'id': '4132',\n",
       "  'title': 'The Maximal Causes of Natural Scenes are Edge Filters',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study the problem of learning a sparse linear regression vector under additional conditions on the structure of its sparsity pattern. We present a family of convex penalty functions, which encode this prior knowledge by means of a set of constraints on the absolute values of the regression coefficients. This family subsumes the $\\\\ell_1$ norm and is flexible enough to include different models of sparsity patterns, which are of practical and theoretical importance. We establish some important properties of these functions and discuss some examples where they can be computed explicitly. Moreover, we present a convergent optimization algorithm for solving regularized least squares with these penalty functions. Numerical simulations highlight the benefit of structured sparsity and the advantage offered by our approach over the Lasso and other related methods.',\n",
       "  'id': '4137',\n",
       "  'title': 'A Family of Penalty Functions for Structured Sparsity',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We combine random forest (RF) and conditional random field (CRF) into a new computational framework, called random forest random field (RF)^2. Inference of (RF)^2 uses the Swendsen-Wang cut algorithm, characterized by Metropolis-Hastings jumps. A jump from one state to another depends on the ratio of the proposal distributions, and on the ratio of the posterior distributions of the two states. Prior work typically resorts to a parametric estimation of these four distributions, and then computes their ratio. Our key idea is to instead directly estimate these ratios using RF. RF collects in leaf nodes of each decision tree the class histograms of training examples. We use these class histograms for a non-parametric estimation of the distribution ratios. We derive the theoretical error bounds of a two-class (RF)^2. (RF)^2 is applied to a challenging task of multiclass object recognition and segmentation over a random field of input image regions. In our empirical evaluation, we use only the visual information provided by image regions (e.g., color, texture, spatial layout), whereas the competing methods additionally use higher-level cues about the horizon location and 3D layout of surfaces in the scene. Nevertheless, (RF)^2 outperforms the state of the art on benchmark datasets, in terms of accuracy and computation time.',\n",
       "  'id': '4140',\n",
       "  'title': '(RF)^2 -- Random Forest Random Field',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We discuss an online learning framework in which the agent is allowed to say ``I don't know'' as well as making incorrect predictions on given examples. We analyze the trade off between saying ``I don't know'' and making mistakes. If the number of don't know predictions is forced to be zero, the model reduces to the well-known mistake-bound model introduced by Littlestone [Lit88]. On the other hand, if no mistakes are allowed, the model reduces to KWIK framework introduced by Li et. al. [LLW08]. We propose a general, though inefficient, algorithm for general finite concept classes that minimizes the number of don't-know predictions if a certain number of mistakes are allowed. We then present specific polynomial-time algorithms for the concept classes of monotone disjunctions and linear separators.\",\n",
       "  'id': '4142',\n",
       "  'title': \"Trading off Mistakes and Don't-Know Predictions\",\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Upstream supervised topic models have been widely used for complicated scene understanding. However, existing maximum likelihood estimation (MLE) schemes can make the prediction model learning independent of latent topic discovery and result in an imbalanced prediction rule for scene classification. This paper presents a joint max-margin and max-likelihood learning method for upstream scene understanding models, in which latent topic discovery and prediction model estimation are closely coupled and well-balanced. The optimization problem is efficiently solved with a variational EM procedure, which iteratively solves an online loss-augmented SVM. We demonstrate the advantages of the large-margin approach on both an 8-category sports dataset and the 67-class MIT indoor scene dataset for scene categorization.',\n",
       "  'id': '4149',\n",
       "  'title': 'Large Margin Learning of Upstream Scene Understanding Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a fast algorithm for the detection of multiple change-points when each is frequently shared by members of a set of co-occurring one-dimensional signals. We give conditions on consistency of the method when the number of signals increases, and provide empirical evidence to support the consistency results.',\n",
       "  'id': '4157',\n",
       "  'title': 'Fast detection of multiple change-points shared by many signals using group LARS',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In this paper we consider the fundamental problem of semi-supervised kernel function learning. We propose a general regularized framework for learning a kernel matrix, and then demonstrate an equivalence between our proposed kernel matrix learning framework and a general linear transformation learning problem. Our result shows that the learned kernel matrices parameterize a linear transformation kernel function and can be applied inductively to new data points. Furthermore, our result gives a constructive method for kernelizing most existing Mahalanobis metric learning formulations. To make our results practical for large-scale data, we modify our framework to limit the number of parameters in the optimization process. We also consider the problem of kernelized inductive dimensionality reduction in the semi-supervised setting. We introduce a novel method for this problem by considering a special case of our general kernel learning framework where we select the trace norm function as the regularizer. We empirically demonstrate that our framework learns useful kernel functions, improving the $k$-NN classification accuracy significantly in a variety of domains. Furthermore, our kernelized dimensionality reduction technique significantly reduces the dimensionality of the feature space while achieving competitive classification accuracies.',\n",
       "  'id': '4159',\n",
       "  'title': 'Inductive Regularized Learning of Kernel Functions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a novel method for multitask learning (MTL) based on {\\\\it manifold regularization}: assume that all task parameters lie on a manifold. This is the generalization of a common assumption made in the existing literature: task parameters share a common {\\\\it linear} subspace. One proposed method uses the projection distance from the manifold to regularize the task parameters. The manifold structure and the task parameters are learned using an alternating optimization framework. When the manifold structure is fixed, our method decomposes across tasks which can be learnt independently. An approximation of the manifold regularization scheme is presented that preserves the convexity of the single task learning problem, and makes the proposed MTL framework efficient and easy to implement. We show the efficacy of our method on several datasets.',\n",
       "  'id': '4163',\n",
       "  'title': 'Learning Multiple Tasks using Manifold Regularization',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Computing a {\\\\em maximum a posteriori} (MAP) assignment in graphical models is a crucial inference problem for many practical applications. Several provably convergent approaches have been successfully developed using linear programming (LP) relaxation of the MAP problem. We present an alternative approach, which transforms the MAP problem into that of inference in a finite mixture of simple Bayes nets. We then derive the Expectation Maximization (EM) algorithm for this mixture that also monotonically increases a lower bound on the MAP assignment until convergence. The update equations for the EM algorithm are remarkably simple, both conceptually and computationally, and can be implemented using a graph-based message passing paradigm similar to max-product computation. We experiment on the real-world protein design dataset and show that EM's convergence rate is significantly higher than the previous LP relaxation based approach MPLP. EM achieves a solution quality within $95$\\\\% of optimal for most instances and is often an order-of-magnitude faster than MPLP.\",\n",
       "  'id': '4165',\n",
       "  'title': 'MAP Estimation for Graphical Models by Likelihood Maximization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider structured multi-armed bandit tasks in which the agent is guided by prior structural knowledge that can be exploited to efficiently select the optimal arm(s) in situations where the number of arms is large, or even infinite. We pro- pose a new optimistic, UCB-like, algorithm for non-linearly parameterized bandit problems using the Generalized Linear Model (GLM) framework. We analyze the regret of the proposed algorithm, termed GLM-UCB, obtaining results similar to those recently proved in the literature for the linear regression case. The analysis also highlights a key difficulty of the non-linear case which is solved in GLM-UCB by focusing on the reward space rather than on the parameter space. Moreover, as the actual efficiency of current parameterized bandit algorithms is often deceiving in practice, we provide an asymptotic argument leading to significantly faster convergence. Simulation studies on real data sets illustrate the performance and the robustness of the proposed GLM-UCB approach.',\n",
       "  'id': '4166',\n",
       "  'title': 'Parametric Bandits: The Generalized Linear Case',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Optimal control entails combining probabilities and utilities. However, for most practical problems probability densities can be represented only approximately. Choosing an approximation requires balancing the benefits of an accurate approximation against the costs of computing it. We propose a variational framework for achieving this balance and apply it to the problem of how a population code should optimally represent a distribution under resource constraints. The essence of our analysis is the conjecture that population codes are organized to maximize a lower bound on the log expected utility. This theory can account for a plethora of experimental data, including the reward-modulation of sensory receptive fields.',\n",
       "  'id': '4167',\n",
       "  'title': 'The Neural Costs of Optimal Control',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Straightforward application of Deep Belief Nets (DBNs) to acoustic modeling produces a rich distributed representation of speech data that is useful for recognition and yields impressive results on the speaker-independent TIMIT phone recognition task. However, the first-layer Gaussian-Bernoulli Restricted Boltzmann Machine (GRBM) has an important limitation, shared with mixtures of diagonal-covariance Gaussians: GRBMs treat different components of the acoustic input vector as conditionally independent given the hidden state. The mean-covariance restricted Boltzmann machine (mcRBM), first introduced for modeling natural images, is a much more representationally efficient and powerful way of modeling the covariance structure of speech data. Every configuration of the precision units of the mcRBM specifies a different precision matrix for the conditional distribution over the acoustic space. In this work, we use the mcRBM to learn features of speech data that serve as input into a standard DBN. The mcRBM features combined with DBNs allow us to achieve a phone error rate of 20.5\\\\%, which is superior to all published results on speaker-independent TIMIT to date.',\n",
       "  'id': '4169',\n",
       "  'title': 'Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose an algorithm for simultaneously estimating state transitions among neural states, the number of neural states, and nonstationary firing rates using a switching state space model (SSSM).  This model enables us to detect state transitions based not only on the discontinuous changes of mean firing rates but also on discontinuous changes in temporal profiles of firing rates, e.g., temporal correlation.  We derive a variational Bayes algorithm for a non-Gaussian SSSM whose non-Gaussian property is caused by binary spike events.  Synthetic data analysis reveals the high performance of our algorithm in estimating state transitions, the number of neural states, and nonstationary firing rates compared to previous methods.  We also analyze neural data recorded from the medial temporal area.  The statistically detected neural states probably coincide with transient and sustained states, which have been detected heuristically. Estimated parameters suggest that our algorithm detects the state transition based on discontinuous change in the temporal correlation of firing rates, which transitions previous methods cannot detect.  This result suggests the advantage of our algorithm in real-data analysis.',\n",
       "  'id': '4172',\n",
       "  'title': 'Switching state space model for simultaneously estimating state transitions and nonstationary firing rates',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a new nonparametric learning method based on multivariate dyadic regression trees (MDRTs).  Unlike traditional dyadic decision trees (DDTs) or classification and regression trees (CARTs), MDRTs are constructed using penalized empirical risk minimization with a novel sparsity-inducing penalty.  Theoretically, we show that MDRTs can simultaneously adapt to the unknown sparsity and smoothness of the true regression functions, and achieve the nearly optimal rates of convergence (in a minimax sense) for the class of $(\\\\alpha, C)$-smooth functions. Empirically, MDRTs can simultaneously conduct function estimation and variable selection in high dimensions. To make MDRTs applicable  for large-scale learning problems, we propose a greedy heuristics. The superior performance of MDRTs are demonstrated on both synthetic and real datasets.',\n",
       "  'id': '4178',\n",
       "  'title': 'Multivariate Dyadic Regression Trees for Sparse Learning Problems',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We address the question of how the approximation error/Bellman residual at each iteration of the Approximate Policy/Value Iteration algorithms influences the quality of the resulted policy. We quantify the performance loss as the Lp norm of the approximation error/Bellman residual at each iteration. Moreover, we show that the performance loss depends on the expectation of the squared Radon-Nikodym derivative of a certain distribution rather than its supremum -- as opposed to what has been suggested by the previous results.  Also our results indicate that the contribution of the approximation/Bellman error to the performance loss is more prominent in the later iterations of API/AVI, and the effect of an error term in the earlier iterations decays exponentially fast.',\n",
       "  'id': '4181',\n",
       "  'title': 'Error Propagation for Approximate Policy and Value Iteration',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the online binary classification problem, where we are given m classifiers. At each stage, the classifiers map the input to the probability that the input belongs to the positive class. An online classification meta-algorithm is an algorithm that combines the outputs of the classifiers in order to attain a certain goal, without having prior knowledge on the form and statistics of the input, and without prior knowledge on the performance of the given classifiers. In this paper, we use sensitivity and  specificity as the performance metrics of the meta-algorithm. In particular, our goal is to design an algorithm which satisfies the following two properties (asymptotically): (i) its average false positive rate (fp-rate) is under some given threshold, and (ii) its average true positive rate (tp-rate) is not worse than the tp-rate of the best convex combination of the m given classifiers that satisfies fp-rate constraint, in hindsight. We show that this problem is in fact a special case of the regret minimization problem with constraints, and therefore the above goal is not attainable. Hence, we pose a relaxed goal and propose a corresponding practical online learning meta-algorithm that attains it. In the case of two classifiers, we show that this algorithm takes a very simple form. To our best knowledge, this is the first algorithm that addresses the problem of the average tp-rate maximization under average fp-rate constraints in the online setting.',\n",
       "  'id': '3896',\n",
       "  'title': 'Online Classification with Specificity Constraints',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Probabilistic graphical models use local factors to represent dependence among sets of variables. For many problem domains, for instance climatology and epidemiology, in addition to local dependencies, we may also wish to model heavy-tailed statistics, where extreme deviations should not be treated as outliers. Specifying such distributions using graphical models for probability density functions (PDFs) generally lead to intractable inference and learning. Cumulative distribution networks (CDNs) provide a means to tractably specify multivariate heavy-tailed models as a product of cumulative distribution functions (CDFs). Currently, algorithms for inference and learning, which correspond to computing mixed derivatives, are exact only for tree-structured graphs. For graphs of arbitrary topology, an efficient algorithm is needed that takes advantage of the sparse structure of the model, unlike symbolic differentiation programs such as Mathematica and D* that do not. We present an algorithm for recursively decomposing the computation of derivatives for CDNs of arbitrary topology, where the decomposition is naturally described using junction trees. We compare the performance of the resulting algorithm to Mathematica and D*, and we apply our method to learning models for rainfall and H1N1 data, where we show that CDNs with cycles are able to provide a significantly better fits to the data as compared to tree-structured and unstructured CDNs and other heavy-tailed multivariate distributions such as the multivariate copula and logistic models.',\n",
       "  'id': '3899',\n",
       "  'title': 'Exact inference and learning for cumulative distribution functions on loopy graphs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We define a data dependent permutation complexity for a hypothesis set \\\\math{\\\\hset}, which is similar to a Rademacher complexity or maximum discrepancy. The permutation complexity is based like the maximum discrepancy on (dependent) sampling. We prove a uniform bound on the generalization error, as well as a concentration result which means that the permutation estimate can be efficiently estimated.',\n",
       "  'id': '3908',\n",
       "  'title': 'Permutation Complexity Bound on Out-Sample Error',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a model that describes the structure in the responses of different brain areas to a set of stimuli in terms of stimulus categories\" (clusters of stimuli) and \"functional units\" (clusters of voxels). We assume that voxels within a unit respond similarly to all stimuli from the same category, and design a nonparametric hierarchical model to capture inter-subject variability among the units. The model explicitly captures the relationship between brain activations and fMRI time courses. A variational inference algorithm derived based on the model can learn categories, units, and a set of unit-category activation probabilities from data. When applied to data from an fMRI study of object recognition, the method finds meaningful and consistent clusterings of stimuli into categories and voxels into units.\"',\n",
       "  'id': '3912',\n",
       "  'title': 'Categories and Functional Units: An Infinite Hierarchical Model for Brain Activations',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Determining whether someone is talking has applications in many areas such as speech recognition, speaker diarization, social robotics, facial expression recognition, and human computer interaction.  One popular approach to this problem is audio-visual synchrony detection. A candidate speaker is deemed to be talking if the visual signal around that speaker correlates with the auditory signal.  Here we show that with the proper visual features (in this case movements of various facial muscle groups), a very accurate detector of speech can be created that does not use the audio signal at all.  Further we show that this person independent visual-only detector can be used to train very accurate audio-based person dependent voice models.  The voice model has the advantage of being able to identify when a particular person is speaking even when they are not visible to the camera (e.g. in the case of a mobile robot).  Moreover, we show that a simple sensory fusion scheme between the auditory and visual models improves performance on the task of talking detection.  The work here provides dramatic evidence about the efficacy of two very different approaches to multimodal speech detection on a challenging database.',\n",
       "  'id': '3915',\n",
       "  'title': 'An Alternative to Low-level-Sychrony-Based Methods for Speech Detection',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Multiple-Instance learning has been long known as a hard non-convex problem.\\n In this work, we propose an approach that recasts it as a convex likelihood ratio\\n estimation problem. Firstly, the constraint in multiple-instance learning is reformulated\\n into a convex constraint on the likelihood ratio. Then we show that a joint\\n estimation of a likelihood ratio function and the likelihood on training instances\\n can be learned convexly. Theoretically, we prove a quantitative relationship between\\n the risk estimated under the 0-1 classification loss, and under a loss function\\n for likelihood ratio estimation. It is shown that our likelihood ratio estimation is\\n generally a good surrogate for the 0-1 loss, and separates positive and negative\\n instances well. However with the joint estimation it tends to underestimate the\\n likelihood of an example to be positive. We propose to use these likelihood ratio\\n estimates as features, and learn a linear combination on them to classify the bags.\\n Experiments on synthetic and real datasets show the superiority of the approach.',\n",
       "  'id': '3926',\n",
       "  'title': 'Convex Multiple-Instance Learning by Estimating Likelihood Ratio',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We extend logistic regression by using t-exponential families which were introduced recently in statistical physics. This gives rise to a regularized risk minimization problem with a non-convex loss  function. An efficient block coordinate descent optimization  scheme can be derived for estimating the parameters. Because of the  nature of the loss function, our algorithm is tolerant to label noise. Furthermore, unlike other algorithms which employ non-convex   loss functions, our algorithm is fairly robust to the choice of  initial values. We verify both these observations empirically on a  number of synthetic and real datasets.',\n",
       "  'id': '3928',\n",
       "  'title': 't-logistic regression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the tree structured group Lasso where the structure over the features can be represented as a tree with leaf nodes as features and internal nodes as clusters of the features. The structured regularization with a pre-defined tree structure is based on a group-Lasso penalty, where one group is defined for each node in the tree. Such a regularization can help uncover the structured sparsity, which is desirable for applications with some meaningful tree structures on the features. However, the tree structured group Lasso is challenging to solve due to the complex regularization. In this paper, we develop an efficient algorithm for the tree structured group Lasso. One of the key steps in the proposed algorithm is to solve the Moreau-Yosida regularization associated with the grouped tree structure. The main technical contributions of this paper include (1) we show that the associated Moreau-Yosida regularization admits an analytical solution, and (2) we develop an efficient algorithm for determining the effective interval for the regularization parameter. Our experimental results on the AR and JAFFE face data sets demonstrate the efficiency and effectiveness of the proposed algorithm.',\n",
       "  'id': '3931',\n",
       "  'title': 'Moreau-Yosida Regularization for Grouped Tree Structure Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Robust regression and classification are often thought to require non-convex loss functions that prevent scalable, global training. However, such a view neglects the possibility of reformulated training methods that can yield practically solvable alternatives. A natural way to make a loss function more robust to outliers is to truncate loss values that exceed a maximum threshold. We demonstrate that a relaxation of this form of ``loss clipping'' can be made globally solvable and applicable to any standard loss while guaranteeing robustness against outliers. We present a generic procedure that can be applied to standard loss functions and demonstrate improved robustness in regression and classification problems.\",\n",
       "  'id': '3936',\n",
       "  'title': 'Relaxed Clipping: A Global Training Method for Robust Regression and Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In multi-instance learning, there are two kinds of prediction failure, i.e., false negative and false positive. Current research mainly focus on avoding the former. We attempt to utilize the geometric distribution of instances inside positive bags to avoid both the former and the latter. Based on kernel principal component analysis, we define a projection constraint for each positive bag to classify its constituent instances far away from the separating hyperplane while place positive instances and negative instances at opposite sides. We apply the Constrained Concave-Convex Procedure to solve the resulted problem. Empirical results demonstrate that our approach offers improved generalization performance.',\n",
       "  'id': '3941',\n",
       "  'title': 'Avoiding False Positive in Multi-Instance Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Bayesian approaches to utility elicitation typically adopt (myopic) expected value of information (EVOI) as a natural criterion for selecting queries.  However, EVOI-optimization is  usually computationally prohibitive.  In this paper, we examine EVOI optimization using \\\\emph{choice queries}, queries in which a user  is ask to select her most preferred product from a set. We show that,  under very general assumptions, the optimal choice query w.r.t.\\\\ EVOI coincides with \\\\emph{optimal recommendation set}, that is, a set maximizing expected utility of the user selection. Since recommendation set optimization is a simpler, submodular problem, this can greatly reduce the complexity of both exact and approximate (greedy) computation of optimal choice queries.  We  also examine the case where user responses to choice queries are error-prone (using both constant and follow mixed multinomial logit  noise models) and provide worst-case guarantees.   Finally we present a local search technique that works well with large outcome spaces.',\n",
       "  'id': '3943',\n",
       "  'title': 'Optimal Bayesian Recommendation Sets and Myopically Optimal Choice Query Sets',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Conventional dynamic Bayesian networks (DBNs) are based on the homogeneous Markov assumption, which is too restrictive in many practical applications. Various approaches to relax the homogeneity assumption have therefore been proposed in the last few years. The present paper aims to improve the flexibility of two recent versions of non-homogeneous DBNs, which either (i) suffer from the need for data discretization, or (ii) assume a time-invariant network structure. Allowing the network structure to be fully flexible leads to the risk of overfitting and inflated inference uncertainty though, especially in the highly topical field of systems biology, where independent measurements tend to be sparse. In the present paper we investigate three conceptually different regularization schemes based on inter-segment information sharing. We assess the performance in a comparative evaluation study based on simulated data. We compare the predicted segmentation of gene expression time series obtained during embryogenesis in Drosophila melanogaster with other state-of-the-art techniques. We conclude our evaluation with an application to synthetic biology, where the objective is to predict a known regulatory network of five genes in Saccharomyces cerevisiae.',\n",
       "  'id': '3944',\n",
       "  'title': 'Inter-time segment information sharing for non-homogeneous dynamic Bayesian networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A method for computing the rarity of latent fingerprints represented by minutiae is given. It allows determining the probability of finding a match for an evidence print in a database of n known prints. The probability of random correspondence between evidence and database is determined in three procedural steps. In the registration step the latent print is aligned by finding its core point; which is done using a procedure based on a machine learning approach based on Gaussian processes. In the evidence probability evaluation step a generative model based on Bayesian networks is used to determine the probability of the evidence; it takes into account both the dependency of each minutia on nearby minutiae and the confidence of their presence in the evidence. In the specific probability of random correspondence step the evidence probability is used to determine the probability of match among n for a given tolerance; the last evaluation is similar to the birthday correspondence probability for a specific birthday. The generative model is validated using a goodness-of-fit test evaluated with a standard database of fingerprints. The probability of random correspondence for several latent fingerprints are evaluated for varying numbers of minutiae.',\n",
       "  'id': '3945',\n",
       "  'title': 'Evaluation of Rarity of Fingerprints in Forensics',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Heavy-tailed distributions naturally occur in many real life problems. Unfortunately, it is typically not possible to compute inference in closed-form in graphical models which involve such heavy tailed distributions.   In this work, we propose a novel simple linear graphical model for  independent latent random variables, called linear characteristic model (LCM), defined in the characteristic function domain. Using stable distributions, a heavy-tailed family of distributions which is a generalization of Cauchy, L\\\\'evy and Gaussian distributions, we show for the first time, how to compute both exact and approximate inference in such a linear multivariate graphical model. LCMs are not limited to only stable distributions, in fact LCMs are always defined for any random variables (discrete, continuous or a mixture of both).   We provide a realistic problem from the field of computer networks to demonstrate the applicability of our construction. Other potential application is iterative decoding of linear channels with non-Gaussian noise.\",\n",
       "  'id': '3949',\n",
       "  'title': 'Inference with Multivariate Heavy-Tails in Linear Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We study the problem of segmenting specific white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. This is an important requirement in many Neuroimaging studies: for instance, to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images. Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. To address this problem, we endow an image segmentation algorithm with 'advice' encoding some global characteristics of the region(s) we want to extract. This is accomplished by constructing (using expert-segmented images) an epitome of a specific region - as a histogram over a bag of 'words' (e.g.,suitable feature descriptors). Now, given such a representation, the problem reduces to segmenting new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-specified histogram over features. We present combinatorial approximation algorithms to incorporate such domain specific constraints for Markov Random Field (MRF) segmentation. Making use of recent results on image co-segmentation, we derive effective solution strategies for our problem. We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm.\",\n",
       "  'id': '3955',\n",
       "  'title': 'Epitome driven 3-D Diffusion Tensor image segmentation: on extracting specific structures',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present the Copula Bayesian Network model for representing multivariate continuous distributions. Our approach builds on a novel copula-based parameterization of a conditional density that, joined with a graph that encodes independencies, offers great flexibility in modeling high-dimensional densities, while maintaining control over the form of the univariate marginals. We demonstrate the advantage of our framework for generalization over standard Bayesian networks as well as tree structured copula models for varied real-life domains that are of substantially higher dimension than those typically considered in the copula literature.',\n",
       "  'id': '3956',\n",
       "  'title': 'Copula Bayesian Networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a computationally efficient random walk on a convex body which rapidly mixes to a time-varying Gibbs distribution. In the setting of online convex optimization and repeated games, the algorithm yields low regret and presents a novel efficient method for implementing mixture forecasting strategies.',\n",
       "  'id': '3972',\n",
       "  'title': 'Random Walk Approach to Regret Minimization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Robust low-level image features have been proven to be effective representations for a variety of visual recognition tasks such as object recognition and scene classification; but pixels, or even local image patches, carry little semantic meanings. For high level visual tasks, such low-level image representations are potentially not enough. In this paper, we propose a high-level image representation, called the Object Bank, where an image is represented as a scale invariant response map of a large number of pre-trained generic object detectors, blind to the testing dataset or visual task. Leveraging on the Object Bank representation, superior performances on high level visual recognition tasks can be achieved with simple off-the-shelf classifiers such as logistic regression and linear SVM. Sparsity algorithms make our representation more efficient and scalable for large scene datasets, and reveal semantically meaningful feature patterns.',\n",
       "  'id': '4008',\n",
       "  'title': 'Object Bank: A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classification.',\n",
       "  'id': '4014',\n",
       "  'title': 'Agnostic Active Learning Without Constraints',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the following sparse signal recovery (or feature selection) problem: given a design matrix $X\\\\in \\\\mathbb{R}^{n\\\\times m}$ $(m\\\\gg n)$ and a noisy observation vector $y\\\\in \\\\mathbb{R}^{n}$ satisfying $y=X\\\\beta^*+\\\\epsilon$ where $\\\\epsilon$ is the noise vector following a Gaussian distribution $N(0,\\\\sigma^2I)$, how to recover the signal (or parameter vector) $\\\\beta^*$ when the signal is sparse?  The Dantzig selector has been proposed for sparse signal recovery with strong theoretical guarantees. In this paper, we propose a multi-stage Dantzig selector method, which iteratively refines the target signal $\\\\beta^*$. We show that if $X$ obeys a certain condition, then with a large probability the difference between the solution $\\\\hat\\\\beta$ estimated by the proposed method and the true solution $\\\\beta^*$ measured in terms of the $l_p$ norm ($p\\\\geq 1$) is bounded as \\\\begin{equation*} \\\\|\\\\hat\\\\beta-\\\\beta^*\\\\|_p\\\\leq \\\\left(C(s-N)^{1/p}\\\\sqrt{\\\\log m}+\\\\Delta\\\\right)\\\\sigma, \\\\end{equation*} $C$ is a constant, $s$ is the number of nonzero entries in $\\\\beta^*$, $\\\\Delta$ is independent of $m$ and is much smaller than the first term, and $N$ is the number of entries of $\\\\beta^*$ larger than a certain value in the order of $\\\\mathcal{O}(\\\\sigma\\\\sqrt{\\\\log m})$. The proposed method improves the estimation bound of the standard Dantzig selector approximately from $Cs^{1/p}\\\\sqrt{\\\\log m}\\\\sigma$ to $C(s-N)^{1/p}\\\\sqrt{\\\\log m}\\\\sigma$ where the value $N$ depends on the number of large entries in $\\\\beta^*$. When $N=s$, the proposed algorithm achieves the oracle solution with a high probability. In addition, with a large probability, the proposed method can select the same number of correct features under a milder condition than the Dantzig selector.',\n",
       "  'id': '4015',\n",
       "  'title': 'Multi-Stage Dantzig Selector',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'When animals repeatedly choose actions from multiple alternatives, they can allocate their choices stochastically depending on past actions and outcomes. It is commonly assumed that this ability is achieved by modifications in synaptic weights related to decision making. Choice behavior has been empirically found to follow Herrnstein?s matching law. Loewenstein &amp; Seung (2006) demonstrated that matching behavior is a steady state of learning in neural networks if the synaptic weights change proportionally to the covariance between reward and neural activities. However, their proof did not take into account the change in entire synaptic distributions. In this study, we show that matching behavior is not necessarily a steady state of the covariance-based learning rule when the synaptic strength is sufficiently strong so that the fluctuations in input from individual sensory neurons influence the net input to output neurons. This is caused by the increasing variance in the input potential due to the diffusion of synaptic weights. This effect causes an undermatching phenomenon, which has been observed in many behavioral experiments. We suggest that the synaptic diffusion effects provide a robust neural mechanism for stochastic choice behavior.',\n",
       "  'id': '4029',\n",
       "  'title': 'Effects of Synaptic Weight Diffusion on Learning in Decision Making Networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Layered models are a powerful way of describing natural scenes containing smooth surfaces that may overlap and occlude each other. For image motion estimation, such models have a long history but have not achieved the wide use or accuracy of non-layered methods. We present a new probabilistic model of optical flow in layers that addresses many of the shortcomings of previous approaches. In particular, we define a probabilistic graphical model that explicitly captures: 1) occlusions and disocclusions; 2) depth ordering of the layers; 3) temporal consistency of the layer segmentation. Additionally the optical flow in each layer is modeled by a combination of a parametric model and a smooth deviation based on an MRF with a robust spatial prior; the resulting model allows roughness in layers. Finally, a key contribution is the formulation of the layers using an image-dependent hidden field prior based on recent models for static scene segmentation. The method achieves state-of-the-art results on the Middlebury benchmark and produces meaningful scene segmentations as well as detected occlusion regions.',\n",
       "  'id': '4030',\n",
       "  'title': 'Layered image motion with explicit occlusions, temporal consistency, and depth ordering',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"In the neural-network parameter space,  an attractive field is likely to be induced by singularities. In such a singularity region, first-order gradient learning typically causes a long plateau with very little change  in the objective function value E (hence, a flat region). Therefore, it may be confused with ``attractive'' local minima. Our analysis shows that the Hessian matrix of E tends to be indefinite in the vicinity of (perturbed) singular points, suggesting a promising strategy that exploits negative curvature so as to escape from the singularity plateaus. For numerical evidence, we limit the scope to small examples (some of which are found in journal papers)  that allow us to confirm singularities and the eigenvalues of the Hessian matrix, and for which computation using a descent direction of negative curvature encounters no plateau.  Even for those small problems, no efficient methods have been previously developed that avoided plateaus.\",\n",
       "  'id': '4046',\n",
       "  'title': 'An analysis on negative curvature induced by singularity in multi-layer neural-network learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider online learning in finite stochastic Markovian environments where in each time step a new reward function is chosen by an oblivious adversary. The goal of the learning agent is to compete with the best stationary policy in terms of the total reward received. In each time step the agent observes the current state and the reward associated with the last transition, however, the agent does not observe the rewards associated with other state-action pairs. The agent is assumed to know the transition probabilities. The state of the art result for this setting is a no-regret algorithm. In this paper we propose a new learning algorithm and assuming that stationary policies mix uniformly fast, we show that after T time steps, the expected regret of the new algorithm is O(T^{2/3} (ln T)^{1/3}), giving the first rigorously proved convergence rate result for the problem.',\n",
       "  'id': '4048',\n",
       "  'title': 'Online Markov Decision Processes under Bandit Feedback',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Identifying the features of objects becomes a challenge when those features can change in their appearance. We introduce the Transformed Indian Buffet Process (tIBP), and use it to define a nonparametric Bayesian model that infers features that can transform across instantiations. We show that this model can identify features that are location invariant by modeling a previous experiment on human feature learning. However, allowing features to transform adds new kinds of ambiguity: Are two parts of an object the same feature with different transformations or two unique features? What transformations can features undergo? We present two new experiments in which we explore how people resolve these questions, showing that the tIBP model demonstrates a similar sensitivity to context to that shown by human learners when determining the invariant aspects of features.',\n",
       "  'id': '4049',\n",
       "  'title': 'Learning invariant features using the Transformed Indian Buffet Process',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Score Matching is a recently-proposed criterion for training high-dimensional density models for which maximum likelihood training is intractable. It has been applied to learning natural image statistics but has so-far been limited to simple models due to the difficulty of differentiating the loss with respect to the model parameters. We show how this differentiation can be automated with an extended version of the double-backpropagation algorithm. In addition, we introduce a regularization term for the Score Matching loss that enables its use for a broader range of problem by suppressing instabilities that occur with finite training sample sizes and quantized input values. Results are reported for image denoising and super-resolution.',\n",
       "  'id': '4060',\n",
       "  'title': 'Regularized estimation of image statistics by Score Matching',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Divisive normalization (DN) has been advocated as an effective nonlinear {\\\\em efficient coding} transform for natural sensory signals with applications in biology and engineering. In this work, we aim to establish a connection between the DN transform and the statistical properties of natural sensory signals. Our analysis is based on the use of multivariate {\\\\em t} model to capture some important statistical properties of natural sensory signals. The multivariate {\\\\em t} model justifies DN as an approximation to the transform that completely eliminates its statistical dependency. Furthermore, using the multivariate {\\\\em t} model and measuring statistical dependency with multi-information, we can precisely quantify the statistical dependency that is reduced by the DN transform. We compare this with the actual performance of the DN transform in reducing statistical dependencies of natural sensory signals. Our theoretical analysis and quantitative evaluations confirm DN as an effective efficient coding transform for natural sensory signals. On the other hand, we also observe a previously unreported phenomenon that DN may increase statistical dependencies when the size of pooling is small.',\n",
       "  'id': '4065',\n",
       "  'title': 'Divisive Normalization: Justification and Effectiveness as Efficient Coding Transform',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We tackle the fundamental problem of Bayesian active learning with noise, where we need to adaptively select from a number of expensive tests in order to identify an unknown hypothesis sampled from a known prior distribution. In the case of noise-free observations, a greedy algorithm called generalized binary search (GBS) is known to perform near-optimally. We show that if the observations are noisy, perhaps surprisingly, GBS can perform very poorly. We develop EC2, a novel, greedy active learning algorithm and prove that it is competitive with the optimal policy, thus obtaining the first competitiveness guarantees for Bayesian active learning with noisy observations. Our bounds rely on a recently discovered diminishing returns property called adaptive submodularity, generalizing the classical notion of submodular set functions to adaptive policies. Our results hold even if the tests have non?uniform cost and their noise is correlated. We also propose EffECXtive, a particularly fast approximation of EC2, and evaluate it on a Bayesian experimental design problem involving human subjects, intended to tease apart competing economic theories of how people make decisions under uncertainty.',\n",
       "  'id': '4073',\n",
       "  'title': 'Near-Optimal Bayesian Active Learning with Noisy Observations',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'How much information does a neural population convey about a stimulus? Answers to this question are known to strongly depend on the correlation of response variability in neural populations. These noise correlations, however, are essentially immeasurable as the number of parameters in a noise correlation matrix grows quadratically with population size. Here, we suggest to bypass this problem by imposing a parametric model on a noise correlation matrix. Our basic assumption is that noise correlations arise due to common inputs between neurons. On average, noise correlations will therefore reflect signal correlations, which can be measured in neural populations. We suggest an explicit parametric dependency between signal and noise correlations. We show how this dependency can be used to fill the gaps\" in noise correlations matrices using an iterative application of the Wishart distribution over positive definitive matrices. We apply our method to data from the primary somatosensory cortex of monkeys performing a two-alternative-forced choice task. We compare the discrimination thresholds read out from the population of recorded neurons with the discrimination threshold of the monkey and show that our method predicts different results than simpler, average schemes of noise correlations.\"',\n",
       "  'id': '4076',\n",
       "  'title': 'Linear readout from a neural population with partial correlation data',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We prove rates of convergence in the statistical sense for kernel-based least squares regression using a conjugate gradient algorithm, where regularization against overfitting is obtained by early stopping. This method is directly related to Kernel Partial Least Squares, a regression method that combines supervised dimensionality reduction with least squares projection. The rates depend on two key quantities: first, on the regularity of the target regression function and second, on the effective dimensionality of the data mapped into the kernel space. Lower bounds on attainable rates depending on these two quantities were established in earlier literature, and we obtain upper bounds for the considered method that match these lower bounds (up to a log factor) if  the true regression function belongs to the reproducing kernel Hilbert space. If the latter assumption is not fulfilled, we obtain similar convergence rates provided additional unlabeled data are available. The order of the learning rates in these two situations match state-of-the-art results that were recently obtained for the least squares support vector machine and for linear regularization operators.',\n",
       "  'id': '4077',\n",
       "  'title': 'Optimal learning rates for Kernel Conjugate Gradient regression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Cardiovascular disease is the leading cause of death globally, resulting in 17 million deaths each year. Despite the availability of various treatment options, existing techniques based upon conventional medical knowledge often fail to identify patients who might have benefited from more aggressive therapy. In this paper, we describe and evaluate a novel unsupervised machine learning approach for cardiac risk stratification. The key idea of our approach is to avoid specialized medical knowledge, and assess patient risk using symbolic mismatch, a new metric to assess similarity in long-term time-series activity. We hypothesize that high risk patients can be identified using symbolic mismatch, as individuals in a population with unusual long-term physiological activity. We describe related approaches that build on these ideas to provide improved medical decision making for patients who have recently suffered coronary attacks. We first describe how to compute the symbolic mismatch between pairs of long term electrocardiographic (ECG) signals. This algorithm maps the original signals into a symbolic domain, and provides a quantitative assessment of the difference between these symbolic representations of the original signals. We then show how this measure can be used with each of a one-class SVM, a nearest neighbor classifier, and hierarchical clustering to improve risk stratification. We evaluated our methods on a population of 686 cardiac patients with available long-term electrocardiographic data. In a univariate analysis, all of the methods provided a statistically significant association with the occurrence of a major adverse cardiac event in the next 90 days. In a multivariate analysis that incorporated the most widely used clinical risk variables, the nearest neighbor and hierarchical clustering approaches were able to statistically significantly distinguish patients with a roughly two-fold risk of suffering a major adverse cardiac event in the next 90 days.',\n",
       "  'id': '4078',\n",
       "  'title': 'Identifying Patients at Risk of Major Adverse Cardiovascular Events Using Symbolic Mismatch',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'When learning models that are represented in matrix forms, enforcing   a low-rank constraint can dramatically improve the memory and run   time complexity, while providing a natural regularization of the   model.  However, naive approaches for minimizing functions over the   set of low-rank matrices are either prohibitively time   consuming (repeated singular value decomposition of the matrix) or   numerically unstable (optimizing a factored representation of the   low rank matrix). We build on recent advances in optimization over   manifolds, and describe an iterative online learning procedure, consisting of a   gradient step, followed by a second-order retraction back to the   manifold. While the ideal retraction is hard to compute, and so is   the projection operator that approximates it, we describe another   second-order retraction that can be computed efficiently, with run   time and memory complexity of O((n+m)k) for a rank-k   matrix of dimension m x n, given rank one gradients.  We use   this algorithm, LORETA, to learn a matrix-form similarity measure over pairs of   documents represented as high dimensional vectors. LORETA   improves the mean average precision over a passive-   aggressive approach in a factorized model, and also improves over   a full model trained over pre-selected features using the same   memory requirements. LORETA also showed consistent improvement over   standard methods in a large (1600 classes) multi-label image classification task.',\n",
       "  'id': '4084',\n",
       "  'title': 'Online Learning in The Manifold of Low-Rank Matrices',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We consider the problem of retrieving the database points nearest to a given {\\\\em hyperplane} query without exhaustively scanning the database. We propose two hashing-based solutions. Our first approach maps the data to two-bit binary keys that are locality-sensitive for the angle between the hyperplane normal and a database point. Our second approach embeds the data into a vector space where the Euclidean norm reflects the desired distance between the original points and hyperplane query. Both use hashing to retrieve near points in sub-linear time. Our first method's preprocessing stage is more efficient, while the second has stronger accuracy guarantees. We apply both to pool-based active learning: taking the current hyperplane classifier as a query, our algorithm identifies those points (approximately) satisfying the well-known minimal distance-to-hyperplane selection criterion. We empirically demonstrate our methods' tradeoffs, and show that they make it practical to perform active selection with millions of unlabeled points.\",\n",
       "  'id': '4088',\n",
       "  'title': 'Hashing Hyperplane Queries to Near Points with Applications to Large-Scale Active Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We extend Latent Dirichlet Allocation (LDA) by explicitly allowing for the encoding of side information in the distribution over words. This results in a variety of new capabilities, such as improved estimates for infrequently occurring words, as well as the ability to leverage thesauri and dictionaries in order to boost topic cohesion within and across languages. We present experiments on multi-language topic synchronisation where dictionary information is used to bias corresponding words towards similar topics. Results indicate that our model substantially improves topic cohesion when compared to the standard LDA model.',\n",
       "  'id': '4094',\n",
       "  'title': 'Word Features for Latent Dirichlet Allocation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In this paper, we propose a matrix-variate normal penalty with sparse inverse covariances to couple multiple tasks. Learning multiple (parametric) models can be viewed as estimating a matrix of parameters, where rows and columns of the matrix correspond to tasks and features, respectively. Following the matrix-variate normal density, we design a penalty that decomposes the full covariance of matrix elements into the Kronecker product of row covariance and column covariance, which characterizes both task relatedness and feature representation. Several recently proposed methods are variants of the special cases of this formulation. To address the overfitting issue and select meaningful task and feature structures, we include sparse covariance selection into our matrix-normal regularization via L-1 penalties on task and feature inverse covariances. We empirically study the proposed method and compare with related models in two real-world problems: detecting landmines in multiple fields and recognizing faces between different subjects. Experimental results show that the proposed framework provides an effective and flexible way to model various different structures of multiple tasks.',\n",
       "  'id': '4095',\n",
       "  'title': 'Learning Multiple Tasks with a Sparse Matrix-Normal Penalty',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A standard approach to learning object category detectors is to provide strong supervision in the form of a region of interest (ROI) specifying each instance of the object in the training images. In this work are goal is to learn from heterogeneous labels, in which some images are only weakly supervised, specifying only the presence or absence of the object or a weak indication of object location, whilst others are fully annotated. To this end we develop a discriminative learning approach and make two contributions: (i) we propose a structured output formulation for weakly annotated images where full annotations are treated as latent variables; and (ii) we propose to optimize a ranking objective function, allowing our method to more effectively use negatively labeled images to improve detection average precision performance. The method is demonstrated on the benchmark INRIA pedestrian detection dataset of Dalal and Triggs and the PASCAL VOC dataset, and it is shown that for a significant proportion of weakly supervised images the performance achieved is very similar to the fully supervised (state of the art) results.',\n",
       "  'id': '4105',\n",
       "  'title': 'Simultaneous Object Detection and Ranking with Weak Supervision',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Many problems in machine learning and statistics can be formulated as (generalized) eigenproblems. In terms of the associated optimization problem, computing linear eigenvectors amounts to finding critical points of a quadratic function subject to quadratic constraints. In this paper we show that a certain class of constrained optimization problems with nonquadratic objective and constraints can be understood as nonlinear eigenproblems. We derive a generalization of the inverse power method which is guaranteed to converge to a nonlinear eigenvector. We apply the inverse power method to 1-spectral clustering and sparse PCA which can naturally be formulated as nonlinear eigenproblems. In both applications we achieve state-of-the-art results in terms of solution quality and runtime. Moving beyond the standard eigenproblem should be useful also in many other applications and our inverse power method can be easily adapted to new problems.',\n",
       "  'id': '4110',\n",
       "  'title': 'An Inverse Power Method for Nonlinear Eigenproblems with Applications in 1-Spectral Clustering and Sparse PCA',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Computing two-way and multi-way set similarities is a fundamental problem. This study focuses on estimating 3-way resemblance (Jaccard similarity) using b-bit minwise hashing. While traditional minwise hashing methods store each hashed value using 64 bits, b-bit minwise hashing only stores the lowest b bits (where b>= 2 for 3-way). The extension to 3-way similarity from the prior work on 2-way similarity is technically non-trivial. We develop the precise estimator which is accurate and very complicated; and we recommend a much simplified estimator suitable for sparse data. Our analysis shows that $b$-bit minwise hashing can normally achieve a 10 to 25-fold improvement in the storage space required for a given estimator accuracy of the 3-way resemblance.',\n",
       "  'id': '4119',\n",
       "  'title': 'b-Bit Minwise Hashing for Estimating Three-Way Similarities',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'There has been a recent push in extraction of 3D spatial layout of scenes. However, none of these approaches model the 3D interaction between objects and the spatial layout. In this paper, we argue for a parametric representation of objects in 3D, which allows us to incorporate volumetric constraints of the physical world. We show that augmenting current structured prediction techniques with volumetric reasoning significantly improves the performance of the state-of-the-art.',\n",
       "  'id': '4120',\n",
       "  'title': 'Estimating Spatial Layout of Rooms using Volumetric Reasoning about Objects and Surfaces',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The max-norm was proposed as a convex matrix regularizer by Srebro et al (2004) and was shown to be empirically superior to the trace-norm for collaborative filtering problems. Although the max-norm can be computed in polynomial time, there are currently no practical algorithms for solving large-scale optimization problems that incorporate the max-norm. The present work uses a factorization technique of Burer and Monteiro (2003) to devise scalable first-order algorithms for convex programs involving the max-norm. These algorithms are applied to solve huge collaborative filtering, graph cut, and clustering problems. Empirically, the new methods outperform mature techniques from all three areas.',\n",
       "  'id': '4124',\n",
       "  'title': 'Practical Large-Scale Optimization for Max-norm Regularization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Learning from multi-view data is important in many applications, such as image classification and annotation. In this paper, we present a large-margin learning framework to discover a predictive latent subspace representation shared by multiple views. Our approach is based on an undirected latent space Markov network that fulfills a weak conditional independence assumption that multi-view observations and response variables are independent given a set of latent variables. We provide efficient inference and parameter estimation methods for the latent subspace model. Finally, we demonstrate the advantages of large-margin learning on real video and web image data for discovering predictive latent representations and improving the performance on image classification, annotation and retrieval.',\n",
       "  'id': '4128',\n",
       "  'title': 'Predictive Subspace Learning for Multi-view Data: a Large Margin Approach',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In this paper we consider the problem of learning an n x n Kernel matrix from m similarity matrices under general convex loss. Past research have extensively studied the m =1 case and have derived several algorithms which require sophisticated techniques like ACCP, SOCP, etc. The existing algorithms do not apply if one uses arbitrary losses and often can not handle m > 1 case. We present several provably convergent iterative algorithms, where each iteration requires either an SVM or a Multiple Kernel Learning (MKL) solver for m > 1 case. One of the major contributions of the paper is to extend the well known Mirror Descent(MD) framework to handle Cartesian product of psd matrices. This novel extension leads to an algorithm, called EMKL, which solves the problem in O(m^2 log n) iterations; in each iteration one solves an MKL involving m kernels and m eigen-decomposition of n x n matrices. By suitably defining a restriction on the objective function, a faster version of EMKL is proposed, called REKL, which avoids the eigen-decomposition. An alternative to both EMKL and REKL is also suggested which requires only an SVM solver. Experimental results on real world protein data set involving several similarity matrices illustrate the efficacy of the proposed algorithms.',\n",
       "  'id': '4131',\n",
       "  'title': 'Efficient algorithms for learning kernels from multiple similarity matrices with general convex loss functions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'For many structured prediction problems, complex models often require adopting approximate inference techniques such as variational methods or sampling, which generally provide no satisfactory accuracy guarantees. In this work, we propose sidestepping intractable inference altogether by learning ensembles of tractable sub-models as part of a structured prediction cascade. We focus in particular on problems with high-treewidth and large state-spaces, which occur in many computer vision tasks. Unlike other variational methods, our ensembles do not enforce agreement between sub-models, but filter the space of possible outputs by simply adding and thresholding the max-marginals of each constituent model. Our framework jointly estimates parameters for all models in the ensemble for each level of the cascade by minimizing a novel, convex loss function, yet requires only a linear increase in computation over learning or inference in a single tractable sub-model. We provide a generalization bound on the filtering loss of the ensemble as a theoretical justification of our approach, and we evaluate our method on both synthetic data and the task of estimating articulated human pose from challenging videos. We find that our approach significantly outperforms loopy belief propagation on the synthetic data and a state-of-the-art model on the pose estimation/tracking problem.',\n",
       "  'id': '4134',\n",
       "  'title': 'Sidestepping Intractable Inference with Structured Ensemble Cascades',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper tackles the complex problem of visually matching people in similar pose but with different clothes, background, and other appearance changes. We achieve this with a novel method for learning a nonlinear embedding based on several extensions to the Neighborhood Component Analysis (NCA) framework. Our method is convolutional, enabling it to scale to realistically-sized images. By cheaply labeling the head and hands in large video databases through Amazon Mechanical Turk (a crowd-sourcing service), we can use the task of localizing the head and hands as a proxy for determining body pose. We apply our method to challenging real-world data and show that it can generalize beyond hand localization to infer a more general notion of body pose. We evaluate our method quantitatively against other embedding methods. We also demonstrate that real-world performance can be improved through the use of synthetic data.',\n",
       "  'id': '4143',\n",
       "  'title': 'Pose-Sensitive Embedding by Nonlinear NCA Regression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Predicting the execution time of computer programs is an important but challenging problem in the community of computer systems. Existing methods require experts to perform detailed analysis of program code in order to construct predictors or select important features. We recently developed a new system to automatically extract a large number of features from program execution on sample inputs, on which prediction models can be constructed without expert knowledge. In this paper we study the construction of predictive models for this problem. We propose the SPORE (Sparse POlynomial REgression) methodology to build accurate prediction models of program performance using feature data collected from program execution on sample inputs. Our two SPORE algorithms are able to build relationships between responses (e.g., the execution time of a computer program) and features, and select a few from hundreds of the retrieved features to construct an explicitly sparse and non-linear model to predict the response variable. The compact and explicitly polynomial form of the estimated model could reveal important insights into the computer program (e.g., features and their non-linear combinations that dominate the execution time), enabling a better understanding of the program?s behavior. Our evaluation on three widely used computer programs shows that SPORE methods can give accurate prediction with relative error less than 7% by using a moderate number of training data samples. In addition, we compare SPORE algorithms to state-of-the-art sparse regression algorithms, and show that SPORE methods, motivated by real applications, outperform the other methods in terms of both interpretability and prediction accuracy.',\n",
       "  'id': '4145',\n",
       "  'title': 'Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The design of low-level image features is critical for computer vision algorithms. Orientation histograms, such as those in SIFT~\\\\cite{Lowe2004Distinctive} and HOG~\\\\cite{Dalal2005Histograms}, are the most successful and popular features for visual object and scene recognition. We highlight the kernel view of orientation histograms, and show that they are equivalent to a certain type of match kernels over image patches. This novel view allows us to design a family of kernel descriptors which provide a unified and principled framework to turn pixel attributes (gradient, color, local binary pattern, \\\\etc) into compact patch-level features. In particular, we introduce three types of match kernels to measure similarities between image patches, and construct compact low-dimensional kernel descriptors from these match kernels using kernel principal component analysis (KPCA)~\\\\cite{Scholkopf1998Nonlinear}. Kernel descriptors are easy to design and can turn any type of pixel attribute into patch-level features. They outperform carefully tuned and sophisticated features including SIFT and deep belief networks. We report superior performance on standard image classification benchmarks: Scene-15, Caltech-101, CIFAR10 and CIFAR10-ImageNet.',\n",
       "  'id': '4147',\n",
       "  'title': 'Kernel Descriptors for Visual Recognition',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The standard strategy for efficient object detection consists of building a cascade composed of several binary classifiers. The detection process takes the form of a lazy evaluation of the conjunction of the responses of these classifiers, and concentrates the computation on difficult parts of the image which can not be trivially rejected.  We introduce a novel algorithm to construct jointly the classifiers of such a cascade. We interpret the response of a classifier as a probability of a positive prediction, and the overall response of the cascade as the probability that all the predictions are positive. From this noisy-AND model, we derive a consistent loss and a Boosting procedure to optimize that global probability on the training set.  Such a joint learning allows the individual predictors to focus on a more restricted modeling problem, and improves the performance compared to a standard cascade. We demonstrate the efficiency of this approach on face and pedestrian detection with standard data-sets and comparisons with reference baselines.',\n",
       "  'id': '4148',\n",
       "  'title': 'Joint Cascade Optimization Using A Product Of Boosted Classifiers',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider problems for which one has incomplete binary matrices that evolve with time (e.g., the votes of legislators on particular legislation, with each year characterized by a different such matrix). An objective of such analysis is to infer structure and inter-relationships underlying the matrices, here defined by latent features associated with each axis of the matrix. In addition, it is assumed that documents are available for the entities associated with at least one of the matrix axes. By jointly analyzing the matrices and documents, one may be used to inform the other within the analysis, and the model offers the opportunity to predict matrix values (e.g., votes) based only on an associated document (e.g., legislation). The research presented here merges two areas of machine-learning that have previously been investigated separately: incomplete-matrix analysis and topic modeling. The analysis is performed from a Bayesian perspective, with efficient inference constituted via Gibbs sampling. The framework is demonstrated by considering all voting data and available documents (legislation) during the 220-year lifetime of the United States Senate and House of Representatives.',\n",
       "  'id': '4152',\n",
       "  'title': 'Joint Analysis of Time-Evolving Binary Matrices and Associated Documents',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The commute distance between two vertices in a graph is the expected   time it takes a random walk to travel from the first to the second   vertex and back. We study the behavior of the commute distance as the size of the underlying graph   increases. We prove that the commute distance converges to an   expression that does not take into account the structure of the   graph at all and that is completely meaningless as a distance   function on the graph. Consequently, the use of the raw commute   distance for machine learning purposes is strongly discouraged for   large graphs and in high dimensions. As an alternative we introduce   the amplified commute distance that corrects for   the undesired large sample effects.',\n",
       "  'id': '3891',\n",
       "  'title': 'Getting lost in space: Large sample analysis of the resistance distance',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We introduce a new family of online learning algorithms based upon   constraining the velocity flow over a distribution of weight   vectors.  In particular, we show how to effectively  herd a   Gaussian weight vector distribution by trading off velocity   constraints with a loss function.  By uniformly bounding this loss   function, we demonstrate how to solve the resulting optimization   analytically.  We compare the resulting algorithms on a variety of    real world datasets, and demonstrate how these algorithms achieve   state-of-the-art robust performance, especially with high label   noise in the training data.',\n",
       "  'id': '3893',\n",
       "  'title': 'Learning via Gaussian Herding',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper explores links between basis construction methods in Markov decision processes and power series expansions of value functions. This perspective provides a useful framework to analyze properties of existing bases, as well as provides insight into constructing more effective bases. Krylov and Bellman error bases are based on the Neumann series expansion. These bases incur very large initial Bellman errors, and can converge rather slowly as the discount factor approaches unity. The Laurent series expansion, which relates discounted and average-reward formulations, provides both an explanation for this slow convergence as well as suggests a way to construct more efficient basis representations. The first two terms in the Laurent series represent the scaled average-reward and the average-adjusted sum of rewards, and subsequent terms expand the discounted value function using powers of a generalized inverse called the Drazin (or group inverse) of a singular matrix derived from the transition matrix. Experiments show that Drazin bases converge considerably more quickly than several other bases, particularly for large values of the discount factor. An incremental variant of Drazin bases called Bellman average-reward bases (BARBs) is described, which provides some of the same benefits at lower computational cost.',\n",
       "  'id': '3898',\n",
       "  'title': 'Basis Construction from Power Series Expansions of Value Functions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Many complex systems, ranging from neural cell assemblies to insect societies, involve and rely on some division of labor. How to enforce such a division in a decentralized and distributed way, is tackled in this paper, using a spiking neuron network architecture. Specifically, a spatio-temporal model called SpikeAnts is shown to enforce the emergence of synchronized activities in an ant colony. Each ant is modelled from two spiking neurons; the ant colony is a sparsely connected spiking neuron network. Each ant makes its decision (among foraging, sleeping and self-grooming) from the competition between its two neurons, after the signals received from its neighbor ants. Interestingly, three types of temporal patterns emerge in the ant colony: asynchronous, synchronous, and synchronous periodic foraging activities - similar to the actual behavior of some living ant colonies. A phase diagram of the emergent activity patterns with respect to two control parameters, respectively accounting for ant sociability and receptivity, is presented and discussed.',\n",
       "  'id': '3900',\n",
       "  'title': 'SpikeAnts, a spiking neuron network modelling the emergence of organization in a complex system',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper discusses the topic of dimensionality reduction for $k$-means clustering. We prove that any set of $n$ points in $d$ dimensions (rows in a matrix $A \\\\in \\\\RR^{n \\\\times d}$) can be projected into $t = \\\\Omega(k / \\\\eps^2)$ dimensions, for any $\\\\eps \\\\in (0,1/3)$, in $O(n d \\\\lceil \\\\eps^{-2} k/ \\\\log(d) \\\\rceil )$ time, such that with  constant probability the optimal $k$-partition of the point set is preserved within a factor of $2+\\\\eps$. The projection is done by post-multiplying $A$ with a $d \\\\times t$ random matrix $R$ having entries $+1/\\\\sqrt{t}$ or $-1/\\\\sqrt{t}$ with equal probability. A numerical implementation of our technique and experiments on a large face images dataset verify the speed and the accuracy of our theoretical results.',\n",
       "  'id': '3901',\n",
       "  'title': 'Random Projections for ',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We develop an online variational Bayes (VB) algorithm for Latent Dirichlet Allocation (LDA). Online LDA is based on online stochastic optimization with a natural gradient step, which we show converges to a local optimum of the VB objective function. It can handily analyze massive document collections, including those arriving in a stream. We study the performance of online LDA in several ways, including by fitting a 100-topic topic model to 3.3M articles from Wikipedia in a single pass. We demonstrate that online LDA finds topic models as good or better than those found with batch VB, and in a fraction of the time.',\n",
       "  'id': '3902',\n",
       "  'title': 'Online Learning for Latent Dirichlet Allocation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper is concerned with rank aggregation, which aims to combine multiple input rankings to get a better ranking. A popular approach to rank aggregation is based on probabilistic models on permutations, e.g., the Luce model and the Mallows model. However, these models have their limitations in either poor expressiveness or high computational complexity. To avoid these limitations, in this paper, we propose a new model, which is defined with a coset-permutation distance, and models the generation of a permutation as a stagewise process. We refer to the new model as coset-permutation distance based stagewise (CPS) model. The CPS model has rich expressiveness and can therefore be used in versatile applications, because many different permutation distances can be used to induce the coset-permutation distance. The complexity of the CPS model is low because of the stagewise decomposition of the permutation probability and the efficient computation of most coset-permutation distances. We apply the CPS model to supervised rank aggregation, derive the learning and inference algorithms, and empirically study their effectiveness and efficiency. Experiments on public datasets show that the derived algorithms based on the CPS model can achieve state-of-the-art ranking accuracy, and are much more efficient than previous algorithms.',\n",
       "  'id': '3906',\n",
       "  'title': 'A New Probabilistic Model for Rank Aggregation',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"In this paper we propose an approximated learning framework for large scale graphical models and derive message passing algorithms for learning their parameters efficiently.  We first relate CRFs and structured SVMs  and show that in the CRF's primal a variant of the log-partition function, known as soft-max, smoothly approximates the hinge loss function of structured SVMs.  We then propose an intuitive approximation for structured prediction problems using Fenchel duality based on a local entropy approximation that computes the exact gradients of the approximated problem and is guaranteed to converge. Unlike existing approaches, this allow us to learn graphical models with cycles and very large number of parameters efficiently. We demonstrate the effectiveness of our approach  in an image denoising task. This task was previously solved by sharing parameters across cliques. In contrast, our algorithm is able to efficiently learn large number of parameters resulting in orders of magnitude better prediction.\",\n",
       "  'id': '3913',\n",
       "  'title': 'A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Multi-label classification is the task of predicting potentially multiple labels for a given instance. This is common in several applications such as image annotation, document classification and gene function prediction. In this paper we present a formulation for this problem based on reverse prediction: we predict sets of instances given the labels. By viewing the problem from this perspective, the most popular quality measures for assessing the performance of multi-label classification admit relaxations that can be efficiently optimised. We optimise these relaxations with standard algorithms and compare our results with several state-of-the-art methods, showing excellent performance.',\n",
       "  'id': '3920',\n",
       "  'title': 'Reverse Multi-Label Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Remarkably easy implementation and guaranteed convergence has made the EM algorithm one of the most used algorithms for mixture modeling. On the downside, the E-step is linear in both the sample size and the number of mixture components, making it impractical for large-scale data. Based on the variational EM framework, we propose a fast alternative that uses component-specific data partitions to obtain a sub-linear E-step in sample size, while the algorithm still maintains provable convergence. Our approach builds on previous work, but is significantly faster and scales much better in the number of mixture components. We demonstrate this speedup by experiments on large-scale synthetic and real data.',\n",
       "  'id': '3924',\n",
       "  'title': 'Fast Large-scale Mixture Modeling with Component-specific Data Partitions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Intelligent agents are often faced with the need to choose actions with uncertain consequences, and to modify those actions according to ongoing sensory processing and changing task demands. The requisite ability to dynamically modify or cancel planned actions is known as inhibitory control in psychology. We formalize inhibitory control as a rational decision-making problem, and apply to it to the classical stop-signal task. Using Bayesian inference and stochastic control tools, we show that the optimal policy systematically depends on various parameters of the problem, such as the relative costs of different action choices, the noise level of sensory inputs, and the dynamics of changing environmental demands. Our normative model accounts for a range of behavioral data in humans and animals in the stop-signal task, suggesting that the brain implements statistically optimal, dynamically adaptive, and reward-sensitive decision-making in the context of inhibitory control problems.',\n",
       "  'id': '3937',\n",
       "  'title': 'A rational decision making framework for inhibitory control',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The sequence memoizer is a model for sequence data with state-of-the-art performance on language modeling and compression. We propose a number of improvements to the model and inference algorithm, including an enlarged range of hyperparameters, a memory-efficient representation, and inference algorithms operating on the new representation. Our derivations are based on precise definitions of the various processes that will also allow us to provide an elementary proof of the mysterious\" coagulation and fragmentation properties used in the original paper on the sequence memoizer by Wood et al. (2009). We present some experimental results supporting our improvements.\"',\n",
       "  'id': '3938',\n",
       "  'title': 'Improvements to the Sequence Memoizer',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In this paper, we point out that there exist scaling and initialization problems in most existing multiple kernel learning (MKL) approaches, which employ the large margin principle to jointly learn both a kernel and an SVM classifier. The reason is that the margin itself can not well describe how good a kernel is due to the negligence of the scaling. We use the ratio between the margin and the radius of the minimum enclosing ball to measure the goodness of a kernel, and present a new minimization formulation for kernel learning. This formulation is invariant to scalings of learned kernels, and when learning linear combination of basis kernels it is also invariant to scalings of basis kernels and to the types (e.g., L1 or L2) of norm constraints on combination coefficients. We establish the differentiability of our formulation, and propose a gradient projection algorithm for kernel learning. Experiments show that our method significantly outperforms both SVM with the uniform combination of basis kernels and other state-of-art MKL approaches.',\n",
       "  'id': '3954',\n",
       "  'title': 'Learning Kernels with Radiuses of Minimum Enclosing Balls',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider bandit problems, motivated by applications in online advertising and news story selection, in which the learner must repeatedly select a slate, that is, a subset of size s from K possible actions, and then receives rewards for just the selected actions. The goal is to minimize the regret with respect to total reward of the best slate computed in hindsight. We consider unordered and ordered versions of the problem, and give efficient algorithms which have regret O(sqrt(T)), where the constant depends on the specific nature of the problem. We also consider versions of the problem where we have access to a number of policies which make recommendations for slates in every round, and give algorithms with O(sqrt(T)) regret for competing with the best such policy as well. We make use of the technique of relative entropy projections combined with the usual multiplicative weight update algorithm to obtain our algorithms.',\n",
       "  'id': '3962',\n",
       "  'title': 'Non-Stochastic Bandit Slate Problems',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider a class of learning problems that involve a structured sparsity-inducing norm defined as the sum of $\\\\ell_\\\\infty$-norms over groups of variables. Whereas a lot of effort has been put in developing fast optimization methods when the groups are disjoint or embedded in a specific hierarchical structure, we address here the case of general overlapping groups. To this end, we show that the corresponding optimization problem is related to network flow optimization. More precisely, the proximal problem associated with the norm we consider is dual to a quadratic min-cost flow problem. We propose an efficient procedure which computes its solution exactly in polynomial time. Our algorithm scales up to millions of groups and variables, and opens up a whole new range of applications for structured sparse models. We present several experiments on image and video data, demonstrating the applicability and scalability of our approach for various problems.',\n",
       "  'id': '3965',\n",
       "  'title': 'Network Flow Algorithms for Structured Sparsity',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a discriminative latent model for annotating images with unaligned object-level textual annotations. Instead of using the bag-of-words image representation currently popular in the computer vision community, our model explicitly captures more intricate relationships underlying visual and textual information. In particular, we model the mapping that translates image regions to annotations. This mapping allows us to relate image regions to their corresponding annotation terms. We also model the overall scene label as latent information. This allows us to cluster test images. Our training data consist of images and their associated annotations. But we do not have access to the ground-truth region-to-annotation mapping or the overall scene label. We develop a novel variant of the latent SVM framework to model them as latent variables. Our experimental results demonstrate the effectiveness of the proposed model compared with other baseline methods.',\n",
       "  'id': '3968',\n",
       "  'title': 'A Discriminative Latent Model of Image Region and Object Tag Correspondence',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a novel probabilistic model for distributions over sets of structures -- for example, sets of sequences, trees, or graphs. The critical characteristic of our model is a preference for diversity: sets containing dissimilar structures are more likely. Our model is a marriage of structured probabilistic models, like Markov random fields and context free grammars, with determinantal point processes, which arise in quantum physics as models of particles with repulsive interactions. We extend the determinantal point process model to handle an exponentially-sized set of particles (structures) via a natural factorization of the model into parts. We show how this factorization leads to tractable algorithms for exact inference, including computing marginals, computing conditional probabilities, and sampling. Our algorithms exploit a novel polynomially-sized dual representation of determinantal point processes, and use message passing over a special semiring to compute relevant quantities. We illustrate the advantages of the model on tracking and articulated pose estimation problems.',\n",
       "  'id': '3969',\n",
       "  'title': 'Structured Determinantal Point Processes',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Partially Observable Markov Decision Processes (POMDPs) model sequential decision-making problems under uncertainty and partial observability. Unfortunately, some problems cannot be modeled with state-dependent reward functions, e.g., problems whose objective explicitly implies reducing the uncertainty on the state. To that end, we introduce rho-POMDPs, an extension of POMDPs where the reward function rho depends on the belief state. We show that, under the common assumption that rho is convex, the value function is also convex, what makes it possible to (1) approximate rho arbitrarily well with a piecewise linear and convex (PWLC) function, and (2) use state-of-the-art exact or approximate solving algorithms with limited changes.',\n",
       "  'id': '3971',\n",
       "  'title': 'A POMDP Extension with Belief-dependent Rewards',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We provide a sound and consistent foundation for the use of \\\\emph{nonrandom} exploration data in ``contextual bandit'' or ``partially labeled'' settings where only the value of a chosen action is learned.                                                       The primary challenge in a variety of settings is that the exploration policy, in which ``offline'' data is logged, is not explicitly known. Prior solutions here require either control of the actions during the learning process, recorded random exploration, or actions chosen obliviously in a repeated manner.  The techniques reported here lift these restrictions, allowing the learning of a policy for choosing actions given features from historical data where no randomization occurred or was logged.  We empirically verify our solution on two reasonably sized sets of real-world data obtained from an Internet %online advertising company.\",\n",
       "  'id': '3977',\n",
       "  'title': 'Learning from Logged Implicit Exploration Data',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recent proposals suggest that large, generic neuronal networks could store memory traces of past input sequences in their instantaneous state. Such a proposal raises important theoretical questions about the duration of these memory traces and their dependence on network size, connectivity and signal statistics. Prior work, in the case of gaussian input sequences and linear neuronal networks, shows that the duration of memory traces in a network cannot exceed the number of neurons (in units of the neuronal time constant), and that no network can out-perform an equivalent feedforward network. However a more ethologically relevant scenario is that of sparse input sequences. In this scenario, we show how linear neural networks can essentially perform compressed sensing (CS) of past inputs, thereby attaining a memory capacity that {\\\\it exceeds} the number of neurons. This enhanced capacity is achieved by a class of ``orthogonal recurrent networks and not by feedforward networks or generic recurrent networks. We exploit techniques from the statistical physics of disordered systems to analytically compute the decay of memory traces in such networks as a function of network size, signal sparsity and integration time. Alternately, viewed purely from the perspective of CS, this work introduces a new ensemble of measurement matrices derived from dynamical systems, and provides a theoretical analysis of their asymptotic performance.\"',\n",
       "  'id': '3980',\n",
       "  'title': 'Short-term memory in neuronal networks through dynamical compressed sensing',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Latent force models encode the interaction between multiple related dynamical systems in the form of a kernel or covariance function. Each variable to be modeled is represented as the output of a differential equation and each differential equation is driven by a weighted sum of latent functions with uncertainty given by a Gaussian process prior. In this paper we consider employing the latent force model framework for the problem of determining robot motor primitives. To deal with discontinuities in the dynamical systems or the latent driving force we introduce an extension of the basic latent force model, that switches between different latent functions and potentially different dynamical systems. This creates a versatile representation for robot movements that can capture discrete changes and non-linearities in the dynamics. We give illustrative examples on both synthetic data and for striking movements recorded using a Barrett WAM robot as haptic input device. Our inspiration is robot motor primitives, but we expect our model to have wide application for dynamical systems including models for human motion capture data and systems biology.',\n",
       "  'id': '4001',\n",
       "  'title': 'Switched Latent Force Models for Movement Segmentation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present an algorithm for learning high-treewidth Markov networks where inference is still tractable. This is made possible by exploiting context specific independence and determinism in the domain. The class of models our algorithm can learn has the same desirable properties as thin junction trees: polynomial inference, closed form weight learning, etc., but is much broader. Our algorithm searches for a feature that divides the state space into subspaces where the remaining variables decompose into independent subsets (conditioned on the feature or its negation) and recurses on each subspace/subset of variables until no useful new features can be found. We provide probabilistic performance guarantees for our algorithm under the assumption that the maximum feature length is k (the treewidth can be much larger) and dependences are of bounded strength. We also propose a greedy version of the algorithm that, while forgoing these guarantees, is much more efficient.Experiments on a variety of domains show that our approach compares favorably with thin junction trees and other Markov network structure learners.',\n",
       "  'id': '4010',\n",
       "  'title': 'Learning Efficient Markov Networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Consider a convex relaxation $\\\\hat f$ of a pseudo-boolean function $f$. We say that the relaxation is {\\\\em totally half-integral} if $\\\\hat f(\\\\bx)$ is a polyhedral function with half-integral extreme points $\\\\bx$, and this property is preserved after adding an arbitrary combination of constraints of the form $x_i=x_j$, $x_i=1-x_j$, and $x_i=\\\\gamma$ where $\\\\gamma\\\\in\\\\{0,1,\\\\frac{1}{2}\\\\}$ is a constant. A well-known example is the {\\\\em roof duality} relaxation for quadratic pseudo-boolean functions $f$. We argue that total half-integrality is a natural requirement for generalizations of roof duality to arbitrary pseudo-boolean functions.  Our contributions are as follows. First, we provide a complete characterization of totally half-integral relaxations $\\\\hat f$ by establishing a one-to-one correspondence with {\\\\em bisubmodular functions}. Second, we give a new characterization of bisubmodular functions. Finally, we show some relationships between general totally half-integral relaxations and relaxations based on the roof duality.',\n",
       "  'id': '4021',\n",
       "  'title': 'Generalized roof duality and bisubmodular functions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The problem of optimal and automatic design of a detector cascade is considered. A novel mathematical model is introduced for a cascaded detector. This model is analytically tractable, leads to recursive computation, and accounts for both classification and complexity. A boosting algorithm, FCBoost, is proposed for fully automated cascade design. It exploits the new cascade model, minimizes a Lagrangian cost that accounts for both classification risk and complexity. It searches the space of cascade configurations to automatically determine the optimal number of stages and their predictors, and is compatible with bootstrapping of negative examples and cost sensitive learning. Experiments show that the resulting cascades have state-of-the-art performance in various computer vision problems.',\n",
       "  'id': '4033',\n",
       "  'title': 'Boosting Classifier Cascades',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a new way of converting a reversible finite Markov chain into a nonreversible one, with a theoretical guarantee that the asymptotic variance of the MCMC estimator based on the non-reversible chain is reduced. The method is applicable to any reversible chain whose states are not connected through a tree, and can be interpreted graphically as inserting vortices into the state transition graph. Our result confirms that non-reversible chains are fundamentally better than reversible ones in terms of asymptotic performance, and suggests interesting directions for further improving MCMC.',\n",
       "  'id': '4037',\n",
       "  'title': 'Improving the Asymptotic Performance of Markov Chain Monte-Carlo by Inserting Vortices',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In many real world applications we do not have access to fully-labeled training data, but only to a list of possible labels. This is the case, e.g., when learning visual classifiers from images downloaded from the web, using just their text captions or tags as learning oracles. In general, these problems can be very difficult. However most of the time there exist different implicit sources of information, coming from the relations between instances and labels, which are usually dismissed. In this paper, we propose a semi-supervised framework to model this kind of problems. Each training sample is a bag containing multi-instances, associated with a set of candidate labeling vectors. Each labeling vector encodes the possible labels for the instances in the bag, with only one being fully correct. The use of the labeling vectors provides a principled way not to exclude any information. We propose a large margin discriminative formulation, and an efficient algorithm to solve it. Experiments conducted on artificial datasets and a real-world images and captions dataset show that our approach achieves performance comparable to SVM trained with the ground-truth labels, and outperforms other baselines.',\n",
       "  'id': '4041',\n",
       "  'title': 'Learning from Candidate Labeling Sets',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Steinwart was the ?rst to prove universal consistency of support vector machine  classi?cation. His proof analyzed the ?standard? support vector machine classi?er,  which is restricted to binary classi?cation problems. In contrast, recent analysis  has resulted in the common belief that several extensions of SVM classi?cation to  more than two classes are inconsistent.  Countering this belief, we proof the universal consistency of the multi-class support vector machine by Crammer and Singer. Our proof extends Steinwart?s techniques to the multi-class case.',\n",
       "  'id': '4042',\n",
       "  'title': 'Universal Consistency of Multi-Class Support Vector Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider linear models for stochastic dynamics. Any such model can be associated a network (namely a directed graph) describing which degrees of freedom interact under the dynamics. We tackle the problem of learning such a network from observation of the system trajectory over a time interval T. We analyse the l1-regularized least squares algorithm and, in the setting in which the underlying network is sparse, we prove performance guarantees that are uniform in the sampling rate as long as this is sufficiently high. This result substantiates the notion of a well defined ?time complexity? for the network inference problem.',\n",
       "  'id': '4055',\n",
       "  'title': 'Learning Networks of Stochastic Differential Equations',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Functional magnetic resonance imaging (fMRI) can be applied to study the functional connectivity of the neural elements which form complex network at a whole brain level. Most analyses of functional resting state networks (RSN) have been based on the analysis of correlation between the temporal dynamics of various regions of the brain. While these models can identify coherently behaving groups in terms of correlation they give little insight into how these groups interact. In this paper we take a different view on the analysis of functional resting state networks. Starting from the definition of resting state as functional coherent groups we search for functional units of the brain that communicate with other parts of the brain in a coherent manner as measured by mutual information. We use the infinite relational model (IRM) to quantify functional coherent groups of resting state networks and demonstrate how the extracted component interactions can be used to discriminate between functional resting state activity in multiple sclerosis and normal subjects.',\n",
       "  'id': '4057',\n",
       "  'title': 'Infinite Relational Modeling of Functional Connectivity in Resting State fMRI',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Figure/ground assignment, in which the visual image is divided into nearer (figural) and farther (ground) surfaces, is an essential step in visual processing, but its underlying computational mechanisms are poorly understood. Figural assignment (often referred to as border ownership) can vary along a contour, suggesting a spatially distributed process whereby local and global cues are combined to yield local estimates of border ownership. In this paper we model figure/ground estimation in a Bayesian belief network, attempting to capture the propagation of border ownership across the image as local cues (contour curvature and T-junctions) interact with more global cues to yield a figure/ground assignment. Our network includes as a nonlocal factor skeletal (medial axis) structure, under the hypothesis that medial structure ``draws'' border ownership so that borders are owned by their interiors. We also briefly present a psychophysical experiment in which we measured local border ownership along a contour at various distances from an inducing cue (a T-junction). Both the human subjects and the network show similar patterns of performance, converging rapidly to a similar pattern of spatial variation in border ownership along contours.\",\n",
       "  'id': '4058',\n",
       "  'title': 'A Bayesian Framework for Figure-Ground Interpretation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Bayesian methods of matrix factorization (MF) have been actively explored recently as promising alternatives to classical singular value decomposition. In this paper, we show that, despite the fact that the optimization problem is non-convex, the global optimal solution of variational Bayesian (VB) MF can be computed analytically by solving a quartic equation. This is highly advantageous over a popular VBMF algorithm based on iterated conditional modes since it can only find a local optimal solution after iterations. We further show that the global optimal solution of empirical VBMF (hyperparameters are also learned from data) can also be analytically computed. We illustrate the usefulness of our results through experiments.',\n",
       "  'id': '4063',\n",
       "  'title': 'Global Analytic Solution for Variational Bayesian Matrix Factorization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Many studies have explored the impact of response variability on the quality of sensory codes. The source of this variability is almost always assumed to be intrinsic to the brain. However, when inferring a particular stimulus property, variability associated with other stimulus attributes also effectively act as noise. Here we study the impact of such stimulus-induced response variability for the case of binocular disparity inference. We characterize the response distribution for the binocular energy model in response to random dot stereograms and find it to be very different from the Poisson-like noise usually assumed. We then compute the Fisher information with respect to binocular disparity, present in the monocular inputs to the standard model of early binocular processing, and thereby obtain an upper bound on how much information a model could theoretically extract from them. Then we analyze the information loss incurred by the different ways of combining those inputs to produce a scalar single-neuron response. We find that in the case of depth inference, monocular stimulus variability places a greater limit on the extractable information than intrinsic neuronal noise for typical spike counts. Furthermore, the largest loss of information is incurred by the standard model for position disparity neurons (tuned-excitatory), that are the most ubiquitous in monkey primary visual cortex, while more information from the inputs is preserved in phase-disparity neurons (tuned-near or tuned-far) primarily found in higher cortical regions.',\n",
       "  'id': '4066',\n",
       "  'title': 'Evaluating neuronal codes for inference using Fisher information',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In system identification both the input and the output of a system are available to an observer and an algorithm is sought to identify parameters of a hypothesized model of that system. Here we present a novel formal methodology for identifying dendritic processing in a neural circuit consisting of a linear dendritic processing filter in cascade with a spiking neuron model. The input to the circuit is an analog signal that belongs to the space of bandlimited functions. The output is a time sequence associated with the spike train. We derive an algorithm for identification of the dendritic processing filter and reconstruct its kernel with arbitrary precision.',\n",
       "  'id': '4070',\n",
       "  'title': 'Identifying Dendritic Processing',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present original empirical Bernstein inequalities for U-statistics with bounded symmetric kernels q. They are expressed with respect to empirical estimates of either the variance of q or the conditional variance that appears in the Bernstein-type inequality for U-statistics derived by Arcones [2]. Our result subsumes other existing empirical Bernstein inequalities, as it reduces to them when U-statistics of order 1 are considered. In addition, it is based on a rather direct argument using two applications of the same (non-empirical) Bernstein inequality for U-statistics. We discuss potential applications of our new inequalities, especially in the realm of learning ranking/scoring functions. In the process, we exhibit an efficient procedure to compute the variance estimates for the special case of bipartite ranking that rests on a sorting argument. We also argue that our results may provide test set bounds and particularly interesting empirical racing algorithms for the problem of online learning of scoring functions.',\n",
       "  'id': '4081',\n",
       "  'title': 'Empirical Bernstein Inequalities for U-Statistics',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Languages vary widely in many ways, including their canonical word order. A basic aspect of the observed variation is the fact that some word orders are much more common than others. Although this regularity has been recognized for some time, it has not been well-explained. In this paper we offer an information-theoretic explanation for the observed word-order distribution across languages, based on the concept of Uniform Information Density (UID). We suggest that object-first languages are particularly disfavored because they are highly non-optimal if the goal is to distribute information content approximately evenly throughout a sentence, and that the rest of the observed word-order distribution is at least partially explainable in terms of UID. We support our theoretical analysis with data from child-directed speech and experimental work.',\n",
       "  'id': '4085',\n",
       "  'title': 'Why are some word orders more common than others? A uniform information density account',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The reinforcement learning community has explored many approaches to obtain- ing value estimates and models to guide decision making; these approaches, how- ever, do not usually provide a measure of confidence in the estimate. Accurate estimates of an agent?s confidence are useful for many applications, such as bi- asing exploration and automatically adjusting parameters to reduce dependence on parameter-tuning. Computing confidence intervals on reinforcement learning value estimates, however, is challenging because data generated by the agent- environment interaction rarely satisfies traditional assumptions. Samples of value- estimates are dependent, likely non-normally distributed and often limited, partic- ularly in early learning when confidence estimates are pivotal. In this work, we investigate how to compute robust confidences for value estimates in continuous Markov decision processes. We illustrate how to use bootstrapping to compute confidence intervals online under a changing policy (previously not possible) and prove validity under a few reasonable assumptions. We demonstrate the applica- bility of our confidence estimation algorithms with experiments on exploration, parameter estimation and tracking.',\n",
       "  'id': '4090',\n",
       "  'title': 'Interval Estimation for Reinforcement-Learning Algorithms in Continuous-State Domains',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In order to study the properties of total visual input in humans, a single subject wore a camera for two weeks capturing, on average, an image every 20 seconds (www.research.microsoft.com/~jojic/aihs). The resulting new dataset contains a mix of indoor and outdoor scenes as well as numerous foreground objects. Our first analysis goal is to create a visual summary of the subject?s two weeks of life using unsupervised algorithms that would automatically discover recurrent scenes, familiar faces or common actions. Direct application of existing algorithms, such as panoramic stitching (e.g.  Photosynth) or appearance-based clustering models (e.g. the epitome), is impractical due to either the large dataset size or the dramatic variation in the lighting conditions.    As a remedy to these problems, we introduce a novel image representation, the ?stel epitome,? and an associated efficient learning algorithm. In our model, each image or image patch is characterized by a hidden mapping T, which, as in previous epitome models, defines a mapping between the image-coordinates and the coordinates in the large all-I-have-seen\" epitome matrix. The limited epitome real-estate forces the mappings of different images to overlap, with this overlap indicating image similarity. However, in our model the image similarity does not depend on direct pixel-to-pixel intensity/color/feature comparisons as in previous epitome models, but on spatial configuration of scene or object parts, as the model is based on the palette-invariant stel models. As a result, stel epitomes capture structure that is invariant to non-structural changes, such as illumination, that tend to uniformly affect pixels belonging to a single scene or object part.\"',\n",
       "  'id': '4092',\n",
       "  'title': 'Structural epitome: a way to summarize one?s visual experience',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the problem of learning a coefficient vector x0 from noisy linear observation y=Ax0+w. In many contexts (ranging from model selection to image processing) it is desirable to construct a sparse estimator. In this case, a popular approach consists in solving an l1-penalized least squares problem known as the LASSO or BPDN.  For sequences of matrices A of increasing dimensions, with iid gaussian entries, we prove that the normalized risk of the LASSO converges to a limit, and we obtain an explicit expression for this limit. Our result is the first rigorous derivation of an explicit formula for the asymptotic risk of the LASSO for random instances. The proof technique is based on the analysis of AMP, a recently developed efficient algorithm, that is inspired from graphical models ideas.   Through simulations on real data matrices (gene expression data and hospital medical records) we observe that these results can be relevant in a broad array of practical applications.',\n",
       "  'id': '4096',\n",
       "  'title': 'The LASSO risk: asymptotic results and real world examples',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The International Monitoring System (IMS) is a global network of sensors whose purpose is to identify potential violations of the Comprehensive Nuclear-Test-Ban Treaty (CTBT), primarily through detection and localization of seismic events. We report on the first stage of a project to improve on the current automated software system with a Bayesian inference system that computes the most likely global event history given the record of local sensor data. The new system, VISA (Vertically Integrated Seismological Analysis), is based on empirically calibrated, generative models of event occurrence, signal propagation, and signal detection. VISA exhibits significantly improved precision and recall compared to the current operational system and is able to detect events that are missed even by the human analysts who post-process the IMS output.',\n",
       "  'id': '4100',\n",
       "  'title': 'Global seismic monitoring as probabilistic inference',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields significant gains on the highly non-uniformly sampled Netflix dataset.',\n",
       "  'id': '4102',\n",
       "  'title': 'Collaborative Filtering in a Non-Uniform World: Learning with the Weighted Trace Norm',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Many time-series such as human movement data consist of a sequence of basic actions, e.g., forehands and backhands in tennis. Automatically extracting and characterizing such actions is an important problem for a variety of different applications. In this paper, we present a probabilistic segmentation approach in which an observed time-series is modeled as a concatenation of segments corresponding to different basic actions. Each segment is generated through a noisy transformation of one of a few hidden trajectories representing different types of movement, with possible time re-scaling. We analyze three different approximation methods for dealing with model intractability, and demonstrate how the proposed approach can successfully segment table tennis movements recorded using a robot arm as haptic input device.',\n",
       "  'id': '4109',\n",
       "  'title': 'Movement extraction by detecting dynamics switches and repetitions',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In many real-world scenarios, it is nearly impossible to collect explicit social network data. In such cases, whole networks must be inferred from underlying observations. Here, we formulate the problem of inferring latent social networks based on network diffusion or disease propagation data. We consider contagions propagating over the edges of an unobserved social network, where we only observe the times when nodes became infected, but not who infected them. Given such node infection times, we then identify the optimal network that best explains the observed data. We present a maximum likelihood approach based on convex programming with a l1-like penalty term that encourages sparsity. Experiments on real and synthetic data reveal that our method near-perfectly recovers the underlying network structure as well as the parameters of the contagion propagation model. Moreover, our approach scales well as it can infer optimal networks on thousands of nodes in a matter of minutes.',\n",
       "  'id': '4113',\n",
       "  'title': 'On the Convexity of Latent Social Network Inference',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The Gaussian process (GP) is a popular way to specify dependencies between random variables in a probabilistic model. In the Bayesian framework the covariance structure can be specified using unknown hyperparameters. Integrating over these hyperparameters considers different possible explanations for the data when making predictions. This integration is often performed using Markov chain Monte Carlo (MCMC) sampling. However, with non-Gaussian observations standard hyperparameter sampling approaches require careful tuning and may converge slowly. In this paper we present a slice sampling approach that requires little tuning while mixing well in both strong- and weak-data regimes.',\n",
       "  'id': '4114',\n",
       "  'title': 'Slice sampling covariance hyperparameters of latent Gaussian models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper introduces the first set of PAC-Bayesian bounds for the batch reinforcement learning problem in finite state spaces. These bounds hold regardless of the correctness of the prior distribution. We demonstrate how such bounds can be used for model-selection in control problems where prior information is available either on the dynamics of the environment, or on the value of actions. Our empirical results confirm that PAC-Bayesian model-selection is able to leverage prior distributions when they are informative and, unlike standard Bayesian RL approaches, ignores them when they are misleading.',\n",
       "  'id': '4117',\n",
       "  'title': 'PAC-Bayesian Model Selection for Reinforcement Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study repeated zero-sum games against an adversary on a budget. Given that an adversary has some constraint on the sequence of actions that he plays, we consider what ought to be the player\\'s best mixed strategy with knowledge of this budget. We show that, for a general class of normal-form games, the minimax strategy is indeed efficiently computable and relies on a random playout\" technique. We give three diverse applications of this algorithmic template: a cost-sensitive \"Hedge\" setting, a particular problem in Metrical Task Systems, and the design of combinatorial prediction markets.\"',\n",
       "  'id': '4123',\n",
       "  'title': 'Repeated Games against Budgeted Adversaries',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Convolutional neural networks (CNNs) have been successfully applied to many tasks such as digit and object recognition. Using convolutional (tied) weights signi?cantly reduces the number of parameters that have to be learned, and also allows translational invariance to be hard-coded into the architecture. In this paper, we consider the problem of learning invariances, rather than relying on hard-coding. We propose tiled convolution neural networks (Tiled CNNs), which use a regular ?tiled? pattern of tied weights that does not require that adjacent hidden units share identical weights, but instead requires only that hidden units k steps away from each other to have tied weights. By pooling over neighboring units, this architecture is able to learn complex invariances (such as scale and rotational invariance) beyond translational invariance. Further, it also enjoys much of CNNs? advantage of having a relatively small number of learned parameters (such as ease of learning and greater scalability). We provide an efficient learning algorithm for Tiled CNNs based on Topographic ICA, and show that learning complex invariant features allows us to achieve highly competitive results for both the NORB and CIFAR-10 datasets.',\n",
       "  'id': '4136',\n",
       "  'title': 'Tiled convolutional neural networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Recent work has demonstrated that when artificial agents are limited in their ability to achieve their goals, the agent designer can benefit by making the agent's goals different from the designer's. This gives rise to the optimization problem of designing the artificial agent's goals---in the RL framework, designing the agent's reward function. Existing attempts at solving this optimal reward problem do not leverage experience gained online during the agent's lifetime nor do they take advantage of knowledge about the agent's structure. In this work, we develop a gradient ascent approach with formal convergence guarantees for approximately solving the optimal reward problem online during an agent's lifetime. We show that our method generalizes a standard policy gradient approach, and we demonstrate its ability to improve reward functions in agents with various forms of limitations.\",\n",
       "  'id': '4146',\n",
       "  'title': 'Reward Design via Online Gradient Ascent',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recent studies compare gene expression data across species to identify core and species specific genes in biological systems. To perform such comparisons researchers need to match genes across species. This is a challenging task since the correct matches (orthologs) are not known for most genes. Previous work in this area used deterministic matchings or reduced multidimensional expression data to binary representation. Here we develop a new method that can utilize soft matches (given as priors) to infer both, unique and similar expression patterns across species and a matching for the genes in both species. Our method uses a Dirichlet process mixture model which includes a latent data matching variable. We present learning and inference algorithms based on variational methods for this model. Applying our method to immune response data we show that it can accurately identify common and unique response patterns by improving the matchings between human and mouse genes.',\n",
       "  'id': '4153',\n",
       "  'title': 'Cross Species Expression Analysis using a Dirichlet Process Mixture Model with Latent Matchings',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Is there a principled way to learn a probabilistic discriminative classifier from an unlabeled data set? We present a framework that simultaneously clusters the data and trains a discriminative classifier. We call it Regularized Information Maximization (RIM). RIM optimizes an intuitive information-theoretic objective function which balances class separation, class balance and classifier complexity. The approach can flexibly incorporate different likelihood functions, express prior assumptions about the relative size of different classes and incorporate partial labels for semi-supervised learning. In particular, we instantiate the framework to unsupervised, multi-class kernelized logistic regression. Our empirical evaluation indicates that RIM outperforms existing methods on several real data sets, and demonstrates that RIM is an effective model selection method.',\n",
       "  'id': '4154',\n",
       "  'title': 'Discriminative Clustering by Regularized Information Maximization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a novel Bayesian nonparametric approach to learning with probabilistic deterministic finite automata (PDFA). We define and develop and sampler for a PDFA with an infinite number of states which we call the probabilistic deterministic infinite automata (PDIA). Posterior predictive inference in this model, given a finite training sequence, can be interpreted as averaging over multiple PDFAs of varying structure, where each PDFA is biased towards having few states. We suggest that our method for averaging over PDFAs is a novel approach to predictive distribution smoothing. We test PDIA inference both on PDFA structure learning and on both natural language and DNA data prediction tasks. The results suggest that the PDIA presents an attractive compromise between the computational cost of hidden Markov models and the storage requirements of hierarchically smoothed Markov models.',\n",
       "  'id': '4161',\n",
       "  'title': 'Probabilistic Deterministic Infinite Automata',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'For over half a century, psychologists have been struck by how poor people are at expressing their internal sensations, impressions, and evaluations via rating scales. When individuals make judgments, they are incapable of using an absolute rating scale, and instead rely on reference points from recent experience. This relativity of judgment limits the usefulness of responses provided by individuals to surveys, questionnaires, and evaluation forms. Fortunately, the cognitive processes that transform internal states to responses are not simply noisy, but rather are influenced by recent experience in a lawful manner. We explore techniques to remove sequential dependencies, and thereby decontaminate a series of ratings to obtain more meaningful human judgments. In our formulation, decontamination is fundamentally a problem of inferring latent states (internal sensations) which, because of the relativity of judgment, have temporal dependencies. We propose a decontamination solution using a conditional random field with constraints motivated by psychological theories of relative judgment. Our exploration of decontamination models is supported by two experiments we conducted to obtain ground-truth rating data on a simple length estimation task. Our decontamination techniques yield an over 20% reduction in the error of human judgments.',\n",
       "  'id': '4162',\n",
       "  'title': 'Improving Human Judgments by Decontaminating Sequential Dependencies',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a novel method for inferring whether X causes Y or vice versa from joint observations of X and Y. The basic idea is to model the observed data using probabilistic latent variable models, which incorporate the effects of unobserved noise. To this end, we consider the hypothetical effect variable to be a function of the hypothetical cause variable and an independent noise term (not necessarily additive). An important novel aspect of our work is that we do not restrict the model class, but instead put general non-parametric priors on this function and on the distribution of the cause. The causal direction can then be inferred by using standard Bayesian model selection. We evaluate our approach on synthetic data and real-world data and report encouraging results.',\n",
       "  'id': '4173',\n",
       "  'title': 'Probabilistic latent variable models for distinguishing between cause and effect',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recent studies have shown that multiple kernel learning is very effective for object recognition, leading to the popularity  of kernel learning in computer vision problems. In this work, we develop an efficient algorithm for multi-label multiple kernel learning (ML-MKL). We assume that all the classes under  consideration  share the same combination of kernel functions, and the objective is to find the optimal kernel combination that benefits all the classes. Although several algorithms have been developed for ML-MKL, their computational cost is linear in the number of classes, making them unscalable when the number of classes is large, a challenge  frequently  encountered in visual object recognition. We address this computational challenge by developing a framework for ML-MKL that combines the worst-case analysis with stochastic approximation. Our analysis shows that the complexity of our algorithm is $O(m^{1/3}\\\\sqrt{ln m})$, where $m$ is the number of classes. Empirical studies with object recognition show that while achieving similar classification accuracy, the proposed method is significantly more efficient than the state-of-the-art algorithms for ML-MKL.',\n",
       "  'id': '4177',\n",
       "  'title': 'Multi-label Multiple Kernel Learning by Stochastic Approximation: Application to Visual Object Recognition',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We describe a log-bilinear\" model that computes class probabilities by combining an input vector multiplicatively with a vector of binary latent variables. Even though the latent variables can take on exponentially many possible combinations of values, we can efficiently compute the exact probability of each class by marginalizing over the latent variables. This makes it possible to get the exact gradient of the log likelihood. The bilinear score-functions are defined using a three-dimensional weight tensor, and we show that factorizing this tensor allows the model to encode invariances inherent in a task by learning a dictionary of invariant basis functions. Experiments on a set of benchmark problems show that this fully probabilistic model can achieve classification performance that is competitive with (kernel) SVMs, backpropagation, and deep belief nets.\"',\n",
       "  'id': '3895',\n",
       "  'title': 'Gated Softmax Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics. In this paper we propose a simple and fast algorithm SVP (Singular Value Projection) for rank minimization under affine constraints ARMP and show that SVP recovers the minimum rank solution for affine constraints that satisfy a Restricted Isometry Property} (RIP). Our method guarantees geometric convergence rate even in the presence of noise and requires strictly weaker assumptions on the RIP constants than the existing methods. We also introduce a Newton-step for our SVP framework to speed-up the convergence with substantial empirical gains. Next, we address a practically important application of ARMP - the problem of low-rank matrix completion, for which the defining affine constraints do not directly obey RIP, hence the guarantees of SVP do not hold. However, we provide partial progress towards a proof of exact recovery for our algorithm by showing a more restricted isometry property and observe empirically that our algorithm recovers low-rank Incoherent matrices from an almost optimal number of uniformly sampled entries. We also demonstrate empirically that our algorithms outperform existing methods, such as those of \\\\cite{CaiCS2008,LeeB2009b, KeshavanOM2009}, for ARMP and the matrix completion problem by an order of magnitude and are also more robust to noise and sampling schemes. In particular, results show that our SVP-Newton method is significantly robust to noise and performs impressively on a more realistic power-law sampling scheme for the matrix completion problem.',\n",
       "  'id': '3904',\n",
       "  'title': 'Guaranteed Rank Minimization via Singular Value Projection',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"When the distribution of unlabeled data in feature space lies along a manifold, the information it provides may be used by a learner to assist classification in a semi-supervised setting. While manifold learning is well-known in machine learning, the use of manifolds in human learning is largely unstudied. We perform a set of experiments which test a human's ability to use a manifold in a semi-supervised learning task, under varying conditions. We show that humans may be encouraged into using the manifold, overcoming the strong preference for a simple, axis-parallel linear boundary.\",\n",
       "  'id': '3905',\n",
       "  'title': 'Humans Learn Using Manifolds, Reluctantly',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Dimensionality reduction is commonly used in the setting of multi-label supervised classification to control the learning capacity and to provide a meaningful representation of the data. We introduce a simple forward probabilistic model which is a multinomial extension of reduced rank regression; we show that this model provides a probabilistic interpretation of discriminative clustering methods with added benefits in terms of number of hyperparameters and optimization. While expectation-maximization (EM) algorithm is commonly used to learn these models, its optimization usually leads to local minimum because it relies on a non-convex cost function with many such local minima. To avoid this problem, we introduce a local approximation of this cost function, which leads to a quadratic non-convex optimization problem over a product of simplices. In order to minimize such functions, we propose an efficient algorithm based on convex relaxation and low-rank representation of our data, which allows to deal with large instances. Experiments on text document classification show that the new model outperforms other supervised dimensionality reduction methods, while simulations on unsupervised clustering show that our probabilistic formulation has better properties than existing discriminative clustering methods.',\n",
       "  'id': '3907',\n",
       "  'title': 'Efficient Optimization for Discriminative Latent Class Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Support vector machines (SVM) are increasingly used in brain image analyses since they allow capturing complex multivariate relationships in the data. Moreover, when the kernel is linear, SVMs can be used to localize spatial patterns of discrimination between two groups of subjects. However, the features' spatial distribution is not taken into account. As a consequence, the optimal margin hyperplane is often scattered and lacks spatial coherence, making its anatomical interpretation difficult. This paper introduces a framework to spatially regularize SVM for brain image analysis. We show that Laplacian regularization provides a flexible framework to integrate various types of constraints and can be applied to both cortical surfaces and 3D brain images. The proposed framework is applied to the classification of MR images based on gray matter concentration maps and cortical thickness measures from 30 patients with Alzheimer's disease and 30 elderly controls. The results demonstrate that the proposed method enables natural spatial and anatomical regularization of the classifier.\",\n",
       "  'id': '3914',\n",
       "  'title': 'Spatial and anatomical regularization of SVM for brain image analysis',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Undirected graphical models encode in a graph $G$ the dependency structure of a random vector $Y$. In many applications, it is of interest to model $Y$ given another random vector $X$ as input. We refer to the problem of estimating the graph $G(x)$ of $Y$ conditioned on $X=x$ as ``graph-valued regression''. In this paper, we propose a semiparametric method for estimating $G(x)$ that builds a tree on the $X$ space just as in CART (classification and regression trees), but at each leaf of the tree estimates a graph. We call the method ``Graph-optimized CART'', or Go-CART. We study the theoretical properties of Go-CART using dyadic partitioning trees, establishing oracle inequalities on risk minimization and tree partition consistency. We also demonstrate the application of Go-CART to a meteorological dataset, showing how graph-valued regression can provide a useful tool for analyzing complex data.\",\n",
       "  'id': '3916',\n",
       "  'title': 'Graph-Valued Regression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'When stimulated with complex action potential sequences synapses exhibit spike timing-dependent plasticity (STDP) with attenuated and enhanced pre- and postsynaptic contributions to long-term synaptic modifications. In order to investigate the functional consequences of these contribution dynamics (CD) we propose a minimal model formulated in terms of differential equations. We find that our model reproduces a wide range of experimental results with a small number of biophysically interpretable parameters. The model allows to investigate the susceptibility of STDP to arbitrary time courses of pre- and postsynaptic activities, i.e. its nonlinear filter properties. We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic firing rates for which our model can be solved. It predicts synaptic strengthening for synchronous rate modulations. For low baseline rates modifications are dominant in the theta frequency range, a result which underlines the well known relevance of theta activities in hippocampus and cortex for learning. We also find emphasis of low baseline spike rates and suppression for high baseline rates. The latter suggests a mechanism of network activity regulation inherent in STDP. Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP in both spike-based as well as rate-based neuronal network models.',\n",
       "  'id': '3917',\n",
       "  'title': 'Spike timing-dependent plasticity as dynamic filter',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recently, batch-mode active learning has attracted a lot of attention. In this paper, we propose a novel batch-mode active learning approach that selects a batch of queries in each iteration by maximizing a natural form of mutual information criterion between the labeled and unlabeled instances. By employing a Gaussian process framework, this mutual information based instance selection problem can be formulated as a matrix partition problem. Although the matrix partition is an NP-hard combinatorial optimization problem, we show a good local solution can be obtained by exploiting an effective local optimization technique on the relaxed continuous optimization problem. The proposed active learning approach is independent of employed classification models. Our empirical studies show this approach can achieve comparable or superior performance to discriminative batch-mode active learning methods.',\n",
       "  'id': '3919',\n",
       "  'title': 'Active Instance Sampling via Matrix Partition',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Latent variable models are a powerful tool for addressing several tasks in machine learning. However, the algorithms for learning the parameters of latent variable models are prone to getting stuck in a bad local optimum. To alleviate this problem, we build on the intuition that, rather than considering all samples simultaneously, the algorithm should be presented with the training data in a meaningful order that facilitates learning. The order of the samples is determined by how easy they are. The main challenge is that often we are not provided with a readily computable measure of the easiness of samples. We address this issue by  proposing a novel, iterative self-paced learning algorithm where each iteration simultaneously selects easy samples and learns a new parameter vector. The number of samples selected is governed by a weight that is annealed until the entire training data has been considered. We empirically demonstrate that the self-paced learning algorithm outperforms the state of the art method for learning a latent structural SVM on four applications: object localization, noun phrase coreference, motif finding and handwritten digit recognition.',\n",
       "  'id': '3923',\n",
       "  'title': 'Self-Paced Learning for Latent Variable Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We cast the problem of identifying basic blocks of code in a binary executable as learning a mapping from a byte sequence to a segmentation of the sequence. In general, inference in segmentation models, such as semi-CRFs, can be cubic in the length of the sequence. By taking advantage of the structure of our problem, we derive a linear-time inference algorithm which makes our approach practical, given that even small programs are tens or hundreds of thousands bytes long. Furthermore, we introduce two loss functions which are appropriate for our problem and show how to use structural SVMs to optimize the learned mapping for these losses. Finally, we present experimental results that demonstrate the advantages of our method against a strong baseline.',\n",
       "  'id': '3925',\n",
       "  'title': 'Static Analysis of Binary Executables Using Structural SVMs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper proposes a principled extension of the traditional single-layer flat sparse coding scheme, where a two-layer coding scheme is derived based on theoretical analysis of nonlinear functional approximation that extends recent results for local coordinate coding. The two-layer approach can be easily generalized to deeper structures in a hierarchical multiple-layer manner. Empirically, it is shown that the deep coding approach yields improved performance in benchmark datasets.',\n",
       "  'id': '3929',\n",
       "  'title': 'Deep Coding Network',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Continuous Markov random fields are a general formalism to model joint probability distributions over events with continuous outcomes. We prove that marginal computation for constrained continuous MRFs is #P-hard in general and present a polynomial-time approximation scheme under mild assumptions on the structure of the random field. Moreover, we introduce a sampling algorithm to compute marginal distributions and develop novel techniques to increase its efficiency. Continuous MRFs are a general purpose probabilistic modeling tool and we demonstrate how they can be applied to statistical relational learning. On the problem of collective classification, we evaluate our algorithm and show that the standard deviation of marginals serves as a useful measure of confidence.',\n",
       "  'id': '3942',\n",
       "  'title': 'Computing Marginal Distributions over Continuous Markov Networks for Statistical Relational Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'It has been speculated that the human motion system combines noisy measurements with prior expectations in an optimal, or rational, manner. The basic goal of our work is to discover experimentally which prior distribution is used. More specifically, we seek to infer the functional form of the motion prior from the performance of human subjects on motion estimation tasks. We restricted ourselves to priors which combine three terms for motion slowness, first-order smoothness, and second-order smoothness. We focused on two functional forms for prior distributions: L2-norm and L1-norm regularization corresponding to the Gaussian and Laplace distributions respectively. In our first experimental session we estimate the weights of the three terms for each functional form to maximize the fit to human performance. We then measured human performance for motion tasks and found that we obtained better fit for the L1-norm (Laplace) than for the L2-norm (Gaussian). We note that the L1-norm is also a better fit to the statistics of motion in natural environments. In addition, we found large weights for the second-order smoothness term, indicating the importance of high-order smoothness compared to slowness and lower-order smoothness. To validate our results further, we used the best fit models using the L1-norm to predict human performance in a second session with different experimental setups. Our results showed excellent agreement between human performance and model prediction -- ranging from 3\\\\% to 8\\\\% for five human subjects over ten experimental conditions -- and give further support that the human visual system uses an L1-norm (Laplace) prior.',\n",
       "  'id': '3948',\n",
       "  'title': 'Functional form of motion priors in human motion perception',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The Diffusion Network(DN) is a stochastic recurrent network which has been shown capable of modeling the distributions of continuous-valued, continuous-time paths. However, the dynamics of the DN are governed by stochastic differential equations, making the DN unfavourable for simulation in a digital computer. This paper presents the implementation of the DN in analogue Very Large Scale Integration, enabling the DN to be simulated in real time. Moreover, the log-domain representation is applied to the DN, allowing the supply voltage and thus the power consumption to be reduced without limiting the dynamic ranges for diffusion processes. A VLSI chip containing a DN with two stochastic units has been designed and fabricated. The design of component circuits will be described, so will the simulation of the full system be presented. The simulation results demonstrate that the DN in VLSI is able to regenerate various types of continuous paths in real-time.',\n",
       "  'id': '3950',\n",
       "  'title': 'A Log-Domain Implementation of the Diffusion Network in Very Large Scale Integration',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Network models are widely used to capture interactions among component of complex systems, such as social and biological. To understand their behavior, it is often necessary to analyze functionally related components of the system, corresponding to subsystems. Therefore, the analysis of subnetworks may provide additional insight into the behavior of the system, not evident from individual components. We propose a novel approach for incorporating available network information into the analysis of arbitrary subnetworks. The proposed method offers an efficient dimension reduction strategy using Laplacian eigenmaps with Neumann boundary conditions, and provides a flexible inference framework for analysis of subnetworks, based on a group-penalized principal component regression model on graphs. Asymptotic properties of the proposed inference method, as well as the choice of the tuning parameter for control of the false positive rate are discussed in high dimensional settings. The performance of the proposed methodology is illustrated using simulated and real data examples from biology.',\n",
       "  'id': '3957',\n",
       "  'title': 'Penalized Principal Component Regression on Graphs for Analysis of Subnetworks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The hypothesis that high dimensional data tends to lie in the vicinity of a low dimensional manifold is the basis of a collection of methodologies termed Manifold Learning. In this paper, we study statistical aspects of the question of fitting a manifold with a nearly optimal least squared error.   Given upper bounds on the dimension, volume, and curvature, we show that Empirical Risk Minimization can produce a nearly optimal manifold using a number of random samples that is {\\\\it independent} of the ambient dimension of the space in which data lie. We obtain an upper bound on the required number of samples that depends polynomially on the curvature, exponentially on the intrinsic dimension, and linearly on the intrinsic volume. For constant error, we prove a matching minimax lower bound on the sample complexity that shows that this dependence on intrinsic dimension, volume and curvature is unavoidable. Whether the known lower bound of $O(\\\\frac{k}{\\\\eps^2} + \\\\frac{\\\\log \\\\frac{1}{\\\\de}}{\\\\eps^2})$ for the sample complexity of Empirical Risk minimization on $k-$means applied to data in a unit ball of arbitrary dimension is tight, has been an open question since 1997 \\\\cite{bart2}. Here $\\\\eps$ is the desired bound on the error and $\\\\de$ is a bound on the probability of failure. We improve the best currently known upper bound \\\\cite{pontil} of $O(\\\\frac{k^2}{\\\\eps^2} + \\\\frac{\\\\log \\\\frac{1}{\\\\de}}{\\\\eps^2})$ to $O\\\\left(\\\\frac{k}{\\\\eps^2}\\\\left(\\\\min\\\\left(k, \\\\frac{\\\\log^4 \\\\frac{k}{\\\\eps}}{\\\\eps^2}\\\\right)\\\\right) + \\\\frac{\\\\log \\\\frac{1}{\\\\de}}{\\\\eps^2}\\\\right)$. Based on these results, we devise a simple algorithm for $k-$means and another that uses a family of convex programs to fit a piecewise linear curve of a specified length to  high dimensional data, where the sample complexity is independent of the ambient dimension.',\n",
       "  'id': '3958',\n",
       "  'title': 'Sample Complexity of Testing the Manifold Hypothesis',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We develop a deterministic single-pass algorithm for latent Dirichlet allocation (LDA) in order to process received documents one at a time and then discard them in an excess text stream. Our algorithm does not need to store old statistics for all data. The proposed algorithm is much faster than a batch algorithm and is comparable to the batch algorithm in terms of perplexity in experiments.',\n",
       "  'id': '3959',\n",
       "  'title': 'Deterministic Single-Pass Algorithm for LDA',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is introduced because Q-learning uses the maximum action value as an approximation for the maximum expected action value. We introduce an alternative way to approximate the maximum expected value for any set of random variables. The obtained double estimator method is shown to sometimes underestimate rather than overestimate the maximum expected value. We apply the double estimator to Q-learning to construct Double Q-learning, a new off-policy reinforcement learning algorithm. We show the new algorithm converges to the optimal policy and that it performs well in some settings in which Q-learning performs poorly due to its overestimation.',\n",
       "  'id': '3964',\n",
       "  'title': 'Double Q-learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider least-squares regression using a randomly generated subspace G_P\\\\subset F of finite dimension P, where F is a function space of infinite dimension, e.g.~L_2([0,1]^d).  G_P is defined as the span of P random features  that are linear combinations of the basis functions of F weighted by random Gaussian i.i.d.~coefficients. In particular, we consider multi-resolution random combinations at all scales of a given mother function,  such as a hat function or a wavelet. In this latter case, the resulting Gaussian objects are called {\\\\em scrambled wavelets} and we show that they enable to approximate functions in Sobolev spaces H^s([0,1]^d). As a result, given N data, the least-squares estimate \\\\hat g built from P scrambled wavelets has excess risk ||f^* - \\\\hat g||_\\\\P^2 = O(||f^*||^2_{H^s([0,1]^d)}(\\\\log N)/P + P(\\\\log N )/N) for target functions f^*\\\\in H^s([0,1]^d) of smoothness order s>d/2. An interesting aspect of the resulting bounds is that they do not depend on the distribution \\\\P from which the data are generated, which is important in a statistical regression setting considered here. Randomization enables to adapt to any possible distribution.   We conclude by describing an efficient numerical implementation using lazy expansions with numerical complexity \\\\tilde O(2^d N^{3/2}\\\\log N + N^2), where d is the dimension of the input space.',\n",
       "  'id': '3973',\n",
       "  'title': 'Scrambled Objects for Least-Squares Regression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We deal with the problem of variable selection when  variables must be selected group-wise, with possibly overlapping groups defined a priori. In particular we propose a new optimization procedure  for solving the regularized algorithm presented in Jacob et al. 09, where the group lasso  penalty is generalized to overlapping groups of variables. While in Jacob et al. 09 the proposed implementation requires explicit replication of the variables belonging to more than one group, our iterative procedure is based on a combination of proximal methods in the primal space and constrained Newton method in a reduced dual space, corresponding to the active groups.  This procedure provides a scalable alternative with no need for data duplication, and allows to deal with high dimensional problems without pre-processing  to reduce the  dimensionality of the data.  The computational advantages of our scheme with respect to state-of-the-art algorithms  using data duplication are shown empirically with numerical simulations.',\n",
       "  'id': '3974',\n",
       "  'title': 'A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Motivated by an application to unsupervised part-of-speech tagging, we present an algorithm for the Euclidean embedding of large sets of categorical data based on co-occurrence statistics. We use the CODE model of Globerson et al. but constrain the embedding to lie on a high-dimensional unit sphere. This constraint allows for efficient optimization, even in the case of large datasets and high embedding dimensionality. Using k-means clustering of the embedded data, our approach efficiently produces state-of-the-art results. We analyze the reasons why the sphere constraint is beneficial in this application, and conjecture that these reasons might apply quite generally to other large-scale tasks.',\n",
       "  'id': '3979',\n",
       "  'title': 'Sphere Embedding: An Application to Part-of-Speech Induction',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The determination of dominant orientation at a given image location is formulated as a decision-theoretic question. This leads to a novel measure for the dominance of a given orientation $\\\\theta$, which is similar to that used by SIFT. It is then shown that the new measure can be computed with a network that implements the sequence of operations of the standard neurophysiological model of V1. The measure can thus be seen as a biologically plausible version of SIFT, and is denoted as bioSIFT. The network units are shown to exhibit trademark properties of V1 neurons, such as cross-orientation suppression, sparseness and independence. The connection between SIFT and biological vision provides a justification for the success of SIFT-like features and reinforces the importance of contrast normalization in computer vision. We illustrate this by replacing the Gabor units of an HMAX network with the new bioSIFT units. This is shown to lead to significant gains for classification tasks, leading to state-of-the-art performance among biologically inspired network models and performance competitive with the best non-biological object recognition systems.',\n",
       "  'id': '3982',\n",
       "  'title': 'A biologically plausible network for the computation of orientation dominance',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a class of sparse coding models that utilizes a Laplacian Scale Mixture (LSM) prior to model dependencies among coefficients. Each coefficient is modeled as a Laplacian distribution with a variable scale parameter, with a Gamma distribution prior over the scale parameter. We show that, due to the conjugacy of the Gamma prior, it is possible to derive efficient inference procedures for both the coefficients and the scale parameter. When the scale parameters of a group of coefficients are combined into a single variable, it is possible to describe the dependencies that occur due to common amplitude fluctuations among coefficients, which have been shown to constitute a large fraction of the redundancy in natural images. We show that, as a consequence of this group sparse coding, the resulting inference of the coefficients follows a divisive normalization rule, and that this may be efficiently implemented a network architecture similar to that which has been proposed to occur in primary visual cortex. We also demonstrate improvements in image coding and compressive sensing recovery using the LSM model.',\n",
       "  'id': '3997',\n",
       "  'title': 'Group Sparse Coding with a Laplacian Scale Mixture Prior',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Dimensionality reduction is often needed in many applications due to the high dimensionality of the data involved. In this paper, we first analyze the scatter measures used in the conventional linear discriminant analysis~(LDA) model and note that the formulation is based on the average-case view. Based on this analysis, we then propose a new dimensionality reduction method called worst-case linear discriminant analysis~(WLDA) by defining new between-class and within-class scatter measures. This new model adopts the worst-case view which arguably is more suitable for applications such as classification. When the number of training data points or the number of features is not very large, we relax the optimization problem involved and formulate it as a metric learning problem. Otherwise, we take a greedy approach by finding one direction of the transformation at a time. Moreover, we also analyze a special case of WLDA to show its relationship with conventional LDA. Experiments conducted on several benchmark datasets demonstrate the effectiveness of WLDA when compared with some related dimensionality reduction methods.',\n",
       "  'id': '3998',\n",
       "  'title': 'Worst-Case Linear Discriminant Analysis',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The paper develops a connection between traditional perceptron algorithms and recently introduced herding algorithms. It is shown that both algorithms can be viewed as an application of the perceptron cycling theorem. This connection strengthens some herding results and suggests new (supervised) herding algorithms that, like CRFs or discriminative RBMs, make predictions by conditioning on the input attributes. We develop and investigate variants of conditional herding, and show that conditional herding leads to practical algorithms that perform better than or on par with related classifiers such as the voted perceptron and the discriminative RBM.',\n",
       "  'id': '4004',\n",
       "  'title': 'On Herding and the Perceptron Cycling Theorem',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'With the increase in available data parallel machine learning has   become an increasingly pressing problem. In this paper we present   the first parallel stochastic gradient descent algorithm including a   detailed analysis and experimental evidence. Unlike prior work on   parallel optimization algorithms our   variant comes with parallel acceleration guarantees and it poses no   overly tight latency constraints, which might only be available in   the multicore setting. Our analysis introduces a novel proof   technique --- contractive mappings to quantify the   speed of convergence of parameter distributions to their asymptotic   limits. As a side effect this answers the question of how quickly   stochastic gradient descent algorithms reach the asymptotically   normal regime.',\n",
       "  'id': '4006',\n",
       "  'title': 'Parallelized Stochastic Gradient Descent',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present policy gradient results within the framework of linearly-solvable MDPs. For the first time, compatible function approximators and natural policy gradients are obtained by estimating the cost-to-go function, rather than the (much larger) state-action advantage function as is necessary in traditional MDPs. We also develop the first compatible function approximators and natural policy gradients for continuous-time stochastic systems.',\n",
       "  'id': '4013',\n",
       "  'title': 'Policy gradients in linearly-solvable MDPs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Multi-class classification becomes challenging at test time when the number of classes is very large and testing against every possible class can become computationally infeasible. This problem can be alleviated by imposing (or learning) a structure over the set of classes. We propose an algorithm for learning a tree-structure of classifiers which, by optimizing the overall tree loss, provides superior accuracy to existing tree labeling methods. We also propose a method that learns to embed labels in a low dimensional space that is faster than non-embedding approaches and has superior accuracy to existing embedding approaches. Finally we combine the two ideas resulting in the label embedding tree that outperforms alternative methods including One-vs-Rest while being orders of magnitude faster.',\n",
       "  'id': '4027',\n",
       "  'title': 'Label Embedding Trees for Large Multi-Class Tasks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'As increasing amounts of sensitive personal information finds its way into data repositories, it is important to develop analysis mechanisms that can derive aggregate information from these repositories without revealing information about individual data instances. Though the differential privacy model  provides a framework to analyze such mechanisms for databases belonging to a single party, this framework has not yet been considered in a multi-party setting. In this paper, we propose a privacy-preserving protocol for composing a differentially private aggregate classifier  using classifiers trained locally by separate mutually untrusting parties. The protocol allows these parties to interact with an untrusted curator to construct additive shares of a perturbed aggregate classifier. We also present a detailed theoretical analysis containing a proof of differential privacy  of the perturbed aggregate classifier and a bound on the excess risk introduced by the perturbation. We verify the bound with an experimental evaluation on a real dataset.',\n",
       "  'id': '4034',\n",
       "  'title': 'Multiparty Differential Privacy via Aggregation of Locally Trained Classifiers',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The Random Projection Tree (RPTree) structures proposed in [Dasgupta-Freund-STOC-08] are space partitioning data structures that automatically adapt to various notions of intrinsic dimensionality of data. We prove new results for both the RPTree-Max and the RPTree-Mean data structures. Our result for RPTree-Max gives a near-optimal bound on the number of levels required by this data structure to reduce the size of its cells by a factor s >= 2. We also prove a packing lemma for this data structure. Our final result shows that low-dimensional manifolds possess bounded Local Covariance Dimension. As a consequence we show that RPTree-Mean adapts to manifold dimension as well.',\n",
       "  'id': '4039',\n",
       "  'title': 'Random Projection Trees Revisited',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a new supervised learning framework for visual object counting tasks, such as estimating the number of cells in a microscopic image or the number of humans in surveillance video frames. We focus on the practically-attractive case when the training images are annotated with dots (one dot per object).   Our goal is to accurately estimate the count. However, we evade the hard task of learning to detect and localize individual object instances. Instead, we cast the problem as that of estimating an image density whose integral over any image region gives the count of objects within that region. Learning to infer such density can be formulated as a minimization of a regularized risk quadratic cost function. We introduce a new loss function, which is well-suited for such learning, and at the same time can be computed efficiently via a maximum subarray algorithm. The learning can then be posed as a convex quadratic program solvable with cutting-plane optimization.  The proposed framework is very flexible as it can accept any domain-specific visual features. Once trained, our system provides accurate object counts and requires a very small time overhead over the feature extraction step, making it a good candidate for applications involving real-time processing or dealing with huge amount of visual data.',\n",
       "  'id': '4043',\n",
       "  'title': 'Learning To Count Objects in Images',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In this paper, we regard clustering as ensembles of k-ary affinity relations and clusters correspond to subsets of objects with maximal average affinity relations. The average affinity relation of a cluster is relaxed and well approximated by a constrained homogenous function. We present an efficient procedure to solve this optimization problem, and show that the underlying clusters can be robustly revealed by using priors systematically constructed from the data. Our method can automatically select some points to form clusters, leaving other points un-grouped; thus it is inherently robust to large numbers of outliers, which has seriously limited the applicability of classical methods. Our method also provides a unified solution to clustering from k-ary affinity relations with k ? 2, that is, it applies to both graph-based and hypergraph-based clustering problems. Both theoretical analysis and experimental results show the superiority of our method over classical solutions to the clustering problem, especially when there exists a large number of outliers.',\n",
       "  'id': '4045',\n",
       "  'title': 'Robust Clustering as Ensembles of Affinity Relations',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We study several classes of interactive assistants from the points of view of decision theory and computational complexity. We first introduce a class of POMDPs called hidden-goal MDPs (HGMDPs), which formalize the problem of interactively assisting an agent whose goal is hidden and whose actions are observable. In spite of its restricted nature, we show that optimal action selection in finite horizon HGMDPs is PSPACE-complete even in domains with deterministic dynamics. We then introduce a more restricted model called helper action MDPs (HAMDPs), where the assistant's action is accepted by the agent when it is helpful, and can be easily ignored by the agent otherwise. We show classes of HAMDPs that are complete for PSPACE and NP along with a polynomial time class. Furthermore, we show that for general HAMDPs a simple myopic policy achieves a regret, compared to an omniscient assistant, that is bounded by the entropy of the initial goal distribution. A variation of this policy is shown to achieve worst-case regret that is logarithmic in the number of goals for any goal distribution.\",\n",
       "  'id': '4052',\n",
       "  'title': 'A Computational Decision Theory for Interactive Assistants',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Experts (human or computer) are often required to assess the probability of uncertain events. When a collection of experts independently assess events that are structurally interrelated, the resulting assessment may violate fundamental laws of probability. Such an assessment is termed incoherent. In this work we investigate how the problem of incoherence may be affected by allowing experts to specify likelihood models and then update their assessments based on the realization of a globally-observable random sequence.',\n",
       "  'id': '4053',\n",
       "  'title': 'Probabilistic Belief Revision with Structural Constraints',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Lifted inference algorithms for representations that combine first-order logic and probabilistic graphical models have been the focus of much recent research. All lifted algorithms developed to date are based on the same underlying idea: take a standard probabilistic inference algorithm (e.g., variable elimination, belief propagation etc.) and improve its efficiency by exploiting repeated structure in the first-order model. In this paper, we propose an approach from the other side in that we use techniques from logic for probabilistic inference. In particular, we define a set of rules that look only at the logical representation to identify models for which exact efficient inference is possible. We show that our rules yield several new tractable classes that cannot be solved efficiently by any of the existing techniques.',\n",
       "  'id': '4067',\n",
       "  'title': 'Lifted Inference Seen from the Other Side : The Tractable Features',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'For a density f on R^d, a high-density cluster is any connected component of {x: f(x) >= c}, for some c > 0. The set of all high-density clusters form a hierarchy called the cluster tree of f. We present a procedure for estimating the cluster tree given samples from f. We give finite-sample convergence rates for our algorithm, as well as lower bounds on the sample complexity of this estimation problem.',\n",
       "  'id': '4068',\n",
       "  'title': 'Rates of convergence for the cluster tree',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We present simple and computationally efficient nonparametric estimators of R\\\\'enyi entropy and mutual information based on an i.i.d. sample drawn from an unknown, absolutely continuous distribution over $\\\\R^d$. The estimators are calculated as the sum of $p$-th powers of the Euclidean lengths of the edges of the `generalized nearest-neighbor' graph of the sample and the empirical copula of the sample respectively. For the first time, we prove the almost sure consistency of these estimators and upper bounds on their rates of convergence, the latter of which under the assumption that the density underlying the sample is Lipschitz continuous. Experiments demonstrate their usefulness in independent subspace analysis.\",\n",
       "  'id': '4072',\n",
       "  'title': 'Estimation of R?nyi Entropy and Mutual Information Based on Generalized Nearest-Neighbor Graphs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reflects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data.  Learning such models entails two main challenges:  i) modeling full brain connectivity is a difficult estimation problem that faces the curse of dimensionality and  ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging.  We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the first report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the first time that known cognitive networks appear as the integrated communities of functional connectivity graph.',\n",
       "  'id': '4080',\n",
       "  'title': 'Brain covariance selection: better individual functional connectivity models using population prior',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Bayesian optimization methods are often used to optimize unknown functions that are costly to evaluate. Typically, these methods sequentially select inputs to be evaluated one at a time based on a posterior over the unknown function that is updated after each evaluation. There are a number of effective sequential policies for selecting the individual inputs. In many applications, however, it is desirable to perform multiple evaluations in parallel, which requires selecting batches of multiple inputs to evaluate at once. In this paper, we propose a novel approach to batch Bayesian optimization, providing a policy for selecting batches of inputs with the goal of optimizing the function as efficiently as possible. The key idea is to exploit the availability of high-quality and efficient sequential policies, by using Monte-Carlo simulation to select input batches that closely match their expected behavior. To the best of our knowledge, this is the first batch selection policy for Bayesian optimization. Our experimental results on six benchmarks show that the proposed approach significantly outperforms two baselines and can lead to large advantages over a top sequential approach in terms of performance per unit time.',\n",
       "  'id': '4083',\n",
       "  'title': 'Batch Bayesian Optimization via Simulation Matching',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recent work in reinforcement learning has emphasized the power of L1 regularization to perform feature selection and prevent overfitting. We propose formulating the L1 regularized linear fixed point problem as a linear complementarity problem (LCP). This formulation offers several advantages over the LARS-inspired formulation, LARS-TD. The LCP formulation allows the use of efficient off-the-shelf solvers, leads to a new uniqueness result, and can be initialized with starting points from similar problems (warm starts). We demonstrate that warm starts, as well as the efficiency of LCP solvers, can speed up policy iteration. Moreover, warm starts permit a form of modified policy iteration that can be used to approximate a greedy\" homotopy path, a generalization of the LARS-TD homotopy path that combines policy evaluation and optimization.\"',\n",
       "  'id': '4086',\n",
       "  'title': 'Linear Complementarity for Regularized Policy Evaluation and Improvement',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We describe a model based on a Boltzmann machine with third-order connections that can learn how to accumulate information about a shape over several fixations. The model uses a retina that only has enough high resolution pixels to cover a small area of the image, so it must decide on a sequence of fixations and it must combine the glimpse\" at each fixation with the location of the fixation before integrating the information with information from other glimpses of the same object. We evaluate this model on a synthetic dataset and two image classification datasets, showing that it can perform at least as well as a model trained on whole images.\"',\n",
       "  'id': '4089',\n",
       "  'title': 'Learning to combine foveal glimpses with a third-order Boltzmann machine',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'While clinicians can accurately identify different types of heartbeats in electrocardiograms (ECGs) from different patients, researchers have had limited success in applying supervised machine learning to the same task. The problem is made challenging by the variety of tasks, inter- and intra-patient differences, an often severe class imbalance, and the high cost of getting cardiologists to label data for individual patients. We address these difficulties using active learning to perform patient-adaptive and task-adaptive heartbeat classification. When tested on a benchmark database of cardiologist annotated ECG recordings, our method had considerably better performance than other recently proposed methods on the two primary classification tasks recommended by the Association for the Advancement of Medical Instrumentation. Additionally, our method required over 90% less patient-specific training data than the methods to which we compared it.',\n",
       "  'id': '4091',\n",
       "  'title': 'Active Learning Applied to Patient-Adaptive Heartbeat Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study convex stochastic optimization problems where a noisy objective function value is observed after a decision is made. There are many stochastic optimization problems whose behavior depends on an exogenous state variable which affects the shape of the objective function. Currently, there is no general purpose algorithm to solve this class of problems. We use nonparametric density estimation for the joint distribution of state-outcome pairs to create weights for previous observations. The weights effectively group similar states. Those similar to the current state are used to create a convex, deterministic approximation of the objective function. We propose two solution methods that depend on the problem characteristics: function-based and gradient-based optimization. We offer two weighting schemes, kernel based weights and Dirichlet process based weights, for use with the solution methods. The weights and solution methods are tested on a synthetic multi-product newsvendor problem and the hour ahead wind commitment problem. Our results show Dirichlet process weights can offer substantial benefits over kernel based weights and, more generally, that nonparametric estimation methods provide good solutions to otherwise intractable problems.',\n",
       "  'id': '4098',\n",
       "  'title': 'Nonparametric Density Estimation for Stochastic Optimization with an Observable State Variable',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Gaussian graphical models are of great interest in statistical learning.  Because the conditional independencies between different nodes correspond to zero entries in the inverse covariance matrix of the Gaussian distribution, one can learn the structure of the graph by estimating a sparse inverse covariance matrix from sample data, by solving a convex maximum likelihood problem with an $\\\\ell_1$-regularization term. In this paper, we propose a first-order method based on an alternating linearization technique that exploits the problem's special structure; in particular, the subproblems solved in each iteration have closed-form solutions. Moreover, our algorithm obtains an $\\\\epsilon$-optimal solution in $O(1/\\\\epsilon)$ iterations. Numerical experiments on both synthetic  and real data from gene association networks show that a practical version of  this algorithm outperforms other competitive algorithms.\",\n",
       "  'id': '4099',\n",
       "  'title': 'Sparse Inverse Covariance Selection via Alternating Linearization Methods',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Generalized Binary Search (GBS) is a well known greedy algorithm for identifying an unknown object while minimizing the number of yes\" or \"no\" questions posed about that object, and arises in problems such as active learning and active diagnosis. Here, we provide a coding-theoretic interpretation for GBS and show that GBS can be viewed as a top-down algorithm that greedily minimizes the expected number of queries required to identify an object. This interpretation is then used to extend GBS in two ways. First, we consider the case where the objects are partitioned into groups, and the objective is to identify only the group to which the object belongs. Then, we consider the case where the cost of identifying an object grows exponentially in the number of queries. In each case, we present an exact formula for the objective function involving Shannon or Renyi entropy, and develop a greedy algorithm for minimizing it.\"',\n",
       "  'id': '4103',\n",
       "  'title': 'Extensions of Generalized Binary Search to Group Identification and Exponential Costs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Metric constraints are known to be highly discriminative for many objects, but if training is limited to data captured from a particular 3-D sensor the quantity of training data may be severly limited. In this paper, we show how a crucial aspect of 3-D information?object and feature absolute size?can be added to models learned from commonly available online imagery, without use of any 3-D sensing or re- construction at training time. Such models can be utilized at test time together with explicit 3-D sensing to perform robust search. Our model uses a ?2.1D? local feature, which combines traditional appearance gradient statistics with an estimate of average absolute depth within the local window. We show how category size information can be obtained from online images by exploiting relatively unbiquitous metadata fields specifying camera intrinstics. We develop an efficient metric branch-and-bound algorithm for our search task, imposing 3-D size constraints as part of an optimal search for a set of features which indicate the presence of a category. Experiments on test scenes captured with a traditional stereo rig are shown, exploiting training data from from purely monocular sources with associated EXIF metadata.',\n",
       "  'id': '4104',\n",
       "  'title': 'Size Matters: Metric Visual Search Constraints from Monocular Metadata',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Size, color, and orientation have long been considered elementary features whose attributes are extracted in parallel and available to guide the deployment of attention. If each is processed in the same fashion with simply a different set of local detectors, one would expect similar search behaviours on localizing an equivalent flickering change among identically laid out disks. We analyze feature transitions associated with saccadic search and find out that size, color, and orientation are not alike in dynamic attribute processing over time. The Markovian feature transition is attractive for size, repulsive for color, and largely reversible for orientation.',\n",
       "  'id': '4112',\n",
       "  'title': 'Feature Transitions with Saccadic Search: Size, Color, and Orientation Are Not Alike',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Despite the ubiquity of clustering as a tool in unsupervised learning, there is not yet a consensus on a formal theory, and the vast majority  of work in this direction has focused on unsupervised clustering. We study a recently proposed framework for supervised clustering where there is access to a teacher. We give an improved generic algorithm to cluster any concept class  in that model. Our algorithm is query-efficient in the sense that it involves only a small amount  of interaction with the teacher. We also present and study two natural generalizations of the model.  The model assumes that the teacher response to the algorithm is perfect. We eliminate  this limitation by proposing a noisy model and give an algorithm for  clustering the class of intervals in this noisy model. We also propose a dynamic model where the teacher sees  a random subset of the points. Finally, for datasets  satisfying a spectrum of weak to strong properties, we give query bounds, and show that a class  of clustering functions containing Single-Linkage will find the target clustering under the strongest  property.',\n",
       "  'id': '4115',\n",
       "  'title': 'Supervised Clustering',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We develop a theory of online learning by defining several complexity measures. Among them are analogues of Rademacher complexity, covering numbers and fat-shattering dimension from statistical learning theory. Relationship among these complexity measures, their connection to online learning, and tools for bounding them are provided. We apply these results to various learning problems. We provide a complete characterization of online learnability in the supervised setting.',\n",
       "  'id': '4116',\n",
       "  'title': 'Online Learning: Random Averages, Combinatorial Parameters, and Learnability',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We apply the framework of kernel dimension reduction, originally designed for supervised problems, to unsupervised dimensionality reduction. In this framework, kernel-based measures of independence are used to derive low-dimensional representations that maximally capture information in covariates in order to predict responses. We extend this idea and develop similarly motivated measures for unsupervised problems where covariates and responses are the same. Our empirical studies show that the resulting compact representation yields meaningful and appealing visualization and clustering of data. Furthermore, when used in conjunction with supervised learners for classification, our methods lead to lower classification errors than state-of-the-art methods, especially when embedding data in spaces of very few dimensions.',\n",
       "  'id': '4122',\n",
       "  'title': 'Unsupervised Kernel Dimension Reduction',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Hypothesis testing on point processes has several applications such as model fitting, plasticity detection, and non-stationarity detection. Standard tools for hypothesis testing include tests on mean firing rate and time varying rate function. However, these statistics do not fully describe a point process and thus the tests can be misleading. In this paper, we introduce a family of non-parametric divergence measures for hypothesis testing. We extend the traditional Kolmogorov--Smirnov and Cramer--von-Mises tests for point process via stratification. The proposed divergence measures compare the underlying probability structure and, thus, is zero if and only if the point processes are the same. This leads to a more robust test of hypothesis. We prove consistency and show that these measures can be efficiently estimated from data. We demonstrate an application of using the proposed divergence as a cost function to find optimally matched spike trains.',\n",
       "  'id': '4126',\n",
       "  'title': 'A novel family of non-parametric cumulative based divergences for point processes',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"To localise the source of a sound, we use location-specific properties of the signals received at the two ears caused by the asymmetric filtering of the original sound by our head and pinnae, the head-related transfer functions (HRTFs). These HRTFs change throughout an organism's lifetime, during development for example, and so the required neural circuitry cannot be entirely hardwired. Since HRTFs are not directly accessible from perceptual experience, they can only be inferred from filtered sounds. We present a spiking neural network model of sound localisation based on extracting location-specific synchrony patterns, and a simple supervised algorithm to learn the mapping between synchrony patterns and locations from a set of example sounds, with no previous knowledge of HRTFs. After learning, our model was able to accurately localise new sounds in both azimuth and elevation, including the difficult task of distinguishing sounds coming from the front and back.\",\n",
       "  'id': '4127',\n",
       "  'title': 'Learning to localise sounds with spiking neural networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'To cope with concept drift, we placed a probability distribution over the location of the most-recent drift point. We used Bayesian model comparison to update this distribution from the predictions of models trained on blocks of consecutive observations and pruned potential drift points with low probability. We compare our approach to a non-probabilistic method for drift and a probabilistic method for change-point detection. In our experiments, our approach generally yielded improved accuracy and/or speed over these other methods.',\n",
       "  'id': '4129',\n",
       "  'title': 'A Bayesian Approach to Concept Drift',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose an unsupervised method for learning multi-stage   hierarchies of sparse convolutional features. While sparse coding   has become an increasingly popular method for learning visual   features, it is most often trained at the patch level. Applying the   resulting filters convolutionally results in highly redundant codes   because overlapping patches are encoded in isolation.  By training   convolutionally over large image windows, our method reduces the   redudancy between feature vectors at neighboring locations and   improves the efficiency of the overall representation. In addition   to a linear decoder that reconstructs the image from sparse   features, our method trains an efficient feed-forward encoder that   predicts quasi-sparse features from the input.  While patch-based   training rarely produces anything but oriented edge detectors, we   show that convolutional training produces highly diverse filters,   including center-surround filters, corner detectors, cross   detectors, and oriented grating detectors.  We show that using these   filters in multi-stage convolutional network architecture improves   performance on a number of visual recognition and detection tasks.',\n",
       "  'id': '4133',\n",
       "  'title': 'Learning Convolutional Feature Hierarchies for Visual Recognition',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Bayesian approaches to preference elicitation (PE) are particularly attractive due to their ability to explicitly model uncertainty in users' latent utility functions. However, previous approaches to Bayesian PE have ignored the important problem of generalizing from previous users to an unseen user in order to reduce the elicitation burden on new users. In this paper, we address this deficiency by introducing a Gaussian Process (GP) prior over users' latent utility functions on the joint space of user and item features. We learn the hyper-parameters of this GP on a set of preferences of previous users and use it to aid in the elicitation process for a new user. This approach provides a flexible model of a multi-user utility function, facilitates an efficient value of information (VOI) heuristic query selection strategy, and provides a principled way to incorporate the elicitations of multiple users back into the model. We show the effectiveness of our method in comparison to previous work on a real dataset of user preferences over sushi types.\",\n",
       "  'id': '4141',\n",
       "  'title': 'Gaussian Process Preference Elicitation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In a recent paper Joachims (2006) presented SVM-Perf, a cutting plane method (CPM) for training linear Support Vector Machines (SVMs) which converges to an $\\\\epsilon$ accurate solution in $O(1/\\\\epsilon^{2})$ iterations. By tightening the analysis, Teo et al. (2010) showed that $O(1/\\\\epsilon)$ iterations suffice. Given the impressive convergence speed of CPM on a number of practical problems, it was conjectured that these rates could be further improved. In this paper we disprove this conjecture. We present counter examples which are not only applicable for training linear SVMs with hinge loss, but also hold for support vector methods which optimize a \\\\emph{multivariate} performance score. However, surprisingly, these problems are not inherently hard. By exploiting the structure of the objective function we can devise an algorithm that converges in $O(1/\\\\sqrt{\\\\epsilon})$ iterations.',\n",
       "  'id': '4144',\n",
       "  'title': 'Lower Bounds on Rate of Convergence of Cutting Plane Methods',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper presents an analysis of importance weighting for learning from finite samples and gives a series of theoretical and algorithmic results. We point out simple cases where importance weighting can fail, which suggests the need for an analysis of the properties of this technique. We then give both upper and lower bounds for generalization with bounded importance weights and, more significantly, give learning guarantees for the more common case of unbounded importance weights under the weak assumption that the second moment is bounded, a condition related to the Renyi divergence of the training and test distributions. These results are based on a series of novel and general bounds we derive for unbounded loss functions, which are of independent interest. We use these bounds to guide the definition of an alternative reweighting algorithm and report the results of experiments demonstrating its benefits. Finally, we analyze the properties of normalized importance weights which are also commonly used.',\n",
       "  'id': '4156',\n",
       "  'title': 'Learning Bounds for Importance Weighting',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We consider the problem of apprenticeship learning where the examples, demonstrated by an expert, cover only a small part of a large state space. Inverse Reinforcement Learning (IRL) provides an efficient tool for generalizing the demonstration, based on the assumption that the expert is maximizing a utility function that is a linear combination of state-action features. Most IRL algorithms use a simple Monte Carlo estimation to approximate the expected feature counts under the expert's policy. In this paper, we show that the quality of the learned policies is highly sensitive to the error in estimating the feature counts. To reduce this error, we introduce a novel approach for bootstrapping the demonstration by assuming that: (i), the expert is (near-)optimal, and (ii), the dynamics of the system is known. Empirical results on gridworlds and car racing problems show that our approach is able to learn good policies from a small number of demonstrations.\",\n",
       "  'id': '4160',\n",
       "  'title': 'Bootstrapping Apprenticeship Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'During the last years support vector machines (SVMs) have been successfully applied even in situations where the input space $X$ is not necessarily a subset of $R^d$. Examples include SVMs using probability measures to analyse e.g. histograms or coloured images, SVMs for text classification and web mining, and SVMs for applications from computational biology using, e.g., kernels for trees and graphs. Moreover, SVMs are known to be consistent to the Bayes risk, if either the input space is a complete separable metric space and the reproducing kernel Hilbert space (RKHS) $H\\\\subset L_p(P_X)$ is dense, or if the SVM is based on a universal kernel $k$.  So far, however, there are no RKHSs of practical interest known that satisfy these assumptions on $\\\\cH$ or $k$ if $X \\\\not\\\\subset R^d$.  We close this gap by providing a general technique based on Taylor-type kernels to explicitly construct universal kernels on compact metric spaces which are not subset of $R^d$. We apply this technique for the following special cases: universal kernels on the set of probability measures, universal kernels based on Fourier transforms, and universal kernels for signal processing.',\n",
       "  'id': '4168',\n",
       "  'title': 'Universal Kernels on Non-Standard Input Spaces',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The CUR decomposition provides an approximation of a matrix X that has low reconstruction error and that is sparse in the sense that the resulting approximation lies in the span of only a few columns of X. In this regard, it appears to be similar to many sparse PCA methods. However, CUR takes a randomized algorithmic approach whereas most sparse PCA methods are framed as convex optimization problems. In this paper, we try to understand CUR from a sparse optimization viewpoint. In particular, we show that CUR is implicitly optimizing a sparse regression objective and, furthermore, cannot be directly cast as a sparse PCA method. We observe that the sparsity attained by CUR possesses an interesting structure, which leads us to formulate a sparse PCA method that achieves a CUR-like sparsity.',\n",
       "  'id': '3890',\n",
       "  'title': 'CUR from a Sparse Optimization Viewpoint',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We identify and investigate a strong connection between probabilistic inference and differential privacy, the latter being a recent privacy definition that permits only indirect observation of data through noisy measurement. Previous research on differential privacy has focused on designing measurement processes whose output is likely to be useful on its own. We consider the potential of applying probabilistic inference to the measurements and measurement process to derive posterior distributions over the data sets and model parameters thereof. We find that probabilistic inference can improve accuracy, integrate multiple observations, measure uncertainty, and even provide posterior distributions over quantities that were not directly measured.',\n",
       "  'id': '3897',\n",
       "  'title': 'Probabilistic Inference and Differential Privacy',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We introduce CST, an algorithm for constructing skill trees from demonstration trajectories in continuous reinforcement learning domains. CST uses a changepoint detection method to segment each trajectory into a skill chain by detecting a change of appropriate abstraction, or that a segment is too complex to model as a single skill. The skill chains from each trajectory are then merged to form a skill tree. We demonstrate that CST constructs an appropriate skill tree that can be further refined through learning in a challenging continuous domain, and that it can be used to segment demonstration trajectories on a mobile manipulator into chains of skills where each skill is assigned an appropriate abstraction.',\n",
       "  'id': '3903',\n",
       "  'title': 'Constructing Skill Trees for Reinforcement Learning Agents from Demonstration Trajectories',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The goal of inverse reinforcement learning is to find a reward function for a Markov decision process, given example traces from its optimal policy. Current IRL techniques generally rely on user-supplied features that form a concise basis for the reward. We present an algorithm that instead constructs reward features from a large collection of component features, by building logical conjunctions of those component features that are relevant to the example policy. Given example traces, the algorithm returns a reward function as well as the constructed features. The reward function can be used to recover a full, deterministic, stationary policy, and the features can be used to transplant the reward function into any novel environment on which the component features are well defined.',\n",
       "  'id': '3918',\n",
       "  'title': 'Feature Construction for Inverse Reinforcement Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The problem of learning to predict structured labels is of key importance in many applications. However, for general graph structure both learning and inference in this setting are intractable. Here we show that it is possible to circumvent this difficulty when the input distribution is rich enough via a method similar in spirit to pseudo-likelihood. We show how our new method achieves consistency, and illustrate empirically that it indeed performs as well as exact methods when sufficiently large training sets are used.',\n",
       "  'id': '3921',\n",
       "  'title': 'More data means less inference: A pseudo-max approach to structured learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Likelihood ratio policy gradient methods have been some of the most successful reinforcement learning algorithms, especially for learning on physical systems. We describe how the likelihood ratio policy gradient can be derived from an importance sampling perspective. This derivation highlights how likelihood ratio methods under-use past experience by (a) using the past experience to estimate {\\\\em only} the gradient of the expected return $U(\\\\theta)$ at the current policy parameterization $\\\\theta$, rather than to obtain a more complete estimate of $U(\\\\theta)$, and (b) using past experience under the current policy {\\\\em only} rather than using all past experience to improve the estimates. We present a new policy search method, which leverages both of these observations as well as generalized baselines---a new technique which generalizes commonly used baseline techniques for policy gradient methods. Our algorithm outperforms standard likelihood ratio policy gradient algorithms on several testbeds.',\n",
       "  'id': '3922',\n",
       "  'title': 'On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Although the Dirichlet distribution is widely used, the independence structure of its components limits its accuracy as a model. The proposed shadow Dirichlet distribution manipulates the support in order to model probability mass functions (pmfs) with dependencies or constraints that often arise in real world problems, such as regularized pmfs, monotonic pmfs, and pmfs with bounded variation. We describe some properties of this new class of distributions, provide maximum entropy constructions, give an expectation-maximization method for estimating the mean parameter, and illustrate with real data.',\n",
       "  'id': '3934',\n",
       "  'title': 'Shadow Dirichlet for Restricted Probability Modeling',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Multi-task learning (MTL) improves the prediction performance on multiple, different but related, learning problems through shared parameters or representations. One of the most prominent multi-task learning algorithms is an extension to svms by Evgeniou et al. Although very elegant, multi-task svm is inherently restricted by the fact that support vector machines require each class to be addressed explicitly with its own weight vector which, in a multi-task setting, requires the different learning tasks to share the same set of classes. This paper proposes an alternative formulation for multi-task learning by extending the recently published large margin nearest neighbor (lmnn) algorithm to the MTL paradigm. Instead of relying on separating hyperplanes, its decision function is based on the nearest neighbor rule which inherently extends to many classes and becomes a natural fit for multitask learning. We evaluate the resulting multi-task lmnn on real-world insurance data and speech classification problems and show that it consistently outperforms single-task kNN under several metrics and state-of-the-art MTL classifiers.',\n",
       "  'id': '3935',\n",
       "  'title': 'Large Margin Multi-Task Metric Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Neuronal connection weights exhibit short-term depression (STD). The present study investigates the impact of STD on the dynamics of a continuous attractor neural network (CANN) and its potential roles in neural information processing. We find that the network with STD can generate both static and traveling bumps, and STD enhances the performance of the network in tracking external inputs. In particular, we find that STD endows the network with slow-decaying plateau behaviors, namely, the network being initially stimulated to an active state will decay to silence very slowly in the time scale of STD rather than that of neural signaling. We argue that this provides a mechanism for neural systems to hold short-term memory easily and shut off persistent activities naturally.',\n",
       "  'id': '3939',\n",
       "  'title': 'Attractor Dynamics with Synaptic Depression',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a technique for exact simulation of Gaussian Markov random fields (GMRFs), which can be interpreted as locally injecting noise to each Gaussian factor independently, followed by computing the mean/mode of the perturbed GMRF. Coupled with standard iterative techniques for the solution of symmetric positive definite systems, this yields a very efficient sampling algorithm with essentially linear complexity in terms of speed and memory requirements, well suited to extremely large scale probabilistic models. Apart from synthesizing data under a Gaussian model, the proposed technique directly leads to an efficient unbiased estimator of marginal variances. Beyond Gaussian models, the proposed algorithm is also very useful for handling highly non-Gaussian continuously-valued MRFs such as those arising in statistical image modeling or in the first layer of deep belief networks describing real-valued data, where the non-quadratic potentials coupling different sites can be represented as finite or infinite mixtures of Gaussians with the help of local or distributed latent mixture assignment variables. The Bayesian treatment of such models most naturally involves a block Gibbs sampler which alternately draws samples of the conditionally independent latent mixture assignments and the conditionally multivariate Gaussian continuous vector and we show that it can directly benefit from the proposed methods.',\n",
       "  'id': '3940',\n",
       "  'title': 'Gaussian sampling by local perturbations',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Communication between a speaker and hearer will be most efficient when both parties make accurate inferences about the other. We study inference and communication in a television game called Password, where speakers must convey secret words to hearers by providing one-word clues. Our working hypothesis is that human communication is relatively efficient, and we use game show data to examine three predictions. First, we predict that speakers and hearers are both considerate, and that both take the other?s perspective into account. Second, we predict that speakers and hearers are calibrated, and that both make accurate assumptions about the strategy used by the other. Finally, we predict that speakers and hearers are collaborative, and that they tend to share the cognitive burden of communication equally. We find evidence in support of all three predictions, and demonstrate in addition that efficient communication tends to break down when speakers and hearers are placed under time pressure.',\n",
       "  'id': '3951',\n",
       "  'title': 'Inference and communication in the game of Password',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recent approaches to multi-view learning have shown that factorizing the information into parts that are shared across all views and parts that are private to each view could effectively account for the dependencies and independencies between the different input modalities. Unfortunately, these approaches involve minimizing non-convex objective functions. In this paper, we propose an approach to learning such factorized representations inspired by sparse coding techniques. In particular, we show that structured sparsity allows us to address the multi-view learning problem by alternately solving two convex optimization problems. Furthermore, the resulting factorized latent spaces generalize over existing approaches in that they allow :having latent dimensions shared between any subset of the views instead of between all the views only. We show that our approach outperforms state-of-the-art methods on the task of human pose estimation.',\n",
       "  'id': '3953',\n",
       "  'title': 'Factorized Latent Spaces with Structured Sparsity',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In Learning Using Privileged Information (LUPI) paradigm, along with the standard training data in the decision space, a teacher supplies a learner with the privileged information in the correcting space. The goal of the learner is to find a classifier with a low generalization error in the decision space. We consider a new version of  empirical risk minimization algorithm, called Privileged ERM, that takes into account the privileged information in order to find a good function in the decision space. We outline the conditions on the correcting space that, if satisfied, allow Privileged ERM to have much faster learning rate in the decision space than the one of the regular empirical risk minimization.',\n",
       "  'id': '3960',\n",
       "  'title': 'On the Theory of Learnining with Privileged Information',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Generalized Linear Models (GLMs) are an increasingly popular framework for modeling neural spike trains. They have been linked to the theory of stochastic point processes and researchers have used this relation to assess goodness-of-fit using methods from point-process theory, e.g. the time-rescaling theorem. However, high neural firing rates or coarse discretization lead to a breakdown of the assumptions necessary for this connection. Here, we show how goodness-of-fit tests from point-process theory can still be applied to GLMs by constructing equivalent surrogate point processes out of time-series observations. Furthermore, two additional tests based on thinning and complementing point processes are introduced. They augment the instruments available for checking model adequacy of point processes as well as discretized models.',\n",
       "  'id': '3967',\n",
       "  'title': 'Rescaling, thinning or complementing? On goodness-of-fit procedures for point process models and Generalized Linear Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Sodium entry during an action potential determines the energy efficiency of a neuron. The classic Hodgkin-Huxley model of action potential generation is notoriously inefficient in that regard with about 4 times more charges flowing through the membrane than the theoretical minimum required to achieve the observed depolarization. Yet, recent experimental results show that mammalian neurons are close to the optimal metabolic efficiency and that the dynamics of their voltage-gated channels is significantly different than the one exhibited by the classic Hodgkin-Huxley model during the action potential. Nevertheless, the original Hodgkin-Huxley model is still widely used and rarely to model the squid giant axon from which it was extracted. Here, we introduce a novel family of Hodgkin-Huxley models that correctly account for sodium entry, action potential width and whose voltage-gated channels display a dynamics very similar to the most recent experimental observations in mammalian neurons. We speak here about a family of models because the model is parameterized by a unique parameter the variations of which allow to reproduce the entire range of experimental observations from cortical pyramidal neurons to Purkinje cells, yielding a very economical framework to model a wide range of different central neurons. The present paper demonstrates the performances and discuss the properties of this new family of models.',\n",
       "  'id': '3970',\n",
       "  'title': 'Sodium entry efficiency during action potentials: A novel single-parameter family of Hodgkin-Huxley models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Probabilistic grammars are generative statistical models that are  useful for compositional and sequential structures. We present a framework, reminiscent of structural risk minimization, for empirical risk minimization of the parameters of a fixed probabilistic grammar using the log-loss. We derive sample complexity bounds in this framework that apply both to the supervised setting and the unsupervised setting.',\n",
       "  'id': '3975',\n",
       "  'title': 'Empirical Risk Minimization with Approximations of Probabilistic Grammars',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"This paper describes a probabilistic framework for studying associations between multiple genotypes, biomarkers, and phenotypic traits in the presence of noise and unobserved confounders for large genetic studies. The framework builds on sparse linear methods developed for regression and modified here for inferring causal structures of richer networks with latent variables. The method is motivated by the use of genotypes as ``instruments'' to infer causal associations between phenotypic biomarkers and outcomes, without making the common restrictive assumptions of instrumental variable methods. The method may be used for an effective screening of potentially interesting genotype phenotype and biomarker-phenotype associations in genome-wide studies, which may have important implications for validating biomarkers as possible proxy endpoints for early stage clinical trials. Where the biomarkers are gene transcripts, the method can be used for fine mapping of quantitative trait loci (QTLs) detected in genetic linkage studies. The method is applied for examining effects of gene transcript levels in the liver on plasma HDL cholesterol levels for a sample of sequenced mice from a heterogeneous stock, with $\\\\sim 10^5$ genetic instruments and $\\\\sim 47 \\\\times 10^3$ gene transcripts.\",\n",
       "  'id': '3976',\n",
       "  'title': 'Sparse Instrumental Variables (SPIV) for Genome-Wide Studies',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We study learning curves for Gaussian process regression which characterise performance in terms of the Bayes error averaged over datasets of a given size. Whilst learning curves are in general very difficult to calculate we show that for discrete input domains, where similarity between input points is characterised in terms of a graph, accurate predictions can be obtained. These should in fact become exact for large graphs drawn from a broad range of random graph ensembles with arbitrary degree distributions where each input (node) is connected only to a finite number of others. The method is based on translating the appropriate belief propagation equations to the graph ensemble. We demonstrate the accuracy of the predictions for Poisson (Erdos-Renyi) and regular random graphs, and discuss when and why previous approximations to the learning curve fail.',\n",
       "  'id': '3981',\n",
       "  'title': 'Exact learning curves for Gaussian process regression on large random graphs',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recent experimental work has suggested that the neural firing rate can be interpreted as a fractional derivative, at least when signal variation induces neural adaptation. Here, we show that the actual neural spike-train itself can be considered as the fractional derivative, provided that the neural signal is approximated by a sum of power-law kernels. A simple standard thresholding spiking neuron suffices to carry out such an approximation, given a suitable refractory response. Empirically, we find that the online approximation of signals with a sum of power-law kernels is beneficial for encoding signals with slowly varying components, like long-memory self-similar signals. For such signals, the online power-law kernel approximation typically required less than half the number of spikes for similar SNR as compared to sums of similar but exponentially decaying kernels. As power-law kernels can be accurately approximated using sums or cascades of weighted exponentials, we demonstrate that the corresponding decoding of spike-trains by a receiving neuron allows for natural and transparent temporal signal filtering by tuning the weights of the decoding kernel.',\n",
       "  'id': '3983',\n",
       "  'title': 'Fractionally Predictive Spiking Neurons',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Our objective is to train $p$-norm Multiple Kernel Learning (MKL) and, more generally, linear MKL regularised by the Bregman divergence, using the Sequential Minimal Optimization (SMO) algorithm. The SMO algorithm is simple, easy to implement and adapt, and efficiently scales to large problems. As a result, it has gained widespread acceptance and SVMs are routinely trained using SMO in diverse real world applications. Training using SMO has been a long standing goal in MKL for the very same reasons. Unfortunately, the standard MKL dual is not differentiable, and therefore can not be optimised using SMO style co-ordinate ascent. In this paper, we demonstrate that linear MKL regularised with the $p$-norm squared, or with certain Bregman divergences, can indeed be trained using SMO. The resulting algorithm retains both simplicity and efficiency and is significantly faster than the state-of-the-art specialised $p$-norm MKL solvers. We show that we can train on a hundred thousand kernels in approximately seven minutes and on fifty thousand points in less than half an hour on a single core.',\n",
       "  'id': '3985',\n",
       "  'title': 'Multiple Kernel Learning and the SMO Algorithm',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In this paper, we propose an efficient algorithm for estimating the natural policy gradient with parameter-based exploration; this algorithm samples directly in the parameter space. Unlike previous methods based on natural gradients, our algorithm calculates the natural policy gradient using the inverse of the exact Fisher information matrix. The computational cost of this algorithm is equal to that of conventional policy gradients whereas previous natural policy gradient methods have a prohibitive computational cost. Experimental results show that the proposed method outperforms several policy gradient methods.',\n",
       "  'id': '3987',\n",
       "  'title': 'Natural Policy Gradient Methods with Parameter-based Exploration for Control Tasks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The sample complexity of active learning under the realizability assumption has been well-studied. The realizability assumption, however, rarely holds in practice. In this paper, we theoretically characterize the sample complexity of active learning in the non-realizable case under multi-view setting. We prove that, with unbounded Tsybakov noise, the sample complexity of multi-view active learning can be $\\\\widetilde{O}(\\\\log \\\\frac{1}{\\\\epsilon})$, contrasting to single-view setting where the polynomial improvement is the best possible achievement. We also prove that in general multi-view setting the sample complexity of active learning with unbounded Tsybakov noise is $\\\\widetilde{O}(\\\\frac{1}{\\\\epsilon})$, where the order of $1/\\\\epsilon$ is independent of the parameter in Tsybakov noise, contrasting to previous polynomial bounds where the order of $1/\\\\epsilon$ is related to the parameter in Tsybakov noise.',\n",
       "  'id': '3991',\n",
       "  'title': 'Multi-View Active Learning in the Non-Realizable Case',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the problem of reinforcement learning in high-dimensional spaces when the number of features is bigger than the number of samples. In particular, we study the least-squares temporal difference (LSTD) learning algorithm when a space of low dimension is generated with a random projection from a high-dimensional space. We provide a thorough theoretical analysis of the LSTD with random projections and derive performance bounds for the resulting algorithm. We also show how the error of LSTD with random projections is propagated through the iterations of a policy iteration algorithm and provide a performance bound for the resulting least-squares policy iteration (LSPI) algorithm.',\n",
       "  'id': '3994',\n",
       "  'title': 'LSTD with Random Projections',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Heavy-tailed distributions are often used to enhance the robustness of regression and classification methods to outliers in output space.  Often, however, we are confronted with ``outliers'' in input space, which are isolated observations in sparsely populated regions. We show that heavy-tailed process priors (which we construct from Gaussian processes via a copula), can be used to improve robustness of regression and classification estimators to such outliers by selectively shrinking them more strongly in sparse regions than in dense regions. We carry out a theoretical analysis to show that selective shrinkage occurs provided the marginals of the heavy-tailed process have sufficiently heavy tails. The analysis is complemented by experiments on biological data which indicate significant improvements of estimates in sparse regions while producing competitive results in dense regions.\",\n",
       "  'id': '3996',\n",
       "  'title': 'Heavy-Tailed Process Priors for Selective Shrinkage',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We address the problem of estimating the F-measure of a given model as accurately as possible on a fixed labeling budget. This problem occurs whenever an estimate cannot be obtained from held-out training data; for instance, when data that have been used to train the model are held back for reasons of privacy or do not reflect the test distribution. In this case, new test instances have to be drawn and labeled at a cost. An active estimation procedure selects instances according to an instrumental sampling distribution. An analysis of the sources of estimation error leads to an optimal sampling distribution that minimizes estimator variance. We explore conditions under which active estimates of F-measures are more accurate than estimates based on instances sampled from the test distribution.',\n",
       "  'id': '3999',\n",
       "  'title': 'Active Estimation of F-Measures',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Regularization technique has become a principle tool for statistics and machine learning research and practice. However, in most situations, these regularization terms are not well interpreted, especially on how they are related to the loss function and data. In this paper, we propose a robust minimax framework to interpret the relationship between data and regularization terms for a large class of loss functions. We show that various regularization terms are essentially corresponding to different distortions to the original data matrix. This minimax framework includes ridge regression, lasso, elastic net, fused lasso, group lasso, local coordinate coding, multiple kernel learning, etc., as special cases. Within this minimax framework, we further gave mathematically exact definition for a novel representation called sparse grouping representation (SGR), and proved sufficient conditions for generating such group level sparsity. Under these sufficient conditions, a large set of consistent regularization terms can be designed. This SGR is essentially different from group lasso in the way of using class or group information, and it outperforms group lasso when there appears group label noise. We also gave out some generalization bounds in a classification setting.',\n",
       "  'id': '4000',\n",
       "  'title': 'Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In many machine learning domains (such as scene understanding), several related sub-tasks (such as scene categorization, depth estimation, object detection) operate on the same raw data and provide correlated outputs. Each of these tasks is often notoriously hard, and state-of-the-art classifiers already exist for many sub-tasks. It is desirable to have an algorithm that can capture such correlation without requiring to make any changes to the inner workings of any classifier.  We propose Feedback Enabled Cascaded Classification Models (FE-CCM), that maximizes the joint likelihood of the sub-tasks, while requiring only a ?black-box? interface to the original classifier for each sub-task. We use a two-layer cascade of classifiers, which are repeated instantiations of the original ones, with the output of the first layer fed into the second layer as input. Our training method involves a feedback step that allows later classifiers to provide earlier classifiers information about what error modes to focus on. We show that our method significantly improves performance in all the sub-tasks in two different domains: (i) scene understanding, where we consider depth estimation, scene categorization, event categorization, object detection, geometric labeling and saliency detection, and (ii) robotic grasping, where we consider grasp point detection and object classification.',\n",
       "  'id': '4003',\n",
       "  'title': 'Towards Holistic Scene Understanding: Feedback Enabled Cascaded Classification Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Singular Value Decomposition (and Principal Component Analysis)  is one of the most widely used techniques for dimensionality reduction: successful and efficiently computable, it is nevertheless plagued by a well-known, well-documented sensitivity to outliers. Recent work has considered the setting where each point has a few arbitrarily corrupted components. Yet, in applications of SVD or PCA such as robust collaborative filtering or bioinformatics, malicious agents, defective genes, or simply corrupted or contaminated experiments may effectively yield entire points that are completely corrupted.  We present an efficient convex optimization-based  algorithm we call Outlier Pursuit, that under some mild assumptions on the uncorrupted points (satisfied, e.g., by the standard generative assumption in PCA problems) recovers the *exact* optimal low-dimensional subspace, and identifies the corrupted points. Such identification of corrupted points that do not conform to the low-dimensional approximation, is of paramount interest in bioinformatics and financial applications, and beyond. Our techniques involve matrix decomposition using nuclear norm minimization, however, our results, setup, and approach, necessarily differ considerably from the existing line of work in matrix completion and matrix decomposition, since we develop an approach to recover the correct *column space* of the uncorrupted matrix, rather than the exact matrix itself.',\n",
       "  'id': '4005',\n",
       "  'title': 'Robust PCA via Outlier Pursuit',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper presents a co-regularization based approach to semi-supervised domain adaptation. Our proposed approach (EA++) builds on the notion of augmented space (introduced in EASYADAPT (EA) [1]) and harnesses unlabeled data in target domain to further enable the transfer of information from source to target. This semi-supervised approach to domain adaptation is extremely simple to implement and can be applied as a pre-processing step to any supervised learner. Our theoretical analysis (in terms of Rademacher complexity) of EA and EA++ show that the hypothesis class of EA++ has lower complexity (compared to EA) and hence results in tighter generalization bounds. Experimental results on sentiment analysis tasks reinforce our theoretical findings and demonstrate the efficacy of the proposed method when compared to EA as well as a few other baseline approaches.',\n",
       "  'id': '4009',\n",
       "  'title': 'Co-regularization Based Semi-supervised Domain Adaptation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper presents an approach to the visual recognition of human actions using only single images as input. The task is easy for humans but difficult for current approaches to object recognition, because action instances may be similar in terms of body pose, and often require detailed examination of relations between participating objects and body parts in order to be recognized. The proposed approach applies a two-stage interpretation procedure to each training and test image. The first stage produces accurate detection of the relevant body parts of the actor, forming a prior for the local evidence needed to be considered for identifying the action. The second stage extracts features that are ?anchored? to the detected body parts, and uses these features and their feature-to-part relations in order to recognize the action. The body anchored priors we propose apply to a large range of human actions. These priors allow focusing on the relevant regions and relations, thereby significantly simplifying the learning process and increasing recognition performance.',\n",
       "  'id': '4012',\n",
       "  'title': 'Using body-anchored priors for identifying actions in single images',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"Functional segregation and integration are fundamental characteristics of the human brain. Studying the connectivity among segregated regions and the dynamics of integrated brain networks has drawn increasing interest. A very controversial, yet fundamental issue in these studies is how to determine the best functional brain regions or ROIs (regions of interests) for individuals. Essentially, the computed connectivity patterns and dynamics of brain networks are very sensitive to the locations, sizes, and shapes of the ROIs. This paper presents a novel methodology to optimize the locations of an individual's ROIs in the working memory system. Our strategy is to formulate the individual ROI optimization as a group variance minimization problem, in which group-wise functional and structural connectivity patterns, and anatomic profiles are defined as optimization constraints. The optimization problem is solved via the simulated annealing approach. Our experimental results show that the optimized ROIs have significantly improved consistency in structural and functional profiles across subjects, and have more reasonable localizations and more consistent morphological and anatomic profiles.\",\n",
       "  'id': '4016',\n",
       "  'title': 'Individualized ROI Optimization via Maximization of Group-wise Consistency of Structural and Functional Profiles',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Algorithms based on iterative local approximations present a practical approach to optimal control in robotic systems. However, they generally require the temporal parameters (for e.g. the movement duration or the time point of reaching an intermediate goal) to be specified \\\\textit{a priori}. Here, we present a methodology that is capable of jointly optimising the temporal parameters in addition to the control command profiles. The presented approach is based on a Bayesian canonical time formulation of the optimal control problem, with the temporal mapping from canonical to real time parametrised by an additional control variable. An approximate EM algorithm is derived that efficiently optimises both the movement duration and control commands offering, for the first time, a practical approach to tackling generic via point problems in a systematic way under the optimal control framework. The proposed approach is evaluated on simulations of a redundant robotic plant.',\n",
       "  'id': '4018',\n",
       "  'title': 'An Approximate Inference Approach to Temporal Optimization in Optimal Control',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper is concerned with the generalization analysis on learning to rank for information retrieval (IR). In IR, data are hierarchically organized, i.e., consisting of queries and documents per query. Previous generalization analysis for ranking, however, has not fully considered this structure, and cannot explain how the simultaneous change of query number and document number in the training data will affect the performance of algorithms. In this paper, we propose performing generalization analysis under the assumption of two-layer sampling, i.e., the i.i.d. sampling of queries and the conditional i.i.d sampling of documents per query. Such a sampling can better describe the generation mechanism of real data, and the corresponding generalization analysis can better explain the real behaviors of learning to rank algorithms. However, it is challenging to perform such analysis, because the documents associated with different queries are not identically distributed, and the documents associated with the same query become no longer independent if represented by features extracted from the matching between document and query. To tackle the challenge, we decompose the generalization error according to the two layers, and make use of the new concept of two-layer Rademacher average. The generalization bounds we obtained are quite intuitive and are in accordance with previous empirical studies on the performance of ranking algorithms.',\n",
       "  'id': '4019',\n",
       "  'title': 'Two-Layer Generalization Analysis for Ranking Using Rademacher Average',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A striking aspect of cortical neural networks is the divergence of a relatively small number of input channels from the peripheral sensory apparatus into a large number of cortical neurons, an over-complete representation strategy. Cortical neurons are then connected by a sparse network of lateral synapses. Here we propose that such architecture may increase the persistence of the representation of an incoming stimulus, or a percept. We demonstrate that for a family of networks in which the receptive field of each neuron is re-expressed by its outgoing connections, a represented percept can remain constant despite changing activity. We term this choice of connectivity REceptive FIeld REcombination (REFIRE) networks. The sparse REFIRE network may serve as a high-dimensional integrator and a biologically plausible model of the local cortical circuit.',\n",
       "  'id': '4020',\n",
       "  'title': 'Over-complete representations on recurrent neural networks can support persistent percepts',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'When software developers modify one or more files in a large code base, they must also identify and update other related files. Many file dependencies can be detected by mining the development history of the code base: in essence, groups of related files are revealed by the logs of previous workflows. From data of this form, we show how to detect dependent files by solving a problem in binary matrix completion. We explore different latent variable models (LVMs) for this problem, including Bernoulli mixture models, exponential family PCA, restricted Boltzmann machines, and fully Bayesian approaches. We evaluate these models on the development histories of three large, open-source software systems: Mozilla Firefox, Eclipse Subversive, and Gimp. In all of these applications, we find that LVMs improve the performance of related file prediction over current leading methods.',\n",
       "  'id': '4022',\n",
       "  'title': 'Latent Variable Models for Predicting File Dependencies in Large-Scale Software Development',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The problem of controlling the margin of a classifier is studied. A detailed analytical study is presented on how properties of the classification risk, such as its optimal link and minimum risk functions, are related to the shape of the loss, and its margin enforcing properties. It is shown that for a class of risks, denoted canonical risks, asymptotic Bayes consistency is compatible with simple analytical relationships between these functions. These enable a precise characterization of the loss for a popular class of link functions. It is shown that, when the risk is in canonical form and the link is inverse sigmoidal, the margin properties of the loss are determined by a single parameter. Novel families of Bayes consistent loss functions, of variable margin, are derived. These families are then used to design boosting style algorithms with explicit control of the classification margin. The new algorithms generalize well established approaches, such as LogitBoost. Experimental results show that the proposed variable margin losses outperform the fixed margin counterparts used by existing algorithms. Finally, it is shown that best performance can be achieved by cross-validating the margin parameter.',\n",
       "  'id': '4024',\n",
       "  'title': 'Variable margin losses for classifier design',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We present a novel algorithm, Random Conic Pursuit, that solves semidefinite programs (SDPs) via repeated optimization over randomly selected two-dimensional subcones of the PSD cone. This scheme is simple, easily implemented, applicable to very general SDPs, scalable, and theoretically interesting. Its advantages are realized at the expense of an ability to readily compute highly exact solutions, though useful approximate solutions are easily obtained. This property renders Random Conic Pursuit of particular interest for machine learning applications, in which the relevant SDPs are generally based upon random data and so exact minima are often not a priority. Indeed, we present empirical results to this effect for various SDPs encountered in machine learning; these experiments demonstrate the potential practical usefulness of Random Conic Pursuit. We also provide a preliminary analysis that yields insight into the theoretical properties and convergence of the algorithm.',\n",
       "  'id': '4026',\n",
       "  'title': 'Random Conic Pursuit for Semidefinite Programming',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Many combinatorial problems arising in machine learning can be reduced to the problem of minimizing a submodular function. Submodular functions are a natural discrete analog of convex functions, and can be minimized in strongly polynomial time. Unfortunately, state-of-the-art algorithms for general submodular minimization are intractable for practical problems. In this paper, we introduce a novel subclass of submodular minimization problems that we call decomposable. Decomposable submodular functions are those that can be represented as sums of concave functions applied to linear functions. We develop an algorithm, SLG, that can efficiently minimize decomposable submodular functions with tens of thousands of variables. Our algorithm exploits recent results in smoothed convex minimization. We apply SLG to synthetic benchmarks and a joint classification-and-segmentation task, and show that it outperforms the state-of-the-art general purpose submodular minimization algorithms by several orders of magnitude.',\n",
       "  'id': '4028',\n",
       "  'title': 'Efficient Minimization of Decomposable Submodular Functions',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We obtain a tight distribution-specific characterization of the sample complexity of large-margin classification with L2 regularization: We introduce the gamma-adapted-dimension, which is a simple function of the spectrum of a distribution's covariance matrix, and show distribution-specific upper and lower bounds on the sample complexity, both governed by the gamma-adapted-dimension of the source distribution. We conclude that this new quantity tightly characterizes the true sample complexity of large-margin classification. The bounds hold for a rich family of sub-Gaussian distributions.\",\n",
       "  'id': '4032',\n",
       "  'title': 'Tight Sample Complexity of Large-Margin Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'To understand the relationship between genomic variations among population and complex diseases, it is essential to detect eQTLs which are associated with phenotypic effects. However, detecting eQTLs remains a challenge due to complex underlying mechanisms and the very large number of genetic loci involved compared to the number of samples. Thus, to address the problem, it is desirable to take advantage of the structure of the data and prior information about genomic locations such as conservation scores and transcription factor binding sites.  In this paper, we propose a novel regularized regression approach for detecting eQTLs which takes into account related traits simultaneously while incorporating many regulatory features. We first present a Bayesian network for a multi-task learning problem that includes priors on SNPs, making it possible to estimate the significance of each covariate adaptively. Then we find the maximum a posteriori (MAP) estimation of regression coefficients and estimate weights of covariates jointly. This optimization procedure is efficient since it can be achieved by using convex optimization and a coordinate descent procedure iteratively. Experimental results on simulated and real yeast datasets confirm that our model outperforms previous methods for finding eQTLs.',\n",
       "  'id': '4038',\n",
       "  'title': 'Adaptive Multi-Task Lasso: with Application to eQTL Detection',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the problem of learning a local metric to enhance the performance of nearest neighbor classification. Conventional metric learning methods attempt to separate data distributions in a purely discriminative manner; here we show how to take advantage of information from parametric generative models. We focus on the bias in the information-theoretic error arising from finite sampling effects, and find an appropriate local metric that maximally reduces the bias based upon knowledge from generative models. As a byproduct, the asymptotic theoretical analysis in this work relates metric learning with dimensionality reduction, which was not understood from previous discriminative approaches. Empirical experiments show that this learned local metric enhances the discriminative nearest neighbor performance on various datasets using simple class conditional generative models.',\n",
       "  'id': '4040',\n",
       "  'title': 'Generative Local Metric Learning for Nearest Neighbor Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'When working with network datasets, the theoretical framework of detection theory for Euclidean vector spaces no longer applies. Nevertheless, it is desirable to determine the detectability of small, anomalous graphs embedded into background networks with known statistical properties. Casting the problem of subgraph detection in a signal processing context, this article provides a framework and empirical results that elucidate a detection theory\" for graph-valued data. Its focus is the detection of anomalies in unweighted, undirected graphs through L1 properties of the eigenvectors of the graph?s so-called modularity matrix. This metric is observed to have relatively low variance for certain categories of randomly-generated graphs, and to reveal the presence of an anomalous subgraph with reasonable reliability when the anomaly is not well-correlated with stronger portions of the background graph. An analysis of subgraphs in real network datasets confirms the efficacy of this approach.\"',\n",
       "  'id': '4044',\n",
       "  'title': 'Subgraph Detection Using Eigenvector L1 Norms',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'How are the spatial patterns of spontaneous and evoked population responses related? We study the impact of connectivity on the spatial pattern of fluctuations in the input-generated response of a neural network, by comparing the distribution of evoked and intrinsically generated activity across the different units. We develop a complementary approach to principal component analysis in which separate high-variance directions are typically derived for each input condition. We analyze subspace angles to compute the difference between the shapes of trajectories corresponding to different network states, and the orientation of the low-dimensional subspaces that driven trajectories occupy within the full space of neuronal activity. In addition to revealing how the spatiotemporal structure of spontaneous activity affects input-evoked responses, these methods can be used to infer input selectivity induced by network dynamics from experimentally accessible measures of spontaneous activity (e.g. from voltage- or calcium-sensitive optical imaging experiments). We conclude that the absence of a detailed spatial map of afferent inputs and cortical connectivity does not limit our ability to design spatially extended stimuli that evoke strong responses.',\n",
       "  'id': '4051',\n",
       "  'title': 'Inferring Stimulus Selectivity from the Spatial Structure of Neural Network Dynamics',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Automatic speech recognition has gradually improved over the years, but the reliable recognition of unconstrained speech is still not within reach. In order to achieve a breakthrough, many research groups are now investigating new methodologies that have potential to outperform the Hidden Markov Model technology that is at the core of all present commercial systems. In this paper, it is shown that the recently introduced concept of Reservoir Computing might form the basis of such a methodology. In a limited amount of time, a reservoir system that can recognize the elementary sounds of continuous speech has been built. The system already achieves a state-of-the-art performance, and there is evidence that the margin for further improvements is still significant.',\n",
       "  'id': '4056',\n",
       "  'title': 'Phoneme Recognition with Large Hierarchical Reservoirs',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"In this paper we consider the problem of learning from data  the  support of a probability distribution when  the distribution {\\\\em does not} have a density (with respect to some reference measure). We  propose a  new class of regularized spectral estimators based on a new notion of reproducing kernel Hilbert space,  which we call {\\\\em   ``completely regular''}. Completely regular kernels   allow to capture the relevant  geometric and topological properties  of an arbitrary probability space.  In particular, they are the key ingredient to prove the  universal consistency  of the spectral  estimators and in this respect they are the analogue of  universal kernels for supervised problems. Numerical  experiments show that spectral estimators compare favorably to state of the art machine learning algorithms for  density support  estimation.\",\n",
       "  'id': '4062',\n",
       "  'title': 'Spectral Regularization for Support Estimation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Most current image categorization methods require large collections of manually annotated training examples to learn accurate visual recognition models. The time-consuming human labeling effort effectively limits these approaches to recognition problems involving a small number of different object classes. In order to address this shortcoming, in recent years several authors have proposed to learn object classifiers from weakly-labeled Internet images, such as photos retrieved by keyword-based image search engines. While this strategy eliminates the need for human supervision, the recognition accuracies of these methods are considerably lower than those obtained with fully-supervised approaches, because of the noisy nature of the labels associated to Web data.  In this paper we investigate and compare methods that learn image classifiers by combining very few manually annotated examples (e.g., 1-10 images per class) and a large number of weakly-labeled Web photos retrieved using keyword-based image search. We cast this as a domain adaptation problem: given a few strongly-labeled examples in a target domain (the manually annotated examples) and many source domain examples (the weakly-labeled Web photos), learn classifiers yielding small generalization error on the target domain. Our experiments demonstrate that, for the same number of strongly-labeled examples, our domain adaptation approach produces significant recognition rate improvements over the best published results (e.g., 65% better when using 5 labeled training examples per class) and that our classifiers are one order of magnitude faster to learn and to evaluate than the best competing method, despite our use of large weakly-labeled data sets.',\n",
       "  'id': '4064',\n",
       "  'title': 'Exploiting weakly-labeled Web images to improve object classification: a domain adaptation approach',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'In discriminative machine learning one is interested in training a system to optimize a certain desired measure of performance, or loss. In binary classification one typically tries to minimizes the error rate. But in structured prediction each task often has its own measure of performance such as the BLEU score in machine translation or the intersection-over-union score in PASCAL segmentation. The most common approaches to structured prediction, structural SVMs and CRFs, do not minimize the task loss: the former minimizes a surrogate loss with no guarantees for task loss and the latter minimizes log loss independent of task loss. The main contribution of this paper is a theorem stating that a certain perceptron-like learning rule, involving features vectors derived from loss-adjusted inference, directly corresponds to the gradient of task loss. We give empirical results on phonetic alignment of a standard test set from the TIMIT corpus, which surpasses all previously reported results on this problem.',\n",
       "  'id': '4069',\n",
       "  'title': 'Direct Loss Minimization for Structured Prediction',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the problem of identifying an activation pattern in a complex, large-scale network that is embedded in very noisy measurements. This problem is relevant to several applications, such as identifying traces of a biochemical spread by a sensor network, expression levels of genes, and anomalous activity or congestion in the Internet. Extracting such patterns is a challenging task specially if the network is large (pattern is very high-dimensional) and the noise is so excessive that it masks the activity at any single node. However, typically there are statistical dependencies in the network activation process that can be leveraged to fuse the measurements of multiple nodes and enable reliable extraction of high-dimensional noisy patterns. In this paper, we analyze an estimator based on the graph Laplacian eigenbasis, and establish the limits of mean square error recovery of noisy patterns arising from a probabilistic (Gaussian or Ising) model based on an arbitrary graph structure. We consider both deterministic and probabilistic network evolution models, and our results indicate that by leveraging the network interaction structure, it is possible to consistently recover high-dimensional patterns even when the noise variance increases with network size.',\n",
       "  'id': '4075',\n",
       "  'title': 'Identifying graph-structured activation patterns in networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"A new algorithm for isotonic regression is presented based on recursively partitioning the solution space. We develop efficient methods for each partitioning subproblem through an equivalent representation as a network flow problem, and prove that this sequence of partitions converges to the global solution. These network flow problems can further be decomposed in order to solve very large problems. Success of isotonic regression in prediction and our algorithm's favorable computational properties are demonstrated through simulated examples as large as 2x10^5 variables and 10^7 constraints.\",\n",
       "  'id': '4079',\n",
       "  'title': 'Decomposing Isotonic Regression for Efficiently Solving Large Problems',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Gaussian graphical models with sparsity in the inverse covariance matrix are of significant interest in many modern applications. For the problem of recovering the graphical structure, information criteria provide useful optimization objectives for algorithms searching through sets of graphs or for selection of tuning parameters of other methods such as the graphical lasso, which is a likelihood penalization technique. In this paper we establish the asymptotic consistency of an extended Bayesian information criterion for Gaussian graphical models in a scenario where both the number of variables p and the sample size n grow. Compared to earlier work on the regression case, our treatment allows for growth in the number of non-zero parameters in the true model, which is necessary in order to cover connected graphs. We demonstrate the performance of this criterion on simulated data when used in conjuction with the graphical lasso, and verify that the criterion indeed performs better than either cross-validation or the ordinary Bayesian information criterion when p and the number of non-zero parameters q both scale with n.',\n",
       "  'id': '4087',\n",
       "  'title': 'Extended Bayesian Information Criteria for Gaussian Graphical Models',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A new algorithm is proposed for a) unsupervised learning of sparse representations from subsampled measurements and b) estimating the parameters required for linearly reconstructing signals from the sparse codes. We verify that the new algorithm performs efficient data compression on par with the recent method of compressive sampling. Further, we demonstrate that the algorithm performs robustly when stacked in several stages or when applied in undercomplete or overcomplete situations. The new algorithm can explain how neural populations in the brain that receive subsampled input through fiber bottlenecks are able to form coherent response properties.',\n",
       "  'id': '4093',\n",
       "  'title': 'Deciphering subsampled data: adaptive compressive sampling as a principle of brain communication',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The Charles Bonnet Syndrome (CBS) is characterized by complex vivid visual hallucinations in people with, primarily, eye diseases and no other neurological pathology. We present a Deep Boltzmann Machine model of CBS, exploring two core hypotheses: First, that the visual cortex learns a generative or predictive model of sensory input, thus explaining its capability to generate internal imagery. And second, that homeostatic mechanisms stabilize neuronal activity levels, leading to hallucinations being formed when input is lacking. We reproduce a variety of qualitative findings in CBS. We also introduce a modification to the DBM that allows us to model a possible role of acetylcholine in CBS as mediating the balance of feed-forward and feed-back processing. Our model might provide new insights into CBS and also demonstrates that generative frameworks are promising as hypothetical models of cortical learning and perception.',\n",
       "  'id': '4097',\n",
       "  'title': 'Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis: a Deep Boltzmann Machine Model',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'A number of objective functions in clustering problems can be described with submodular functions. In this paper, we introduce the minimum average cost criterion, and show that the theory of intersecting submodular functions can be used for clustering with submodular objective functions. The proposed algorithm does not require the number of clusters in advance, and it will be determined by the property of a given set of data points. The minimum average cost clustering problem is parameterized with a real variable, and surprisingly, we show that all information about optimal clusterings for all parameters can be computed in polynomial time in total. Additionally, we evaluate the performance of the proposed algorithm through computational experiments.',\n",
       "  'id': '4106',\n",
       "  'title': 'Minimum Average Cost Clustering',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper proposes a simple and efficient finite difference method for implicit differentiation of marginal inference results in discrete graphical models. Given an arbitrary loss function, defined on marginals, we show that the derivatives of this loss with respect to model parameters can be obtained by running the inference procedure twice, on slightly perturbed model parameters. This method can be used with approximate inference, with a loss function over approximate marginals. Convenient choices of loss functions make it practical to fit graphical models with hidden variables, high treewidth and/or model misspecification.',\n",
       "  'id': '4107',\n",
       "  'title': 'Implicit Differentiation by Perturbation',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We tackle the problem of simultaneously detecting occlusions and estimating optical flow. We show that, under standard assumptions of Lambertian reflection and static illumination, the task can be posed as a convex minimization problem. Therefore, the solution, computed using efficient algorithms, is guaranteed to be globally optimal, for any number of independently moving objects, and any number of occlusion layers. We test the proposed algorithm on benchmark datasets, expanded to enable evaluation of occlusion detection performance.',\n",
       "  'id': '4118',\n",
       "  'title': 'Occlusion Detection and Motion Estimation with Convex Optimization',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Several motor related Brain Computer Interfaces (BCIs) have been developed over the years that use activity decoded from the contralateral hemisphere to operate devices. Many recent studies have also talked about the importance of ipsilateral activity in planning of motor movements. For successful upper limb BCIs, it is important to decode finger movements from brain activity. This study uses ipsilateral cortical signals from humans (using ECoG) to decode finger movements. We demonstrate, for the first time, successful finger movement detection using machine learning algorithms. Our results show high decoding accuracies in all cases which are always above chance. We also show that significant accuracies can be achieved with the use of only a fraction of all the features recorded and that these core features also make sense physiologically. The results of this study have a great potential in the emerging world of motor neuroprosthetics and other BCIs.',\n",
       "  'id': '4121',\n",
       "  'title': 'Decoding Ipsilateral Finger Movements from ECoG Signals in Humans',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We consider the multiple linear regression problem, in a setting where some of the set of relevant features could be shared across the tasks. A lot of recent research has studied the use of $\\\\ell_1/\\\\ell_q$ norm block-regularizations with $q > 1$  for such (possibly) block-structured problems, establishing strong guarantees on recovery even under high-dimensional scaling where the number of features scale with the number of observations. However, these papers also caution that the performance of such block-regularized methods are very dependent on the {\\\\em extent} to which the features are shared across tasks. Indeed they show~\\\\citep{NWJoint} that if the extent of overlap is less than a threshold, or even if parameter {\\\\em values} in the shared features are highly uneven, then block $\\\\ell_1/\\\\ell_q$ regularization could actually perform {\\\\em worse} than simple separate elementwise $\\\\ell_1$ regularization. We are far away from a realistic multi-task setting: not only do the set of relevant features have to be exactly the same across tasks, but their values have to as well.  Here, we ask the question: can we leverage support and parameter overlap when it exists, but not pay a penalty when it does not? Indeed, this falls under a more general question of whether we can model such \\\\emph{dirty data} which may not fall into a single neat structural bracket (all block-sparse, or all low-rank and so on). Here, we take a first step, focusing on developing a dirty model for the multiple regression problem. Our method uses a very simple idea: we decompose  the parameters into two components and {\\\\em regularize these differently.} We show both theoretically and empirically, our method strictly and noticeably outperforms both $\\\\ell_1$ and $\\\\ell_1/\\\\ell_q$ methods, over the entire range of possible overlaps. We also provide theoretical guarantees that the method performs well under high-dimensional scaling.',\n",
       "  'id': '4125',\n",
       "  'title': 'A Dirty Model for Multi-task Learning',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Optimal coding provides a guiding principle for understanding the representation of sensory variables in neural populations. Here we consider the influence of a prior probability distribution over sensory variables on the optimal allocation of cells and spikes in a neural population. We model the spikes of each cell as samples from an independent Poisson process with rate governed by an associated tuning curve. For this response model, we approximate the Fisher information in terms of the density and amplitude of the tuning curves, under the assumption that tuning width varies inversely with cell density. We consider a family of objective functions based on the expected value, over the sensory prior, of a functional of the Fisher information. This family includes lower bounds on mutual information and perceptual discriminability as special cases. In all cases, we find a closed form expression for the optimum, in which the density and gain of the cells in the population are power law functions of the stimulus prior. This also implies a power law relationship between the prior and perceptual discriminability. We show preliminary evidence that the theory successfully predicts the relationship between empirically measured stimulus priors, physiologically measured neural response properties (cell density, tuning widths, and firing rates), and psychophysically measured discrimination thresholds.',\n",
       "  'id': '4130',\n",
       "  'title': 'Implicit encoding of prior probabilities in optimal neural populations',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Probabilistic models of natural images are usually evaluated by measuring performance on rather indirect tasks, such as denoising and inpainting. A more direct way to evaluate a generative model is to draw samples from it and to check whether statistical properties of the samples match the statistics of natural images. This method is seldom used with high-resolution images, because current models produce samples that are very different from natural images, as assessed by even simple visual inspection. We investigate the reasons for this failure and we show that by augmenting existing models so that there are two sets of latent variables, one set modelling pixel intensities and the other set modelling image-specific pixel covariances, we are able to generate high-resolution images that look much more realistic than before. The overall model can be interpreted as a gated MRF where both pair-wise dependencies and mean intensities of pixels are modulated by the states of latent variables. Finally, we confirm that if we disallow weight-sharing between receptive fields that overlap each other, the gated MRF learns more efficient internal representations, as demonstrated in several recognition tasks.',\n",
       "  'id': '4138',\n",
       "  'title': \"Generating more realistic images using gated MRF's\",\n",
       "  'year': '2010'},\n",
       " {'abstract': 'This paper outlines a hierarchical Bayesian model for human category learning that learns both the organization of objects into categories, and the context in which this knowledge should be applied. The model is fit to multiple data sets, and provides a parsimonious method for describing how humans learn context specific conceptual representations.',\n",
       "  'id': '4139',\n",
       "  'title': 'Learning the context of a category',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Recently, some variants of the $l_1$ norm, particularly matrix norms such as the $l_{1,2}$ and $l_{1,\\\\infty}$ norms, have been widely used in multi-task learning, compressed sensing and other related areas to enforce sparsity via joint regularization. In this paper, we unify the $l_{1,2}$ and $l_{1,\\\\infty}$ norms by considering a family of $l_{1,q}$ norms for $1 < q\\\\le\\\\infty$ and study the problem of determining the most appropriate sparsity enforcing norm to use in the context of multi-task feature selection. Using the generalized normal distribution, we provide a probabilistic interpretation of the general multi-task feature selection problem using the $l_{1,q}$ norm. Based on this probabilistic interpretation, we develop a probabilistic model using the noninformative Jeffreys prior. We also extend the model to learn and exploit more general types of pairwise relationships between tasks. For both versions of the model, we devise expectation-maximization~(EM) algorithms to learn all model parameters, including $q$, automatically. Experiments have been conducted on two cancer classification applications using microarray gene expression data.',\n",
       "  'id': '4150',\n",
       "  'title': 'Probabilistic Multi-Task Feature Selection',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'From a functional viewpoint, a spiking neuron is a device that transforms input spike trains on its various synapses into an output spike train on its axon. We demonstrate in this paper that the function mapping underlying the device can be tractably learned based on input and output spike train data alone. We begin by posing the problem in a classification based framework. We then derive a novel kernel for an SRM0 model that is based on PSP and AHP like functions. With the kernel we demonstrate how the learning problem can be posed as a Quadratic Program. Experimental results demonstrate the strength of our approach.',\n",
       "  'id': '4155',\n",
       "  'title': 'A Novel Kernel for Learning a Neuron Model from Spike Train Data',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'We propose a discriminative model for recognizing group activities. Our model jointly captures the group activity, the individual person actions, and the interactions among them. Two new types of contextual information, group-person interaction and person-person interaction, are explored in a latent variable framework. Different from most of the previous latent structured models which assume a predefined structure for the hidden layer, e.g. a tree structure, we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference. Our experimental results demonstrate that by inferring this contextual information together with adaptive structures, the proposed model can significantly improve activity recognition performance.',\n",
       "  'id': '4158',\n",
       "  'title': 'Beyond Actions: Discriminative Models for Contextual Group Activities',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'The goal of decentralized optimization over a network is to optimize a global objective formed by a sum of local (possibly nonsmooth) convex functions using only local computation and communication. We develop and analyze distributed algorithms based on dual averaging of subgradients, and we provide sharp bounds on their convergence rates as a function of the network size and topology. Our analysis clearly separates the convergence of the optimization algorithm itself from the effects of communication constraints arising from the network structure. We show that the number of iterations required by our algorithm scales inversely in the spectral gap of the network. The sharpness of this prediction is confirmed both by theoretical lower bounds and simulations for various networks.',\n",
       "  'id': '4164',\n",
       "  'title': 'Distributed Dual Averaging In Networks',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Games of incomplete information, or Bayesian games, are an important game-theoretic model and have many applications in economics. We propose Bayesian action-graph games (BAGGs), a novel graphical representation for Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly express Bayesian games exhibiting commonly encountered types of structure including symmetry, action- and type-specific utility independence, and probabilistic independence of type distributions. We provide an algorithm for computing expected utility in BAGGs, and discuss conditions under which the algorithm runs in polynomial time.  Bayes-Nash equilibria of BAGGs can be computed by adapting existing algorithms for complete-information normal form games and leveraging our expected utility algorithm. We show both theoretically and empirically that our approaches improve significantly on the state of the art.',\n",
       "  'id': '4171',\n",
       "  'title': 'Bayesian Action-Graph Games',\n",
       "  'year': '2010'},\n",
       " {'abstract': \"We provide new theoretical results for apprenticeship learning, a variant of reinforcement learning in which the true reward function is unknown, and the goal is to perform well relative to an observed expert. We study a common approach to learning from expert demonstrations: using a classification algorithm to learn to imitate the expert's behavior. Although this straightforward learning strategy is widely-used in practice, it has been subject to very little formal analysis. We prove that, if the learned classifier has error rate $\\\\eps$, the difference between the value of the apprentice's policy and the expert's policy is $O(\\\\sqrt{\\\\eps})$. Further, we prove that this difference is only $O(\\\\eps)$ when the expert's policy is close to optimal. This latter result has an important practical consequence: Not only does imitating a near-optimal expert result in a better policy, but far fewer demonstrations are required to successfully imitate such an expert. This suggests an opportunity for substantial savings whenever the expert is known to be good, but demonstrations are expensive or difficult to obtain.\",\n",
       "  'id': '4180',\n",
       "  'title': 'A Reduction from Apprenticeship Learning to Classification',\n",
       "  'year': '2010'},\n",
       " {'abstract': 'Most methods for decision-theoretic online learning are based on the Hedge algorithm, which takes a parameter called the learning rate. In most previous analyses the learning rate was carefully tuned to obtain optimal worst-case performance, leading to suboptimal performance on easy instances, for example when there exists an action that is significantly better than all others. We propose a new way of setting the learning rate, which adapts to the difficulty of the learning problem: in the worst case our procedure still guarantees optimal performance, but on easy instances it achieves much smaller regret. In particular, our adaptive method achieves constant regret in a probabilistic setting, when there exists an action that on average obtains strictly smaller loss than all other actions. We also provide a simulation study comparing our approach to existing methods.',\n",
       "  'id': '4191',\n",
       "  'title': 'Adaptive Hedge',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Principal Components Analysis~(PCA) is often used as a feature extraction procedure. Given a matrix $X \\\\in \\\\mathbb{R}^{n \\\\times d}$, whose rows represent $n$ data points with respect to $d$ features, the top $k$ right singular vectors of $X$ (the so-called \\\\textit{eigenfeatures}), are arbitrary linear combinations of all available features. The eigenfeatures are very useful in data analysis, including the regularization of linear regression. Enforcing sparsity on the eigenfeatures, i.e., forcing them to be linear combinations of only a \\\\textit{small} number of actual features (as opposed to all available features), can promote better generalization error and improve the interpretability of the eigenfeatures. We present deterministic and randomized algorithms that construct such sparse eigenfeatures while \\\\emph{provably} achieving in-sample performance comparable to regularized linear regression. Our algorithms are relatively simple and practically efficient, and we demonstrate their performance on several data sets.',\n",
       "  'id': '4196',\n",
       "  'title': 'Sparse Features for PCA-Like Linear Regression',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Knowledge-based support vector machines (KBSVMs) incorporate advice from domain experts, which can improve generalization significantly. A major limitation that has not been fully addressed occurs when the expert advice is imperfect, which can lead to poorer models. We propose a model that extends KBSVMs and is able to not only learn from data and advice, but also simultaneously improve the advice. The proposed approach is particularly effective for knowledge discovery in domains with few labeled examples. The proposed model contains bilinear constraints, and is solved using two iterative approaches: successive linear programming and a constrained concave-convex approach. Experimental results demonstrate that these algorithms yield useful refinements to expert advice, as well as improve the performance of the learning algorithm overall.',\n",
       "  'id': '4199',\n",
       "  'title': 'Advice Refinement in Knowledge-Based SVMs',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'State-of-the-art statistical methods in neuroscience have enabled us to fit mathematical models to experimental data and subsequently to infer the dynamics of hidden parameters underlying the observable phenomena. Here, we develop a Bayesian method for inferring the time-varying mean and variance of the synaptic input, along with the dynamics of each ion channel from a single voltage trace of a neuron. An estimation problem may be formulated on the basis of the state-space model with prior distributions that penalize large fluctuations in these parameters. After optimizing the hyperparameters by maximizing the marginal likelihood, the state-space model provides the time-varying parameters of the input signals and the ion channel states. The proposed method is tested not only on the simulated data from the Hodgkin-Huxley type models but also on experimental data obtained from a cortical slice in vitro.',\n",
       "  'id': '4214',\n",
       "  'title': 'Estimating time-varying input signals and ion channel states from a single voltage trace of a neuron',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"In this paper, we derive a method to refine a Bayes network diagnostic model by exploiting constraints implied by expert decisions on test ordering. At each step, the expert executes an evidence gathering test, which suggests the test's relative diagnostic value. We demonstrate that consistency with an expert's test selection leads to non-convex constraints on the model parameters.  We incorporate these constraints by augmenting the network with nodes that represent the constraint likelihoods. Gibbs sampling, stochastic hill climbing and greedy search algorithms are proposed to find a MAP estimate that takes into account test ordering constraints and any data available. We demonstrate our approach on diagnostic sessions from a manufacturing scenario.\",\n",
       "  'id': '4219',\n",
       "  'title': \"Automated Refinement of Bayes Networks' Parameters based on Test Ordering Constraints\",\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Inexpensive RGB-D cameras that give an RGB image together with depth data have become widely available. In this paper, we use this data to build 3D point clouds of full indoor scenes such as an office and address the task of semantic labeling of these 3D point clouds. We propose a graphical model that captures various features and contextual relations, including the local visual appearance and shape cues, object co-occurence relationships and geometric relationships. With a large number of object classes and relations, the model?s parsimony becomes important and we address that by using multiple types of edge potentials. The model admits efficient approximate inference, and we train it using a maximum-margin learning approach. In our experiments over a total of 52 3D scenes of homes and offices (composed from about 550 views, having 2495 segments labeled with 27 object classes), we get a performance of 84.06% in labeling 17 object classes for offices, and 73.38% in labeling 17 object classes for home scenes. Finally, we applied these algorithms successfully on a mobile robot for the task of finding objects in large cluttered rooms.',\n",
       "  'id': '4226',\n",
       "  'title': 'Semantic Labeling of 3D Point Clouds for Indoor Scenes',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Non-negative data are commonly encountered in numerous fields, making non-negative least squares regression (NNLS) a frequently used tool.   At least relative to its simplicity, it often performs rather well in practice. Serious doubts about its usefulness arise for modern  high-dimensional linear models. Even in this setting - unlike first intuition may suggest - we show that for a broad class of designs, NNLS is resistant to overfitting and works excellently for sparse recovery when combined with thresholding, experimentally even outperforming L1-regularization.   Since NNLS also circumvents the delicate choice of a regularization parameter, our findings suggest that NNLS may be the method of choice.',\n",
       "  'id': '4231',\n",
       "  'title': 'Sparse recovery by thresholded non-negative least squares',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We present theoretical and empirical results for a framework  that combines the benefits of apprenticeship and autonomous reinforcement learning.  Our approach modifies an existing apprenticeship learning framework that relies on teacher demonstrations and does not necessarily explore the environment.  The first change is replacing previously used Mistake Bound model learners with a recently proposed framework that melds the  KWIK and Mistake Bound supervised learning protocols.  The second change is introducing a communication of expected utility from the student to the teacher.   The resulting system only uses teacher traces when the agent needs to learn concepts it cannot efficiently learn on its own.',\n",
       "  'id': '4240',\n",
       "  'title': 'Blending Autonomous Exploration and Apprenticeship Learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Off-policy learning, the ability for an agent to learn about a policy other than the one it is following, is a key element of Reinforcement Learning, and in recent years there has been much work on developing Temporal Different (TD) algorithms that are guaranteed to converge under off-policy sampling.  It has remained an open question, however, whether anything can be said a priori about the quality of the TD solution when off-policy sampling is employed with function approximation.  In general the answer is no: for arbitrary off-policy sampling the error of the TD solution can be unboundedly large, even when the approximator can represent the true value function well.  In this paper we propose a novel approach to address this problem: we show that by considering a certain convex subset of off-policy distributions we can indeed provide guarantees as to the solution quality similar to the on-policy case.  Furthermore, we show that we can efficiently project on to this convex set using only samples generated from the system.  The end result is a novel TD algorithm that has approximation guarantees even in the case of off-policy sampling and which empirically outperforms existing TD methods.',\n",
       "  'id': '4244',\n",
       "  'title': 'The Fixed Points of Off-Policy TD',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We analyze the convergence of gradient-based optimization algorithms whose updates depend on delayed stochastic gradient information. The  main application of our results is to the development of distributed  minimization algorithms where a master node performs parameter updates while worker nodes compute stochastic gradients based on local information in parallel, which may give rise to delays due to  asynchrony. Our main contribution is to show that for smooth stochastic problems, the delays are asymptotically negligible. In  application to distributed optimization, we show $n$-node architectures whose optimization error in stochastic problems---in spite of asynchronous delays---scales asymptotically as $\\\\order(1 / \\\\sqrt{nT})$, which is known to be optimal even in the absence of delays.',\n",
       "  'id': '4247',\n",
       "  'title': 'Distributed Delayed Stochastic Optimization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'A new Le ?vy process prior is proposed for an uncountable collection of covariate- dependent feature-learning measures; the model is called the kernel beta process (KBP). Available covariates are handled efficiently via the kernel construction, with covariates assumed observed with each data sample (?customer?), and latent covariates learned for each feature (?dish?). Each customer selects dishes from an infinite buffet, in a manner analogous to the beta process, with the added constraint that a customer first decides probabilistically whether to ?consider? a dish, based on the distance in covariate space between the customer and dish. If a customer does consider a particular dish, that dish is then selected probabilistically as in the beta process. The beta process is recovered as a limiting case of the KBP. An efficient Gibbs sampler is developed for computations, and state-of-the-art results are presented for image processing and music analysis tasks.',\n",
       "  'id': '4255',\n",
       "  'title': 'The Kernel Beta Process',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We address the challenging task of decoupling material properties from lighting properties given a single image. In the last two decades virtually all works have concentrated on exploiting edge information to address this problem. We take a different route by introducing a new prior on reflectance, that models reflectance values as being drawn from a sparse set of basis colors. This results in a Random Field model with global, latent variables (basis colors) and pixel-accurate output reflectance values. We show that without edge information high-quality results can be achieved, that are on par with methods exploiting this source of information. Finally, we present competitive results by integrating an additional edge model. We believe that our approach is a solid starting point for future development in this domain.',\n",
       "  'id': '4256',\n",
       "  'title': 'Recovering Intrinsic Images with a Global Sparsity Prior on Reflectance',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"The L_1 regularized Gaussian maximum likelihood estimator has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix, or alternatively the underlying graph structure of a Gaussian Markov Random Field, from very limited samples. We propose a novel algorithm for solving the resulting optimization problem which is a regularized log-determinant program.  In contrast to other state-of-the-art methods that largely use first order gradient information, our algorithm is based on Newton's method and employs a quadratic approximation, but with some modifications that leverage the structure of the sparse Gaussian MLE problem. We show that our method is superlinearly convergent, and also present experimental results using synthetic and real application data that demonstrate the considerable improvements in performance of our method when  compared to other state-of-the-art methods.\",\n",
       "  'id': '4266',\n",
       "  'title': 'Sparse Inverse Covariance Matrix Estimation Using Quadratic Approximation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Recently, Mahoney and Orecchia demonstrated that popular diffusion-based procedures to compute a quick approximation to the first nontrivial eigenvector of a data graph Laplacian exactly solve certain regularized Semi-Definite Programs (SDPs). In this paper, we extend that result by providing a statistical interpretation of their approximation procedure. Our interpretation will be analogous to the manner in which l2-regularized or l1-regularized l2 regression (often called Ridge regression and Lasso regression, respectively) can be interpreted in terms of a Gaussian prior or a Laplace prior, respectively, on the coefficient vector of the regression problem. Our framework will imply that the solutions to the Mahoney-Orecchia regularized SDP can be interpreted as regularized estimates of the pseudoinverse of the graph Laplacian. Conversely, it will imply that the solution to this regularized estimation problem can be computed very quickly by running, e.g., the fast diffusion-based PageRank procedure for computing an approximation to the first nontrivial eigenvector of the graph Laplacian. Empirical results are also provided to illustrate the manner in which approximate eigenvector computation implicitly performs statistical regularization, relative to running the corresponding exact algorithm.',\n",
       "  'id': '4272',\n",
       "  'title': 'Regularized Laplacian Estimation and Fast Eigenvector Approximation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This paper considers the problem of embedding directed graphs in Euclidean space while retaining directional information. We model the observed graph as a sample from a manifold endowed with a vector field, and we design an algo- rithm that separates and recovers the features of this process: the geometry of the manifold, the data density and the vector field. The algorithm is motivated by our analysis of Laplacian-type operators and their continuous limit as generators of diffusions on a manifold. We illustrate the recovery algorithm on both artificially constructed and real data.',\n",
       "  'id': '4282',\n",
       "  'title': 'Directed Graph Embedding: an Algorithm based on Continuous Limits of Laplacian-type Operators',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of Bayesian inference for continuous time multi-stable stochastic systems which can change both their diffusion and drift parameters at discrete times. We propose exact inference and sampling methodologies for two specific cases where the discontinuous dynamics is given by a Poisson process and a two-state Markovian switch. We test the methodology on simulated data, and apply it to two real data sets in finance and systems biology. Our experimental results show that the approach leads to valid inferences and non-trivial insights.',\n",
       "  'id': '4286',\n",
       "  'title': 'Inference in continuous-time change-point models',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Neurons in the neocortex code and compute as part of a locally interconnected population. Large-scale multi-electrode recording makes it possible to access these population processes empirically by fitting statistical models to unaveraged data. What statistical structure best describes the concurrent spiking of cells within  a local network? We argue that in the cortex, where firing exhibits extensive correlations in both time and space and where a typical sample of neurons still reflects only a very small fraction of the local population, the most appropriate model captures shared variability by a low-dimensional latent process evolving with smooth dynamics, rather than by putative direct coupling. We test this claim by comparing  a latent dynamical model with realistic spiking observations to coupled generalised  linear spike-response models (GLMs) using cortical recordings. We find that the latent dynamical approach outperforms the GLM in terms of goodness-of-fit, and reproduces the temporal correlations in the data more accurately. We also compare models whose observations models are either derived from a Gaussian or point-process models, finding that the non-Gaussian model provides slightly  better goodness-of-fit and more realistic population spike counts.',\n",
       "  'id': '4289',\n",
       "  'title': 'Empirical models of spiking in neural populations',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In this paper, we address the problem of learning the structure of a pairwise graphical model from samples in a high-dimensional setting. Our first main result studies the sparsistency, or consistency in sparsity pattern recovery, properties of a forward-backward greedy algorithm as applied to general statistical models. As a special case, we then apply this algorithm to learn the structure of a discrete graphical model via neighborhood estimation. As a corollary of our general result, we derive sufficient conditions on the number of samples n, the maximum node-degree d and the problem size p, as well as other conditions on the model parameters, so that the algorithm recovers all the edges with high probability. Our result guarantees graph selection for samples scaling as n = Omega(d log(p)), in contrast to existing convex-optimization based algorithms that require a sample complexity of Omega(d^2 log(p)). Further, the greedy algorithm only requires a restricted strong convexity condition which is typically milder than irrepresentability assumptions. We corroborate these results using numerical simulations at the end.',\n",
       "  'id': '4290',\n",
       "  'title': 'On Learning Discrete Graphical Models using Greedy Methods',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Recent deep learning and unsupervised feature learning systems that learn from unlabeled data have achieved high performance in benchmarks by using extremely large architectures with many features (hidden units) at each layer.  Unfortunately, for such large architectures the number of parameters usually grows quadratically in the width of the network, thus necessitating hand-coded \"local receptive fields\" that limit the number of connections from lower level features to higher ones (e.g., based on spatial locality).  In this paper we propose a fast method to choose these connections that may be incorporated into a wide variety of unsupervised training methods.  Specifically, we choose local receptive fields that group together those low-level features that are most similar to each other according to a pairwise similarity metric.  This approach  allows us to harness the advantages of local receptive fields (such  as improved scalability, and reduced data requirements) when we do  not know how to specify such receptive fields by hand or where our  unsupervised training algorithm has no obvious generalization to a  topographic setting.  We produce results showing how this method allows us to use even simple unsupervised training algorithms to train successful multi-layered etworks that achieve state-of-the-art results on CIFAR and STL datasets: 82.0% and 60.1% accuracy, respectively.',\n",
       "  'id': '4293',\n",
       "  'title': 'Selecting Receptive Fields in Deep Networks',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Applications such as robot control and wireless communication require planning under uncertainty. Partially observable Markov decision processes (POMDPs) plan policies for single agents under uncertainty and their decentralized versions (DEC-POMDPs) find a policy for multiple agents. The policy in infinite-horizon POMDP and DEC-POMDP problems has been represented as finite state controllers (FSCs). We introduce a novel class of periodic FSCs, composed of layers connected only to the previous and next layer. Our periodic FSC method finds a deterministic finite-horizon policy and converts it to an initial periodic infinite-horizon policy. This policy is optimized by a new infinite-horizon algorithm to yield deterministic periodic policies, and by a new expectation maximization algorithm to yield stochastic periodic policies. Our method yields better results than earlier planning methods and can compute larger solutions than with regular FSCs.',\n",
       "  'id': '4297',\n",
       "  'title': 'Periodic Finite State Controllers for Efficient POMDP and DEC-POMDP Planning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Learning problems such as logistic regression are typically formulated as pure  optimization problems defined on some loss function. We argue that this view  ignores the fact that the loss function depends on stochastically generated data  which in turn determines an intrinsic scale of precision for statistical estimation.  By considering the statistical properties of the update variables used during  the optimization (e.g. gradients), we can construct frequentist hypothesis tests  to determine the reliability of these updates. We utilize subsets of the data  for computing updates, and use the hypothesis tests for determining when the  batch-size needs to be increased. This provides computational benefits and avoids  overfitting by stopping when the batch-size has become equal to size of the full  dataset. Moreover, the proposed algorithms depend on a single interpretable  parameter ? the probability for an update to be in the wrong direction ? which is  set to a single value across all algorithms and datasets. In this paper, we illustrate  these ideas on three L1 regularized coordinate algorithms: L1 -regularized L2 -loss  SVMs, L1 -regularized logistic regression, and the Lasso, but we emphasize that  the underlying methods are much more generally applicable.',\n",
       "  'id': '4308',\n",
       "  'title': 'Statistical Tests for Optimization Efficiency',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Classical Boosting algorithms, such as AdaBoost, build a strong classifier without concern about the computational cost.  Some applications, in particular in computer vision, may involve up to millions of training examples and features.  In such contexts, the training time may become prohibitive.  Several methods exist to accelerate training, typically either by sampling the features, or the examples, used to train the weak learners.  Even if those methods can precisely quantify the speed improvement they deliver, they offer no guarantee of being more efficient than any other, given the same amount of time.    This paper aims at shading some light on this problem, i.e. given a fixed amount of time, for a particular problem, which strategy is optimal in order to reduce the training loss the most.  We apply this analysis to the design of new algorithms which estimate on the fly at every iteration the optimal trade-off between the number of samples and the number of features to look at in order to maximize the expected loss reduction.  Experiments in object recognition with two standard computer vision data-sets show that the adaptive methods we propose outperform basic sampling and state-of-the-art bandit methods.',\n",
       "  'id': '4310',\n",
       "  'title': 'Boosting with Maximum Adaptive Sampling',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Extensive evidence suggests that items are not encoded independently in visual short-term memory (VSTM). However, previous research has not quantitatively considered how the encoding of an item influences the encoding of other items. Here, we model the dependencies among VSTM representations using a multivariate Gaussian distribution with a stimulus-dependent mean and covariance matrix. We report the results of an experiment designed to determine the specific form of the stimulus-dependence of the mean and the covariance matrix. We find that the magnitude of the covariance between the representations of two items is a monotonically decreasing function of the difference between the items' feature values, similar to a Gaussian process with a distance-dependent, stationary kernel function. We further show that this type of covariance function can be explained as a natural consequence of encoding multiple stimuli in a population of neurons with correlated responses.\",\n",
       "  'id': '4320',\n",
       "  'title': 'Probabilistic Modeling of Dependencies Among Visual Short-Term Memory Representations',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"The efficient coding hypothesis holds that neural receptive fields are adapted to the statistics of the environment, but is agnostic to the timescale of this adaptation, which occurs on both evolutionary and developmental timescales. In this work we focus on that component of adaptation which occurs during an organism's lifetime, and show that a number of unsupervised feature learning algorithms can account for features of normal receptive field properties across multiple primary sensory cortices. Furthermore, we show that the same algorithms account for altered receptive field properties in response to experimentally altered environmental statistics. Based on these modeling results we propose these models as phenomenological models of receptive field plasticity during an organism's lifetime. Finally, due to the success of the same models in multiple sensory areas, we suggest that these algorithms may provide a constructive realization of the theory, first proposed by Mountcastle (1978), that a qualitatively similar learning algorithm acts throughout primary sensory cortices.\",\n",
       "  'id': '4331',\n",
       "  'title': 'Unsupervised learning models of primary cortical receptive fields and receptive field plasticity',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Unsupervised feature learning has been shown to be effective at learning representations that perform well on image, video and audio classification. However, many existing feature learning algorithms are hard to use and require extensive hyperparameter tuning. In this work, we present sparse filtering, a simple new algorithm which is efficient and only has one hyperparameter, the number of features to learn.  In contrast to most other feature learning methods, sparse filtering does not explicitly attempt to construct a model of the data distribution. Instead, it optimizes a simple cost function -- the sparsity of L2-normalized features -- which can easily be implemented in a few lines of MATLAB code. Sparse filtering scales gracefully to handle high-dimensional inputs, and can also be used to learn meaningful features in additional layers with greedy layer-wise stacking. We evaluate sparse filtering on natural images, object classification (STL-10), and phone classification (TIMIT), and show that our method works well on a range of different modalities.',\n",
       "  'id': '4334',\n",
       "  'title': 'Sparse Filtering',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In the vast majority of recent work on sparse estimation algorithms, performance has been evaluated using ideal or quasi-ideal dictionaries (e.g., random Gaussian or Fourier) characterized by unit $\\\\ell_2$ norm, incoherent columns or features.  But in reality, these types of dictionaries represent only a subset of the dictionaries that are actually used in practice (largely restricted to idealized compressive sensing applications).  In contrast, herein sparse estimation is considered in the context of structured dictionaries possibly exhibiting high coherence between arbitrary groups of columns and/or rows.  Sparse penalized regression models are analyzed with the purpose of finding, to the extent possible, regimes of dictionary invariant performance.  In particular, a Type II Bayesian estimator with a dictionary-dependent sparsity penalty is shown to have a number of desirable invariance properties leading to provable advantages over more conventional penalties such as the $\\\\ell_1$ norm, especially in areas where existing theoretical recovery guarantees no longer hold.  This can translate into improved performance in applications such as model selection with correlated features, source localization, and compressive sensing with constrained measurement directions.',\n",
       "  'id': '4335',\n",
       "  'title': 'Sparse Estimation with Structured Dictionaries',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Sparse PCA provides a linear combination of small number of features that maximizes variance across data. Although Sparse PCA has apparent advantages compared to PCA, such as better interpretability, it is generally thought to be computationally much more expensive. In this paper, we demonstrate the surprising fact that sparse PCA can be easier than PCA in practice, and that it can be reliably applied to very large data sets. This comes from a rigorous feature elimination  pre-processing result, coupled with the favorable fact that features in real-life data typically have exponentially decreasing variances, which allows for many features to be eliminated. We introduce a fast block coordinate ascent algorithm with much better computational complexity than the existing first-order ones. We provide  experimental results obtained on text corpora involving millions of documents and hundreds of thousands of features. These results illustrate how Sparse PCA can help organize a large corpus of text data in a user-interpretable way, providing an attractive alternative approach to topic models.',\n",
       "  'id': '4337',\n",
       "  'title': 'Large-Scale Sparse Principal Component Analysis with Application to Text Data',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'An increasing number of experimental studies indicate that perception encodes a posterior probability distribution over possible causes of sensory stimuli, which is used to act close to optimally in the environment. One outstanding difficulty with this hypothesis is that the exact posterior will in general be too complex to be represented directly, and thus neurons will have to represent an approximation of this distribution. Two influential proposals of efficient posterior representation by neural populations are: 1) neural activity represents samples of the underlying distribution, or 2) they represent a parametric representation of a variational approximation of the posterior. We show that these approaches can be combined for an inference scheme that retains the advantages of both: it is able to represent multiple modes and arbitrary correlations, a feature of sampling methods, and it reduces the represented space to regions of high probability mass, a strength of variational approximations. Neurally, the combined method can be interpreted as a feed-forward preselection of the relevant state space, followed by a neural dynamics implementation of Markov Chain Monte Carlo (MCMC) to approximate the posterior over the relevant states. We demonstrate the effectiveness and efficiency of this approach on a sparse coding model. In numerical experiments on artificial data and image patches, we compare the performance of the algorithms to that of exact EM, variational state space selection alone, MCMC alone, and the combined select and sample approach. The select and sample approach integrates the advantages of the sampling and variational approximations, and forms a robust, neurally plausible, and very efficient model of processing and learning in cortical networks. For sparse coding we show applications easily exceeding a thousand observed and a thousand hidden dimensions.',\n",
       "  'id': '4346',\n",
       "  'title': 'Select and Sample - A Model of Efficient Neural Inference and Learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Most previous research on image categorization has focused on medium-scale data sets, while large-scale image categorization with millions of images from thousands of categories remains a challenge. With the emergence of structured large-scale dataset such as the ImageNet, rich information about the conceptual relationships between images, such as a tree hierarchy among various image categories, become available. As human cognition of complex visual world benefits from underlying semantic relationships between object classes, we believe a machine learning system can and should leverage such information as well for better performance. In this paper, we employ such semantic relatedness among image categories for large-scale image categorization. Specifically, a category hierarchy is utilized to properly define loss function and select common set of features for  related categories. An efficient optimization method based on proximal approximation and accelerated parallel gradient method is introduced. Experimental results on a subset of ImageNet containing 1.2 million images from 1000 categories demonstrate the effectiveness and promise of our proposed approach.',\n",
       "  'id': '4347',\n",
       "  'title': 'Large-Scale Category Structure Aware Image Categorization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We are motivated by an application to extract a representative subset of machine learning training data and by the poor empirical performance we observe of the popular minimum norm algorithm. In fact, for our application, minimum norm can have a running time of about O(n^7 ) (O(n^5 ) oracle calls). We therefore propose a fast approximate method to minimize arbitrary submodular functions. For a large sub-class of submodular functions, the algorithm is exact. Other submodular functions are iteratively approximated by tight submodular upper bounds, and then repeatedly optimized. We show theoretical properties, and empirical results suggest significant speedups over minimum norm while retaining higher accuracies.',\n",
       "  'id': '4348',\n",
       "  'title': 'On fast approximate submodular minimization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Given a set V of n vectors in d-dimensional space, we provide an efficient method  for computing quality upper and lower bounds of the Euclidean distances between  a pair of the vectors in V . For this purpose, we define a distance measure, called  the MS-distance, by using the mean and the standard deviation values of vectors in  V . Once we compute the mean and the standard deviation values of vectors in V in  O(dn) time, the MS-distance between them provides upper and lower bounds of  Euclidean distance between a pair of vectors in V in constant time. Furthermore,  these bounds can be refined further such that they converge monotonically to the  exact Euclidean distance within d refinement steps. We also provide an analysis on  a random sequence of refinement steps which can justify why MS-distance should  be refined to provide very tight bounds in a few steps of a typical sequence. The  MS-distance can be used to various problems where the Euclidean distance is used  to measure the proximity or similarity between objects. We provide experimental  results on the nearest and the farthest neighbor searches.',\n",
       "  'id': '4353',\n",
       "  'title': 'Convergent Bounds on the Euclidean Distance',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Variability in single neuron models is typically implemented either by a stochastic Leaky-Integrate-and-Fire model or by a model of the Generalized Linear Model (GLM) family. We use analytical and numerical methods to relate state-of-the-art models from both schools of thought. First we find the analytical expressions relating the subthreshold voltage from the Adaptive Exponential Integrate-and-Fire model (AdEx) to the Spike-Response Model with escape noise (SRM as an example of a GLM). Then we calculate numerically the link-function that provides the firing probability given a deterministic membrane potential. We find a mathematical expression for this link-function and test the ability of the GLM to predict the firing probability of a neuron receiving complex stimulation. Comparing the prediction performance of various link-functions, we find that a GLM with an exponential link-function provides an excellent approximation to the Adaptive Exponential Integrate-and-Fire with colored-noise input. These results help to understand the relationship between the different approaches to stochastic neuron models.',\n",
       "  'id': '4355',\n",
       "  'title': 'From Stochastic Nonlinear Integrate-and-Fire to Generalized Linear Models',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In many clustering problems, we have access to multiple views of the data each  of which could be individually used for clustering. Exploiting information from  multiple views, one can hope to find a clustering that is more accurate than the  ones obtained using the individual views. Since the true clustering would assign  a point to the same cluster irrespective of the view, we can approach this problem  by looking for clusterings that are consistent across the views, i.e., corresponding  data points in each view should have same cluster membership. We propose a  spectral clustering framework that achieves this goal by co-regularizing the clustering  hypotheses, and propose two co-regularization schemes to accomplish this.  Experimental comparisons with a number of baselines on two synthetic and three  real-world datasets establish the efficacy of our proposed approaches.',\n",
       "  'id': '4360',\n",
       "  'title': 'Co-regularized Multi-view Spectral Clustering',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Probabilistic logics are receiving a lot of attention today because of their expressive power for knowledge representation and learning. However, this expressivity is detrimental to the tractability of inference, when done at the propositional level.  To solve this problem, various lifted inference algorithms have been proposed that reason at the first-order level, about groups of objects as a whole. Despite the existence of various lifted inference approaches, there are currently no completeness results about these algorithms.  The key contribution of this paper is that we introduce a formal definition of lifted inference that allows us to reason about the completeness of lifted inference algorithms relative to a particular class of probabilistic models.  We then show how to obtain a completeness result using a first-order knowledge compilation approach for theories of formulae containing up to two logical variables.',\n",
       "  'id': '4374',\n",
       "  'title': 'On the Completeness of First-Order Knowledge Compilation for Lifted Probabilistic Inference',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve state-of-the-art performance on a variety of machine  learning tasks.  Several researchers have recently proposed schemes  to parallelize SGD, but all require  performance-destroying memory locking and synchronization. This work aims to show using novel theoretical analysis, algorithms,  and implementation that SGD can be implemented *without any locking*. We present an update scheme called Hogwild which allows processors access to shared memory with the possibility of overwriting each other's work. We show that when the associated optimization problem is sparse, meaning most gradient updates only modify small parts of the decision variable, then Hogwild achieves a nearly optimal rate of convergence.  We demonstrate experimentally that Hogwild outperforms alternative schemes that use locking by an order of magnitude.\",\n",
       "  'id': '4390',\n",
       "  'title': 'Hogwild: A Lock-Free Approach to Parallelizing Stochastic Gradient Descent',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This paper studies the problem of semi-supervised learning from the vector field perspective. Many of the existing work use the graph Laplacian to ensure the smoothness of the prediction function on the data manifold. However, beyond smoothness, it is suggested by recent theoretical work that we should ensure second order smoothness for achieving faster rates of convergence for semi-supervised regression problems. To achieve this goal, we show that the second order smoothness measures the linearity of the function, and the gradient field of a linear function has to be a parallel vector field. Consequently, we propose to find a function which minimizes the empirical error, and simultaneously requires its gradient field to be as parallel as possible. We give a continuous objective function on the manifold and discuss how to discretize it by using random points. The discretized optimization problem turns out to be a sparse linear system which can be solved very efficiently. The experimental results have demonstrated the effectiveness of our proposed approach.',\n",
       "  'id': '4398',\n",
       "  'title': 'Semi-supervised Regression via Parallel Field Regularization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We improve the theoretical analysis and empirical performance of algorithms for the stochastic multi-armed bandit problem and the linear stochastic multi-armed bandit problem. In particular, we show that a simple modification of Auer?s UCB algorithm (Auer, 2002) achieves with high probability constant regret. More importantly, we modify and, consequently, improve the analysis of the algorithm for the for linear stochastic bandit problem studied by Auer (2002), Dani et al. (2008), Rusmevichientong and Tsitsiklis (2010), Li et al. (2010). Our modification improves the regret bound by a logarithmic factor, though experiments show a vast improvement. In both cases, the improvement stems from the construction of smaller confidence sets. For their construction we use a novel tail inequality for vector-valued martingales.',\n",
       "  'id': '4417',\n",
       "  'title': 'Improved Algorithms for Linear Stochastic Bandits',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Log-linear models are widely used probability models for statistical pattern recognition. Typically, log-linear models are trained according to a convex criterion. In recent years, the interest in log-linear models has greatly increased. The optimization of log-linear model parameters is costly and therefore an important topic, in particular for large-scale applications. Different optimization algorithms have been evaluated empirically in many papers. In this work, we analyze the optimization problem analytically and show that the training of log-linear models can be highly ill-conditioned. We verify our findings on two handwriting tasks. By making use of our convergence analysis, we obtain good results on a large-scale continuous handwriting recognition task with a simple and generic approach.',\n",
       "  'id': '4421',\n",
       "  'title': 'A Convergence Analysis of Log-Linear Training',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Many machine learning and signal processing problems can be formulated as linearly constrained convex programs, which could be efficiently solved by the alternating direction method (ADM). However, usually the subproblems in ADM are easily solvable only when the linear mappings in the constraints are identities. To address this issue, we propose a linearized ADM (LADM) method by linearizing the quadratic penalty term and adding a proximal term when solving the subproblems. For fast convergence, we also allow the penalty to change adaptively according a novel update rule. We prove the global convergence of LADM with adaptive penalty (LADMAP). As an example, we apply LADMAP to solve low-rank representation (LRR), which is an important subspace clustering technique yet suffers from high computation cost. By combining LADMAP with a skinny SVD representation technique, we are able to reduce the complexity $O(n^3)$  of the original ADM based method to $O(rn^2)$, where $r$ and $n$ are the rank and size of the representation matrix, respectively, hence making LRR possible for large scale applications. Numerical experiments verify that for LRR our LADMAP based methods are much faster than state-of-the-art algorithms.',\n",
       "  'id': '4434',\n",
       "  'title': 'Linearized Alternating Direction Method with Adaptive Penalty for Low-Rank Representation',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"We propose a novel Adaptive Markov Chain Monte Carlo algorithm to  compute the partition function. In particular, we show how to  accelerate a flat histogram sampling technique by significantly  reducing the number of ``null moves'' in the chain, while maintaining  asymptotic convergence properties. Our experiments show that our  method converges quickly to highly accurate solutions on a range of  benchmark instances, outperforming other state-of-the-art methods such  as IJGP, TRW, and Gibbs sampling both in run-time and accuracy. We  also show how obtaining a so-called density of states distribution  allows for efficient weight learning in Markov Logic theories.\",\n",
       "  'id': '4448',\n",
       "  'title': 'Accelerated Adaptive Markov Chain for Partition Function Computation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We analyze the statistical performance of a recently proposed convex tensor decomposition algorithm. Conventionally tensor decomposition has been formulated as non-convex optimization problems, which hindered the analysis of their performance. We show under some conditions that the mean squared error of the convex method scales linearly with the quantity we call the normalized rank of the true tensor. The current analysis naturally extends the analysis of convex low-rank matrix estimation to tensors. Furthermore, we show through numerical experiments that our theory can precisely predict the scaling behaviour in practice.',\n",
       "  'id': '4453',\n",
       "  'title': 'Statistical Performance of Convex Tensor Decomposition',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'When used to learn high dimensional parametric probabilistic models, the clas- sical maximum likelihood (ML) learning often suffers from computational in- tractability, which motivates the active developments of non-ML learning meth- ods. Yet, because of their divergent motivations and forms, the objective func- tions of many non-ML learning methods are seemingly unrelated, and there lacks a unified framework to understand them. In this work, based on an information geometric view of parametric learning, we introduce a general non-ML learning principle termed as minimum KL contraction, where we seek optimal parameters that minimizes the contraction of the KL divergence between the two distributions after they are transformed with a KL contraction operator. We then show that the objective functions of several important or recently developed non-ML learn- ing methods, including contrastive divergence [12], noise-contrastive estimation [11], partial likelihood [7], non-local contrastive objectives [31], score match- ing [14], pseudo-likelihood [3], maximum conditional likelihood [17], maximum mutual information [2], maximum marginal likelihood [9], and conditional and marginal composite likelihood [24], can be unified under the minimum KL con- traction framework with different choices of the KL contraction operators.',\n",
       "  'id': '4456',\n",
       "  'title': 'Unifying Non-Maximum Likelihood Learning Objectives with Minimum KL Contraction',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'The performance of Markov chain Monte Carlo methods is often sensitive to the scaling and correlations between the random variables of interest. An important source of information about the local correlation and scale is given by the Hessian matrix of the target distribution, but this is often either computationally expensive or infeasible. In this paper we propose MCMC samplers that make use of quasi-Newton approximations from the optimization literature, that approximate the Hessian of the target distribution from previous samples and gradients generated by the sampler. A key issue is that MCMC samplers that depend on the history of previous states are in general not valid. We address this problem by using limited memory quasi-Newton methods, which depend only on a fixed window of previous samples. On several real world datasets, we show that the quasi-Newton sampler is a more effective sampler than standard Hamiltonian Monte Carlo at a fraction of the cost of MCMC methods that require higher-order derivatives.',\n",
       "  'id': '4464',\n",
       "  'title': 'Quasi-Newton Methods for Markov Chain Monte Carlo',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We propose an online prediction version of submodular set cover with connections to ranking and repeated active learning.  In each round, the learning algorithm chooses a sequence of items.  The algorithm then receives a monotone submodular function and suffers loss equal to the cover time of the function: the number of items needed, when items are selected in order of the chosen sequence, to achieve a coverage constraint.  We develop an online learning algorithm whose loss converges to approximately that of the best sequence in hindsight.  Our proposed algorithm is readily extended to a setting where multiple functions are revealed at each round and to bandit and contextual bandit settings.',\n",
       "  'id': '4465',\n",
       "  'title': 'Online Submodular Set Cover, Ranking, and Repeated Active Learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'With the advent of crowdsourcing services it has become quite cheap and reasonably effective to get a dataset labeled by multiple annotators in a short amount of time. Various methods have been proposed to estimate the consensus labels by correcting for the bias of annotators with different kinds of expertise. Often we have low quality annotators or spammers--annotators who assign labels randomly (e.g., without actually looking at the instance). Spammers can make the cost of acquiring labels very expensive and can potentially degrade the quality of the consensus labels. In this paper we formalize the notion of a spammer and define a score which can be used to rank the annotators---with the spammers having a score close to zero and the good annotators having a high score close to one.',\n",
       "  'id': '4469',\n",
       "  'title': 'Ranking annotators for crowdsourced labeling tasks',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This paper addresses the problem of minimizing a convex, Lipschitz  function $f$ over a convex, compact set $X$ under a stochastic bandit feedback model. In this model, the algorithm is allowed to  observe noisy realizations of the function value $f(x)$ at any query  point $x \\\\in X$. We demonstrate a generalization of the  ellipsoid algorithm that incurs $O(\\\\poly(d)\\\\sqrt{T})$ regret. Since any algorithm has regret at least $\\\\Omega(\\\\sqrt{T})$  on this problem, our algorithm is optimal in terms of the scaling  with $T$.',\n",
       "  'id': '4475',\n",
       "  'title': 'Stochastic convex optimization with bandit feedback',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"We derive algorithms for generalised tensor factorisation (GTF) by building upon the well-established theory of Generalised Linear Models. Our algorithms are general in the sense that we can compute arbitrary factorisations in a message passing framework, derived for a broad class of exponential family distributions including special cases such as Tweedie's distributions corresponding to $\\\\beta$-divergences. By bounding the step size of the Fisher Scoring iteration of the GLM, we obtain general updates for real data and multiplicative updates for non-negative data. The GTF framework is, then extended easily to address the problems when multiple observed tensors are factorised simultaneously. We illustrate our coupled factorisation approach on synthetic data as well as on a musical audio restoration problem.\",\n",
       "  'id': '4480',\n",
       "  'title': 'Generalised Coupled Tensor Factorisation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We describe a novel technique for feature combination in the bag-of-words model of image classification. Our approach builds discriminative compound words from primitive cues learned independently from training images. Our main observation is that modeling joint-cue distributions independently is more statistically robust for typical classification problems than attempting to empirically estimate the dependent, joint-cue distribution directly. We use Information theoretic vocabulary compression to find discriminative combinations of cues and the resulting vocabulary of portmanteau words is compact, has the cue binding property, and supports individual weighting of cues in the final image representation. State-of-the-art results on both the Oxford Flower-102 and Caltech-UCSD Bird-200 datasets demonstrate the effectiveness of our technique compared to other, significantly more complex approaches to multi-cue image representation',\n",
       "  'id': '4481',\n",
       "  'title': 'Portmanteau Vocabularies for Multi-Cue Image Representation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'How should we design experiments to maximize performance of a complex system, taking into account uncontrollable environmental conditions? How should we select relevant documents (ads) to display, given information about the user? These tasks can be formalized as contextual bandit problems, where at each round, we receive context (about the experimental conditions, the query), and have to choose an action (parameters, documents). The key challenge is to trade off exploration by gathering data for estimating the mean payoff function over the context-action space, and to exploit by choosing an action deemed optimal based on the gathered data. We model the payoff function as a sample from a Gaussian process defined over the joint context-action space, and develop CGP-UCB, an intuitive upper-confidence style algorithm. We show that by mixing and matching kernels for contexts and actions, CGP-UCB can handle a variety of practical applications. We further provide generic tools for deriving regret bounds when using such composite kernel functions. Lastly, we evaluate our algorithm on two case studies, in the context of automated vaccine design and sensor management. We show that context-sensitive optimization outperforms no or naive use of context.',\n",
       "  'id': '4487',\n",
       "  'title': 'Contextual Gaussian Process Bandit Optimization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We study multi-label prediction for structured output spaces, a problem that occurs, for example, in object detection in images, secondary structure prediction in computational biology, and graph matching with symmetries. Conventional multi-label classification techniques are typically not applicable in this situation, because they require explicit enumeration of the label space, which is infeasible in case of structured outputs. Relying on techniques originally designed for single- label structured prediction, in particular structured support vector machines, results in reduced prediction accuracy, or leads to infeasible optimization problems.  In this work we derive a maximum-margin training formulation for multi-label structured prediction that remains computationally tractable while achieving high prediction accuracy. It also shares most beneficial properties with single-label maximum-margin approaches, in particular a formulation as a convex optimization problem, efficient working set training, and PAC-Bayesian generalization bounds.',\n",
       "  'id': '4184',\n",
       "  'title': 'Maximum Margin Multi-Label Structured Prediction',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Is it possible to crowdsource categorization? Amongst the challenges: (a) each annotator has only a partial view of the data, (b) different annotators may have different clustering criteria and may produce different numbers of categories, (c) the underlying category structure may be hierarchical. We propose a Bayesian model of how annotators may approach clustering and show how one may infer clusters/categories, as well as annotator parameters, using this model. Our experiments, carried out on large collections of images, suggest that Bayesian crowdclustering works well and may be superior to single-expert annotations.',\n",
       "  'id': '4187',\n",
       "  'title': 'Crowdclustering',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We present a new algorithm for exactly solving decision-making problems represented as an influence diagram. We do not require the usual assumptions of no forgetting and regularity, which allows us to solve problems with limited information. The algorithm, which implements a sophisticated variable elimination procedure, is empirically shown to outperform a state-of-the-art algorithm in randomly generated problems of up to 150 variables and $10^{64}$ strategies.',\n",
       "  'id': '4188',\n",
       "  'title': 'Solving Decision Problems with Limited Information',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Recently, there has been substantial interest in using large amounts of unlabeled data to learn word representations which can then be used as features in supervised classifiers for NLP tasks. However, most current approaches are slow to train, do not model context of the word, and lack theoretical grounding. In this paper, we present a new learning method, Low Rank Multi-View Learning (LR-MVL) which uses a fast spectral method to estimate  low dimensional context-specific word representations from unlabeled data. These representation features can then be used with any supervised learner. LR-MVL is extremely fast, gives guaranteed convergence to a global optimum, is theoretically elegant, and achieves state-of-the-art performance on named entity recognition (NER) and chunking problems.',\n",
       "  'id': '4193',\n",
       "  'title': 'Multi-View Learning of Word Embeddings via CCA',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We present a novel regularization-based Multitask Learning (MTL) formulation  for Structured Output (SO) prediction for the case of hierarchical task relations.  Structured output learning often results in dif?cult inference problems and   requires large amounts of training data to obtain accurate models. We propose to  use MTL to exploit information available for related structured output learning  tasks by means of hierarchical regularization. Due to the combination of example   sets, the cost of training models for structured output prediction can easily  become infeasible for real world applications. We thus propose an ef?cient   algorithm based on bundle methods to solve the optimization problems resulting from  MTL structured output learning. We demonstrate the performance of our approach  on gene ?nding problems from the application domain of computational biology.  We show that 1) our proposed solver achieves much faster convergence than previous   methods and 2) that the Hierarchical SO-MTL approach clearly outperforms  considered non-MTL methods.',\n",
       "  'id': '4194',\n",
       "  'title': 'Hierarchical Multitask Structured Output Learning for Large-scale Sequence Segmentation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In recent years semidefinite optimization has become a tool of major importance in various optimization and machine learning problems. In many of these problems the amount of data in practice is so large that there is a constant need for faster algorithms. In this work we present the first  sublinear time approximation algorithm for semidefinite programs which we believe may be useful for such problems in which the size of data may cause even linear time algorithms to have prohibitive running times in practice. We present the algorithm and its analysis alongside with some theoretical lower bounds and an improved algorithm for the special problem of supervised learning of a distance metric.',\n",
       "  'id': '4198',\n",
       "  'title': 'Approximating Semidefinite Programs in Sublinear Time',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This paper proposes a novel boosting algorithm called VadaBoost which is motivated by recent empirical Bernstein bounds.  VadaBoost iteratively minimizes a cost function that balances the sample mean and the sample variance of the exponential loss. Each step of the proposed algorithm minimizes the cost efficiently by providing weighted data to a weak learner rather than requiring a brute force evaluation of all possible weak learners. Thus, the proposed algorithm solves a key limitation of previous empirical Bernstein boosting methods which required brute force enumeration of all possible weak learners. Experimental results confirm that the new algorithm achieves the performance improvements of EBBoost yet goes beyond decision stumps to handle any weak learner. Significant performance gains are obtained over AdaBoost for arbitrary weak learners including decision trees (CART).',\n",
       "  'id': '4207',\n",
       "  'title': 'Variance Penalizing AdaBoost',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We prove a new oracle inequality for support vector machines with Gaussian RBF kernels solving the regularized least squares regression problem. To this end, we apply the modulus of smoothness. With the help of the new oracle inequality we then derive learning rates that can also be achieved by a simple data-dependent parameter selection method. Finally, it turns out that our learning rates are asymptotically optimal for regression functions satisfying certain standard smoothness conditions.',\n",
       "  'id': '4216',\n",
       "  'title': 'Optimal learning rates for least squares SVMs using Gaussian kernels',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'There are many settings in which we wish to fit a model of the behavior of individuals but where our data consist only of aggregate information (counts or low-dimensional contingency tables).  This paper introduces Collective Graphical Models---a framework for modeling and probabilistic inference that operates directly on the sufficient statistics of the individual model.  We derive a highly-efficient Gibbs sampling algorithm for sampling from the posterior distribution of the sufficient statistics conditioned on noisy aggregate observations, prove its correctness, and demonstrate its effectiveness experimentally.',\n",
       "  'id': '4220',\n",
       "  'title': 'Collective Graphical Models',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider a multi-armed bandit problem where there are two phases. The first phase is an experimentation phase where the decision maker is free to explore multiple options. In the second phase the decision maker has to commit to one of the arms and stick with it. Cost is incurred during both phases with a higher cost during the experimentation phase. We analyze the regret in this setup, and both propose algorithms and provide upper and lower bounds that depend on the ratio of the duration of the experimentation phase to the duration of the commitment phase. Our analysis reveals that if given the choice, it is optimal to experiment $\\\\Theta(\\\\ln T)$ steps and then commit, where $T$ is the time horizon.',\n",
       "  'id': '4223',\n",
       "  'title': 'Committing Bandits',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We investigate a discriminatively trained model of person-object interactions for recognizing common human actions in still images. We build on the locally order-less spatial pyramid bag-of-features model, which was shown to perform extremely well on a range of object, scene and human action recognition tasks. We introduce three principal contributions. First, we replace the standard quantized local HOG/SIFT features with stronger discriminatively trained body part and object detectors. Second, we introduce new person-object interaction features based on spatial co-occurrences of individual body parts and objects. Third, we address the combinatorial problem of a large number of possible interaction pairs and propose a discriminative selection procedure using a linear support vector machine (SVM) with a sparsity inducing regularizer. Learning of action-specific body part and object interactions bypasses the difficult problem of estimating the complete human body pose configuration. Benefits of the proposed model are shown on human action recognition in consumer photographs, outperforming the strong bag-of-features baseline.',\n",
       "  'id': '4224',\n",
       "  'title': 'Learning person-object interactions for action recognition in still images',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In this paper we present an algorithm to learn a multi-label classifier which attempts at directly optimising the F-score. The key novelty of our formulation is that we explicitly allow for assortative (submodular) pairwise label interactions, i.e., we can leverage the co-ocurrence of pairs of labels in order to improve the quality of prediction. Prediction in this model consists of minimising a particular submodular set function, what can be accomplished exactly and efficiently via graph-cuts. Learning however is substantially more involved and requires the solution of an intractable combinatorial optimisation problem. We present an approximate algorithm for this problem and prove that it is sound in the sense that it never predicts incorrect labels. We also present a nontrivial test of a sufficient condition for our algorithm to have found an optimal solution. We present experiments on benchmark multi-label datasets, which attest the value of our proposed technique. We also make available source code that enables the reproduction of our experiments.',\n",
       "  'id': '4239',\n",
       "  'title': 'Submodular Multi-Label Learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We propose an algorithm called Sparse Manifold Clustering and Embedding (SMCE) for simultaneous clustering and dimensionality reduction of data lying in multiple nonlinear manifolds. Similar to most dimensionality reduction methods, SMCE finds a small neighborhood around each data point and connects each point to its neighbors with appropriate weights. The key difference is that SMCE finds both the neighbors and the weights automatically. This is done by solving a sparse optimization problem, which encourages selecting nearby points that lie in the same manifold and approximately span a low-dimensional affine subspace. The optimal solution encodes information that can be used for clustering and dimensionality reduction using spectral clustering and embedding. Moreover, the size of the optimal neighborhood of a data point, which can be different for different points, provides an estimate of the dimension of the manifold to which the point belongs. Experiments demonstrate that our method can effectively handle multiple manifolds that are very close to each other, manifolds with non-uniform sampling and holes, as well as estimate the intrinsic dimensions of the manifolds.',\n",
       "  'id': '4246',\n",
       "  'title': 'Sparse Manifold Clustering and Embedding',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We introduce a new convergent variant of Q-learning, called speedy Q-learning, to address the problem of slow convergence in the standard form of the Q-learning algorithm. We prove a PAC bound on the performance of SQL, which shows that for an MDP with n state-action pairs  and the discount factor \\\\gamma only T=O\\\\big(\\\\log(n)/(\\\\epsilon^{2}(1-\\\\gamma)^{4})\\\\big) steps are required for the SQL algorithm to converge to an \\\\epsilon-optimal action-value function with high probability. This bound has a better dependency on 1/\\\\epsilon and 1/(1-\\\\gamma), and thus, is tighter than the best available result for Q-learning. Our bound is also superior to the existing results for both model-free and model-based instances of batch Q-value iteration that are considered to be more efficient than the incremental methods like Q-learning.',\n",
       "  'id': '4251',\n",
       "  'title': 'Speedy Q-Learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'While signal estimation under random amplitudes, phase shifts, and additive noise is studied frequently, the problem of estimating a deterministic signal under random time-warpings has been relatively unexplored. We present a novel framework for estimating the unknown signal that utilizes the action of the warping group to form an equivalence relation between signals. First, we derive an estimator for the equivalence class of the unknown signal using the notion of Karcher mean on the quotient space of equivalence classes. This step requires the use of Fisher-Rao Riemannian metric  and a square-root representation of signals to enable computations of distances and means under this metric. Then, we define a notion of the center of a class and show that the center of the estimated class is a consistent estimator of the underlying unknown signal. This estimation algorithm has many applications: (1)registration/alignment of functional data, (2) separation of phase/amplitude components of functional data, (3) joint demodulation and carrier estimation, and (4) sparse modeling of functional data. Here we demonstrate only (1) and (2):  Given signals are temporally aligned using nonlinear warpings and, thus, separated into their phase and amplitude components. The proposed method for signal alignment is shown to have state of the art performance using Berkeley growth, handwritten signatures, and neuroscience spike train data.',\n",
       "  'id': '4253',\n",
       "  'title': 'Signal Estimation Under Random Time-Warpings and Nonlinear Signal Alignment',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Spectral clustering is based on the spectral relaxation of the normalized/ratio graph cut criterion. While the  spectral relaxation is known to be loose, it has been shown recently that a non-linear  eigenproblem yields a tight relaxation of the Cheeger cut.   In this paper, we extend this result considerably by providing a   characterization of all balanced graph cuts which allow for a tight relaxation. Although the resulting optimization problems are non-convex and non-smooth, we provide   an efficient first-order scheme which scales to large graphs. Moreover, our approach  comes with the quality guarantee that given any partition as initialization the   algorithm either outputs a better partition or it stops immediately.',\n",
       "  'id': '4261',\n",
       "  'title': 'Beyond Spectral Clustering - Tight Relaxations of Balanced Graph Cuts',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Policy gradient is a useful model-free reinforcement learning approach,  but it tends to suffer from instability of gradient estimates.  In this paper, we analyze and improve the stability of policy gradient methods. We first prove that the variance of gradient estimates in the PGPE(policy gradients with parameter-based exploration) method is smaller than that of the classical REINFORCE method under a mild assumption.  We then derive the optimal baseline for PGPE, which contributes to further reducing the variance.  We also theoretically show that PGPE with the optimal baseline is more preferable than REINFORCE with the optimal baseline in terms of the variance of gradient estimates.  Finally, we demonstrate the usefulness of the improved PGPE method through experiments.',\n",
       "  'id': '4264',\n",
       "  'title': 'Analysis and Improvement of Policy Gradient Estimation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In this paper we describe a maximum likelihood likelihood approach for dictionary learning in the multiplicative exponential noise model. This model is prevalent in audio signal processing where it underlies a generative composite model of the power spectrogram. Maximum joint likelihood estimation of the dictionary and expansion coefficients leads to a nonnegative matrix factorization problem where the Itakura-Saito divergence is used. The optimality of this approach is in question because the number of parameters (which include the expansion coefficients) grows with the number of observations. In this paper we describe a variational procedure for optimization of the marginal likelihood, i.e., the likelihood of the dictionary where the activation coefficients have been integrated out (given a specific prior). We compare the output of both maximum joint likelihood estimation (i.e., standard Itakura-Saito NMF) and maximum marginal likelihood estimation (MMLE) on real and synthetical datasets. The MMLE approach is shown to embed automatic model order selection, akin to automatic relevance determination.',\n",
       "  'id': '4273',\n",
       "  'title': 'Nonnegative dictionary learning in the exponential noise model for adaptive music signal representation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'A majority of approximate dynamic programming approaches to the reinforcement learning problem can be categorized into greedy value function methods and value-based policy gradient methods. The former approach, although fast, is well known to be susceptible to the policy oscillation phenomenon. We take a fresh view to this phenomenon by casting a considerable subset of the former approach as a limiting special case of the latter. We explain the phenomenon in terms of this view and illustrate the underlying mechanism with artificial examples. We also use it to derive the constrained natural actor-critic algorithm that can interpolate between the aforementioned approaches. In addition, it has been suggested in the literature that the oscillation phenomenon might be subtly connected to the grossly suboptimal performance in the Tetris benchmark problem of all attempted approximate dynamic programming methods. We report empirical evidence against such a connection and in favor of an alternative explanation. Finally, we report scores in the Tetris problem that improve on existing dynamic programming based results.',\n",
       "  'id': '4274',\n",
       "  'title': 'A reinterpretation of the policy oscillation phenomenon in approximate policy iteration',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Motor prostheses aim to restore function to disabled patients. Despite compelling proof of concept systems, barriers to clinical translation remain. One challenge is to develop a low-power, fully-implantable system that dissipates only minimal power so as not to damage tissue. To this end, we implemented a Kalman-filter based decoder via a spiking neural network (SNN) and tested it in brain-machine interface (BMI) experiments with a rhesus monkey. The Kalman filter was trained to predict the arm?s velocity and mapped on to the SNN using the Neural Engineer- ing Framework (NEF). A 2,000-neuron embedded Matlab SNN implementation runs in real-time and its closed-loop performance is quite comparable to that of the standard Kalman filter. The success of this closed-loop decoder holds promise for hardware SNN implementations of statistical signal processing algorithms on neuromorphic chips, which may offer power savings necessary to overcome a major obstacle to the successful clinical translation of neural motor prostheses.',\n",
       "  'id': '4276',\n",
       "  'title': 'A Brain-Machine Interface Operating with a Real-Time Spiking Neural Network Control Algorithm',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Using the $\\\\ell_1$-norm to regularize the estimation of  the parameter vector of a linear model leads to an unstable estimator when covariates are highly correlated. In this paper, we introduce a new penalty function which takes into account the correlation of the design matrix to stabilize the estimation. This norm, called the trace Lasso, uses the trace norm of the selected covariates, which is a convex surrogate of their rank, as the criterion of model complexity. We analyze the properties of our norm, describe an optimization algorithm based on reweighted least-squares, and illustrate the behavior of this norm on synthetic data, showing that it is more adapted to strong correlations than competing methods such as the elastic net.',\n",
       "  'id': '4277',\n",
       "  'title': 'Trace Lasso: a trace norm regularization for correlated designs',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We show an application of a tree structure for approximate inference in graphical models using the expectation propagation algorithm. These approximations are typically used over graphs with short-range cycles. We demonstrate that these approximations also help in sparse graphs with long-range loops, as the ones used in coding theory to approach channel capacity. For asymptotically large sparse graph, the expectation propagation algorithm together with the tree structure yields a completely disconnected approximation to the graphical model but, for for finite-length practical sparse graphs, the tree structure approximation to the code graph provides accurate estimates for the marginal of each variable.',\n",
       "  'id': '4280',\n",
       "  'title': 'An Application of Tree-Structured Expectation Propagation for Channel Decoding',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Multi-task learning (MTL) learns multiple related tasks simultaneously to improve generalization performance. Alternating structure optimization (ASO) is a popular MTL method that learns a shared low-dimensional predictive structure on hypothesis spaces from multiple related tasks. It has been applied successfully in many real world applications. As an alternative MTL approach, clustered multi-task learning (CMTL) assumes that multiple tasks follow a clustered structure, i.e., tasks are partitioned into a set of groups where tasks in the same group are similar to each other, and that such a clustered structure is unknown a priori. The objectives in ASO and CMTL differ in how multiple tasks are related. Interestingly, we show in this paper the equivalence relationship between ASO and CMTL, providing significant new insights into ASO and CMTL as well as their inherent relationship. The CMTL formulation is non-convex, and we adopt a convex relaxation to the CMTL formulation. We further establish the equivalence relationship between the proposed convex relaxation of CMTL and an existing convex relaxation of ASO, and show that the proposed convex CMTL formulation is significantly more efficient especially for high-dimensional data. In addition, we present three algorithms for solving the convex CMTL formulation. We report experimental results on benchmark datasets to demonstrate the efficiency of the proposed algorithms.',\n",
       "  'id': '4292',\n",
       "  'title': 'Clustered Multi-Task Learning Via Alternating Structure Optimization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Fitted value iteration (FVI) with ordinary least squares regression is known to diverge. We present a new method, \"Expansion-Constrained Ordinary Least Squares\" (ECOLS), that produces a linear approximation but also guarantees convergence when used with FVI. To ensure convergence, we constrain the least squares regression operator to be a non-expansion in the infinity-norm. We show that the space of function approximators that satisfy this constraint is more rich than the space of \"averagers,\" we prove a minimax property of the ECOLS residual error, and we give an efficient algorithm for computing the coefficients of ECOLS based on constraint generation. We illustrate the algorithmic convergence of FVI with ECOLS in a suite of experiments, and discuss its properties.',\n",
       "  'id': '4298',\n",
       "  'title': 'Convergent Fitted Value Iteration with Linear Function Approximation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Budgeted optimization involves optimizing an unknown function that is costly to evaluate by requesting a limited number of function evaluations at intelligently selected inputs. Typical problem formulations assume that experiments are selected one at a time with a limited total number of experiments, which fail to capture important aspects of many real-world problems. This paper defines a novel problem formulation with the following important extensions: 1) allowing for concurrent experiments; 2) allowing for stochastic experiment durations; and 3) placing constraints on both the total number of experiments and the total experimental time. We develop both offline and online algorithms for selecting concurrent experiments in this new setting and provide experimental results on a number of optimization benchmarks. The results show that our algorithms produce highly effective schedules compared to natural baselines.',\n",
       "  'id': '4300',\n",
       "  'title': 'Budgeted Optimization with Concurrent Stochastic-Duration Experiments',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of classification using similarity/distance functions over data. Specifically, we propose a framework for defining the goodness of a (dis)similarity function with respect to a given learning task and propose algorithms that have guaranteed generalization properties when working with such good functions. Our framework unifies and generalizes the frameworks proposed by (Balcan-Blum 2006) and (Wang et al 2007). An attractive feature of our framework is its adaptability to data - we do not promote a fixed notion of goodness but rather let data dictate it. We show, by giving theoretical guarantees that the goodness criterion best suited to a problem can itself be learned which makes our approach applicable to a variety of domains and problems. We propose a landmarking-based approach to obtaining a classifier from such learned goodness criteria. We then provide a novel diversity based heuristic to perform task-driven selection of landmark points instead of random selection. We demonstrate the effectiveness of our goodness criteria learning method as well as the landmark selection heuristic on a variety of similarity-based learning datasets and benchmark UCI datasets on which our method consistently outperforms existing approaches by a significant margin.',\n",
       "  'id': '4306',\n",
       "  'title': 'Similarity-based Learning via Data Driven Embeddings',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Probabilistic programming languages allow modelers to specify a stochastic    process using syntax that resembles modern programming languages.  Because    the program is in machine-readable format, a variety of techniques from    compiler design and program analysis can be used to examine the structure of    the distribution represented by the probabilistic program.  We show how    nonstandard interpretations of probabilistic programs can be used to    craft efficient inference algorithms: information about the structure of a    distribution (such as gradients or dependencies) is generated as a monad-like side    computation while executing the program.  These interpretations can be easily    coded using special-purpose objects and operator overloading.  We implement    two examples of nonstandard interpretations in two different languages, and    use them as building blocks to construct inference algorithms: automatic    differentiation, which enables gradient based methods, and provenance    tracking, which enables efficient construction of global proposals.',\n",
       "  'id': '4309',\n",
       "  'title': 'Nonstandard Interpretations of Probabilistic Programs for Efficient Inference',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We introduce hierarchically supervised latent Dirichlet allocation (HSLDA), a model for hierarchically and multiply labeled bag-of-word data. Examples of such data include web pages and their placement in directories, product descriptions and associated categories from product hierarchies, and free-text clinical records and their assigned diagnosis codes. Out-of-sample label prediction is the primary goal of this work, but improved lower-dimensional representations of the bag-of-word data are also of interest. We demonstrate HSLDA on large-scale data from clinical document labeling and retail product categorization tasks. We show that leveraging the structure from hierarchical labels improves out-of-sample label prediction substantially when compared to models that do not.',\n",
       "  'id': '4313',\n",
       "  'title': 'Hierarchically Supervised Latent Dirichlet Allocation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Many studies have uncovered evidence that visual cortex contains specialized regions involved in processing faces but not other object classes.  Recent electrophysiology studies of cells in several of these specialized regions revealed that at least some of these regions are organized in a hierarchical manner with viewpoint-specific cells projecting to downstream viewpoint-invariant identity-specific cells (Freiwald and Tsao 2010).  A separate computational line of reasoning leads to the claim that some transformations of visual inputs that preserve viewed object identity are class-specific.  In particular, the 2D images evoked by a face undergoing a 3D rotation are not produced by the same image transformation (2D) that would produce the images evoked by an object of another class undergoing the same 3D rotation.  However, within the class of faces, knowledge of the image transformation evoked by 3D rotation can be reliably transferred from previously viewed faces to help identify a novel face at a new viewpoint.  We show, through computational simulations, that an architecture which applies this method of gaining invariance to class-specific transformations is effective when restricted to faces and fails spectacularly when applied across object classes.  We argue here that in order to accomplish viewpoint-invariant face identification from a single example view, visual cortex must separate the circuitry involved in discounting 3D rotations of faces from the generic circuitry involved in processing other objects.  The resulting model of the ventral stream of visual cortex is consistent with the recent physiology results showing the hierarchical organization of the face processing network.',\n",
       "  'id': '4318',\n",
       "  'title': 'Why The Brain Separates Face Recognition From Object Recognition',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We introduce PiCoDes: a very compact image descriptor which nevertheless allows high performance on object category recognition. In particular, we address novel-category recognition: the task of defining indexing structures and image representations which enable a large collection of images to be searched for an object category that was not known when the index was built. Instead, the training images defining the category are supplied at query time. We explicitly learn descriptors of a given length (from as small as 16 bytes per image) which have good object-recognition performance. In contrast to previous work in the domain of object recognition, we do not choose an arbitrary intermediate representation, but explicitly learn short codes. In contrast to previous approaches to learn compact codes, we optimize explicitly for (an upper bound on) classification performance. Optimization directly for binary features is difficult and nonconvex, but we present an alternation scheme and convex upper bound which demonstrate excellent performance in practice. PiCoDes of 256 bytes match the accuracy of the current best known classifier for the Caltech256 benchmark, but they decrease the database storage size by a factor of 100 and speed-up the training and testing of novel classes by orders of magnitude.',\n",
       "  'id': '4319',\n",
       "  'title': 'PiCoDes: Learning a Compact Code for Novel-Category Recognition',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We propose a robust filtering approach based on semi-supervised and multiple instance learning (MIL). We assume that the posterior density would be unimodal if not for the effect of outliers that we do not wish to explicitly model. Therefore, we seek for a point estimate at the outset, rather than a generic approximation of the entire posterior. Our approach can be thought of as a combination of standard finite-dimensional filtering (Extended Kalman Filter, or Unscented Filter) with multiple instance learning, whereby the initial condition comes with a putative set of inlier measurements. We show how both the state (regression) and the inlier set (classification) can be estimated iteratively and causally by processing only the current measurement. We illustrate our approach on visual tracking problems whereby the object of interest (target) moves and evolves as a result of occlusions and deformations, and partial knowledge of the target is given in the form of a bounding box (training set).',\n",
       "  'id': '4324',\n",
       "  'title': 'Multiple Instance Filtering',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Local Coordinate Coding (LCC) [18] is a method for modeling functions of data lying on non-linear manifolds. It provides a set of anchor points which form a local coordinate system, such that each data point on the manifold can be approximated by a linear combination of its anchor points, and the linear weights become the local coordinate coding. In this paper we propose encoding data using orthogonal  anchor planes, rather than anchor points. Our method needs only a few orthogonal anchor planes for coding, and it can linearize any (\\\\alpha,\\\\beta,p)-Lipschitz smooth nonlinear  function with a fixed expected value of the upper-bound approximation error on any high dimensional data. In practice, the orthogonal coordinate system can be easily learned by minimizing this upper bound using singular value decomposition (SVD). We apply our method to model the coordinates locally in linear SVMs for classification tasks, and our experiment on MNIST shows that using only 50 anchor planes our method achieves 1.72% error rate, while LCC achieves 1.90% error rate using 4096 anchor points.',\n",
       "  'id': '4326',\n",
       "  'title': 'Learning Anchor Planes for Classification',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'The multi-armed bandit (MAB) setting is a useful abstraction of many online learning tasks which focuses on the trade-off between exploration and exploitation. In this setting, an online algorithm has a fixed set of alternatives (\"arms\"), and in each round it selects one arm and then observes the corresponding reward. While the case of small number of arms is by now well-understood, a lot of recent work has focused on multi-armed bandits with (infinitely) many arms, where one needs to assume extra structure in order to make the problem tractable. In particular, in the Lipschitz MAB problem there is an underlying similarity metric space, known to the algorithm, such that any two arms that are close in this metric space have similar payoffs.  In this paper we consider the more realistic scenario in which the metric space is *implicit* -- it is defined by the available structure but not revealed to the algorithm directly. Specifically, we assume that an algorithm is given a tree-based classification of arms. For any given problem instance such a classification implicitly defines a similarity metric space, but the numerical similarity information is not available to the algorithm. We provide an algorithm for this setting, whose performance guarantees (almost) match the best known guarantees for the corresponding instance of the Lipschitz MAB problem.',\n",
       "  'id': '4332',\n",
       "  'title': 'Multi-armed bandits on implicit metric spaces',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We propose an approach for linear unsupervised dimensionality reduction, based on the sparse linear model that has been used to probabilistically interpret sparse coding. We formulate an optimization problem for learning a linear projection from the original signal domain to a lower-dimensional one in a way that approximately preserves, in expectation, pairwise inner products in the sparse domain. We derive solutions to the problem, present nonlinear extensions, and discuss relations to compressed sensing. Our experiments using facial images, texture patches, and images of object categories suggest that the approach can improve our ability to recover meaningful structure in many classes of signals.',\n",
       "  'id': '4336',\n",
       "  'title': 'Dimensionality Reduction Using the Sparse Linear Model',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Modern classification tasks usually involve many class labels and can be informed by a broad range of features. Many of these tasks are tackled by constructing a set of classifiers, which are then applied at test time and then pieced together in a fixed procedure determined in advance or at training time. We present an active classification process at the test time, where each classifier in a large ensemble is viewed as a potential observation that might inform our classification process. Observations are then selected dynamically based on previous observations, using a value-theoretic computation that balances an estimate of the expected classification gain from each observation as well as its computational cost. The expected classification gain is computed using a probabilistic model that uses the outcome from previous observations. This active classification process is applied at test time for each individual test instance, resulting in an efficient instance-specific decision path. We demonstrate the benefit of the active scheme on various real-world datasets, and show that it can achieve comparable or even higher classification accuracy at a fraction of the computational costs of traditional methods.',\n",
       "  'id': '4340',\n",
       "  'title': 'Active Classification based on Value of Classifier',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"A Bayesian approach to partitioning distance matrices is presented. It is inspired by the 'Translation-Invariant Wishart-Dirichlet' process (TIWD) in (Vogt et al., 2010) and shares a number of advantageous properties like the fully probabilistic nature of the inference model, automatic selection of the number of clusters and applicability in semi-supervised settings. In addition, our method (which we call 'fastTIWD') overcomes the main shortcoming of the original TIWD, namely its high computational costs. The fastTIWD reduces the workload in each iteration of a Gibbs sampler from O(n^3) in the TIWD to O(n^2). Our experiments show that this cost reduction does not compromise the quality of the inferred partitions. With this new method it is now possible to 'mine' large relational datasets with a probabilistic model, thereby automatically detecting new and potentially interesting clusters.\",\n",
       "  'id': '4341',\n",
       "  'title': 'Bayesian Partitioning of Large-Scale Distance Data',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This manuscript considers the convergence rate of boosting under a large class of losses, including the exponential and logistic losses, where the best previous rate of convergence was O(exp(1/??)).  First, it is established that the setting of weak learnability aids the entire class, granting a rate O(ln(1/?)).  Next, the (disjoint) conditions under which the infimal empirical risk is attainable are characterized in terms of the sample and weak learning class, and a new proof is given for the known rate O(ln(1/?)).  Finally, it is established that any instance can be decomposed into two smaller instances resembling the two preceding special cases, yielding a rate O(1/?), with a matching lower bound for the logistic loss.  The principal technical hurdle throughout this work is the potential unattainability of the infimal empirical risk; the technique for overcoming this barrier may be of general interest.',\n",
       "  'id': '4343',\n",
       "  'title': 'The Fast Convergence of Boosting',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Variational Bayesian matrix factorization (VBMF) efficiently   approximates the posterior distribution of factorized matrices   by assuming matrix-wise independence of the two factors.  A recent study on fully-observed VBMF  showed that, under a stronger assumption that the two factorized matrices are  column-wise independent,  the global optimal solution can be analytically computed.  However, it was not clear how restrictive  the column-wise independence assumption is.  In this paper, we prove that the global solution under matrix-wise  independence is actually column-wise independent,  implying that the column-wise independence assumption is harmless.  A practical consequence of our theoretical finding is that  the global solution under matrix-wise independence (which is a standard setup)  can be obtained analytically in a computationally very efficient way  without any iterative algorithms.  We experimentally illustrate advantages of using our analytic solution  in probabilistic principal component analysis.',\n",
       "  'id': '4344',\n",
       "  'title': 'Global Solution of Fully-Observed Variational Bayesian Matrix Factorization is Column-Wise Independent',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We describe a family of global optimization procedures that automatically decompose optimization problems into smaller loosely coupled problems, then combine the solutions of these with message passing algorithms.  We show empirically that these methods excel in avoiding local minima and produce better solutions with fewer function evaluations than existing global optimization methods.  To develop these methods, we introduce a notion of coupling between variables of optimization that generalizes the notion of coupling that arises from factoring functions into terms that involve small subsets of the variables. It therefore subsumes the notion of independence between random variables in statistics, sparseness of the Hessian in nonlinear optimization, and the generalized distributive law. Despite being more general, this notion of coupling is easier to verify empirically -- making structure estimation easy -- yet it allows us to migrate well-established inference methods on graphical models to the setting of global optimization.',\n",
       "  'id': '4345',\n",
       "  'title': 'Structure Learning for Optimization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of recovering the parameter alpha in R^K of a sparse function f, i.e. the number of non-zero entries of alpha is small compared to the number K of features, given noisy evaluations of f at a set of well-chosen sampling points. We introduce an additional randomisation process, called Brownian sensing, based on the computation of stochastic integrals, which produces a Gaussian sensing matrix, for which good recovery properties are proven independently on the number of sampling points N, even when the features are arbitrarily non-orthogonal. Under the assumption that f is H?lder continuous with exponent at least 1/2, we provide an estimate a of the parameter such that ||\\\\alpha - a||_2 = O(||eta||_2\\\\sqrt{N}), where eta is the observation noise. The method uses a set of sampling points uniformly distributed along a one-dimensional curve selected according to the features. We report numerical experiments illustrating our method.',\n",
       "  'id': '4349',\n",
       "  'title': 'Sparse Recovery with Brownian Sensing',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from  training data. Existing approaches however, are either too simplistic (linear), too complex to learn, or  can only learn latent spaces from \"simple data\", i.e., single activities such as walking or running. In this paper, we present an efficient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent  spaces composed of multiple  activities. Furthermore, we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the  effectiveness of our approach on the  task of monocular and multi-view tracking and show that our approach  outperforms the state-of-the-art.',\n",
       "  'id': '4352',\n",
       "  'title': 'Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Maximum entropy models have become popular statistical models in neuroscience and other areas in biology, and can be useful tools for obtaining estimates of mu- tual information in biological systems. However, maximum entropy models fit to small data sets can be subject to sampling bias; i.e. the true entropy of the data can be severely underestimated. Here we study the sampling properties of estimates of the entropy obtained from maximum entropy models. We show that if the data is generated by a distribution that lies in the model class, the bias is equal to the number of parameters divided by twice the number of observations. However, in practice, the true distribution is usually outside the model class, and we show here that this misspecification can lead to much larger bias. We provide a perturba- tive approximation of the maximally expected bias when the true model is out of model class, and we illustrate our results using numerical simulations of an Ising model; i.e. the second-order maximum entropy distribution on binary data.',\n",
       "  'id': '4357',\n",
       "  'title': 'How biased are maximum entropy models?',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'The distance dependent Chinese restaurant process (ddCRP) was recently introduced to accommodate random partitions of non-exchangeable data.  The ddCRP clusters data in a biased way: each data point is more likely to be clustered with other data that are near it in an external sense.  This paper examines the ddCRP in a spatial setting with the goal of natural image segmentation.  We explore the biases of the spatial ddCRP model and propose a novel hierarchical extension better suited for producing \"human-like\" segmentations. We then study the sensitivity of the models to various distance and appearance hyperparameters, and provide the first rigorous comparison of nonparametric Bayesian models in the image segmentation domain. On unsupervised image segmentation, we demonstrate that similar performance to existing nonparametric Bayesian models is possible with substantially simpler models and algorithms.',\n",
       "  'id': '4361',\n",
       "  'title': 'Spatial distance dependent Chinese restaurant processes for image segmentation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of Ising and Gaussian graphical model selection given n i.i.d. samples from the model. We propose an efficient threshold-based algorithm   for structure estimation based known as  conditional mutual information test. This simple local algorithm    requires only low-order statistics of the data and decides    whether  two nodes   are neighbors in the unknown graph. Under some transparent assumptions, we establish that the proposed algorithm is structurally consistent (or sparsistent)  when the number of samples scales as n= Omega(J_{min}^{-4} log p), where p is the number of nodes and J_{min} is the minimum edge potential.  We also prove novel non-asymptotic necessary conditions for graphical model selection.',\n",
       "  'id': '4370',\n",
       "  'title': 'High-Dimensional Graphical Model Selection: Tractable Graph Families and Necessary Conditions',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Many fundamental questions in theoretical neuroscience involve optimal  decoding and the computation of Shannon information rates in  populations of spiking neurons.  In this paper, we apply methods from  the asymptotic theory of statistical inference to obtain a clearer  analytical understanding of these quantities.  We find that for large  neural populations carrying a finite total amount of information, the  full spiking population response is asymptotically as informative as a  single observation from a Gaussian process whose mean and covariance  can be characterized explicitly in terms of network and single neuron  properties.  The Gaussian form of this asymptotic sufficient  statistic allows us in certain cases to perform optimal Bayesian  decoding by simple linear transformations, and to obtain closed-form  expressions of the Shannon information carried by the network.  One  technical advantage of the theory is that it may be applied easily  even to non-Poisson point process network models; for example, we find  that under some conditions, neural populations with strong  history-dependent (non-Poisson) effects carry exactly the same  information as do simpler equivalent populations of non-interacting  Poisson neurons with matched firing rates.  We argue that our findings  help to clarify some results from the recent literature on neural  decoding and neuroprosthetic design.',\n",
       "  'id': '4371',\n",
       "  'title': 'Information Rates and Optimal Decoding in Large Neural Populations',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"For many real-world applications, we often need to select correlated variables---such as genetic variations and imaging features associated with Alzheimer's disease---in a high dimensional space. The correlation between variables presents a challenge to classical variable selection methods. To address this challenge, the elastic net has been developed and successfully applied to many applications. Despite its great success, the elastic net does not exploit the correlation information embedded in the data to select correlated variables. To overcome this limitation, we present a novel hybrid model, EigenNet, that uses the eigenstructures of data to guide variable selection. Specifically, it integrates a sparse conditional classification model with a generative model capturing variable correlations in a principled Bayesian framework. We develop an efficient active-set algorithm to estimate the model via evidence maximization. Experiments on synthetic data and imaging genetics data demonstrated the superior predictive performance of the EigenNet over the lasso, the elastic net, and the automatic relevance determination.\",\n",
       "  'id': '4378',\n",
       "  'title': 'EigenNet: A Bayesian hybrid of generative and conditional models for sparse learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Motivated by the spread of on-line information in general and   on-line petitions in particular, recent research has raised the following   combinatorial estimation problem.  There is a tree T that we cannot observe directly (representing  the structure along which the information has spread), and certain  nodes randomly decide to make their copy of the information public.  In the case of a petition, the list of names on each public copy   of the petition also reveals a path leading back to the root of the tree.  What can we conclude about the properties of the tree we observe  from these revealed paths,  and can we use the structure of the observed tree  to estimate the size of the full unobserved tree T?    Here we provide the first algorithm for this size estimation task,  together with provable guarantees on its performance.  We also establish structural properties of the observed tree, providing the  first rigorous explanation for some of the unusual structural  phenomena present in the spread of real chain-letter petitions  on the Internet.',\n",
       "  'id': '4379',\n",
       "  'title': 'Reconstructing Patterns of Information Diffusion from Incomplete Observations',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We present explicit classes of probability distributions that can be learned by Restricted Boltzmann Machines (RBMs) depending on the number of units that they contain, and which are representative for the expressive power of the model. We use this to show that the maximal Kullback-Leibler divergence to the RBM model with n visible and m hidden units is bounded from above by (n-1)-log(m+1). In this way we can specify the number of hidden units that guarantees a sufficiently rich model containing different classes of distributions and respecting a given error tolerance.',\n",
       "  'id': '4380',\n",
       "  'title': 'Expressive Power and Approximation Errors of Restricted Boltzmann Machines',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Cancer has complex patterns of progression that include converging as  well as diverging progressional pathways. Vogelstein's path model of  colon cancer was a pioneering contribution to cancer research.  Since  then, several attempts have been made at obtaining mathematical models  of cancer progression, devising learning algorithms, and applying  these to cross-sectional data. Beerenwinkel {\\\\em et al.}  provided,  what they coined, EM-like algorithms for Oncogenetic Trees (OTs) and  mixtures of such. Given the small size of current and future data  sets, it is important to minimize the number of parameters of a  model. For this reason, we too focus on tree-based models and  introduce Hidden-variable Oncogenetic Trees (HOTs). In contrast to  OTs, HOTs allow for errors in the data and thereby provide more  realistic modeling. We also design global structural EM algorithms for  learning HOTs and mixtures of HOTs (HOT-mixtures). The algorithms are  global in the sense that, during the M-step, they find a structure  that yields a global maximum of the expected complete log-likelihood  rather than merely one that improves it. The algorithm for single HOTs  performs very well on reasonable-sized data sets, while that for  HOT-mixtures requires data sets of sizes obtainable only with  tomorrow's more cost-efficient technologies.\",\n",
       "  'id': '4397',\n",
       "  'title': 'A Global Structural EM Algorithm for a Model of Cancer Progression',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'A hallmark of modern machine learning is its ability to deal with high dimensional problems by exploiting structural assumptions that limit the degrees of freedom in the underlying model.  A deep understanding of the capabilities and limits of high dimensional learning methods under specific assumptions such as sparsity, group sparsity, and low rank has been attained.  Efforts (Negahban et al., 2010, Chandrasekaran et al., 2010} are now underway to distill this valuable experience by proposing general unified frameworks that can achieve the twin goals of summarizing previous analyses and enabling their application to notions of structure hitherto unexplored. Inspired by these developments, we propose and analyze a general computational scheme based on a greedy strategy to solve convex optimization problems that arise when dealing with structurally constrained high-dimensional problems. Our framework not only unifies existing greedy algorithms by recovering them as special cases but also yields novel ones. Finally, we extend our results to infinite dimensional problems by using interesting connections between smoothness of norms and behavior of martingales in Banach spaces.',\n",
       "  'id': '4412',\n",
       "  'title': 'Greedy Algorithms for Structurally Constrained High Dimensional Problems',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of estimating neural spikes from extracellular voltage recordings. Most current methods are based on clustering, which requires substantial human supervision and produces systematic errors by failing to properly handle temporally overlapping spikes. We formulate the problem as one of statistical inference, in which the recorded voltage is a noisy sum of the spike trains of each neuron convolved with its associated spike waveform.  Joint maximum-a-posteriori (MAP) estimation of the waveforms and spikes is then a blind deconvolution problem in which the coefficients are sparse. We develop a block-coordinate descent method for approximating the MAP solution.  We validate our method on data simulated according to the generative model, as well as on real data for which ground truth is available via simultaneous intracellular recordings. In both cases, our method substantially reduces the number of missed spikes and false positives when compared to a standard clustering algorithm, primarily by recovering temporally overlapping spikes.  The method offers a fully automated alternative to clustering methods that is less susceptible to systematic errors.',\n",
       "  'id': '4416',\n",
       "  'title': 'A blind sparse deconvolution method for neural spike identification',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Components estimated by independent component analysis and related methods  are typically not independent in real data. A very common form of nonlinear  dependency between the components is correlations in their variances or ener-  gies. Here, we propose a principled probabilistic model to model the energy-  correlations between the latent variables. Our two-stage model includes a linear  mixing of latent signals into the observed ones like in ICA. The main new fea-  ture is a model of the energy-correlations based on the structural equation model  (SEM), in particular, a Linear Non-Gaussian SEM. The SEM is closely related to  divisive normalization which effectively reduces energy correlation. Our new two-  stage model enables estimation of both the linear mixing and the interactions re-  lated to energy-correlations, without resorting to approximations of the likelihood  function or other non-principled approaches. We demonstrate the applicability of  our method with synthetic dataset, natural images and brain signals.',\n",
       "  'id': '4426',\n",
       "  'title': 'Structural equations and divisive normalization for energy-dependent component analysis',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Mini-batch algorithms have recently received significant attention as a way to speed-up stochastic convex optimization problems. In this paper, we study how such algorithms can be improved using accelerated gradient methods. We provide a novel analysis, which shows how standard gradient methods may sometimes be insufficient to obtain a significant speed-up. We propose a novel accelerated gradient algorithm, which deals with this deficiency, and enjoys a uniformly superior guarantee. We conclude our paper with experiments  on real-world datasets, which validates our algorithm and  substantiates our theoretical insights.',\n",
       "  'id': '4432',\n",
       "  'title': 'Better Mini-Batch Algorithms via Accelerated Gradient Methods',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In recent years, a rich variety of shrinkage priors have been proposed that have great promise in addressing massive regression problems.  In general, these new priors can be expressed as scale mixtures of normals, but have more complex forms and better properties than traditional Cauchy and double exponential priors. We first propose a new class of normal scale mixtures through a novel generalized beta distribution that encompasses many interesting priors as special cases.  This encompassing framework should prove useful in comparing competing priors, considering properties and revealing close connections. We then develop a class of variational Bayes approximations through the new hierarchy presented that will scale more efficiently to the types of truly massive data sets that are now encountered routinely.',\n",
       "  'id': '4439',\n",
       "  'title': 'Generalized Beta Mixtures of Gaussians',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [Larochelle et al., 2007] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P (y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.',\n",
       "  'id': '4443',\n",
       "  'title': 'Algorithms for Hyper-Parameter Optimization',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"We present a novel class of actor-critic algorithms for actors consisting of sets of interacting modules. We present, analyze theoretically, and empirically evaluate an update rule for each module, which requires only local information: the module's input, output, and the TD error broadcast by a critic. Such updates are necessary when computation of compatible features becomes prohibitively difficult and are also desirable to increase the biological plausibility of reinforcement learning methods.\",\n",
       "  'id': '4449',\n",
       "  'title': 'Policy Gradient Coagent Networks',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Many nonparametric regressors were recently shown to converge at rates that depend only on the intrinsic dimension of data.  These regressors thus escape the curse of dimension when high-dimensional data has low intrinsic dimension (e.g. a manifold).   We show that $k$-NN regression is also adaptive to intrinsic dimension. In particular our rates are local to a query $x$   and depend only on the way masses of balls centered at $x$ vary with radius.    Furthermore, we show a simple way to choose $k = k(x)$ locally at any $x$ so as to nearly achieve the minimax rate at $x$  in terms of the unknown intrinsic dimension in the vicinity of $x$. We also establish that the minimax rate does not depend   on a particular choice of metric space or distribution, but rather that this minimax rate holds for any metric space and doubling measure.',\n",
       "  'id': '4455',\n",
       "  'title': 'k-NN Regression Adapts to Local Intrinsic Dimension',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Vector Auto-regressive models (VAR) are useful tools for analyzing time series  data. In quite a few modern time series modelling tasks, the collection of reliable  time series turns out to be a major challenge, either due to the slow progression of  the dynamic process of interest, or inaccessibility of repetitive measurements of  the same dynamic process over time. In those situations, however, we observe that  it is often easier to collect a large amount of non-sequence samples, or snapshots  of the dynamic process of interest. In this work, we assume a small amount of time  series data are available, and propose methods to incorporate non-sequence data  into penalized least-square estimation of VAR models. We consider non-sequence  data as samples drawn from the stationary distribution of the underlying VAR  model, and devise a novel penalization scheme based on the discrete-time Lyapunov  equation concerning the covariance of the stationary distribution. Experiments  on synthetic and video data demonstrate the effectiveness of the proposed  methods.',\n",
       "  'id': '4482',\n",
       "  'title': 'Learning Auto-regressive Models from Sequence and Non-sequence Data',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We propose maximum covariance unfolding (MCU), a manifold learning algorithm for simultaneous dimensionality reduction of data from different input modalities.   Given high dimensional inputs from two different but naturally aligned sources, MCU computes a common low dimensional embedding that maximizes the cross-modal (inter-source) correlations while preserving the local (intra-source) distances.  In this paper, we explore two applications of MCU.  First we use MCU to analyze EEG-fMRI data, where an important goal is to visualize the fMRI voxels that are most strongly correlated with changes in EEG traces.  To perform this visualization, we augment MCU with an additional step for metric learning in the high dimensional voxel space.  Second, we use MCU to perform cross-modal retrieval of matched image and text samples from Wikipedia.  To manage large applications of MCU, we develop a fast implementation based on ideas from spectral graph theory.  These ideas transform the original problem for MCU, one of semidefinite programming, into a simpler problem in semidefinite quadratic linear programming.',\n",
       "  'id': '4186',\n",
       "  'title': 'Maximum Covariance Unfolding : Manifold Learning for Bimodal Data',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This work considers the problem of learning the structure of multivariate linear tree models, which include a variety of directed tree graphical models with continuous, discrete, and mixed latent variables such as linear-Gaussian models, hidden Markov models, Gaussian mixture models, and Markov evolutionary trees.  The setting is one where we only have samples from certain observed variables in the tree, and our goal is to estimate the tree structure (i.e., the graph of how the underlying hidden variables are connected to each other and to the observed variables).  We propose the Spectral Recursive Grouping algorithm, an efficient and simple bottom-up procedure for recovering the tree structure from independent samples of the observed variables.  Our finite sample size bounds for exact recovery of the tree structure  reveal certain natural dependencies on underlying statistical and structural properties of the underlying joint distribution.  Furthermore, our sample complexity guarantees have no explicit dependence on the dimensionality of the observed variables, making the algorithm applicable to many high-dimensional settings.  At the heart of our algorithm is a spectral quartet test for determining the relative topology of a quartet of variables from second-order statistics.',\n",
       "  'id': '4208',\n",
       "  'title': 'Spectral Methods for Learning Multivariate Latent Tree Structure',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'In discrete undirected graphical models, the conditional independence of node labels Y is specified by the graph structure. We study the case where there is another input random vector X (e.g. observed features) such that the distribution P (Y | X) is determined by functions of X that characterize the (higher-order) interactions among the Y ?s. The main contribution of this paper is to learn the graph structure and the functions conditioned on X at the same time. We prove that discrete undirected graphical models with feature X are equivalent to mul- tivariate discrete models. The reparameterization of the potential functions in graphical models by conditional log odds ratios of the latter offers advantages in representation of the conditional independence structure. The functional spaces can be flexibly determined by kernels. Additionally, we impose a Structure Lasso (SLasso) penalty on groups of functions to learn the graph structure. These groups with overlaps are designed to enforce hierarchical function selection. In this way, we are able to shrink higher order interactions to obtain a sparse graph structure.',\n",
       "  'id': '4209',\n",
       "  'title': 'Learning Higher-Order Graph Structure with Features by Structure Penalty',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We propose a novel class of Bayesian nonparametric models for sequential data called fragmentation-coagulation processes (FCPs).  FCPs model a set of sequences using  a partition-valued Markov process which evolves by splitting and merging clusters.  An FCP is exchangeable, projective, stationary and reversible, and its equilibrium distributions are given by the Chinese restaurant process.  As opposed to hidden Markov models, FCPs allow for flexible modelling of the number of clusters, and they avoid label switching non-identifiability problems. We develop an efficient Gibbs sampler for FCPs which uses uniformization and the forward-backward algorithm.  Our development of FCPs is motivated by applications in population genetics, and we demonstrate the utility of FCPs on problems of genotype imputation with phased and unphased SNP data.',\n",
       "  'id': '4211',\n",
       "  'title': 'Modelling Genetic Variations using Fragmentation-Coagulation Processes',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Multiclass prediction is the problem of classifying an object into a    relevant target class.  We consider the problem of learning a    multiclass predictor that uses only few features, and in particular,    the number of used features should increase sub-linearly with the    number of possible classes. This implies that features should be    shared by several classes. We describe and analyze the ShareBoost    algorithm for learning a multiclass predictor that uses few shared    features. We prove that ShareBoost efficiently finds a predictor    that uses few shared features (if such a predictor exists) and that    it has a small generalization error. We also describe how to use    ShareBoost for learning a non-linear predictor that has a fast    evaluation time. In a series of experiments with natural data sets    we demonstrate the benefits of ShareBoost and evaluate its success    relatively to other state-of-the-art approaches.',\n",
       "  'id': '4213',\n",
       "  'title': 'ShareBoost: Efficient multiclass learning with feature sharing',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Kernel-based reinforcement-learning (KBRL) is a method for learning a decision policy from a set of sample transitions which stands out for its strong theoretical guarantees. However, the size of the approximator grows with the number of transitions, which makes the approach impractical for large problems.  In this paper we introduce a novel algorithm to improve the scalability of KBRL. We resort to a special decomposition of a transition matrix, called stochastic factorization, to fix the size of the approximator while at the same time incorporating all the information contained in the data. The resulting algorithm, kernel-based stochastic factorization (KBSF), is much faster but still converges to a unique solution. We derive a theoretical upper bound for the distance between the value functions computed by KBRL and KBSF. The effectiveness of our method is illustrated with computational experiments on four reinforcement-learning problems, including a difficult task in which the goal is to learn a neurostimulation policy to suppress the occurrence of seizures in epileptic rat brains. We empirically demonstrate that the proposed approach is able to compress the information contained in KBRL's model. Also, on the tasks studied, KBSF outperforms two of the most prominent reinforcement-learning algorithms, namely least-squares policy iteration and fitted Q-iteration.\",\n",
       "  'id': '4217',\n",
       "  'title': 'Reinforcement Learning using Kernel-Based Stochastic Factorization',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We study the problem of reconstructing an unknown matrix M of rank r and dimension d using O(rd polylog d) Pauli measurements.  This has applications in quantum state tomography, and is a non-commutative analogue of a well-known problem in compressed sensing:  recovering a sparse vector from a few of its Fourier coefficients.      We show that almost all sets of O(rd log^6 d) Pauli measurements satisfy the rank-r restricted isometry property (RIP).  This implies that M can be recovered from a fixed (\"universal\") set of Pauli measurements, using nuclear-norm minimization (e.g., the matrix Lasso), with nearly-optimal bounds on the error.  A similar result holds for any class of measurements that use an orthonormal operator basis whose elements have small operator norm.  Our proof uses Dudley\\'s inequality for Gaussian processes, together with bounds on covering numbers obtained via entropy duality.',\n",
       "  'id': '4222',\n",
       "  'title': 'Universal low-rank matrix recovery from Pauli measurements',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of stratified sampling for Monte-Carlo integration. We model this problem in a multi-armed bandit setting, where the arms represent the strata, and the goal is to estimate a weighted average of the mean values of the arms. We propose a strategy that samples the arms according to an upper bound on their standard deviations and compare its estimation quality to an ideal allocation that would know the standard deviations of the arms. We provide two regret analyses: a distribution-dependent bound O(n^{-3/2}) that depends on a measure of the disparity of the arms, and a distribution-free bound O(n^{-4/3}) that does not. To the best of our knowledge, such a finite-time analysis is new for this problem.',\n",
       "  'id': '4225',\n",
       "  'title': 'Finite Time Analysis of Stratified Sampling for Monte Carlo',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"In this paper, we consider the 'Precis' problem of sampling K representative yet diverse data points from a large dataset. This problem arises frequently in applications such as video and document summarization, exploratory data analysis, and pre-filtering. We formulate a general theory which encompasses not just traditional techniques devised for vector spaces, but also non-Euclidean manifolds, thereby enabling these techniques to shapes, human activities, textures and many other image and video based datasets. We propose intrinsic manifold measures for measuring the quality of a selection of points with respect to their representative power, and their diversity. We then propose efficient algorithms to optimize the cost function using a novel annealing-based iterative alternation algorithm. The proposed formulation is applicable to manifolds of known geometry as well as to manifolds whose geometry needs to be estimated from samples. Experimental results show the strength and generality of the proposed approach.\",\n",
       "  'id': '4229',\n",
       "  'title': 'Manifold Precis: An Annealing Technique for Diverse Sampling of Manifolds',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Latent variable models are frequently used to identify structure in dichotomous network data, in part because they give rise to a Bernoulli product likelihood that is both well understood and consistent with the notion of exchangeable random graphs.  In this article we propose conservative confidence sets that hold with respect to these underlying Bernoulli parameters as a function of any given partition of network nodes, enabling us to assess estimates of \\\\emph{residual} network structure, that is, structure that cannot be explained by known covariates and thus cannot be easily verified by manual inspection. We demonstrate the proposed methodology by analyzing student friendship networks from the National Longitudinal Survey of Adolescent Health that include race, gender, and school year as covariates.  We employ a stochastic expectation-maximization algorithm to fit a logistic regression model that includes these explanatory variables as well as a latent stochastic blockmodel component and additional node-specific effects.  Although maximum-likelihood estimates do not appear consistent in this context, we are able to evaluate confidence sets as a function of different blockmodel partitions, which enables us to qualitatively assess the significance of estimated residual network structure relative to a baseline, which models covariates but lacks block structure.',\n",
       "  'id': '4230',\n",
       "  'title': 'Confidence Sets for Network Structure',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We derive here new generalization bounds, based on Rademacher Complexity theory, for model selection and error estimation   of linear (kernel) classifiers, which exploit  the availability of unlabeled samples.   In particular, two results are obtained: the first one shows that, using the unlabeled samples, the  confidence term of the conventional bound can be reduced by a factor of three; the second one  shows that the unlabeled samples can be used to obtain much tighter bounds, by building localized versions  of the hypothesis class containing the optimal classifier.',\n",
       "  'id': '4234',\n",
       "  'title': 'The Impact of Unlabeled Patterns in Rademacher Complexity Theory for Kernel Classifiers',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This paper proposes a parsing algorithm for scene understanding which includes four aspects: computing 3D scene layout, detecting 3D objects (e.g. furniture), detecting 2D faces (windows, doors etc.), and segmenting background. In contrast to previous scene labeling work that applied discriminative classifiers to pixels (or super-pixels), we use a generative Stochastic Scene Grammar (SSG). This grammar represents the compositional structures of visual entities from scene categories, 3D foreground/background, 2D faces, to 1D lines. The grammar includes three types of production rules and two types of contextual relations. Production rules: (i) AND rules represent the decomposition of an entity into sub-parts; (ii) OR rules represent the switching among sub-types of an entity; (iii) SET rules rep- resent an ensemble of visual entities. Contextual relations: (i) Cooperative ?+? relations represent positive links between binding entities, such as hinged faces of a object or aligned boxes; (ii) Competitive ?-? relations represents negative links between competing entities, such as mutually exclusive boxes. We design an efficient MCMC inference algorithm, namely Hierarchical cluster sampling, to search in the large solution space of scene configurations. The algorithm has two stages: (i) Clustering: It forms all possible higher-level structures (clusters) from lower-level entities by production rules and contextual relations. (ii) Sampling: It jumps between alternative structures (clusters) in each layer of the hierarchy to find the most probable configuration (represented by a parse tree). In our experiment, we demonstrate the superiority of our algorithm over existing methods on public dataset. In addition, our approach achieves richer structures in the parse tree.',\n",
       "  'id': '4236',\n",
       "  'title': 'Image Parsing with Stochastic Scene Grammar',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Skill discovery algorithms in reinforcement learning typically identify single states or regions in state space that correspond to task-specific subgoals.  However, such methods do not directly address the question of how many distinct skills are appropriate for solving the tasks that the agent faces.  This can be highly inefficient when many identified subgoals correspond to the same underlying skill, but are all used individually as skill goals.  Furthermore, skills created in this manner are often only transferable to tasks that share identical state spaces, since corresponding subgoals across tasks are not merged into a single skill goal.  We show that these problems can be overcome by clustering subgoal data defined in an agent-space and using the resulting clusters as templates for skill termination conditions.  Clustering via a Dirichlet process mixture model is used to discover a minimal, sufficient collection of portable skills.',\n",
       "  'id': '4238',\n",
       "  'title': 'Clustering via Dirichlet Process Mixture Models for Portable Skill Discovery',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"We consider loss functions for multiclass prediction problems. We   show when a  multiclass loss can be expressed as a ``proper   composite loss'', which is the composition of a proper loss and a link   function. We extend existing results for binary losses to   multiclass losses.  We determine the stationarity condition,   Bregman representation, order-sensitivity, existence and uniqueness   of the composite representation for multiclass losses.  We also   show that the integral representation  for binary proper losses can   not be extended to  multiclass losses. We subsume existing results   on ``classification calibration'' by relating it to properness.  We   draw conclusions concerning the design of multiclass losses.\",\n",
       "  'id': '4248',\n",
       "  'title': 'Composite Multiclass Losses',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Divergence estimators based on direct approximation of density-ratios without going through separate approximation of numerator and denominator densities have been successfully applied to machine learning tasks that involve distribution comparison such as outlier detection, transfer learning, and two-sample homogeneity test. However, since density-ratio functions often possess high fluctuation, divergence estimation is still a challenging task in practice. In this paper, we propose to use relative divergences for distribution comparison, which involves approximation of relative density-ratios. Since relative density-ratios are always smoother than corresponding ordinary density-ratios, our proposed method is favorable in terms of the non-parametric convergence speed. Furthermore, we show that the proposed divergence estimator has asymptotic variance independent of the model complexity under a parametric setup, implying that the proposed estimator hardly overfits even with complex models. Through experiments, we demonstrate the usefulness of the proposed approach.',\n",
       "  'id': '4254',\n",
       "  'title': 'Relative Density-Ratio Estimation for Robust Distribution Comparison',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Learning theory has largely focused on two main learning scenarios: the classical statistical setting where instances are drawn i.i.d. from a fixed distribution, and the adversarial scenario whereby at every time step the worst instance is revealed to the player. It can be argued that in the real world neither of these assumptions is reasonable. We define the minimax value of a game where the adversary is restricted in his moves, capturing stochastic and non-stochastic assumptions on data. Building on the sequential symmetrization approach, we define a notion of distribution-dependent Rademacher complexity for the spectrum of problems ranging from i.i.d. to worst-case. The bounds let us immediately deduce variation-type bounds. We study a smoothed online learning scenario and show that exponentially small amount of noise can make function classes with infinite Littlestone dimension learnable.',\n",
       "  'id': '4262',\n",
       "  'title': 'Online Learning: Stochastic, Constrained, and Smoothed Adversaries',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider latent structural versions of probit loss and ramp loss. We show that  these surrogate loss functions are consistent in the strong sense that for any feature map  (finite or infinite dimensional) they yield predictors approaching the infimum  task loss achievable by any linear predictor over the given features.  We also give  finite sample generalization bounds (convergence rates) for these loss functions.  These bounds suggest that probit loss converges more rapidly.  However, ramp loss is more easily optimized and may ultimately  be more practical.',\n",
       "  'id': '4268',\n",
       "  'title': 'Generalization Bounds and Consistency for Latent Structural Probit and Ramp Loss',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We discuss new methods for the recovery of signals with block-sparse structure, based on l1-minimization. Our emphasis is on the efficiently computable error bounds for the recovery routines. We optimize these bounds with respect to the method parameters to construct the estimators with improved statistical properties. We justify the proposed approach with an oracle inequality which links the properties of the recovery algorithms and the best estimation performance.',\n",
       "  'id': '4270',\n",
       "  'title': 'On the accuracy of l1-filtering of signals with block-sparse structure',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'The group Lasso is an extension of the Lasso for feature selection on (predefined) non-overlapping groups of features. The non-overlapping group structure limits its applicability in practice. There have been several recent attempts to study a more general formulation, where groups of features are given, potentially with overlaps between the groups. The resulting optimization is, however, much more challenging to solve due to the group overlaps. In this paper, we consider the efficient optimization of the overlapping group Lasso penalized problem. We reveal several key properties of the proximal operator associated with the overlapping group Lasso, and compute the proximal operator by solving the smooth and convex dual problem, which allows the use of the gradient descent type of algorithms for the optimization. We have performed empirical evaluations using both synthetic and the breast cancer gene expression data set, which consists of 8,141 genes organized into (overlapping) gene sets. Experimental results show that the proposed algorithm is more efficient than existing state-of-the-art algorithms.',\n",
       "  'id': '4275',\n",
       "  'title': 'Efficient Methods for Overlapping Group Lasso',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Compositional models provide an elegant formalism for representing the  visual appearance of highly variable objects.  While such models are  appealing from a theoretical point of view, it has been difficult to  demonstrate that they lead to performance advantages on challenging  datasets.  Here we develop a grammar model for person detection  and show that it outperforms previous high-performance systems on the  PASCAL benchmark.  Our model represents people using a hierarchy of  deformable parts, variable structure and an explicit model of  occlusion for partially visible objects.  To train the model, we  introduce a new discriminative framework for learning structured  prediction models from weakly-labeled data.',\n",
       "  'id': '4307',\n",
       "  'title': 'Object Detection with Grammar Models',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Biased labelers are a systemic problem in crowdsourcing, and a  comprehensive toolbox for handling their responses is still being  developed. A typical crowdsourcing application can be divided into  three steps: data collection, data curation, and learning. At present  these steps are often treated separately. We present Bayesian Bias  Mitigation for Crowdsourcing (BBMC), a Bayesian model to unify all  three. Most data curation methods account for the {\\\\it effects} of  labeler bias by modeling all labels as coming from a single latent  truth. Our model captures the {\\\\it sources} of bias by describing  labelers as influenced by shared random effects. This approach can  account for more complex bias patterns that arise in ambiguous or hard  labeling tasks and allows us to merge data curation and learning into  a single computation. Active learning integrates data collection with  learning, but is commonly considered infeasible with Gibbs sampling  inference. We propose a general approximation strategy for Markov  chains to efficiently quantify the effect of a perturbation on the  stationary distribution and specialize this approach to active  learning. Experiments show BBMC to outperform many common heuristics.',\n",
       "  'id': '4311',\n",
       "  'title': 'Bayesian Bias Mitigation for Crowdsourcing',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Many functional descriptions of spiking neurons assume a cascade structure where inputs are passed through an initial linear filtering stage that produces a low-dimensional signal that drives subsequent nonlinear stages.  This paper presents a novel and systematic parameter estimation procedure for such models and applies the method to two neural estimation problems: (i) compressed-sensing based neural mapping from multi-neuron excitation, and (ii) estimation of neural receptive yields in sensory neurons.  The proposed estimation algorithm models the neurons via a graphical model and then estimates the parameters in the model using a recently-developed generalized approximate message passing (GAMP) method.  The GAMP method is based on Gaussian approximations of loopy belief propagation.  In the neural connectivity problem, the GAMP-based   method is shown to be computational efficient, provides a more exact modeling of the sparsity, can incorporate nonlinearities in the output and significantly outperforms previous compressed-sensing methods.  For the receptive field estimation, the GAMP method can also exploit inherent structured sparsity in the linear weights.  The method is validated on estimation of linear nonlinear Poisson (LNP) cascade models for receptive fields of salamander retinal ganglion cells.',\n",
       "  'id': '4317',\n",
       "  'title': 'Neural Reconstruction with Approximate Message Passing (NeuRAMP)',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Thompson sampling is one of oldest heuristic to address the exploration / exploitation trade-off, but it is surprisingly not very popular in the literature. We present here some empirical results using Thompson sampling on simulated and real data, and show that it is highly competitive. And since this heuristic is very easy to implement, we argue that it should be part of the standard baselines to compare against.',\n",
       "  'id': '4321',\n",
       "  'title': 'An Empirical Evaluation of Thompson Sampling',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We describe a simple algorithm that runs in time  poly(n,1/gamma,1/eps) and learns an unknown n-dimensional  gamma-margin halfspace to accuracy 1-eps in the presence of  malicious noise, when the noise rate is allowed to be as high as  Theta(eps gamma sqrt(log(1/gamma))). Previous efficient  algorithms could only learn to accuracy eps in the presence of  malicious noise of rate at most Theta(eps gamma).    Our algorithm does not work by optimizing a convex loss function.  We  show that no algorithm for learning gamma-margin halfspaces that  minimizes a convex proxy for misclassification error can tolerate  malicious noise at a rate greater than Theta(eps gamma); this may  partially explain why previous algorithms could not achieve the higher  noise tolerance of our new algorithm.',\n",
       "  'id': '4323',\n",
       "  'title': 'Learning large-margin halfspaces with more malicious noise',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'High dimensional time series are endemic in applications of machine learning  such as robotics (sensor data), computational biology (gene expression data), vision   (video sequences) and graphics (motion capture data). Practical nonlinear  probabilistic approaches to this data are required. In this paper we introduce  the variational Gaussian process dynamical system. Our work builds on recent  variational approximations for Gaussian process latent variable models to allow  for nonlinear dimensionality reduction simultaneously with learning a dynamical  prior in the latent space. The approach also allows for the appropriate dimensionality   of the latent space to be automatically determined. We demonstrate the  model on a human motion capture data set and a series of high resolution video  sequences.',\n",
       "  'id': '4330',\n",
       "  'title': 'Variational Gaussian Process Dynamical Systems',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"For a learning problem whose associated excess loss class is $(\\\\beta,B)$-Bernstein, we show that it is theoretically possible to track the same classification performance  of the best (unknown) hypothesis in our class, provided that we are free to abstain from prediction in some region of our choice. The (probabilistic) volume of this rejected region of the domain is shown to be diminishing at rate $O(B\\\\theta (\\\\sqrt{1/m}))^\\\\beta)$, where $\\\\theta$ is Hanneke's disagreement coefficient. The strategy achieving this performance has computational barriers because it requires empirical error minimization in an agnostic setting. Nevertheless, we heuristically approximate this strategy and develop a novel selective classification algorithm  using constrained SVMs. We show empirically that the resulting algorithm consistently outperforms  the traditional rejection mechanism based on distance from decision boundary.\",\n",
       "  'id': '4339',\n",
       "  'title': 'Agnostic Selective Classification',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Although spectral clustering has enjoyed considerable empirical success in machine learning, its theoretical properties are not yet fully developed. We analyze the performance of a spectral algorithm for hierarchical clustering and show that on a class of hierarchically structured similarity matrices, this algorithm can tolerate noise that grows with the number of data points while still perfectly recovering the hierarchical clusters with high probability. We  additionally improve upon previous results for k-way spectral clustering to derive conditions under which spectral clustering makes no mistakes. Further, using minimax analysis, we derive tight upper and lower bounds for the  clustering problem and compare the performance of spectral clustering to these  information theoretic limits. We also present experiments on simulated and real  world data illustrating our results.',\n",
       "  'id': '4342',\n",
       "  'title': 'Noise Thresholds for Spectral Clustering',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Renewal processes are generalizations of the Poisson process on the real line, whose intervals are drawn i.i.d. from some distribution. Modulated renewal processes allow these distributions to vary with time, allowing the introduction nonstationarity. In this work, we take a nonparametric Bayesian approach, modeling this nonstationarity with a Gaussian process. Our approach is based on the idea of uniformization, allowing us to draw exact samples from an otherwise intractable distribution. We develop a novel and efficient MCMC sampler for posterior inference. In our experiments, we test these on a number of synthetic and real datasets.',\n",
       "  'id': '4358',\n",
       "  'title': 'Gaussian process modulated renewal processes',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'How can we train a statistical mixture model on a massive data set? In this paper, we show how to construct coresets for mixtures of Gaussians and natural generalizations. A coreset is a weighted subset of the data, which guarantees that models fitting the coreset will also provide a good fit for the original data set. We show that, perhaps surprisingly, Gaussian mixtures admit coresets of size independent of the size of the data set. More precisely, we prove that a weighted set of $O(dk^3/\\\\eps^2)$ data points suffices for computing a $(1+\\\\eps)$-approximation for the optimal model on the original $n$ data points. Moreover, such coresets can be efficiently constructed in a map-reduce style computation, as well as in a streaming setting. Our results rely on a novel reduction of statistical estimation to problems in computational geometry, as well as new complexity results about mixtures of Gaussians. We empirically evaluate our algorithms on several real data sets, including a density estimation problem in the context of earthquake detection using accelerometers in  mobile phones.',\n",
       "  'id': '4363',\n",
       "  'title': 'Scalable Training of Mixture Models via Coresets',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Storing a new pattern in a palimpsest memory system comes at the cost of interfering with the memory traces of previously stored items. Knowing the age of a pattern thus becomes critical for recalling it faithfully. This implies that there should be a tight coupling between estimates of age, as a form of familiarity, and the neural dynamics of recollection, something which current theories omit. Using a normative model of autoassociative memory, we show that a dual memory system, consisting of two interacting modules for familiarity and recollection, has best performance for both recollection and recognition. This finding provides a new window onto actively contentious psychological and neural aspects of recognition memory.',\n",
       "  'id': '4364',\n",
       "  'title': 'Two is better than one: distinct roles for familiarity and recollection in retrieving palimpsest memories',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Unlike existing nonparametric Bayesian models, which rely solely on specially conceived priors to incorporate domain knowledge for discovering improved latent representations, we study nonparametric Bayesian inference with regularization on the desired posterior distributions. While priors can indirectly affect posterior distributions through Bayes' theorem, imposing posterior regularization is arguably more direct and in some cases can be much easier. We particularly focus on developing infinite latent support vector machines (iLSVM) and multi-task infinite latent support vector machines (MT-iLSVM), which explore the large-margin idea in combination with a nonparametric Bayesian model for discovering predictive latent features for classification and multi-task learning, respectively. We present efficient inference methods and report empirical studies on several benchmark datasets. Our results appear to demonstrate the merits inherited from both large-margin learning and Bayesian nonparametrics.\",\n",
       "  'id': '4365',\n",
       "  'title': 'Infinite Latent SVM for Classification and Multi-task Learning',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Recovering hidden structure from complex and noisy non-linear data is one of the most fundamental problems in machine learning and statistical inference. While such data is often high-dimensional, it is of interest to approximate it with a low-dimensional or even one-dimensional space, since  many important aspects of  data are often intrinsically low-dimensional.   Furthermore, there are many scenarios where the underlying structure is graph-like, e.g, river/road networks or various trajectories.   In this paper, we develop a framework to extract, as well as to simplify, a one-dimensional \"skeleton\" from unorganized data using the Reeb graph.   Our algorithm is very simple, does not require complex optimizations and can be easily applied to unorganized high-dimensional data such as point clouds or  proximity graphs.   It can also represent arbitrary graph structures in the data.  We also give  theoretical results to justify our method.  We  provide a number of experiments to demonstrate the effectiveness and generality of our algorithm, including comparisons to existing methods, such as principal curves.  We believe that the simplicity and practicality of our algorithm will help to promote skeleton graphs as a data analysis tool for a broad range of applications.',\n",
       "  'id': '4375',\n",
       "  'title': 'Data Skeletonization via Reeb Graphs',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider a statistical framework in which recurrent networks of spiking neurons learn to generate spatio-temporal spike patterns. Given biologically realistic stochastic neuronal dynamics we derive a tractable learning rule for the synaptic weights towards hidden and visible neurons that leads to optimal recall of the training sequences. We show that learning synaptic weights towards hidden neurons significantly improves the storing capacity of the network. Furthermore, we derive an approximate online learning rule and show that our learning rule is consistent with Spike-Timing Dependent Plasticity in that if a presynaptic spike shortly precedes a postynaptic spike, potentiation is induced and otherwise depression is elicited.',\n",
       "  'id': '4383',\n",
       "  'title': 'Sequence learning with hidden units in spiking neural networks',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Loopy belief propagation performs approximate inference on graphical models with loops. One might hope to compensate for the approximation by adjusting model parameters. Learning algorithms for this purpose have been explored previously, and the claim has been made that every set of locally consistent marginals can arise from belief propagation run on a graphical model. On the contrary, here we show that many probability distributions have marginals that cannot be reached by belief propagation using any set of model parameters or any learning algorithm. We call such marginals `unbelievable.' This problem occurs whenever the Hessian of the Bethe free energy is not positive-definite at the target marginals. All learning algorithms for belief propagation necessarily fail in these cases, producing beliefs or sets of beliefs that may even be worse than the pre-learning approximation. We then show that averaging inaccurate beliefs, each obtained from belief propagation using model parameters perturbed about some learned mean values, can achieve the unbelievable marginals.\",\n",
       "  'id': '4391',\n",
       "  'title': 'Learning unbelievable probabilities',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Many real-world networks are described by both connectivity information and features for every node.  To better model and understand these networks, we present structure preserving metric learning (SPML), an algorithm for learning a Mahalanobis distance metric from a network such that the learned distances are tied to the inherent connectivity structure of the network.  Like the graph embedding algorithm structure preserving embedding, SPML learns a metric which is structure preserving, meaning a connectivity algorithm such as k-nearest neighbors will yield the correct connectivity when applied using the distances from the learned metric.  We show a variety of synthetic and real-world experiments where SPML predicts link patterns from node features more accurately than standard techniques.  We further demonstrate a method for optimizing SPML based on stochastic gradient descent which removes the running-time dependency on the size of the network and allows the method to easily scale to networks of thousands of nodes and millions of edges.',\n",
       "  'id': '4392',\n",
       "  'title': 'Learning a Distance Metric from a Network',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'A model of human visual search is proposed. It predicts both response time (RT) and error rates (RT) as a function of image parameters such as target contrast and clutter. The model is an ideal observer, in that it optimizes the Bayes ratio of tar- get present vs target absent. The ratio is computed on the firing pattern of V1/V2 neurons, modeled by Poisson distributions. The optimal mechanism for integrat- ing information over time is shown to be a ?soft max? of diffusions, computed over the visual field by ?hypercolumns? of neurons that share the same receptive field and have different response properties to image features. An approximation of the optimal Bayesian observer, based on integrating local decisions, rather than diffusions, is also derived; it is shown experimentally to produce very similar pre- dictions. A psychophyisics experiment is proposed that may discriminate between which mechanism is used in the human brain.',\n",
       "  'id': '4393',\n",
       "  'title': 'Predicting response time and error rates in visual search',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We introduce the Piecewise-Constant Conditional Intensity Model, a model for learning temporal dependencies in event streams.  We describe a closed-form Bayesian approach to learning these models, and describe an importance sampling algorithm for forecasting future events using these models, using a proposal distribution based on Poisson superposition.  We then use synthetic data, supercomputer event logs, and web search query logs to illustrate that our learning algorithm can efficiently learn nonlinear temporal dependencies, and that our importance sampling algorithm can effectively forecast future events.',\n",
       "  'id': '4395',\n",
       "  'title': 'A Model for Temporal Dependencies in Event Streams',\n",
       "  'year': '2011'},\n",
       " {'abstract': \"Crowdsourcing systems, in which tasks are electronically distributed to numerous ``information piece-workers'', have emerged as an effective paradigm for human-powered solving of large scale problems in domains such as image classification, data entry, optical character recognition, recommendation, and proofreading. Because these low-paid workers can be unreliable, nearly all crowdsourcers must devise schemes to increase confidence in their answers, typically by assigning each task multiple times and combining the answers in some way such as majority voting. In this paper, we consider a general model of such  rowdsourcing tasks, and pose the problem of minimizing the total price (i.e., number of task assignments) that must be paid to achieve a target overall reliability. We give new algorithms for deciding which tasks to assign to which workers and for inferring correct answers from the workers? answers. We show that our algorithm significantly outperforms majority voting and, in fact, are asymptotically optimal through comparison to an oracle that knows the reliability of every worker.\",\n",
       "  'id': '4396',\n",
       "  'title': 'Iterative Learning for Reliable Crowdsourcing Systems',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider large matrices of low rank. We address the problem of recovering such matrices when most of the entries are unknown. Matrix completion finds applications in recommender systems. In this setting, the rows of the matrix may correspond to items and the columns may correspond to users. The known entries are the ratings given by users to some items. The aim is to predict the unobserved ratings. This problem is commonly stated in a constrained optimization framework. We follow an approach that exploits the geometry of the low-rank constraint to recast the problem as an unconstrained optimization problem on the Grassmann manifold. We then apply first- and second-order Riemannian trust-region methods to solve it. The cost of each iteration is linear in the number of known entries. Our methods, RTRMC 1 and 2, outperform state-of-the-art algorithms on a wide range of problem instances.',\n",
       "  'id': '4402',\n",
       "  'title': 'RTRMC: A Riemannian trust-region method for low-rank matrix completion',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Variational Message Passing (VMP) is an algorithmic implementation of the Variational Bayes (VB) method which applies only in the special case of conjugate exponential family models. We propose an extension to VMP, which we refer to as Non-conjugate Variational Message Passing (NCVMP) which aims to alleviate this restriction while maintaining modularity, allowing choice in how expectations are calculated, and integrating into an existing message-passing framework: Infer.NET. We demonstrate NCVMP on logistic binary and multinomial regression. In the multinomial case we introduce a novel variational bound for the softmax factor which is tighter than other commonly used bounds whilst maintaining computational tractability.',\n",
       "  'id': '4407',\n",
       "  'title': 'Non-conjugate Variational Message Passing for Multinomial and Binary Regression',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'While loopy Belief Propagation (LBP) has been utilized in a wide variety of applications with empirical success, it comes with few theoretical guarantees. Especially, if the interactions of random variables in a graphical model are strong, the behaviors of the algorithm can be difficult to analyze due to underlying phase transitions. In this paper, we develop a novel approach to the uniqueness problem of the LBP fixed point; our new ?necessary and sufficient? condition is stated in terms of graphs and signs, where the sign denotes the types (attractive/repulsive) of the interaction (i.e., compatibility function) on the edge. In all previous works, uniqueness is guaranteed only in the situations where the strength of the interactions are ?sufficiently? small in certain senses. In contrast, our condition covers arbitrary strong interactions on the specified class of signed graphs. The result of this paper is based on the recent theoretical advance in the LBP algorithm; the connection with the graph zeta function.',\n",
       "  'id': '4422',\n",
       "  'title': 'Uniqueness of Belief Propagation on Signed Graphs',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We study a particular class of cyclic causal models, where each variable is a (possibly nonlinear) function of its parents and additive noise. We prove that the causal graph of such models is generically identifiable in the bivariate, Gaussian-noise case. We also propose a method to learn such models from observational data. In the acyclic case, the method reduces to ordinary regression, but in the more challenging cyclic case, an additional term arises in the loss function, which makes it a special case of nonlinear independent component analysis. We illustrate the proposed method on synthetic data.',\n",
       "  'id': '4424',\n",
       "  'title': 'On Causal Discovery with Cyclic Additive Noise Models',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Increasingly, optimization problems in machine learning, especially those arising from high-dimensional statistical estimation, have a large number of variables. Modern statistical estimators developed over the past decade have statistical or sample complexity that depends only weakly on the number of parameters when there is some structure to the problem, such as sparsity. A central question is whether similar advances can be made in their computational complexity as well. In this paper, we propose strategies that indicate that such advances can indeed be made. In particular, we investigate the greedy coordinate descent algorithm, and note that performing the greedy step efficiently weakens the costly dependence on the problem size provided the solution is sparse. We then propose a suite of methods that perform these greedy steps efficiently by a reduction to nearest neighbor search.   We also devise a more amenable form of greedy descent for composite non-smooth objectives; as well as several approximate variants of such greedy descent. We develop a practical implementation of our algorithm that combines greedy coordinate descent with locality sensitive hashing. Without tuning the latter data structure, we are not only able to significantly speed up the vanilla greedy method, but also outperform cyclic descent when the problem size becomes large. Our results indicate the effectiveness of our nearest neighbor strategies, and also point to many open questions regarding the development of computational geometric techniques tailored towards first-order optimization methods.',\n",
       "  'id': '4425',\n",
       "  'title': 'Nearest Neighbor based Greedy Coordinate Descent',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects).  In general, the ranking of $n$ objects can be identified by standard sorting methods using $n\\\\log_2 n$ pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. {Specifically, we assume that the objects can be embedded into a $d$-dimensional Euclidean space and that the rankings reflect their relative distances from a common reference point in $\\\\R^d$. We show that under this assumption the number of possible rankings grows like $n^{2d}$ and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than $d\\\\log n$ adaptively selected pairwise comparisons, on average.}  If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis.',\n",
       "  'id': '4427',\n",
       "  'title': 'Active Ranking using Pairwise Comparisons',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Domain adaptation algorithms seek to generalize a model trained in a source domain to a new target domain.  In many  practical cases, the source and target distributions can differ substantially, and in some cases crucial target features may not have support in the source domain.  In this paper we introduce an algorithm that bridges the gap between source and target domains by slowly adding both the target features and instances in which the current  algorithm is the most confident.  Our algorithm is a variant of co-training, and we name it CODA (Co-training for domain adaptation).  Unlike the original co-training work, we do not assume a particular feature split.  Instead, for each iteration of co-training, we add target features and formulate a single optimization problem which simultaneously learns a target predictor, a split of the feature space into views, and a shared subset of source  and target features to include in the predictor.  CODA significantly out-performs the state-of-the-art on the 12-domain benchmark data set of Blitzer et al.. Indeed, over a wide range (65 of 84 comparisons) of target supervision, ranging from no labeled target data to a relatively large number of target labels, CODA achieves the best performance.',\n",
       "  'id': '4433',\n",
       "  'title': 'Co-Training for Domain Adaptation',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Transfer reinforcement learning (RL) methods leverage on the experience collected on a set of source tasks to speed-up RL algorithms. A simple and effective approach is to transfer samples from source tasks and include them in the training set used to solve a target task. In this paper, we investigate the theoretical properties of this transfer method and we introduce novel algorithms adapting the transfer process on the basis of the similarity between source and target tasks. Finally, we report illustrative experimental results in a continuous chain problem.',\n",
       "  'id': '4435',\n",
       "  'title': 'Transfer from Multiple MDPs',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of recovering a matrix $\\\\mathbf{M}$ that is the sum of a low-rank matrix $\\\\mathbf{L}$ and a sparse matrix $\\\\mathbf{S}$ from a small set of linear measurements of the form $\\\\mathbf{y} = \\\\mathcal{A}(\\\\mathbf{M}) = \\\\mathcal{A}({\\\\bf L}+{\\\\bf S})$.  This model subsumes three important classes of signal recovery problems:  compressive sensing, affine rank minimization, and robust principal component analysis.  We propose a natural optimization problem for signal recovery under this model and develop a new greedy algorithm called SpaRCS to solve it.  SpaRCS inherits a number of desirable properties from the state-of-the-art CoSaMP and ADMiRA algorithms, including exponential convergence and efficient implementation.  Simulation results with video compressive sensing, hyperspectral imaging, and robust matrix completion data sets demonstrate both the accuracy and efficacy of the algorithm.',\n",
       "  'id': '4438',\n",
       "  'title': 'SpaRCS: Recovering low-rank and sparse matrices from compressive measurements',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Multi-structure model fitting has traditionally taken a two-stage approach: First, sample a (large) number of model hypotheses, then select the subset of hypotheses that optimise a joint fitting and model selection criterion. This disjoint two-stage approach is arguably suboptimal and inefficient - if the random sampling did not retrieve a good set of hypotheses, the optimised outcome will not represent a good fit. To overcome this weakness we propose a new multi-structure fitting approach based on Reversible Jump MCMC. Instrumental in raising the effectiveness of our method is an adaptive hypothesis generator, whose proposal distribution is learned incrementally and online. We prove that this adaptive proposal satisfies the diminishing adaptation property crucial for ensuring ergodicity in MCMC. Our method effectively conducts hypothesis sampling and optimisation simultaneously, and gives superior computational efficiency over other methods.',\n",
       "  'id': '4458',\n",
       "  'title': 'Simultaneous Sampling and Multi-Structure Fitting with Adaptive Reversible Jump MCMC',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'We consider the problem of computing the Euclidean projection of a vector of length $p$ onto a non-negative max-heap---an ordered tree where the values of the nodes are all nonnegative and the value of any parent node is no less than the value(s) of its child node(s). This Euclidean projection plays a building block role in the optimization problem with a non-negative max-heap constraint. Such a constraint is desirable when the features follow an ordered tree structure, that is, a given feature is selected for the given regression/classification task only if its parent node is selected. In this paper, we show that such Euclidean projection problem admits an analytical solution and we develop a top-down algorithm where the key operation is to find the so-called \\\\emph{maximal root-tree} of the subtree rooted at each node. A naive approach for finding the maximal root-tree is to enumerate all the possible root-trees, which, however, does not scale well. We reveal several important properties of the maximal root-tree, based on which we design a bottom-up algorithm with merge for efficiently finding the maximal root-tree. The proposed algorithm has a (worst-case) linear time complexity for a sequential list, and $O(p^2)$ for a general tree. We report simulation results showing the effectiveness of the max-heap for regression with an ordered tree structure. Empirical results show that the proposed algorithm has an expected linear time complexity for many special cases including a sequential list, a full binary tree, and a tree with depth 1.',\n",
       "  'id': '4459',\n",
       "  'title': 'Projection onto A Nonnegative Max-Heap',\n",
       "  'year': '2011'},\n",
       " {'abstract': 'Independent Components Analysis (ICA) and its variants have been successfully used for unsupervised feature learning. However, standard ICA requires an orthonoramlity constraint to be enforced, which makes it dif?cult to learn overcomplete features. In addition, ICA is sensitive to whitening. These properties make it challenging to scale ICA to high dimensional data. In this paper, we propose a robust soft reconstruction cost for ICA that allows us to learn highly overcomplete sparse features even on unwhitened data. Our formulation reveals formal connections between ICA and sparse autoencoders, which have previously been observed only empirically. Our algorithm can be used in conjunction with off-the-shelf fast unconstrained optimizers. We show that the soft reconstruction cost can also be used to prevent replicated features in tiled convolutional neural networks. Using our method to learn highly overcomplete sparse features and tiled convolutional neural networks, we obtain competitive performances on a wide variety of object recognition tasks. We achieve state-of-the-art test accuracies on the STL-10 and Hollywood2 datasets.',\n",
       "  'id': '4467',\n",
       "  'title': 'ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning',\n",
       "  'year': '2011'},\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list = []\n",
    "\n",
    "year = \"2007\"\n",
    "\n",
    "while year != \"2018\":\n",
    "    num_docs = es.count(index = 'nips_papers', body = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"match\": { \"year\" : year }\n",
    "                },\n",
    "                \"must_not\": {\n",
    "                    \"match\": {\n",
    "                        \"abstract\": \"Abstract Missing\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })['count']\n",
    "    res = es.search(index = 'nips_papers', body = {\n",
    "        \"size\": num_docs,\n",
    "        \"_source\": ['id', 'year', 'title', 'abstract'],\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"match\": { \"year\" : year }\n",
    "                },\n",
    "                \"must_not\": {\n",
    "                    \"match\": {\n",
    "                        \"abstract\": \"Abstract Missing\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    for entry in res['hits']['hits']:\n",
    "        doc_list.append(entry['_source'])\n",
    "    tmp = int(year) + 1\n",
    "    year = str(tmp)\n",
    "\n",
    "doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making sure doc_list only contains documents from years 2007 to 2017\n",
    "\n",
    "years = ['2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n",
    "not_in_range = False\n",
    "\n",
    "for doc in doc_list:\n",
    "    if doc['year'] not in years:\n",
    "        not_in_range = True\n",
    "        break\n",
    "        \n",
    "not_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3804"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3d',\n",
       " 'acceleration',\n",
       " 'action',\n",
       " 'active',\n",
       " 'adaptation',\n",
       " 'additive',\n",
       " 'adversarial',\n",
       " 'agent',\n",
       " 'aggregation',\n",
       " 'algorithm',\n",
       " 'alignment',\n",
       " 'analysi',\n",
       " 'annotation',\n",
       " 'armed',\n",
       " 'assumption',\n",
       " 'asynchronous',\n",
       " 'attention',\n",
       " 'attribute',\n",
       " 'average',\n",
       " 'balanced',\n",
       " 'bandit',\n",
       " 'bayesian',\n",
       " 'binary',\n",
       " 'bound',\n",
       " 'budget',\n",
       " 'carlo',\n",
       " 'cascade',\n",
       " 'case',\n",
       " 'chain',\n",
       " 'choice',\n",
       " 'class',\n",
       " 'classifier',\n",
       " 'coding',\n",
       " 'cold',\n",
       " 'collaborative',\n",
       " 'completion',\n",
       " 'composition',\n",
       " 'compressed',\n",
       " 'conjugate',\n",
       " 'construction',\n",
       " 'context',\n",
       " 'contextual',\n",
       " 'convex',\n",
       " 'convolution',\n",
       " 'convolutional',\n",
       " 'coordinate',\n",
       " 'coupled',\n",
       " 'cover',\n",
       " 'crowdsourcing',\n",
       " 'dataset',\n",
       " 'decentralized',\n",
       " 'decision',\n",
       " 'decomposition',\n",
       " 'deep',\n",
       " 'dependence',\n",
       " 'descent',\n",
       " 'design',\n",
       " 'detection',\n",
       " 'determinantal',\n",
       " 'dictionary',\n",
       " 'dimensional',\n",
       " 'disentangled',\n",
       " 'distributed',\n",
       " 'distribution',\n",
       " 'domain',\n",
       " 'driven',\n",
       " 'dropout',\n",
       " 'dynamical',\n",
       " 'effect',\n",
       " 'embedding',\n",
       " 'estimating',\n",
       " 'estimation',\n",
       " 'evaluation',\n",
       " 'expectation',\n",
       " 'exploiting',\n",
       " 'factor',\n",
       " 'factorization',\n",
       " 'fairness',\n",
       " 'fast',\n",
       " 'feature',\n",
       " 'finite',\n",
       " 'forest',\n",
       " 'frank',\n",
       " 'functional',\n",
       " 'gan',\n",
       " 'gated',\n",
       " 'general',\n",
       " 'generative',\n",
       " 'geometric',\n",
       " 'gradient',\n",
       " 'graph',\n",
       " 'graphical',\n",
       " 'group',\n",
       " 'guarantees',\n",
       " 'guided',\n",
       " 'hashing',\n",
       " 'hierarchical',\n",
       " 'high',\n",
       " 'hilbert',\n",
       " 'human',\n",
       " 'identifying',\n",
       " 'imitation',\n",
       " 'implicit',\n",
       " 'inference',\n",
       " 'infinite',\n",
       " 'interpretable',\n",
       " 'invariance',\n",
       " 'joint',\n",
       " 'kernel',\n",
       " 'knowledge',\n",
       " 'label',\n",
       " 'large',\n",
       " 'lasso',\n",
       " 'latent',\n",
       " 'law',\n",
       " 'learning',\n",
       " 'lifted',\n",
       " 'link',\n",
       " 'logistic',\n",
       " 'low',\n",
       " 'making',\n",
       " 'manifold',\n",
       " 'margin',\n",
       " 'matching',\n",
       " 'matrice',\n",
       " 'maximizing',\n",
       " 'maximum',\n",
       " 'mcmc',\n",
       " 'measure',\n",
       " 'measurement',\n",
       " 'message',\n",
       " 'metric',\n",
       " 'minimization',\n",
       " 'mirror',\n",
       " 'mixing',\n",
       " 'modeling',\n",
       " 'monte',\n",
       " 'motor',\n",
       " 'multi',\n",
       " 'multiclass',\n",
       " 'multiple',\n",
       " 'multivariate',\n",
       " 'neighbor',\n",
       " 'neuronal',\n",
       " 'newton',\n",
       " 'noise',\n",
       " 'nonparametric',\n",
       " 'novel',\n",
       " 'object',\n",
       " 'objective',\n",
       " 'observation',\n",
       " 'online',\n",
       " 'optimality',\n",
       " 'optimistic',\n",
       " 'optimization',\n",
       " 'oracle',\n",
       " 'parallel',\n",
       " 'parametric',\n",
       " 'partitioning',\n",
       " 'passing',\n",
       " 'path',\n",
       " 'pca',\n",
       " 'performance',\n",
       " 'permutation',\n",
       " 'poisson',\n",
       " 'polynomial',\n",
       " 'positive',\n",
       " 'posterior',\n",
       " 'practical',\n",
       " 'predicting',\n",
       " 'prior',\n",
       " 'private',\n",
       " 'probabilistic',\n",
       " 'process',\n",
       " 'proposal',\n",
       " 'rank',\n",
       " 'ranking',\n",
       " 'rational',\n",
       " 'recovery',\n",
       " 'reduction',\n",
       " 'regression',\n",
       " 'regularization',\n",
       " 'return',\n",
       " 'robust',\n",
       " 'robustness',\n",
       " 'safe',\n",
       " 'sampling',\n",
       " 'scalable',\n",
       " 'scale',\n",
       " 'segmentation',\n",
       " 'semantic',\n",
       " 'semi',\n",
       " 'sensing',\n",
       " 'sequential',\n",
       " 'sery',\n",
       " 'setting',\n",
       " 'sgd',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'slow',\n",
       " 'smooth',\n",
       " 'solving',\n",
       " 'sparse',\n",
       " 'sparsity',\n",
       " 'stochastic',\n",
       " 'strategic',\n",
       " 'strategy',\n",
       " 'structural',\n",
       " 'structure',\n",
       " 'structured',\n",
       " 'submodular',\n",
       " 'subset',\n",
       " 'subspace',\n",
       " 'supervised',\n",
       " 'supervision',\n",
       " 'symmetric',\n",
       " 'task',\n",
       " 'template',\n",
       " 'tensor',\n",
       " 'testing',\n",
       " 'thompson',\n",
       " 'tight',\n",
       " 'topic',\n",
       " 'transfer',\n",
       " 'tree',\n",
       " 'unified',\n",
       " 'unknown',\n",
       " 'unlabeled',\n",
       " 'variable',\n",
       " 'walk',\n",
       " 'weighted',\n",
       " 'wolfe'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain a set of significant terms (unigrams) for filtering after RAKE\n",
    "\n",
    "unigrams = set()\n",
    "\n",
    "res = es.search(index = \"nips_papers\", body = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"years\": {\n",
    "            \"terms\": { \"field\" : \"year\" },\n",
    "            \"aggs\": {\n",
    "                \"keywords\": {\n",
    "                    \"significant_terms\": {\n",
    "                        \"field\": \"title\",\n",
    "                        \"size\": 30\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "tmp = res['aggregations']['years']['buckets']\n",
    "\n",
    "for year in tmp:\n",
    "    words = year['keywords']['buckets']\n",
    "    for word in words:\n",
    "        unigrams.add(word['key'])\n",
    "        \n",
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RAKE_score': 9.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'competition adds complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 6.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'positive expected reward',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'reward strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3163', 'keyword': 'posg ),', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'determinining whether',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'cooperative strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'cooperation affected',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'competitive posgs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'class nexp',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3163', 'keyword': 'positive', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3163', 'keyword': 'expected', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3163', 'keyword': 'nexp', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'pomdp', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'oracle', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'np', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'namely', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'known', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'dec', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'complete', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'evaluating search engines',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'relevance', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'relationship',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'modeling', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'clicks', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'two ranked lists',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.714285714285715,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'wise relevance judgements',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.464285714285715,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'two relevance judgments',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.464285714285715,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'relevance judgments paired',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.464285714285715,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'complete relevance judgments',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'web search engines',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'sponsored search results',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'made across time',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.714285714285714,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'predict document relevance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.464285714285714,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'relevance judgments',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'web search',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.714285714285714,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'relevance score',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'search engine',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'results shown',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'previous methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'novel formalization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'general enough',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'financial backbone',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3190', 'keyword': 'dcg ),', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'click data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'improve confidence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'clicks received',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'better ranking',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'additional documents',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3190', 'keyword': 'time', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3190', 'keyword': 'predict', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3190', 'keyword': 'documents', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'confidence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3190', 'keyword': 'clicks', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3190', 'keyword': 'better', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'well', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'using', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'used', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'set', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'selection', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'query', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'provide', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'predictions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'pair', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'model', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'millions', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'method', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'leverages', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'judged', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'judge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'identify', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'guide', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'give', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'furthermore',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'experiments',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'evaluate', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'datasets', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'contrasts', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'comparisons',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'comparison',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'available', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'applicable',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'allows', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': '94', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': '82', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'learning bounds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'domain adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'target empirical risk',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'known learning guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'bounds explicitly model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'test data come',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'multiple source domains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.666666666666666,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'little training data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'different target domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'training data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'different number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'uniform combination',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'source risks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'source domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'real world',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'often wish',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'inherent trade',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'exhibit cases',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'convex combination',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'large amount',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3212', 'keyword': 'training', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3212', 'keyword': 'source', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3212', 'keyword': 'domain', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3212', 'keyword': 'large', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'work', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'though', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'small', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'non', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'minimizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'minimize', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'may', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'instances', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3212', 'keyword': 'adapt', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'stability bounds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'processes', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'non', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'kernel ridge regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'proves novel stability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'existing stability analyses',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'several general classes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning algorithm often',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.2,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'bounds strictly generalize',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.2,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'based generalization bounds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'specific learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'inherent temporal dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'algorithmic stability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning theory',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'general setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.2,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'bounds given',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.2,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'bounds apply',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'used effectively',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'system diagnosis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'particular properties',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'paper studies',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'mixing sequence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'key advantage',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'identically distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3239', 'keyword': 'ary beta', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'also illustrate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'observations received',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5, 'doc_id': '3239', 'keyword': 'hold even', 'year': '2007'},\n",
       " {'RAKE_score': 2.2, 'doc_id': '3239', 'keyword': 'bounds', 'year': '2007'},\n",
       " {'RAKE_score': 2.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'observations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3239', 'keyword': 'hold', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'weaken', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'time', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'station', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'signed', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'scenario', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'samples', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'past', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'notion', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'much', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'independently',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'implies', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'however', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'drawn', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'de', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'clear', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'assumption',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'application',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': '.).', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'heuristic search methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'theoretical analysis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online pomdps',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'general theorem showing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.833333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'offline approximation techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 6.833333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'provide theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.833333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'unify offline',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'theoretical properties',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'offline counterparts',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'seems natural',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'search heuristics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'remarkably scalable',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'reasonable time',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'proposed recently',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'optimal solutions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'optimal algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'lookahead search',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'error made',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'error analysis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'challenging problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'anytime algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'reduce error',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'also practical',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3250', 'keyword': 'provide', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3250', 'keyword': 'reduce', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3250', 'keyword': 'also', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'without', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'use', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'try', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'thus', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'scalability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'proven', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'provably', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'preserving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'potential', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'pomdps', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'planning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'paper', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'near', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'lead', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'latter', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'guide', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'former', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'find', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'epsilon', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'complete', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'best', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'approach', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'aims', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'admissible',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'logical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'causal inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'noisy', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'application',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'new experimental findings',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'conditional distributions provided',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'sufficient number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'special cases',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'complex contexts',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'causal reasoning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'causal features',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'causal factors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'binary inputs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'artificial intelligence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'standard noisy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'novel noisy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'logical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'noisy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'used', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'use', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'terms', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'speculate', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'showing', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'sense', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'representing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'represented',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'represent', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'prove', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'models', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'illustrate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'finally', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'describe', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'conjunctions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'complete', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3259', 'keyword': 'account', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'instance pruning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'multiple', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'two key insights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'safely pruned early',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'operate extremely rapidly',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'multiple instance pruning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'aggressively terminate computation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'false positive rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'detection rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'unsolved issue',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'training process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'training dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'statistical independence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'soft cascades',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'recent years',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'probability distributions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'important applications',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'high accuracy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'fully automatic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'experimental results',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'complete classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade remains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade earning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade detectors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'active research',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'mip process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'algorithm computes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3265', 'keyword': 'mip', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3265', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'thresholds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'success', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'stage', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'shown', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'set', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'requires', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'rejected', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'reduction', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'particular',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'paper', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'nevertheless',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'mit', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'increase', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'ii', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'examples', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'driven', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'determining',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'destined', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'based', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'assumptions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'area', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'modeling image patches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'markov random fields',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'directed hierarchy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'turn must settle',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'markov random fields',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'fast inference procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'directed belief nets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'multilayer generative models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'learned one layer',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'efficient learning procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'generative models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'directed connections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'posterior distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'natural images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'hidden layers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'hidden layer',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'equilibrium given',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'best aspects',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'good approximation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3279', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3279', 'keyword': 'layer', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3279', 'keyword': 'good', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'type', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'top', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'time', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'statistics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'patches', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'modulated', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'model', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'input', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'generate', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'describe', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'deep', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'computing', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'complete', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'combine', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'capturing', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'probability approaching one',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'high dimensional regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'establishing upper bounds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'establishing theoretical limits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'recovering sparse models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'oracle linear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'random linear transformation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333332,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparse linear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'revealing little information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'true model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'random projections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.466666666666667,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparse data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'theoretic terms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'successfully recovered',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'signal reconstruction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'recent research',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'privacy properties',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'primary motivation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'preserve privacy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'nonzero coefficients',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'input variables',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'information communicated',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'establish conditions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compression procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.8,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'uncompressed data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.3,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'original data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.3,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.8, 'doc_id': '3280', 'keyword': 'data', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3280', 'keyword': 'original', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'zero', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'well', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'variant', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'study', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'studied', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'sparsity', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'role', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'required', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'rate', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'problem', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'paper', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'p', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'number', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'n', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'identify', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'finally', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'examples', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'dimensions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'decay', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'characterize',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'anonymize', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'addition', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'poisson feature model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'infinite gamma',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'visual object class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'multiple instances shown',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'possibly unbounded number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'given data point',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'unsupervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'single occurrence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'observed data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'multiple occurrences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'latent causes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'factorial learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'probability model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'likelihood model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'prior together',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'latent features',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'images using',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3309', 'keyword': 'number', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3309', 'keyword': 'data', 'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3309', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'occurrences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3309', 'keyword': 'images', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3309', 'keyword': 'features', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'use', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'unknown', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'set', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'role', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'problem', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'present', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'play', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'non', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'image', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'however', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'g', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'feature', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'e', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'deal', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'columns', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'cases', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'associates',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'address', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'image models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'sparsity', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'overcompleteness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'use bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'indeed best modelled',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'extremely sparse distributions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'coding model based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse coding',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'visual cortex',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3312', 'keyword': 'toy data', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse representation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'natural images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'modestly overcomplete',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'computational models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'selection methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3312', 'keyword': 'sparse', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3312', 'keyword': 'based', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3312', 'keyword': 'methods', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'validated', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'student', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'questions', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'question', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'particular',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'find', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'despite', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'currency', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'complete', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'although', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'address', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'irreducible mdps',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'solving linear programs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'four key differences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5, 'doc_id': '3329', 'keyword': 'p )\\\\ log', 'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'optimize average reward',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'constant factor larger',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'state transition probabilities',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm recently proposed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'transition probabilities',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'reward obtained',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5, 'doc_id': '3329', 'keyword': 'p )$', 'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'dependent constant',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm proposed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'require knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'optimal policy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'closely related',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'chooses actions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'better dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'also similar',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'regret bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5, 'doc_id': '3329', 'keyword': 'olp uses', 'year': '2007'},\n",
       " {'RAKE_score': 3.5, 'doc_id': '3329', 'keyword': 'mdp ).', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3329', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3329', 'keyword': 'regret', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3329', 'keyword': 'olp', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3329', 'keyword': 'mdp', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'within', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'time', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'supports', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'size', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'simpler', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'set', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'proof', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'present', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'ortner', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'next', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'katehakis', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'irreducible',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'flavor', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'far', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'explicit', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'experience',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'estimates', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'estimate', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'corresponds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'computation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'close', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'c', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'burnetas', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'auer', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'testing', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'homogeneity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'give experimental evidence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'two samples',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'real datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'provides us',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'null hypothesis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'asymptotic distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'test', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'relevance', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'method', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'homogeneity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'derive', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'artificial',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'randomized algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'without loss',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'using ideas',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'text classification',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'svm learners',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'subsets chosen',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'random subsets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'random projections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3352', 'keyword': 'log n', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'high probability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'experiments done',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'randomized algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'algorithm scales',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'sample size',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3352', 'keyword': 'size', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'used', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'synthetic', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'solves', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'solution', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'scalability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'problem', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'optimal', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'obtain', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'iterating', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'data', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'crucial', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'context', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'close', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'accuracy', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'nearest neighbor search',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'learning framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'locality sensitive hashing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'leverage learning techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'learning often improves',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'experimental results reveal',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'already strong performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'rectilinear structures employed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'general learning framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structure classes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.666666666666666,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'retrieval data structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.166666666666666,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structures',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'retrieval time',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'novel framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'sample queries',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3357', 'keyword': 'miss rate', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'generalization theory',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'fast nearest',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'nn problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3357', 'keyword': 'nn', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'used', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'trees', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'present', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'potential', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'parameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'neighbor', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'minimize', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'learn', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'kd', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'explore', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'derive', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'build', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'probabilistic relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'constraint propagation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'csps', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'cpr', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'whole parametric family',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'provides another view',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'classical constraint propagation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'applications beyond k',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3361', 'keyword': 'cpr ),', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'approach elucidates',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3361', 'keyword': '1 ).', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'sat', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'pure', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'light', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'leading', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'importantly',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'implicit', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'effectiveness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': '0', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'random projections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'manifold learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'significant potential savings',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'projection space required',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'handle practical situations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'distributed sensing systems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'perform manifold learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'manifold modeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': '{\\\\ em linear',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'n $, meaning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'underlying manifold',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'data acquisition',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'transmission costs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'smallest size',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'small number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'sample points',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'rigorously prove',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'random projections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'particularly relevant',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3191', 'keyword': 'n $.', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'intrinsic dimension',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'high accuracy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'greedy algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'dimensionality reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3191', 'keyword': '$\\\\ reals', 'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'sample set',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'novel method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3191', 'keyword': 'n', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3191', 'keyword': 'linear', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3191', 'keyword': 'set', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3191', 'keyword': 'method', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'using', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'unknown', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'structure', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'storage', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'second', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'logarithmic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'leads', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'k', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'id', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'first', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'estimated', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'estimate', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'develop', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'cases', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'belonging', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'language change',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'efficient inference procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'classical comparative method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'defining probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'based probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'two different schemes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'ancient word forms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'word forms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'schemes using',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'support inferences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'romance languages',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'phylogenetic tree',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'phonological change',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'phoneme sequences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'modern languages',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'linguistic phylogenies',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'language change',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'framework combines',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3196', 'keyword': 'framework', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3196', 'keyword': 'use', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'robustness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3196', 'keyword': 'result', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'represented',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'reconstruction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3196', 'keyword': 'present', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'generalized',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3196', 'keyword': 'explore', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'evaluating',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3196', 'keyword': 'corpus', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'consequences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3196', 'keyword': 'branches', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'advantages',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'topology', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'images', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': '2', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'surprising result presented',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'someone gave us',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'compare different topology',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional topology',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'unknown way',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'strong prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'relative locations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'pixel intensities',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'following question',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'extraction approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'example suppose',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'distributional similarity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional location',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'achieved using',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'thousand pixels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'thousand images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'pixels associated',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'natural images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'relative two',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'approximately recover',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'pixels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3206', 'keyword': 'two', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3206', 'keyword': 'recover', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'yes', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'study', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'something', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'permuted', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'measure', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'learned', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'known', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'fixed', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'exploited', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'exploit', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'examples', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'enough', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'discover', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'could', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'automatically',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'answer', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'stimulus time histograms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'estimating peri',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'spike density function',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'relatively arbitrary fashion',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'peristimulus time historgram',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'generative model approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'usually obtained',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'standard method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'shimazakibinningneco2007 }.',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'recent attempts',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'often done',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'kernel size',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'gaussian kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'exact bayesian',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'even though',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'estimating pshts',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'error bars',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'continuous cousin',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'competing methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'binning spiketrains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'analytic toolkit',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'whereas', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'superiority',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'staples', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'smoothing', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'situation', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'shimazakibinningnips2006',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'selection', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'sdf', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'remedy', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'psth', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'predictions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'neurophysiologists',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'latter', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'former', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'develop', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'demonstate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'cite', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3216', 'keyword': 'bin', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'advantages',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'traditional analysis methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'second order spatial',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'second order methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'phase locked methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'event related potentials',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'brain computer interface',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'benchmark data set',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'e event related',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3236', 'keyword': 'two types', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'temporal features',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'neurological findings',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'bilinear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'best first',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'algorithm learns',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3236', 'keyword': 'ad hoc', 'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'real eeg',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'eeg based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'unified method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'trial classification',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3236', 'keyword': 'e', 'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'eeg',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3236', 'keyword': 'method', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'classification',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'used', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'use', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'synchronization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'single', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'simulated', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'signal', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'process', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'power', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'paradigms', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'paradigm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'interest', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'focus', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'feature', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'encephalography',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'electro', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'efficiency',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'driven', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'demonstrated',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'deciding', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'de', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'amplitude', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'sparse coding model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'learning horizontal connections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'natural images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'primary visual cortex',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'pairwise coupling term',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'coupling terms learn',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'coefficient activity states',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'sparse coding model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'basis function coefficients',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'coefficients results',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'basis functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'thus violating',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'receptive fields',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'physiological experiments',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'natural images',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'maximize sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'independence assumption',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'horizontal connections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'dependencies among',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3237', 'keyword': 'model', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3237', 'keyword': 'function', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'v1', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'statistics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'shown', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'set', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'including', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'implications',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'however', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'findings', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'facilitatory',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'explanation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'discuss', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'dictionary',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'combination',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'capture', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'attempts', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'adapting', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'adapted', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'flexible framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'discriminative',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'diffrac', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'clustering',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'several attractive properties',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'positive definite kernels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'discriminative cost function',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'combinatorial optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'although apparently similar',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'present empirical evaluations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'non linear clustering',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'spectral clustering',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'scale datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'real medium',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'readily extended',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'prior information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'easily incorporated',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'art performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3269', 'keyword': 'present', 'year': '2007'},\n",
       " {'RAKE_score': 2.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'clustering',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'terms', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'synthetic', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'state', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'solved', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'sequence', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'seen', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'robustness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'relies', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'partition', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'particular',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'noise', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'means', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'leading', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'k', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'framework', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'diffrac', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'classification',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'based', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'alternative',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': '3', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': '2', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': '1', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'diffusion processes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'simple gradient techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'parameter inference scheme',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'computationally less demanding',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'variational free energy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'state stochastic processes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'variational treatment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'diffusion processes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'trivial task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'partially observed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'mcmc approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'joint estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'dynamical systems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'current approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'constructed based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3282', 'keyword': 'allows us', 'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'time continuous',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'system noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'forcing parameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'cheap estimate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3282', 'keyword': 'system', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'parameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3282', 'keyword': 'estimate', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'continuous',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'volatility',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'unlike', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'show', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'propose', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'posterior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'nonlinear', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'non', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'multi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'modal', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'general', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'furthermore',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'finally', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'family', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'especially',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'crucial', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'break', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gaussian process models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'transfer learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'link analysis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'transfer learning },',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'efficient learning algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'straightforward gp inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'construct gp priors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'several real',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'link prediction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'intimate connection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'high complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'experimental results',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'bipartite graphs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'model suggests',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.3333333333333335,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gp',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3284', 'keyword': 'model', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'undirected',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3284', 'keyword': 'though', 'year': '2007'},\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RAKE list for both title and abstracts (keywords from length 1 to 3)\n",
    "\n",
    "k_list = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    r = Rake(min_length = 1, max_length = 3)\n",
    "    r.extract_keywords_from_text(doc['title'])\n",
    "    keywords = r.get_ranked_phrases_with_scores()\n",
    "    for word in keywords:\n",
    "        k_list.append({\n",
    "            'doc_id': doc['id'],\n",
    "            'year': doc['year'],\n",
    "            'keyword': word[1],\n",
    "            'RAKE_score': word[0]\n",
    "        })\n",
    "    r.extract_keywords_from_text(doc['abstract'])\n",
    "    keywords = r.get_ranked_phrases_with_scores()\n",
    "    for word in keywords:\n",
    "        k_list.append({\n",
    "            'doc_id': doc['id'],\n",
    "            'year': doc['year'],\n",
    "            'keyword': word[1],\n",
    "            'RAKE_score': word[0]\n",
    "        })\n",
    "        \n",
    "k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176983"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37714"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter the keywords list using significant terms set\n",
    "\n",
    "filtered_list = []\n",
    "\n",
    "for word in k_list:\n",
    "    tokens = word['keyword'].split()\n",
    "    for token in tokens:\n",
    "        if token in unigrams:\n",
    "            filtered_list.append(word)\n",
    "            break\n",
    "            \n",
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RAKE_score': 6.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'positive expected reward',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'reward strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'cooperative strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'class nexp',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3163', 'keyword': 'positive', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3163', 'keyword': 'oracle', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'modeling', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'novel formalization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'general enough',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'better ranking',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3190', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'learning bounds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'domain adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'known learning guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'multiple source domains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'different target domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'source domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'convex combination',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'large amount',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3212', 'keyword': 'domain', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3212', 'keyword': 'large', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'kernel ridge regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'proves novel stability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'several general classes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning algorithm often',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'specific learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'inherent temporal dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning theory',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'general setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'mixing sequence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'identically distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3239', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'assumption',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online pomdps',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'general theorem showing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 6.833333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'provide theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.833333333333334,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'remarkably scalable',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'anytime algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'also practical',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3250', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'logical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'causal inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'binary inputs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'novel noisy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'logical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'multiple', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'multiple instance pruning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'false positive rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'detection rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'training process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'training dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'high accuracy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'complete classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade remains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade earning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade detectors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'active research',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'mip process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'algorithm computes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3265', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'reduction', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3265', 'keyword': 'driven', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'modeling image patches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'fast inference procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'multilayer generative models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'efficient learning procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'generative models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'posterior distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3279', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3279', 'keyword': 'deep', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'high dimensional regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'recovering sparse models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'oracle linear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333332,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparse linear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.466666666666667,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparse data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.3,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3280', 'keyword': 'sparsity', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'poisson feature model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'infinite gamma',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'visual object class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'multiple instances shown',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'unsupervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'multiple occurrences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'latent causes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'factorial learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'prior together',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'latent features',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3309', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'unknown', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3309', 'keyword': 'feature', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'sparsity', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'use bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'extremely sparse distributions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'coding model based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse coding',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse representation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3312', 'keyword': 'sparse', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3312', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'solving linear programs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'optimize average reward',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'constant factor larger',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm recently proposed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm proposed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'require knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'better dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'regret bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3329', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3329', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3335', 'keyword': 'testing', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'asymptotic distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'randomized algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'high probability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'randomized algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'algorithm scales',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3352', 'keyword': 'context', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'nearest neighbor search',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'learning framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'locality sensitive hashing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'leverage learning techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'learning often improves',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'already strong performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'general learning framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structure classes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.666666666666666,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'retrieval data structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.166666666666666,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'novel framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'fast nearest',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3357', 'keyword': 'neighbor', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'probabilistic relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'whole parametric family',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3361', 'keyword': 'implicit', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'manifold learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'handle practical situations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'distributed sensing systems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'perform manifold learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'manifold modeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'underlying manifold',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'high accuracy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'greedy algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'dimensionality reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'novel method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'unknown', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3191', 'keyword': 'structure', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'efficient inference procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'defining probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'based probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'phylogenetic tree',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'robustness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional topology',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'unknown way',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'strong prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional location',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3206', 'keyword': 'measure', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'estimating peri',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'generative model approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'kernel size',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'gaussian kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'exact bayesian',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'estimating pshts',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'algorithm learns',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'unified method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'process', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'feature', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3236', 'keyword': 'driven', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'sparse coding model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'learning horizontal connections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'sparse coding model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'maximize sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'independence assumption',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3237', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'dictionary',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'positive definite kernels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'combinatorial optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'scale datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'prior information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'art performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'robustness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3269', 'keyword': 'noise', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'simple gradient techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'parameter inference scheme',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'state stochastic processes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'trivial task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'mcmc approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'joint estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'dynamical systems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'system noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'posterior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'multi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3282', 'keyword': 'general', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gaussian process models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'transfer learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'link analysis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'transfer learning },',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'efficient learning algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'straightforward gp inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'link prediction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'high complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'weighted matching',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'weighted matching problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'weighted matching problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'general graphs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'distributed fashion',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.75,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'product performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3285', 'keyword': 'tight', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'structured prediction tasks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'single regularization hyperparameter',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'implicit differentiation trick',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'learning regularization hyperparameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'choosing multiple hyperparameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.166666666666666,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'multiple hyperparameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'world task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'efficient gradient',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3286', 'keyword': 'noise', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3286', 'keyword': 'class', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'human data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'graphical model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'multiple feature detectors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'explain human subjects',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'human visual classification',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3289', 'keyword': 'recovery', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3289', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'learning ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'general boosting method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'learning ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'decision trees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3305', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3320', 'keyword': 'low', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'unknown spatiotemporal characteristics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'relatively unknown connection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'dimensional models based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'sequential time points',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'implicit functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'human brain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'dimensionality reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.75,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'fmri dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3320', 'keyword': 'low', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3320', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'relatively large problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'indefinite kernel matrix',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'robust classification problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'problem convex',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'noisy observation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'computing robust counter',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'large extensive games',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'experts algorithm showing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'computing robust counter',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'technique involves solving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'still exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'inferred posterior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'bayesian paradigm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'case performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3347', 'keyword': 'solving', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3347', 'keyword': 'robust', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3347', 'keyword': 'strategy', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised crfs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'scalable training',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3348', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3348', 'keyword': 'fast', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'objective function combines',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'unlabeled sensor traces',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'unlabeled conditional entropy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised training approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'automatic feature selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.166666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised training method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'sveb algorithm reduces',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'feature selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised extension',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'small subset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'parameter learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'parameter estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'large pool',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'algorithm benefits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'efficient semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3348', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3348', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'information bottleneck optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3168', 'keyword': 'pca', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'information bottleneck optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'learning rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3172',\n",
       "  'keyword': 'practical approaches used',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3172',\n",
       "  'keyword': 'sparse matrices',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3172', 'keyword': 'task', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'online learning rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'detecting joint variations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.25,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'solving ica',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'amplitude distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'specified kernel matrices',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333332,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'subspace selection procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.833333333333332,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'iterative subspace selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.333333333333333,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'subspace selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'kernel matrix',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'kernel k',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'favorable performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'convex set',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3176', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3176', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'greedy algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'armed bandits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3178', 'keyword': 'multi', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'standard supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'sample complexity bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'hypothesis class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'armed bandits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3178', 'keyword': 'multi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3178', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3178', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3200',\n",
       "  'keyword': 'tree weights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3200',\n",
       "  'keyword': 'graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3200', 'keyword': 'structure', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3200', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3204', 'keyword': 'inference', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3204',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3204', 'keyword': 'dataset', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3213',\n",
       "  'keyword': 'probabilistic language model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'direct importance estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'covariate shift adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'maximum likelihood estimator',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'high dimensional cases',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'covariate shift adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'since density estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'direct importance estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'weighted according',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'kernel width',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'accurately estimating',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'embedded trees algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'achieving maximum reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'recently developed walk',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'gaussian graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'gaussian estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'larger class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'intractable graph',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'estimation problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'arbitrary structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3275', 'keyword': 'walk', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3275', 'keyword': 'choice', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'random hidden variable',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'achieves better performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'generative procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'spatial structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3278', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3278', 'keyword': 'modeling', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3278', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3278', 'keyword': 'design', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'scale internet diagnosis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'fast variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3292', 'keyword': 'large', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'stochastic gradient descent',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'maintain high reliability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'use bayesian inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'requires inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'inference must',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'fast inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'fast enough',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3292', 'keyword': 'inference', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'symmetric relational data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'stochastic equivalence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'modeling homophily',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'symmetric relational data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'sample predictive performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.333333333333334,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'latent variable model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'latent class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'latent characteristics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'weighted inner',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'practical implications',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'eigenvalue decomposition',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3294', 'keyword': 'inference', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3294', 'keyword': 'context', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'instance selection task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'discriminative classification performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'informative unlabeled instances',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'continuous optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'proposed active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'good classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'target classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'newton method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3295', 'keyword': 'objective', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3295', 'keyword': 'label', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3295', 'keyword': 'guided', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3295', 'keyword': 'convex', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'link swimming robot',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': '14 action dimensions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'robust controllers based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'classic ddp algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'simulated multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'reinforcement learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3297', 'keyword': 'high', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'dimensional',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'two novel kernels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'attribute similarity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'shot annotation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'embedding gives',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3350',\n",
       "  'keyword': 'random sampling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3350',\n",
       "  'keyword': 'random sampling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'pruning large numbers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'promoting sparse solutions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'either prohibitively slow',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'weighted l1 problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'norm sparsity measure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'weight prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'iteratively solving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'feature selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'efficient algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'particular feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3372', 'keyword': 'process', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3372', 'keyword': 'noise', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'efficient principled learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'probabilistic graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'efficient exact inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'arbitrarily large sets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'underlying distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'true distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'polynomial time',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'polynomial number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3164', 'keyword': 'structure', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3164', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3164', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3188', 'keyword': 'lasso', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'variable selection context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'dynamic programming algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'lar algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'white noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3188', 'keyword': 'task', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3195', 'keyword': 'structure', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3195', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3195', 'keyword': 'tree', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'line learning linear',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'learning procedure seems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'improved margin properties',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'new algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'algorithm might',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3209', 'keyword': 'additive', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'greedy algorithm introduced',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'deep generative model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'deep belief net',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.75,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'similar kernel applied',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'use unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.25,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'good covariance kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.25,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'gaussian kernel applied',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.833333333333334,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'unlabeled data using',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.25,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'covariance kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'structured',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3211', 'keyword': 'high', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3211', 'keyword': 'fast', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'dimensional',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'discrete choice data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'active preference learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.6,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'new algorithm compared',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.6,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'algorithm automatically decides',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.6,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'active learning algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'decision making tool',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.6,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'algorithm within',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.6,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'algorithm maximizes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'human psychology',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3219', 'keyword': 'infinite', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'distributed across space',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'dimensional neural measurements',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'distributed response patterns',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'reliably coupled',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'neuronal models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'independent message',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3220', 'keyword': 'subspace', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3220', 'keyword': 'multi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'estimating',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3220', 'keyword': 'bound', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'continuous action',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'greedy action selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'average action values',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'first finite',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.3333333333333335,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'action',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'maximizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3233', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'stochastic gradient descent',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'natural gradient descent',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'large scale problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'natural gradient direction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'descent direction maximizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'large datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'optimization algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'online approximation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3234', 'keyword': 'guided', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3234', 'keyword': 'general', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3234', 'keyword': 'fast', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3234', 'keyword': 'bayesian', 'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'latent dirichlet allocation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.166666666666667,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'latent components',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'learning formulation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'entropic prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'enforce sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3235', 'keyword': 'sparsity', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3235', 'keyword': 'maximum', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'risk minimization principle',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3243', 'keyword': 'class', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'process large datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'ordinal regression tasks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'maximal average margin',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'margin transformation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'optimality principle',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3243', 'keyword': 'design', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3243', 'keyword': 'class', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3263',\n",
       "  'keyword': 'optimal decision rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3263',\n",
       "  'keyword': 'binary classifiers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'human eye fixations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'human saliency',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'surround process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3264', 'keyword': 'decision', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'perform posterior inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'statistical inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'inference problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'practical solution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'parameter estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'large scale learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'underlying optimization algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'scale learning problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'approximate optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3323', 'keyword': 'scale', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3323', 'keyword': 'large', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3323', 'keyword': 'effect', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3323', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'predicting brain states',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'identifying distributed clusters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'stochastic functional measurements',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333332,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'functional neuroimaging data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.666666666666666,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'functional imaging',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'facilitating evaluation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3326', 'keyword': 'domain', 'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'hierarchical bernoulli model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'hierarchical bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'implemented expectation propagation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'unknown function',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'slab prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'mixing weights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'efficient inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3362', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'bilingual topic exploration',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'word alignment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'bilingual topic representation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'topic representations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'parallel sentence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'parallel document',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'novel paradigm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'matching words',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'joint modeling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'coupled via',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'certain semantic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'word alignment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'topical context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3365', 'keyword': 'topic', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3365', 'keyword': 'context', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3365', 'keyword': 'alignment', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'trial error detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'supplementary motor area',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'short window following',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'average recognition rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'positive peak',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3377', 'keyword': 'new human', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'classifier embedded',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3167', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'universal optimization framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'margin cost functionals',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'supervised boosting algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'ensemble learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'decision rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'existing semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3167', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3167', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'novel computational approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'human observers shift',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'human observers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'predictive performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3169', 'keyword': 'low', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3169', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'scale software repositories',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'statistical machine learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'structural information captured',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'scale source code',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.416666666666666,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'topic distributions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'law behavior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'large repositories',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'auc metric',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.75,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'topic scattering',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.75,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'extract topic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.75, 'doc_id': '3171', 'keyword': 'topic', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'approximate inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.0,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'finite sized graph',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'decomposition scheme',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'algorithm works',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3186', 'keyword': 'graph', 'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3186', 'keyword': 'finite', 'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3186', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3186', 'keyword': 'general', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'online linear regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'based reinforcement learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'provably efficient algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'finite state mdps',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'online setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'linear setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'action spaces',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'multiple meteorological phenomena',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'optimal scan strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'using reinforcement learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'markov decision process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'lookahead strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'decision epochs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'average quality',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'maximum radius',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3199', 'keyword': 'decision', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3199', 'keyword': 'making', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'distributed computers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'perform parallel computation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'parallel svm algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'approximate matrix factorization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'factorization ($ p',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'likely human pose',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'inria person dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'small dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'human configuration',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'svm classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'structure learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3210', 'keyword': 'local pca', 'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'oriented gradient',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3210', 'keyword': 'gradient', 'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'bayesian model provides',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.833333333333334,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'cue matching model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'maximum likelihood estimator',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.833333333333334,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'matching models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'matching procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3244', 'keyword': 'maximum', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3244', 'keyword': 'prior', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'suggested action',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'rational players',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'empirical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.8333333333333335,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'regret algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'strategy set',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3249', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'instance active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3252', 'keyword': 'multiple', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'significantly improve performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.666666666666668,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'bag labeled positive',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'actually positive',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.285714285714286,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'instance setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'mi setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.9523809523809526,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'multiple instance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.8333333333333335,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'positive bags',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'two multiple',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'learning problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'multiple',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3252', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'short context units',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 7.5,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'feature selection problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3272', 'keyword': 'topic', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'construction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3272', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'learning task consisting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'training set distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'expectation wrt',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3303', 'keyword': 'algorithm', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'unsupervised learning model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'deep belief networks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'learn hierarchical',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'sparse variant',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'sparse coding',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'prior work',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'hierarchical organization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3313', 'keyword': 'modeling', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3316',\n",
       "  'keyword': 'frequency adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'supervised topic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'separate regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'parameter estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3328', 'keyword': 'maximum', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'estimating disparity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'robust disparity estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'derive feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3334', 'keyword': 'feature', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'robust regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'predictive distribution information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'outlier distribution via',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'latent function values',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'conventional robust methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'general noise models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'robust inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'noise domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'standard process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'mixing weights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'incorporate knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'gating process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'faster inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5, 'doc_id': '3346', 'keyword': 'gp prior', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'attractive graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'tree reparameterization characterization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'attractive binary models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.166666666666666,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'lower bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3354', 'keyword': 'bound', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3354', 'keyword': 'general', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3354', 'keyword': 'class', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'efficient convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'high computation complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'proposed algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'promising performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'unlabeled examples',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3356', 'keyword': 'semi', 'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'sparse feature learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'deep belief networks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'stacking multiple levels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'learn sparse representations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'supervised machine',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'structure hidden',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'low dimension',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'efficient algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3363', 'keyword': 'sparsity', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3363', 'keyword': 'novel', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3363', 'keyword': 'high', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3363', 'keyword': 'dataset', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'distribution family',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'one feature vector',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'feature values',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'feature similarity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'object recognition',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'identically distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3367', 'keyword': 'object', 'year': '2007'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3367', 'keyword': 'knowledge', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3367', 'keyword': 'class', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3368', 'keyword': 'multi', 'year': '2007'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'novel mtl algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'ordinal regression problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'task network',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'task learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'called multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3368', 'keyword': 'solving', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3368', 'keyword': 'convex', 'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'underlying physical process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'recently reported decision',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'preceding decision step',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'extended probabilistic model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'human perception',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'estimation experiment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'estimation bias',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3369', 'keyword': 'inference', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3369', 'keyword': 'context', 'year': '2007'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3370', 'keyword': \"'' cold\", 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3370', 'keyword': 'smooth', 'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3370',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3370', 'keyword': 'case', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3375', 'keyword': 'ranking', 'year': '2007'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'standard performance measure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'ranking problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'maximizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3375', 'keyword': 'learning', 'year': '2007'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3385', 'keyword': 'multi', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'task similarity depends',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'task learning problem',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'either learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3385', 'keyword': 'structure', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3385', 'keyword': 'multi', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'syntactic topic models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'nonparametric bayesian model',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'hierarchical dirichlet processes',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'specific topic weights',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'topic models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'semantic insights',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'parse tree',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'domain adaptation algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'supervised classification task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'domain adaptation methods',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'domain transfer',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'machine learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3407', 'keyword': 'novel', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'level hierarchical models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'posterior mode',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'fast computation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3416', 'keyword': 'multi', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'scale kalman filter',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'response variable organized',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'novel algorithm based',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'online advertising',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'bootstrap strategy',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3416', 'keyword': 'scalable', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3416', 'keyword': 'multi', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': '_2 kernel classification',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'performance analysis',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'give performance guarantees',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'kernel density estimation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.166666666666667,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'kernel classifier',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'regularization parameter',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'oracle inequality',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'sparse classifier',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'classifier',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3430',\n",
       "  'keyword': 'admits efficient optimization',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3430',\n",
       "  'keyword': 'tree structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.75, 'doc_id': '3430', 'keyword': 'link rvs', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3430', 'keyword': 'mcmc', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'online observations',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'homotopy algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3431', 'keyword': 'lasso', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'sequential observations',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'online observations',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'compressed sensing',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'optimization problem',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'efficient algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3431', 'keyword': 'algorithm', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3431', 'keyword': 'sparse', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3431', 'keyword': 'lasso', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'multiclass image segmentation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'including object detection',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 7.333333333333334,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': '3d scene reconstruction',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'object detection',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 5.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': '3d reconstruction',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'improves performance',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'difficult task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'consider learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.5, 'doc_id': '3472', 'keyword': 'large set', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3472', 'keyword': 'coupled', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3472', 'keyword': 'cascade', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'probabilistic inference',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.333333333333334,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'various inference algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'inference procedure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.333333333333334,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'inference problems',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'graphical models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'fast closed',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'extremely fast',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3479', 'keyword': 'algorithm', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'advantage weighted regression',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'unstable learning process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'stable learning process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'smooth policies unsuitable',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'greedy action selection',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'continuous action spaces',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'weighted regression',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'optimization bias',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'unlike standard regression',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'predicting structured outputs',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ohsumed benchmark dataset',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'object scores must',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'multiple pairwise preferences',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'misranking one object',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'cumulative distribution networks',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'listmle probabilistic models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 7.333333333333334,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'graphical modelling framework',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'probabilistic method',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'structure inherent',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'rank using',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'correctly rank',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'broad class',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ranking involves',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.166666666666667,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ranking learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ranking',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3502', 'keyword': 'learning', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3502', 'keyword': 'case', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3508', 'keyword': 'learning', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'human experiments',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'central topic',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'machine learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'general problems',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3508', 'keyword': 'learning', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'margin bounds',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'regularization',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'online learning algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'general notions based',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.25,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'margin bounds',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'unified analysis',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'constant factor',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'dependence',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'neuronal properties',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'functional benefits',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'balanced contributions',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'batch learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3514', 'keyword': 'online', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'scale learning problems',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'batch learning algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.25,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'online learning algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 7.916666666666666,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'original online algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.916666666666666,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'online algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 2.25, 'doc_id': '3514', 'keyword': 'online', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3514', 'keyword': 'making', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3514', 'keyword': 'large', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'transfer learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'distribution matching',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'predicting sociodemographic features',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.75,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'unlabeled samples reflect',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.75,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'large unlabeled samples',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'target distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'learning classifiers',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'joint distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.5,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'given task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.5, 'doc_id': '3515', 'keyword': 'task', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'potentially infinite number',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'new probability distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'combines slice sampling',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'binary markov chains',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'stochastic process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'process extends',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'nonparametric extension',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'inference scheme',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'online models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'content optimization',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'short article lifetimes',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'deserve careful attention',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.666666666666666,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'production online content',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.166666666666666,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'coupling online models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 5.166666666666666,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'online models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'application setting',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'design choices',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'identifying conditional dependencies',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'dynamic bayesian networks',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'stationary process ??',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.25,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'conditional dependence structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'mcmc sampling algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 7.25,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'dbn structure learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.5,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'generation process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.25,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'structure learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0, 'doc_id': '3571', 'keyword': 'new class', 'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'important assumption',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 2.25,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3571', 'keyword': 'learning', 'year': '2008'},\n",
       " {'RAKE_score': 2.0, 'doc_id': '3571', 'keyword': 'algorithm', 'year': '2008'},\n",
       " {'RAKE_score': 1.5,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'assumption',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3574', 'keyword': 'multi', 'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'label correlations encoded',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'induced feature space',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'guaranteed error bound',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 9.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'dimensional space directed',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.5,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'infinite linear program',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 8.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'convex optimization problem',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'smooth min',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'objective function',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'lipschitz gradient',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 4.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'automated annotation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'kernel matrix',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 3.666666666666667,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'kernel matrices',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.6666666666666667,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'kernel',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3574', 'keyword': 'semi', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3574', 'keyword': 'multi', 'year': '2008'},\n",
       " {'RAKE_score': 1.0, 'doc_id': '3574', 'keyword': 'low', 'year': '2008'},\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'RAKE_score': 0.7222222222222222,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'positive expected reward',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'reward strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'cooperative strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'class nexp',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'positive',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3163',\n",
       "  'keyword': 'oracle',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'modeling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'novel formalization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'general enough',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'better ranking',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3190',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'learning bounds',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'domain adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'known learning guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'multiple source domains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'different target domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'source domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'convex combination',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'large amount',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'large',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3212',\n",
       "  'keyword': 'classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'kernel ridge regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'proves novel stability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'several general classes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning algorithm often',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'specific learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'inherent temporal dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'learning theory',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'general setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'mixing sequence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'identically distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'case',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3239',\n",
       "  'keyword': 'assumption',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online pomdps',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'general theorem showing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7592592592592593,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'provide theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5370370370370371,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'remarkably scalable',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'online methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'anytime algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'also practical',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3250',\n",
       "  'keyword': 'exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'logical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'causal inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'binary inputs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'novel noisy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'logical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3259',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'multiple',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'multiple instance pruning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'false positive rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'detection rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'training process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'training dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'high accuracy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'complete classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade remains',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade earning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'cascade detectors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'active research',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'mip process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'algorithm computes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3265',\n",
       "  'keyword': 'driven',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'modeling image patches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'fast inference procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'multilayer generative models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'efficient learning procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'generative models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'posterior distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3279',\n",
       "  'keyword': 'deep',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'high dimensional regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'recovering sparse models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'oracle linear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9259259259259258,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparse linear model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4962962962962963,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparse data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.36666666666666664,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'compressed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3280',\n",
       "  'keyword': 'sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'poisson feature model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'infinite gamma',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'visual object class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'multiple instances shown',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'unsupervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'multiple occurrences',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'latent causes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'factorial learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'prior together',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'latent features',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'unknown',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3309',\n",
       "  'keyword': 'feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'use bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'extremely sparse distributions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'coding model based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse coding',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse representation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'sparse',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3312',\n",
       "  'keyword': 'prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'solving linear programs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'optimize average reward',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'constant factor larger',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm recently proposed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm proposed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'require knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'better dependence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'regret bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3329',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'testing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3335',\n",
       "  'keyword': 'asymptotic distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'randomized algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'high probability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'randomized algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'algorithm scales',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1851851851851852,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3352',\n",
       "  'keyword': 'context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'nearest neighbor search',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'learning framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'locality sensitive hashing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'leverage learning techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'learning often improves',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'already strong performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'general learning framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9074074074074073,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structure classes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8518518518518517,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'retrieval data structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.574074074074074,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'data structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'novel framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'fast nearest',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3357',\n",
       "  'keyword': 'neighbor',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'probabilistic relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'whole parametric family',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3361',\n",
       "  'keyword': 'implicit',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'manifold learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'handle practical situations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'distributed sensing systems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'perform manifold learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9074074074074073,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'manifold modeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5185185185185185,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'underlying manifold',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'high accuracy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'greedy algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'dimensionality reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'novel method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'unknown',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3191',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'efficient inference procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'defining probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'based probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5185185185185185,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'probabilistic approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'phylogenetic tree',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3196',\n",
       "  'keyword': 'robustness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional topology',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'unknown way',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'strong prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'dimensional location',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3206',\n",
       "  'keyword': 'measure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'estimating peri',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'generative model approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'kernel size',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'gaussian kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'exact bayesian',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3216',\n",
       "  'keyword': 'estimating pshts',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'algorithm learns',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'unified method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3236',\n",
       "  'keyword': 'driven',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'sparse coding model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'learning horizontal connections',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'sparse coding model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'maximize sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'independence assumption',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3237',\n",
       "  'keyword': 'dictionary',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'positive definite kernels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'combinatorial optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'scale datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'prior information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'art performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'robustness',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3269',\n",
       "  'keyword': 'noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'simple gradient techniques',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'parameter inference scheme',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'state stochastic processes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'trivial task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'mcmc approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'joint estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'dynamical systems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'system noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'posterior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3282',\n",
       "  'keyword': 'general',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gaussian process models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'transfer learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'link analysis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'transfer learning },',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'efficient learning algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'straightforward gp inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'link prediction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'high complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3284',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'weighted matching',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'weighted matching problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'weighted matching problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'theoretical guarantees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'general graphs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'distributed fashion',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4166666666666667,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'product performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3285',\n",
       "  'keyword': 'tight',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'structured prediction tasks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'single regularization hyperparameter',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'implicit differentiation trick',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'learning regularization hyperparameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9074074074074073,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'choosing multiple hyperparameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.574074074074074,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'multiple hyperparameters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'world task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'efficient gradient',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3286',\n",
       "  'keyword': 'class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'human data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'graphical model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'multiple feature detectors',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'explain human subjects',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'human visual classification',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'recovery',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3289',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'learning ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'general boosting method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'learning ranking functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'decision trees',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3305',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'low',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'unknown spatiotemporal characteristics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'relatively unknown connection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'dimensional models based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'sequential time points',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'implicit functions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'human brain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'dimensionality reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4166666666666667,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'fmri dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'low',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3320',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'relatively large problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'indefinite kernel matrix',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'robust classification problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'problem convex',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'noisy observation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3339',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'computing robust counter',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'large extensive games',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'experts algorithm showing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'computing robust counter',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7777777777777778,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'technique involves solving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'still exploiting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'inferred posterior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'bayesian paradigm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'case performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'solving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'robust',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3347',\n",
       "  'keyword': 'adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised crfs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'scalable training',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'fast',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'objective function combines',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'unlabeled sensor traces',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'unlabeled conditional entropy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9074074074074073,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised training approaches',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'automatic feature selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7962962962962963,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised training method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7777777777777778,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'sveb algorithm reduces',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'feature selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5185185185185185,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5185185185185185,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'supervised extension',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'small subset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'parameter learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'parameter estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'large pool',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'algorithm benefits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'efficient semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3348',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'information bottleneck optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'pca',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'information bottleneck optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3168',\n",
       "  'keyword': 'learning rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3172',\n",
       "  'keyword': 'practical approaches used',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3172',\n",
       "  'keyword': 'sparse matrices',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3172',\n",
       "  'keyword': 'task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'online learning rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'detecting joint variations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4722222222222222,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'solving ica',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3174',\n",
       "  'keyword': 'amplitude distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'specified kernel matrices',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9259259259259258,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'subspace selection procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8703703703703702,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'iterative subspace selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5925925925925926,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'subspace selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'kernel matrix',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'kernel k',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'favorable performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'convex set',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3176',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'greedy algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'armed bandits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'standard supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'sample complexity bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'hypothesis class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'armed bandits',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3178',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3200',\n",
       "  'keyword': 'tree weights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3200',\n",
       "  'keyword': 'graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3200',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3200',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3204',\n",
       "  'keyword': 'inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3204',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3204',\n",
       "  'keyword': 'dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3213',\n",
       "  'keyword': 'probabilistic language model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'direct importance estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'covariate shift adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'maximum likelihood estimator',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'high dimensional cases',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'covariate shift adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'since density estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'direct importance estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'weighted according',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'kernel width',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3248',\n",
       "  'keyword': 'accurately estimating',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'embedded trees algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'achieving maximum reduction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'recently developed walk',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'gaussian graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'gaussian estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'larger class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'intractable graph',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'estimation problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'arbitrary structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'walk',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3275',\n",
       "  'keyword': 'choice',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'random hidden variable',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'achieves better performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'generative procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'spatial structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'modeling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3278',\n",
       "  'keyword': 'design',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'scale internet diagnosis',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'fast variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'large',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'stochastic gradient descent',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'maintain high reliability',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7777777777777778,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'use bayesian inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'requires inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'inference must',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'fast inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'fast enough',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3292',\n",
       "  'keyword': 'inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'symmetric relational data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'stochastic equivalence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'modeling homophily',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'symmetric relational data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'sample predictive performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8148148148148149,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'latent variable model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'latent class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'latent characteristics',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'weighted inner',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'practical implications',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'eigenvalue decomposition',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3294',\n",
       "  'keyword': 'context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'instance selection task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'discriminative classification performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'informative unlabeled instances',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'continuous optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7777777777777778,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'proposed active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'good classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'target classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'newton method',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'objective',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'label',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'guided',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3295',\n",
       "  'keyword': 'convex',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'link swimming robot',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': '14 action dimensions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'robust controllers based',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'classic ddp algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'simulated multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'reinforcement learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'high',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3297',\n",
       "  'keyword': 'dimensional',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'two novel kernels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5185185185185185,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'attribute similarity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'shot annotation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3304',\n",
       "  'keyword': 'embedding gives',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3350',\n",
       "  'keyword': 'random sampling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3350',\n",
       "  'keyword': 'random sampling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'pruning large numbers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'promoting sparse solutions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'either prohibitively slow',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'weighted l1 problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'norm sparsity measure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'weight prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'iteratively solving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'feature selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'efficient algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'particular feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3372',\n",
       "  'keyword': 'noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'efficient principled learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'probabilistic graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'efficient exact inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'arbitrarily large sets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'underlying distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'true distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'polynomial time',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'polynomial number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3164',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'lasso',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'variable selection context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'dynamic programming algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'lar algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'white noise',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'task',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3188',\n",
       "  'keyword': 'estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3195',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3195',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3195',\n",
       "  'keyword': 'tree',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'line learning linear',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'learning procedure seems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'improved margin properties',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'new algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'algorithm might',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3209',\n",
       "  'keyword': 'additive',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'greedy algorithm introduced',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'deep generative model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'deep belief net',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9722222222222222,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'similar kernel applied',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'use unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9166666666666666,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'good covariance kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9166666666666666,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'gaussian kernel applied',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8703703703703705,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'unlabeled data using',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5833333333333334,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'covariance kernel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'structured',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'high',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'fast',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3211',\n",
       "  'keyword': 'dimensional',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'discrete choice data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'active preference learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9555555555555555,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'new algorithm compared',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9555555555555555,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'algorithm automatically decides',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9555555555555555,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'active learning algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'decision making tool',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5111111111111111,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'algorithm within',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5111111111111111,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'algorithm maximizes',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'human psychology',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3219',\n",
       "  'keyword': 'infinite',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'distributed across space',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'dimensional neural measurements',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'distributed response patterns',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'reliably coupled',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'neuronal models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'independent message',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'subspace',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'estimating',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3220',\n",
       "  'keyword': 'bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'continuous action',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'greedy action selection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'average action values',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'first finite',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2592592592592593,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'action',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'maximizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3233',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'stochastic gradient descent',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'natural gradient descent',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'large scale problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'natural gradient direction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'descent direction maximizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'large datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'optimization algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'online approximation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'guided',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'general',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'fast',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3234',\n",
       "  'keyword': 'bayesian',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'latent dirichlet allocation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.462962962962963,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'latent components',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'learning formulation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'entropic prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'enforce sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3235',\n",
       "  'keyword': 'maximum',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'risk minimization principle',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'process large datasets',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'ordinal regression tasks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'maximal average margin',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'margin transformation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'optimality principle',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'design',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3243',\n",
       "  'keyword': 'class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3263',\n",
       "  'keyword': 'optimal decision rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3263',\n",
       "  'keyword': 'binary classifiers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'human eye fixations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'human saliency',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'surround process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3264',\n",
       "  'keyword': 'decision',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'variational inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'perform posterior inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'statistical inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'inference problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'practical solution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'parameter estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3296',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'large scale learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'underlying optimization algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'scale learning problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'learning algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'approximate optimization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'scale',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'large',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'effect',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3323',\n",
       "  'keyword': 'case',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'predicting brain states',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'identifying distributed clusters',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'stochastic functional measurements',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9259259259259258,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'functional neuroimaging data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5185185185185185,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'functional imaging',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'facilitating evaluation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3326',\n",
       "  'keyword': 'domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'hierarchical bernoulli model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'hierarchical bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'implemented expectation propagation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'unknown function',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'slab prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'mixing weights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'efficient inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3362',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'bilingual topic exploration',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'word alignment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'bilingual topic representation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'topic representations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'parallel sentence',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'parallel document',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'novel paradigm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'matching words',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'joint modeling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'coupled via',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'certain semantic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'word alignment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'topical context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'topic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3365',\n",
       "  'keyword': 'alignment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'trial error detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'supplementary motor area',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'short window following',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'average recognition rate',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'positive peak',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'new human',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3377',\n",
       "  'keyword': 'classifier embedded',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'universal optimization framework',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'margin cost functionals',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'supervised boosting algorithms',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'supervised learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'ensemble learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'decision rule',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'existing semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3167',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'novel computational approach',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'human observers shift',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'human observers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'predictive performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'face detection',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'low',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3169',\n",
       "  'keyword': 'case',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'scale software repositories',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'statistical machine learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'structural information captured',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'scale source code',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4907407407407407,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'topic distributions',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'probabilistic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'law behavior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'large repositories',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'auc metric',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4166666666666667,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'topic scattering',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4166666666666667,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'extract topic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.19444444444444445,\n",
       "  'doc_id': '3171',\n",
       "  'keyword': 'topic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'approximate inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.7777777777777778,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'finite sized graph',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'decomposition scheme',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'algorithm works',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'graph',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'finite',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3186',\n",
       "  'keyword': 'general',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'online linear regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'based reinforcement learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'provably efficient algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'finite state mdps',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'online setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'linear setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3197',\n",
       "  'keyword': 'action spaces',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'multiple meteorological phenomena',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'optimal scan strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'using reinforcement learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'markov decision process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'lookahead strategy',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'decision epochs',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'average quality',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'maximum radius',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'decision',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3199',\n",
       "  'keyword': 'making',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'distributed computers',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'perform parallel computation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'parallel svm algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'approximate matrix factorization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3202',\n",
       "  'keyword': 'factorization ($ p',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'likely human pose',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'inria person dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'small dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'human configuration',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'svm classifier',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'structure learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'local pca',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'oriented gradient',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3210',\n",
       "  'keyword': 'gradient',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'bayesian model provides',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8703703703703705,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'cue matching model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'maximum likelihood estimator',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5370370370370371,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'matching models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'matching procedure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'maximum',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3244',\n",
       "  'keyword': 'prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'suggested action',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'rational players',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'empirical distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.42592592592592593,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'regret algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'strategy set',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3249',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'instance active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'multiple',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'significantly improve performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.851851851851852,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'bag labeled positive',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'actually positive',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.47619047619047616,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'instance setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'mi setting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4391534391534392,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'multiple instance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.42592592592592593,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'positive bags',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'two multiple',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'learning problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'active learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1851851851851852,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'multiple',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1851851851851852,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3252',\n",
       "  'keyword': 'case',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'short context units',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8333333333333334,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'feature selection problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'topic',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'construction',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3272',\n",
       "  'keyword': 'case',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'learning task consisting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'training set distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'expectation wrt',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3303',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'unsupervised learning model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'deep belief networks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'learn hierarchical',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'sparse variant',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'sparse coding',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'prior work',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'hierarchical organization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'unlabeled data',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3313',\n",
       "  'keyword': 'modeling',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3316',\n",
       "  'keyword': 'frequency adaptation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'supervised topic models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'separate regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'parameter estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3328',\n",
       "  'keyword': 'maximum',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'estimating disparity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'robust disparity estimation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'derive feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3334',\n",
       "  'keyword': 'feature',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'robust regression',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'predictive distribution information',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'outlier distribution via',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'latent function values',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'conventional robust methods',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'general noise models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'robust inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'noise domain',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'standard process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'mixing weights',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'incorporate knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'gaussian process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'gating process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'faster inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3346',\n",
       "  'keyword': 'gp prior',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'attractive graphical models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'tree reparameterization characterization',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'attractive binary models',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4629629629629629,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'lower bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'bound',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'general',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3354',\n",
       "  'keyword': 'class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'efficient convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'high computation complexity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'proposed algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'promising performance',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'convex relaxation',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'unlabeled examples',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3356',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'sparse feature learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'deep belief networks',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'stacking multiple levels',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'learn sparse representations',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'supervised machine',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'structure hidden',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'low dimension',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'efficient algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'sparsity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'novel',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'high',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3363',\n",
       "  'keyword': 'dataset',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'distribution family',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'one feature vector',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'feature values',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'feature similarity',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'object recognition',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'identically distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'object',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'distributed',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'knowledge',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3367',\n",
       "  'keyword': 'class',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'novel mtl algorithm',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'ordinal regression problems',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'task network',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'task learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'optimization problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'called multi',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'solving',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3368',\n",
       "  'keyword': 'convex',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'bayesian model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'underlying physical process',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'recently reported decision',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'preceding decision step',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'extended probabilistic model',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'human perception',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'estimation experiment',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'estimation bias',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'inference',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3369',\n",
       "  'keyword': 'context',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3370',\n",
       "  'keyword': \"'' cold\",\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3370',\n",
       "  'keyword': 'smooth',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3370',\n",
       "  'keyword': 'predicting',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3370',\n",
       "  'keyword': 'case',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'ranking',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'standard performance measure',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'ranking problem',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'maximizing',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3375',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2007'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'task similarity depends',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'task learning problem',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'either learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3385',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'syntactic topic models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'nonparametric bayesian model',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'hierarchical dirichlet processes',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'specific topic weights',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'topic models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'semantic insights',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'parse tree',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3398',\n",
       "  'keyword': 'distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'domain adaptation algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'supervised classification task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'domain adaptation methods',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'domain transfer',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'machine learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3407',\n",
       "  'keyword': 'novel',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'level hierarchical models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'posterior mode',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'fast computation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'scale kalman filter',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'response variable organized',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'novel algorithm based',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'online advertising',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'bootstrap strategy',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'scalable',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3416',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': '_2 kernel classification',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'performance analysis',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'give performance guarantees',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'kernel density estimation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.462962962962963,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'kernel classifier',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'regularization parameter',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'oracle inequality',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'sparse classifier',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1851851851851852,\n",
       "  'doc_id': '3425',\n",
       "  'keyword': 'classifier',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3430',\n",
       "  'keyword': 'admits efficient optimization',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3430',\n",
       "  'keyword': 'tree structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4166666666666667,\n",
       "  'doc_id': '3430',\n",
       "  'keyword': 'link rvs',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3430',\n",
       "  'keyword': 'mcmc',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'online observations',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'homotopy algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'lasso',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'sequential observations',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'online observations',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'compressed sensing',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'optimization problem',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'efficient algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'sparse',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3431',\n",
       "  'keyword': 'lasso',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'multiclass image segmentation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'including object detection',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8148148148148149,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': '3d scene reconstruction',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'object detection',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5555555555555556,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': '3d reconstruction',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'improves performance',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'difficult task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'consider learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'large set',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'coupled',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3472',\n",
       "  'keyword': 'cascade',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'probabilistic inference',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.925925925925926,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'various inference algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'inference procedure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.48148148148148157,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'inference problems',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'graphical models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'fast closed',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'extremely fast',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3479',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'advantage weighted regression',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'unstable learning process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'stable learning process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'smooth policies unsuitable',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'greedy action selection',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'continuous action spaces',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'weighted regression',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3501',\n",
       "  'keyword': 'optimization bias',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'unlike standard regression',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'predicting structured outputs',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ohsumed benchmark dataset',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'object scores must',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'multiple pairwise preferences',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'misranking one object',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'cumulative distribution networks',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'listmle probabilistic models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8148148148148149,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'graphical modelling framework',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'probabilistic method',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'structure inherent',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'rank using',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'large number',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'correctly rank',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'broad class',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ranking involves',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.35185185185185186,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ranking learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1851851851851852,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'ranking',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3502',\n",
       "  'keyword': 'case',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'human experiments',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'central topic',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'machine learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'general problems',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3508',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'margin bounds',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'regularization',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'online learning algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'general notions based',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4722222222222222,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'margin bounds',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'unified analysis',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3510',\n",
       "  'keyword': 'constant factor',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'dependence',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'neuronal properties',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'functional benefits',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3513',\n",
       "  'keyword': 'balanced contributions',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'batch learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'online',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'scale learning problems',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'batch learning algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9166666666666666,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'online learning algorithms',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8796296296296295,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'original online algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5462962962962963,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'online algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.25, 'doc_id': '3514', 'keyword': 'online', 'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'making',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3514',\n",
       "  'keyword': 'large',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'transfer learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'distribution matching',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'predicting sociodemographic features',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9722222222222222,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'unlabeled samples reflect',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9722222222222222,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'large unlabeled samples',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'target distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'learning classifiers',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'joint distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.3888888888888889,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'given task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3515',\n",
       "  'keyword': 'task',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'potentially infinite number',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'new probability distribution',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'combines slice sampling',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'binary markov chains',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'stochastic process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'process extends',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'nonparametric extension',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3518',\n",
       "  'keyword': 'inference scheme',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'online models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'content optimization',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'short article lifetimes',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'deserve careful attention',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9629629629629629,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'production online content',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9074074074074073,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'coupling online models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.574074074074074,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'online models',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'application setting',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3560',\n",
       "  'keyword': 'design choices',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'identifying conditional dependencies',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'dynamic bayesian networks',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'stationary process ??',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9166666666666666,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'conditional dependence structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'mcmc sampling algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8055555555555556,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'dbn structure learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.5,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'generation process',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4722222222222222,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'structure learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'new class',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'important assumption',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.25,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'structure',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'learning',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.2222222222222222,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'algorithm',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.16666666666666666,\n",
       "  'doc_id': '3571',\n",
       "  'keyword': 'assumption',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'label correlations encoded',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'induced feature space',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'guaranteed error bound',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 1.0,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'dimensional space directed',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.9444444444444444,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'infinite linear program',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.8888888888888888,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'convex optimization problem',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'smooth min',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'objective function',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'lipschitz gradient',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.4444444444444444,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'automated annotation',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'kernel matrix',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.40740740740740744,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'kernel matrices',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1851851851851852,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'kernel',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'semi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'multi',\n",
       "  'year': '2008'},\n",
       " {'RAKE_score': 0.1111111111111111,\n",
       "  'doc_id': '3574',\n",
       "  'keyword': 'low',\n",
       "  'year': '2008'},\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make the score out of 1.0\n",
    "\n",
    "max_score = 0\n",
    "\n",
    "for word in filtered_list:\n",
    "    if word['RAKE_score']>max_score:\n",
    "        max_score = word['RAKE_score']\n",
    "        \n",
    "for word in filtered_list:\n",
    "    word['RAKE_score'] = word['RAKE_score']/max_score\n",
    "    \n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(curr_score, new_score, curr_count):\n",
    "    numerator = curr_score*curr_count + new_score\n",
    "    denominator = curr_count+1\n",
    "    average = numerator/denominator\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a nested dictionary-- keyword: { year: (count, avg_score) }\n",
    "\n",
    "info_1 = {}\n",
    "\n",
    "for word in filtered_list:\n",
    "    if word['keyword'] in info_1:\n",
    "        if word['year'] in info_1[word['keyword']]:\n",
    "            #add count, take average\n",
    "            prev_count = info_1[word['keyword']][word['year']][0]\n",
    "            avg_score = avg(info_1[word['keyword']][word['year']][1], word['RAKE_score'], prev_count)\n",
    "            info_1[word['keyword']][word['year']] = (prev_count+1, avg_score)\n",
    "        else:\n",
    "            info_1[word['keyword']][word['year']] = (1, word['RAKE_score'])\n",
    "    else:\n",
    "        info_1[word['keyword']] = { word['year']: (1, word['RAKE_score']) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimal regret minimization': {'2014': (1, 1.0)},\n",
       " 'memorization task': {'2017': (1, 0.4444444444444444)},\n",
       " 'highly variable indicator': {'2008': (1, 1.0)},\n",
       " 'setting helps': {'2016': (1, 0.4444444444444444)},\n",
       " 'applying functional alignment': {'2017': (1, 0.8888888888888888)},\n",
       " 'graphical gaussian vector': {'2012': (2, 0.9722222222222222)},\n",
       " 'large noise': {'2013': (1, 0.4444444444444444)},\n",
       " 'sample predictive performance': {'2007': (1, 1.0)},\n",
       " 'ranking annotators': {'2011': (1, 0.4444444444444444)},\n",
       " 'probabilistic code': {'2013': (1, 0.5), '2016': (1, 0.4444444444444444)},\n",
       " 'dynamical framework': {'2014': (1, 0.4444444444444444)},\n",
       " 'spatiotemporal modeling': {'2016': (1, 0.4444444444444444)},\n",
       " 'conditional convolutional connections': {'2015': (1, 1.0)},\n",
       " 'performance benefits': {'2009': (1, 0.4444444444444444)},\n",
       " 'rice distribution': {'2013': (1, 0.4444444444444444)},\n",
       " 'parametric mapping': {'2015': (1, 0.4166666666666667)},\n",
       " 'large images': {'2009': (1, 0.5), '2014': (2, 0.4722222222222222)},\n",
       " 'proven structured mean': {'2016': (1, 1.0)},\n",
       " 'joint distributions': {'2008': (2, 0.4444444444444444),\n",
       "  '2013': (2, 0.5),\n",
       "  '2017': (1, 0.48148148148148157)},\n",
       " 'object detection methods': {'2014': (1, 1.0)},\n",
       " 'establish finite identification': {'2016': (1, 1.0)},\n",
       " 'extreme multi': {'2015': (2, 0.4444444444444444)},\n",
       " 'analysis dictionary jointly': {'2014': (1, 0.9629629629629629)},\n",
       " 'music modeling': {'2017': (1, 0.4444444444444444)},\n",
       " 'dynamical isometry': {'2017': (2, 0.49074074074074076)},\n",
       " 'smooth submanifold': {'2016': (1, 0.4444444444444444)},\n",
       " 'dual hybrid gradient': {'2015': (1, 1.0)},\n",
       " 'general however': {'2016': (1, 0.4444444444444444)},\n",
       " 'operator objective': {'2016': (1, 0.48148148148148157)},\n",
       " 'novel set': {'2013': (1, 0.3888888888888889)},\n",
       " 'convex polytope arising': {'2014': (1, 0.9444444444444444)},\n",
       " 'convex learning tasks': {'2017': (1, 0.9629629629629629)},\n",
       " 'regret bound scales': {'2011': (1, 0.9259259259259258),\n",
       "  '2017': (1, 0.9074074074074073)},\n",
       " 'computationally efficient low': {'2017': (1, 0.8888888888888888)},\n",
       " 'online convex optimization': {'2009': (1, 1.0),\n",
       "  '2010': (1, 0.9444444444444444),\n",
       "  '2012': (1, 1.0),\n",
       "  '2014': (1, 0.9444444444444444),\n",
       "  '2016': (3, 0.9925925925925926),\n",
       "  '2017': (1, 1.0)},\n",
       " 'specified task': {'2016': (1, 0.3888888888888889)},\n",
       " 'kernel online learning': {'2016': (1, 0.8888888888888888)},\n",
       " 'iteratively reweighted gradient': {'2017': (1, 1.0)},\n",
       " 'machine translation task': {'2008': (1, 0.925925925925926),\n",
       "  '2016': (1, 0.8888888888888888)},\n",
       " 'uncertain measurement': {'2017': (1, 0.4444444444444444)},\n",
       " 'tractable learning rule': {'2011': (1, 0.8888888888888888)},\n",
       " 'human faces': {'2012': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444)},\n",
       " 'group sparsity regularizer': {'2016': (1, 0.8888888888888888)},\n",
       " 'multiple variational parameters': {'2015': (1, 0.925925925925926)},\n",
       " 'regularized estimation': {'2010': (1, 0.4444444444444444)},\n",
       " 'finite time analysis': {'2011': (1, 1.0)},\n",
       " 'algorithm large amount': {'2011': (1, 0.8888888888888888)},\n",
       " 'proposal distribution': {'2014': (1, 0.4444444444444444),\n",
       "  '2015': (2, 0.44907407407407407)},\n",
       " 'estimation variance': {'2016': (1, 0.5555555555555556)},\n",
       " 'homogeneity testing': {'2012': (1, 0.4444444444444444)},\n",
       " 'expectation propagation offers': {'2013': (1, 1.0)},\n",
       " 'kernel functions based': {'2017': (1, 1.0)},\n",
       " 'making inference challenging': {'2008': (1, 0.8888888888888888)},\n",
       " 'dependent probability distribution': {'2016': (1, 1.0)},\n",
       " 'nonparametric generalization': {'2015': (1, 0.4444444444444444)},\n",
       " 'choice': {'2007': (1, 0.1111111111111111),\n",
       "  '2008': (2, 0.1111111111111111),\n",
       "  '2009': (3, 0.1111111111111111),\n",
       "  '2010': (4, 0.1111111111111111),\n",
       "  '2011': (4, 0.12499999999999999),\n",
       "  '2012': (7, 0.11111111111111113),\n",
       "  '2013': (3, 0.1111111111111111),\n",
       "  '2014': (7, 0.11904761904761904),\n",
       "  '2015': (11, 0.11111111111111115),\n",
       "  '2016': (1, 0.1111111111111111),\n",
       "  '2017': (12, 0.1203703703703704)},\n",
       " 'submodular function': {'2010': (1, 0.5111111111111111),\n",
       "  '2013': (1, 0.5),\n",
       "  '2015': (2, 0.462962962962963),\n",
       "  '2016': (2, 0.4537037037037037),\n",
       "  '2017': (4, 0.43518518518518523)},\n",
       " 'evaluation data': {'2017': (1, 0.42592592592592593)},\n",
       " 'propagate label information': {'2009': (1, 0.9074074074074073)},\n",
       " 'counting matching walks': {'2015': (1, 0.8888888888888888)},\n",
       " 'imposing metric constraints': {'2009': (1, 0.9166666666666666)},\n",
       " 'nonequilibrium observation data': {'2016': (1, 0.9629629629629629)},\n",
       " 'statistical modeling': {'2009': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.3888888888888889)},\n",
       " 'dimensional noisy data': {'2015': (1, 0.9444444444444444)},\n",
       " 'negative objective': {'2010': (1, 0.4444444444444444)},\n",
       " 'unknown data hierarchies': {'2010': (1, 0.8888888888888888)},\n",
       " 'attain low regret': {'2015': (1, 1.0)},\n",
       " 'max inference': {'2017': (1, 0.48148148148148157)},\n",
       " 'active set method': {'2008': (1, 1.0)},\n",
       " 'also learn interpretable': {'2017': (1, 1.0)},\n",
       " 'acquire human responses': {'2015': (1, 0.9166666666666666)},\n",
       " 'tensor': {'2009': (1, 0.1111111111111111),\n",
       "  '2013': (3, 0.15432098765432098),\n",
       "  '2014': (1, 0.2222222222222222),\n",
       "  '2015': (2, 0.2222222222222222),\n",
       "  '2016': (2, 0.20833333333333331),\n",
       "  '2017': (2, 0.16666666666666666)},\n",
       " 'detecting multi': {'2016': (1, 0.4166666666666667)},\n",
       " 'indirect observation': {'2010': (1, 0.4444444444444444)},\n",
       " 'sequential icm': {'2009': (1, 0.40740740740740744)},\n",
       " 'particular topic': {'2016': (1, 0.4444444444444444)},\n",
       " 'world task': {'2007': (1, 0.4444444444444444)},\n",
       " 'hierarchical bayesian models': {'2014': (1, 1.0), '2016': (1, 1.0)},\n",
       " 'output noise': {'2008': (1, 0.4444444444444444)},\n",
       " 'gradient using': {'2017': (1, 0.3888888888888889)},\n",
       " 'function class': {'2013': (1, 0.48148148148148157),\n",
       "  '2014': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4722222222222222)},\n",
       " 'present task': {'2009': (1, 0.3333333333333333)},\n",
       " 'hierarchical language model': {'2008': (1, 0.925925925925926)},\n",
       " 'incoherent subspace': {'2015': (1, 0.4444444444444444)},\n",
       " 'arbitrary spatial structure': {'2013': (1, 0.9444444444444444)},\n",
       " 'optimization domains .\"': {'2008': (1, 0.9722222222222222)},\n",
       " 'tree nodes using': {'2014': (1, 0.925925925925926)},\n",
       " 'full binary tree': {'2011': (1, 0.911111111111111)},\n",
       " '$- dimensional grid': {'2016': (1, 1.0)},\n",
       " 'correlated topic models': {'2017': (1, 0.9629629629629629)},\n",
       " 'underlying cluster structure': {'2016': (1, 1.0)},\n",
       " 'full kernel svm': {'2014': (1, 0.8777777777777778)},\n",
       " 'weak performance guarantees': {'2011': (1, 1.0)},\n",
       " 'gradient vanishing': {'2016': (1, 0.4444444444444444)},\n",
       " 'distributionally robust approach': {'2015': (1, 1.0)},\n",
       " 'globally geometric rate': {'2010': (1, 1.0)},\n",
       " 'mcmc often suffers': {'2015': (1, 0.8611111111111112)},\n",
       " 'based decision criteria': {'2012': (1, 1.0)},\n",
       " 'examine threshold learning': {'2016': (1, 0.8888888888888888)},\n",
       " 'structured graphs': {'2010': (1, 0.3333333333333333),\n",
       "  '2013': (1, 0.4444444444444444)},\n",
       " 'matrix decomposition': {'2010': (1, 0.5),\n",
       "  '2012': (1, 0.5),\n",
       "  '2014': (2, 0.5092592592592592)},\n",
       " '$- mixing processes': {'2009': (1, 0.8888888888888888)},\n",
       " 'novel extension': {'2010': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.5),\n",
       "  '2015': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'good practical performance': {'2014': (1, 0.8888888888888888)},\n",
       " 'performance measures': {'2014': (2, 0.45833333333333337),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'promote sparsity': {'2009': (2, 0.3888888888888889),\n",
       "  '2012': (1, 0.4444444444444444)},\n",
       " 'testing procedure': {'2017': (1, 0.4444444444444444)},\n",
       " 'existing convex relaxation': {'2011': (1, 0.8962962962962963)},\n",
       " 'hastings algorithm': {'2012': (1, 0.4444444444444444), '2013': (1, 0.5)},\n",
       " 'optimistic mirror descent': {'2013': (1, 0.8888888888888888)},\n",
       " 'online prediction problem': {'2017': (1, 0.8888888888888888)},\n",
       " 'densely convolutional network': {'2017': (1, 1.0)},\n",
       " 'dimensional problems take': {'2014': (1, 1.0)},\n",
       " 'important learning task': {'2013': (1, 1.0)},\n",
       " 'structured outputs': {'2008': (1, 0.5555555555555556),\n",
       "  '2011': (1, 0.5185185185185185)},\n",
       " 'dataset size increases': {'2016': (1, 1.0)},\n",
       " 'learning linear models': {'2012': (1, 0.9444444444444444)},\n",
       " 'true pca dimensionality': {'2012': (1, 0.8888888888888888)},\n",
       " 'approximate posterior approaches': {'2017': (1, 0.9444444444444444)},\n",
       " 'unmanageably large dimension': {'2017': (1, 1.0)},\n",
       " 'efficient map inference': {'2009': (1, 1.0)},\n",
       " 'hierarchical filtering stage': {'2008': (1, 0.8888888888888888)},\n",
       " 'motion contrast detection': {'2009': (1, 0.8037037037037038)},\n",
       " 'short article lifetimes': {'2008': (1, 1.0)},\n",
       " 'ratios minimization problem': {'2014': (1, 0.9444444444444444)},\n",
       " 'feature representations trained': {'2009': (1, 1.0)},\n",
       " 'large board': {'2013': (1, 0.3888888888888889)},\n",
       " 'task specification': {'2015': (1, 0.3888888888888889)},\n",
       " 'novel kernel': {'2010': (2, 0.41666666666666663),\n",
       "  '2016': (1, 0.4166666666666667)},\n",
       " 'test domain': {'2014': (1, 0.40740740740740744)},\n",
       " 'users path preferences': {'2017': (1, 0.8888888888888888)},\n",
       " 'causal sufficiency assumption': {'2008': (1, 0.9629629629629629)},\n",
       " 'worst case runtimes': {'2009': (1, 0.9444444444444444)},\n",
       " 'distributed framework': {'2013': (1, 0.5)},\n",
       " 'latter case': {'2010': (1, 0.4444444444444444)},\n",
       " 'polynomial time class': {'2010': (1, 0.8888888888888888)},\n",
       " 'large running': {'2016': (1, 0.4444444444444444)},\n",
       " 'extremehunter algorithm': {'2014': (1, 0.4444444444444444)},\n",
       " 'conjugate gradient algorithm': {'2010': (1, 1.0)},\n",
       " 'multiple responses ),': {'2015': (1, 0.9444444444444444)},\n",
       " 'latent bayesian melding': {'2015': (1, 1.0)},\n",
       " 'traditional convolutional layer': {'2016': (1, 1.0)},\n",
       " 'general polytopes': {'2014': (1, 0.40740740740740744),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'covariance kernel': {'2007': (1, 0.5833333333333334), '2015': (1, 0.5)},\n",
       " 'fixed aggregation function': {'2015': (1, 0.9444444444444444)},\n",
       " 'sentence ranking': {'2015': (1, 0.5)},\n",
       " 'collapsed variational bayesian': {'2009': (1, 1.0)},\n",
       " 'viz lasso': {'2015': (1, 0.40740740740740744)},\n",
       " 'extend submodularity guarantees': {'2013': (1, 1.0)},\n",
       " 'parameter transfer approach': {'2016': (1, 0.9333333333333333)},\n",
       " 'submodular welfare problem': {'2015': (1, 0.8888888888888888)},\n",
       " 'line learning algorithm': {'2008': (1, 0.925925925925926), '2012': (1, 1.0)},\n",
       " 'deep identification': {'2014': (1, 0.4444444444444444)},\n",
       " 'regularization parameters': {'2015': (1, 0.5)},\n",
       " 'inconsistent human feedback': {'2013': (1, 0.9351851851851851)},\n",
       " 'perform multiclass labeling': {'2017': (1, 0.8888888888888888)},\n",
       " 'proposed algorithm considers': {'2012': (1, 1.0)},\n",
       " 'obtain excellent performance': {'2011': (1, 1.0)},\n",
       " 'initial goal distribution': {'2010': (1, 0.8888888888888888)},\n",
       " 'return value': {'2015': (1, 0.4444444444444444)},\n",
       " 'approximate kernel machines': {'2016': (1, 0.8888888888888888)},\n",
       " 'parallel coordinates': {'2012': (1, 0.4444444444444444)},\n",
       " 'newton approximations': {'2011': (1, 0.4444444444444444)},\n",
       " 'coded distributed computing': {'2017': (1, 1.0)},\n",
       " 'metric learning loss': {'2017': (1, 0.8888888888888888)},\n",
       " 'following favorable guarantees': {'2015': (1, 1.0)},\n",
       " 'point processes modeling': {'2017': (1, 0.7962962962962963)},\n",
       " 'goal distribution': {'2010': (1, 0.5555555555555556)},\n",
       " 'average bayes error': {'2012': (1, 0.8888888888888888)},\n",
       " 'different dataset': {'2012': (1, 0.4444444444444444)},\n",
       " 'topic simplex': {'2017': (1, 0.4444444444444444)},\n",
       " 'optimize using monte': {'2017': (1, 1.0)},\n",
       " 'general black': {'2015': (1, 0.4444444444444444)},\n",
       " 'greedy algorithm introduced': {'2007': (1, 1.0)},\n",
       " 'effective tree': {'2016': (1, 0.3888888888888889)},\n",
       " 'spike inference': {'2017': (1, 0.5092592592592593)},\n",
       " 'fully probabilistic nature': {'2011': (1, 0.9444444444444444)},\n",
       " 'exploit contextual information': {'2012': (1, 0.925925925925926)},\n",
       " 'defined kernel': {'2016': (1, 0.4444444444444444)},\n",
       " 'structural relaxations': {'2009': (1, 0.4444444444444444)},\n",
       " 'practical convergence issues': {'2016': (1, 1.0)},\n",
       " 'approximate joint diagonalization': {'2017': (1, 1.0)},\n",
       " 'tensor power iter': {'2015': (1, 0.925925925925926)},\n",
       " 'sampling methods': {'2008': (1, 0.4444444444444444),\n",
       "  '2011': (1, 0.3888888888888889)},\n",
       " 'transition structure': {'2008': (1, 0.4444444444444444)},\n",
       " 'motor imagery': {'2008': (2, 0.4444444444444444)},\n",
       " 'low generalization error': {'2010': (1, 1.0)},\n",
       " 'topic smoothness': {'2009': (1, 0.3888888888888889)},\n",
       " 'positive bag': {'2010': (1, 0.48148148148148157)},\n",
       " 'law decay': {'2009': (1, 0.5)},\n",
       " 'exploiting high': {'2017': (1, 0.4444444444444444)},\n",
       " 'different class': {'2016': (1, 0.3888888888888889)},\n",
       " 'fast parallel algorithms': {'2011': (1, 0.9333333333333333)},\n",
       " 'local objective functions': {'2015': (1, 0.9444444444444444)},\n",
       " 'fulfilling performance': {'2016': (1, 0.4444444444444444)},\n",
       " 'querying process': {'2012': (1, 0.4444444444444444)},\n",
       " 'based structural representations': {'2014': (1, 1.0)},\n",
       " 'binary value': {'2017': (1, 0.4444444444444444)},\n",
       " 'product performance': {'2007': (1, 0.4166666666666667)},\n",
       " 'online learning algorithms': {'2008': (2, 0.9583333333333333),\n",
       "  '2009': (2, 0.9444444444444444),\n",
       "  '2012': (1, 0.9777777777777779),\n",
       "  '2016': (1, 1.0)},\n",
       " 'optimal transport metric': {'2015': (1, 1.0)},\n",
       " 'particle cascade provides': {'2014': (1, 0.9074074074074073)},\n",
       " 'approximate algorithm': {'2011': (1, 0.3888888888888889),\n",
       "  '2013': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'scale space perspective': {'2014': (1, 0.9629629629629629)},\n",
       " 'additive model': {'2009': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.3888888888888889),\n",
       "  '2017': (2, 0.4444444444444444)},\n",
       " 'mcmc outperforms': {'2016': (1, 0.4444444444444444)},\n",
       " 'scale public datasets': {'2017': (1, 0.925925925925926)},\n",
       " 'spectral learning methods': {'2012': (1, 1.0), '2013': (2, 0.875)},\n",
       " 'determinant optimization problem': {'2014': (1, 0.8888888888888888)},\n",
       " 'common feature': {'2012': (1, 0.4444444444444444)},\n",
       " 'transfer framework': {'2017': (1, 0.5)},\n",
       " 'sparse bayesian learning': {'2009': (1, 0.9722222222222222),\n",
       "  '2013': (1, 0.9444444444444444)},\n",
       " 'factorization x': {'2017': (1, 0.40740740740740744)},\n",
       " 'fast variational inference': {'2007': (1, 1.0), '2012': (1, 1.0)},\n",
       " 'learning visual classifiers': {'2010': (1, 0.9444444444444444)},\n",
       " 'decomposes structured objects': {'2016': (1, 0.9444444444444444)},\n",
       " 'resulting objective function': {'2010': (1, 1.0)},\n",
       " 'structure regularization': {'2014': (2, 0.462962962962963)},\n",
       " 'kernel attains': {'2009': (1, 0.40740740740740744)},\n",
       " 'task correlation': {'2012': (1, 0.48148148148148157)},\n",
       " 'rapid path planning': {'2015': (2, 1.0)},\n",
       " 'defining kernel functions': {'2017': (1, 0.75)},\n",
       " 'e ., identifying': {'2012': (1, 1.0)},\n",
       " 'bpc measure': {'2017': (1, 0.48148148148148157)},\n",
       " 'algorithmic task': {'2017': (1, 0.4444444444444444)},\n",
       " 'action sequence': {'2017': (1, 0.4444444444444444)},\n",
       " 'time intensive process': {'2014': (1, 0.8888888888888888)},\n",
       " 'kernel tests based': {'2014': (1, 1.0)},\n",
       " 'univariate optimization objective': {'2015': (1, 0.925925925925926)},\n",
       " 'dimensional perturbation': {'2013': (1, 0.4444444444444444)},\n",
       " 'dependent sparsity penalty': {'2011': (1, 1.0)},\n",
       " 'dependence model': {'2008': (1, 0.3888888888888889)},\n",
       " 'multiple time': {'2014': (1, 0.4444444444444444)},\n",
       " 'target observation': {'2017': (1, 0.4444444444444444)},\n",
       " 'learning image descriptors': {'2012': (1, 1.0)},\n",
       " 'conditional mixture distribution': {'2017': (1, 1.0)},\n",
       " 'learning simultaneously': {'2017': (1, 0.3888888888888889)},\n",
       " 'limiting case': {'2011': (1, 0.4444444444444444)},\n",
       " 'group identification': {'2010': (1, 0.4444444444444444)},\n",
       " 'since probabilistic computations': {'2009': (1, 1.0)},\n",
       " 'geometric random walk': {'2013': (1, 1.0)},\n",
       " 'private counterparts': {'2015': (1, 0.4444444444444444)},\n",
       " 'smooth rotation': {'2008': (1, 0.40740740740740744)},\n",
       " 'probabilistic polynomial': {'2016': (1, 0.4444444444444444)},\n",
       " 'incorporating invariance information': {'2013': (1, 1.0)},\n",
       " 'agent sequential decision': {'2014': (1, 1.0)},\n",
       " 'remove sparse outliers': {'2016': (1, 1.0)},\n",
       " 'aggregation functions': {'2015': (1, 0.5)},\n",
       " 'optimal learning rates': {'2010': (1, 1.0), '2011': (1, 1.0)},\n",
       " 'model reduction': {'2017': (1, 0.48888888888888893)},\n",
       " 'given finite amounts': {'2014': (1, 1.0)},\n",
       " 'polyhedral structure': {'2016': (1, 0.5)},\n",
       " 'exactly solving decision': {'2011': (1, 1.0)},\n",
       " 'fast training': {'2014': (1, 0.4444444444444444)},\n",
       " 'case view': {'2010': (1, 0.4444444444444444)},\n",
       " 'true structure': {'2012': (1, 0.5)},\n",
       " 'choice must': {'2016': (1, 0.4444444444444444)},\n",
       " 'myopic trading agent': {'2015': (1, 0.8611111111111112)},\n",
       " 'novel characterization': {'2013': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'new minimization formulation': {'2010': (1, 0.8888888888888888)},\n",
       " 'learn probabilistic models': {'2015': (1, 1.0)},\n",
       " 'streaming clustering algorithm': {'2009': (1, 0.8796296296296295)},\n",
       " 'iterative algorithm': {'2012': (1, 0.48148148148148157),\n",
       "  '2014': (2, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'shot regression': {'2017': (1, 0.5185185185185185)},\n",
       " 'rank approximation': {'2009': (1, 0.5),\n",
       "  '2011': (1, 0.4444444444444444),\n",
       "  '2014': (2, 0.41666666666666663),\n",
       "  '2015': (1, 0.5555555555555556),\n",
       "  '2017': (3, 0.49382716049382713)},\n",
       " 'constrained maximum likelihood': {'2008': (1, 0.8888888888888888)},\n",
       " 'adversarial input': {'2016': (1, 0.4444444444444444)},\n",
       " 'separate feature analysis': {'2017': (1, 1.0)},\n",
       " 'proposed inference method': {'2010': (1, 0.9629629629629629)},\n",
       " 'fast connections learn': {'2015': (1, 0.8055555555555556)},\n",
       " 'dynamical model': {'2012': (1, 0.5), '2014': (1, 0.4444444444444444)},\n",
       " 'remarkable feature': {'2009': (1, 0.4444444444444444)},\n",
       " 'alternately sampling': {'2012': (1, 0.4444444444444444)},\n",
       " 'whereas regularization': {'2013': (1, 0.4444444444444444)},\n",
       " 'world interaction learning': {'2016': (1, 0.8148148148148149)},\n",
       " 'convex geometry': {'2016': (1, 0.4444444444444444)},\n",
       " 'sparse data instead': {'2012': (1, 1.0)},\n",
       " 'first approach guarantees': {'2014': (1, 1.0)},\n",
       " 'certain general conditions': {'2013': (1, 1.0)},\n",
       " 'standard regression': {'2016': (1, 0.4444444444444444)},\n",
       " 'testing phase': {'2014': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'arbitrary graph structure': {'2010': (1, 1.0)},\n",
       " 'distortion measure': {'2016': (1, 0.40740740740740744)},\n",
       " 'case assumption': {'2015': (1, 0.4444444444444444)},\n",
       " 'statistical estimation procedures': {'2012': (1, 0.9444444444444444)},\n",
       " 'flexible variational inference': {'2016': (1, 0.9444444444444444)},\n",
       " 'minimization algorithms consist': {'2013': (1, 0.9444444444444444)},\n",
       " 'constrained optimization problems': {'2008': (1, 0.8981481481481483),\n",
       "  '2010': (1, 0.925925925925926)},\n",
       " 'robust': {'2007': (1, 0.2222222222222222),\n",
       "  '2008': (4, 0.1111111111111111),\n",
       "  '2009': (3, 0.1111111111111111),\n",
       "  '2010': (3, 0.14814814814814814),\n",
       "  '2011': (4, 0.1111111111111111),\n",
       "  '2012': (5, 0.1222222222222222),\n",
       "  '2013': (8, 0.13888888888888892),\n",
       "  '2014': (10, 0.11111111111111113),\n",
       "  '2015': (11, 0.13973063973063973),\n",
       "  '2016': (7, 0.15079365079365079),\n",
       "  '2017': (22, 0.11616161616161619)},\n",
       " 'listwise ranking methods': {'2009': (1, 0.8074074074074074)},\n",
       " 'natural sparsity assumption': {'2015': (1, 0.8888888888888888)},\n",
       " 'optimal estimation': {'2009': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444)},\n",
       " 'standard generative approaches': {'2016': (1, 0.9444444444444444)},\n",
       " 'rank tensor': {'2014': (2, 0.49444444444444446),\n",
       "  '2015': (2, 0.4722222222222222),\n",
       "  '2017': (2, 0.41666666666666663)},\n",
       " 'wolfe optimization algorithm': {'2015': (1, 0.7222222222222222)},\n",
       " 'exact probabilistic method': {'2016': (1, 0.9444444444444444)},\n",
       " 'improved margin properties': {'2007': (1, 1.0)},\n",
       " 'adaptive sampling called': {'2016': (1, 0.9206349206349205)},\n",
       " 'optimization despite': {'2016': (1, 0.4444444444444444)},\n",
       " 'generates 3d objects': {'2016': (1, 0.9246031746031745)},\n",
       " 'transfer learning': {'2007': (1, 0.4444444444444444),\n",
       "  '2008': (2, 0.4444444444444444),\n",
       "  '2009': (1, 0.5),\n",
       "  '2011': (1, 0.5),\n",
       "  '2012': (2, 0.4722222222222222),\n",
       "  '2013': (2, 0.4444444444444444),\n",
       "  '2014': (1, 0.5370370370370371),\n",
       "  '2016': (1, 0.4444444444444444),\n",
       "  '2017': (2, 0.4722222222222222)},\n",
       " 'adjusted inference': {'2010': (1, 0.4444444444444444)},\n",
       " 'prior information': {'2007': (1, 0.4444444444444444),\n",
       "  '2010': (2, 0.462962962962963),\n",
       "  '2012': (1, 0.4444444444444444),\n",
       "  '2014': (4, 0.4537037037037037),\n",
       "  '2016': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'lasso .\"': {'2013': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'observation sequence': {'2017': (1, 0.40740740740740744)},\n",
       " 'large overestimations': {'2010': (1, 0.4444444444444444)},\n",
       " 'performance approaching': {'2016': (1, 0.4444444444444444)},\n",
       " 'learning high': {'2010': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.3888888888888889),\n",
       "  '2013': (2, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'nonparametric regression': {'2008': (2, 0.45555555555555555),\n",
       "  '2009': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'conjugate posterior': {'2009': (1, 0.48148148148148157)},\n",
       " 'particular dataset': {'2014': (1, 0.4444444444444444)},\n",
       " 'kernel pca': {'2015': (1, 0.4444444444444444)},\n",
       " 'linear domain adaptation': {'2013': (1, 1.0)},\n",
       " 'choice tasks': {'2012': (1, 0.4444444444444444), '2016': (1, 0.5)},\n",
       " 'supervised problems': {'2010': (2, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'asymptotic distribution': {'2007': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'nonlinear deep networks': {'2017': (1, 0.8407407407407407)},\n",
       " 'matching algorithm': {'2013': (1, 0.4444444444444444)},\n",
       " 'deep steganography': {'2017': (1, 0.4444444444444444)},\n",
       " 'simple decomposition algorithm': {'2016': (1, 0.925925925925926)},\n",
       " 'microscopy dataset': {'2016': (1, 0.4444444444444444)},\n",
       " 'additional algorithm': {'2008': (1, 0.4444444444444444)},\n",
       " 'algorithm starts': {'2012': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'different action': {'2014': (1, 0.4444444444444444)},\n",
       " 'motivated learning': {'2015': (1, 0.4666666666666667)},\n",
       " 'probabilistic approach': {'2007': (3, 0.46913580246913583),\n",
       "  '2012': (1, 0.4444444444444444),\n",
       "  '2013': (1, 0.4444444444444444)},\n",
       " 'gradient method achieve': {'2011': (1, 0.8333333333333334)},\n",
       " 'imagenet dataset': {'2015': (1, 0.4444444444444444)},\n",
       " 'restricted matrix regression': {'2017': (1, 0.9444444444444444)},\n",
       " 'data generating process': {'2013': (1, 0.911111111111111), '2015': (1, 1.0)},\n",
       " 'special class': {'2015': (1, 0.3888888888888889)},\n",
       " 'scalable planning': {'2017': (1, 0.4444444444444444)},\n",
       " 'probabilistic beliefs': {'2015': (1, 0.4444444444444444)},\n",
       " 'spectral graph theory': {'2011': (1, 1.0),\n",
       "  '2016': (1, 0.9444444444444444),\n",
       "  '2017': (1, 1.0)},\n",
       " 'dynamical processes underlying': {'2011': (1, 0.8888888888888888)},\n",
       " 'bayesian non': {'2012': (2, 0.4722222222222222),\n",
       "  '2014': (1, 0.3888888888888889)},\n",
       " 'natural language modeling': {'2017': (1, 0.9444444444444444)},\n",
       " 'sparse structures': {'2015': (1, 0.4666666666666667)},\n",
       " 'structural assumptions': {'2013': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'novel hedging strategy': {'2013': (1, 0.9722222222222222)},\n",
       " 'either geometric': {'2016': (1, 0.4444444444444444)},\n",
       " 'leverages ancestor sampling': {'2015': (1, 1.0)},\n",
       " 'structure optimization': {'2015': (1, 0.4444444444444444)},\n",
       " 'underlying graph increases': {'2010': (1, 0.8888888888888888)},\n",
       " 'linear rank process': {'2008': (1, 1.0)},\n",
       " 'gradient increases significantly': {'2017': (1, 0.925925925925926)},\n",
       " 'obtaining estimation procedures': {'2015': (1, 0.9444444444444444)},\n",
       " 'proposed approach guarantees': {'2016': (1, 0.9444444444444444)},\n",
       " 'shazoo algorithm': {'2011': (1, 0.4444444444444444)},\n",
       " 'scalable manner': {'2012': (1, 0.4444444444444444)},\n",
       " 'novel quantity': {'2016': (1, 0.4444444444444444)},\n",
       " 'random classifier drawn': {'2013': (1, 1.0)},\n",
       " 'application setting': {'2008': (1, 0.5)},\n",
       " 'task methods': {'2013': (1, 0.48148148148148157)},\n",
       " 'modeling large multi': {'2012': (1, 0.7222222222222222)},\n",
       " 'max flow algorithm': {'2016': (1, 1.0)},\n",
       " 'smooth objective function': {'2017': (1, 0.8888888888888888)},\n",
       " 'effective gradient directions': {'2013': (1, 0.9333333333333333)},\n",
       " 'piecewise linearized process': {'2013': (1, 1.0)},\n",
       " 'error bound': {'2012': (3, 0.45679012345679015),\n",
       "  '2013': (1, 0.4444444444444444),\n",
       "  '2015': (2, 0.4444444444444444),\n",
       "  '2017': (2, 0.5277777777777778)},\n",
       " 'gaussian functional form': {'2014': (1, 0.9333333333333333)},\n",
       " 'system noise': {'2007': (1, 0.3888888888888889)},\n",
       " 'greedy feature construction': {'2016': (1, 1.0)},\n",
       " 'study learning formulations': {'2008': (1, 1.0)},\n",
       " 'multivariate gaussian case': {'2012': (1, 0.9444444444444444)},\n",
       " 'reinforcement learning algorithm': {'2008': (1, 0.9074074074074073),\n",
       "  '2013': (1, 0.7777777777777778),\n",
       "  '2014': (1, 0.9444444444444444)},\n",
       " 'probabilistic representation': {'2015': (1, 0.4444444444444444)},\n",
       " 'stereotyped structure suggests': {'2017': (1, 1.0)},\n",
       " 'local feature descriptors': {'2012': (1, 1.0)},\n",
       " 'margin maximization': {'2013': (1, 0.4444444444444444)},\n",
       " 'approach stabilizes learning': {'2017': (1, 1.0)},\n",
       " 'probabilistic modeling framework': {'2016': (1, 0.8888888888888888)},\n",
       " 'generalized natural gradient': {'2009': (1, 0.8888888888888888)},\n",
       " 'combines sampling': {'2008': (1, 0.4444444444444444)},\n",
       " 'non robust ),': {'2014': (1, 0.8333333333333334)},\n",
       " 'asymptotic performance guarantees': {'2013': (1, 1.0)},\n",
       " 'novel mtl algorithm': {'2007': (1, 0.925925925925926)},\n",
       " 'inference remains': {'2013': (1, 0.4444444444444444)},\n",
       " 'based optimization method': {'2015': (1, 0.8333333333333334),\n",
       "  '2016': (1, 1.0)},\n",
       " 'source domain': {'2007': (1, 0.4444444444444444),\n",
       "  '2008': (1, 0.5),\n",
       "  '2011': (1, 0.4629629629629629),\n",
       "  '2012': (1, 0.5476190476190477),\n",
       "  '2016': (2, 0.47685185185185186),\n",
       "  '2017': (2, 0.41666666666666663)},\n",
       " 'reduce noise': {'2009': (1, 0.4861111111111111),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'estimated regression coefficients': {'2009': (1, 0.9444444444444444)},\n",
       " 'binary code': {'2012': (1, 0.4444444444444444)},\n",
       " 'achieving maximum reduction': {'2007': (1, 1.0)},\n",
       " 'bayesian hierarchical models': {'2013': (1, 0.9444444444444444),\n",
       "  '2014': (1, 1.0)},\n",
       " 'dimensional statistical estimation': {'2011': (1, 0.8888888888888888)},\n",
       " 'polynomial functions': {'2017': (1, 0.3888888888888889)},\n",
       " 'demonstrably scalable': {'2014': (1, 0.4444444444444444)},\n",
       " 'causal meets submodular': {'2016': (1, 1.0)},\n",
       " 'weighted sgd': {'2011': (1, 0.4444444444444444)},\n",
       " 'time markov chain': {'2017': (1, 1.0)},\n",
       " 'simple feature': {'2008': (1, 0.4444444444444444)},\n",
       " 'large database': {'2009': (2, 0.4444444444444444),\n",
       "  '2011': (1, 0.4444444444444444)},\n",
       " 'general theorem showing': {'2007': (1, 1.0)},\n",
       " 'arbitrary kernel function': {'2014': (1, 0.9629629629629629)},\n",
       " 'factored distribution': {'2017': (1, 0.3888888888888889)},\n",
       " 'average affinity relation': {'2010': (1, 1.0)},\n",
       " 'task parameters share': {'2010': (1, 0.9259259259259258)},\n",
       " \"'' dropout network\": {'2013': (1, 0.9722222222222222)},\n",
       " 'parametric procedure': {'2012': (1, 0.5)},\n",
       " 'measure inequalities': {'2008': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444)},\n",
       " 'another prior approach': {'2009': (1, 1.0)},\n",
       " 'passing': {'2008': (2, 0.1111111111111111),\n",
       "  '2011': (1, 0.1111111111111111),\n",
       "  '2012': (1, 0.1111111111111111),\n",
       "  '2014': (1, 0.1111111111111111),\n",
       "  '2016': (2, 0.1388888888888889)},\n",
       " 'sampling schemes': {'2010': (1, 0.5)},\n",
       " 'existing learning algorithms': {'2017': (1, 0.9444444444444444)},\n",
       " 'practical method': {'2015': (1, 0.4444444444444444)},\n",
       " 'parallel linear boundary': {'2010': (1, 1.0)},\n",
       " 'scale benchmark datasets': {'2012': (1, 0.9444444444444444)},\n",
       " 'yielding interpretable': {'2016': (1, 0.4444444444444444)},\n",
       " 'stochastic transitivity': {'2016': (1, 0.4444444444444444)},\n",
       " 'variational inference uses': {'2016': (1, 0.9301587301587302)},\n",
       " 'multiple bandits': {'2012': (1, 0.4444444444444444)},\n",
       " 'learning glms': {'2011': (1, 0.3888888888888889)},\n",
       " 'convex cone': {'2013': (1, 0.5),\n",
       "  '2014': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4722222222222222)},\n",
       " 'improving topic coherence': {'2011': (1, 1.0)},\n",
       " 'low density regions': {'2008': (2, 1.0)},\n",
       " 'priori unknown distribution': {'2017': (1, 0.8888888888888888)},\n",
       " 'one shot learning': {'2016': (1, 1.0)},\n",
       " 'sampling rate': {'2010': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.5370370370370371)},\n",
       " 'bayes optimal setting': {'2016': (1, 0.8888888888888888)},\n",
       " 'dimensional subspaces': {'2010': (1, 0.4444444444444444),\n",
       "  '2013': (1, 0.4444444444444444)},\n",
       " 'general generative model': {'2014': (1, 0.9444444444444444)},\n",
       " 'ptimization algorithm': {'2015': (1, 0.4444444444444444)},\n",
       " 'learning meaningful representations': {'2012': (1, 1.0),\n",
       "  '2017': (1, 0.9722222222222222)},\n",
       " 'latent feature models': {'2009': (1, 0.8518518518518517), '2013': (1, 1.0)},\n",
       " 'hashing trick': {'2017': (1, 0.5555555555555556)},\n",
       " 'multiple kernels': {'2009': (1, 0.5),\n",
       "  '2011': (2, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'bound even': {'2014': (1, 0.4666666666666667)},\n",
       " 'auditory map alignment': {'2008': (1, 0.8055555555555556)},\n",
       " 'active learner': {'2015': (3, 0.4074074074074074)},\n",
       " 'scale l': {'2014': (1, 0.4444444444444444)},\n",
       " 'linear function class': {'2015': (1, 1.0)},\n",
       " 'scale optimization problems': {'2010': (1, 0.9629629629629629),\n",
       "  '2012': (1, 1.0),\n",
       "  '2017': (1, 0.8703703703703705)},\n",
       " 'dimensional inference': {'2008': (1, 0.4444444444444444)},\n",
       " 'aided matching algorithm': {'2016': (1, 0.8888888888888888)},\n",
       " 'sparse signal recovery': {'2010': (1, 0.7777777777777778),\n",
       "  '2015': (1, 0.8333333333333334)},\n",
       " 'much remains unknown': {'2017': (1, 1.0)},\n",
       " 'better noise tolerance': {'2012': (1, 1.0)},\n",
       " 'perform survey sampling': {'2013': (1, 1.0)},\n",
       " 'generic optimization problems': {'2016': (1, 0.9629629629629629)},\n",
       " 'high baseline rates': {'2010': (1, 1.0)},\n",
       " 'effectively optimize high': {'2017': (1, 1.0)},\n",
       " 'learning population': {'2015': (1, 0.4444444444444444)},\n",
       " 'term feasible reduction': {'2017': (1, 1.0)},\n",
       " 'sparse approximations': {'2012': (1, 0.5)},\n",
       " 'general linear programming': {'2012': (1, 0.8999999999999999)},\n",
       " 'private framework': {'2016': (1, 0.4444444444444444)},\n",
       " 'extracting 3d shape': {'2014': (1, 0.9074074074074073)},\n",
       " 'class imbalanced settings': {'2014': (1, 0.9629629629629629)},\n",
       " 'propositional satisfiability testing': {'2015': (1, 0.9444444444444444)},\n",
       " 'hierarchical transition behavior': {'2012': (1, 1.0)},\n",
       " 'large errors': {'2013': (1, 0.5)},\n",
       " 'estimating peri': {'2007': (1, 0.4444444444444444)},\n",
       " 'pcs estimation upon': {'2013': (1, 0.8888888888888888)},\n",
       " 'motor prostheses aim': {'2011': (1, 1.0)},\n",
       " 'finite time': {'2013': (1, 0.4444444444444444)},\n",
       " 'size estimation task': {'2011': (1, 0.8888888888888888)},\n",
       " 'gradient vector field': {'2017': (1, 1.0)},\n",
       " 'object category recognition': {'2011': (1, 0.7222222222222222)},\n",
       " 'bayesian posterior inference': {'2015': (1, 1.0)},\n",
       " 'domain adaptation methods': {'2008': (1, 0.9444444444444444)},\n",
       " 'multiple task': {'2017': (1, 0.5)},\n",
       " 'language learning problem': {'2015': (1, 0.9629629629629629)},\n",
       " 'based lifted inference': {'2015': (1, 1.0)},\n",
       " 'gradient oracle': {'2016': (1, 0.48148148148148157)},\n",
       " 'inferring latent structure': {'2016': (1, 0.9166666666666666)},\n",
       " 'factor models': {'2009': (1, 0.5555555555555556), '2014': (1, 0.5)},\n",
       " 'bound algorithms': {'2014': (1, 0.4444444444444444)},\n",
       " 'choice options presented': {'2012': (1, 0.925925925925926)},\n",
       " 'kernel descriptors': {'2010': (2, 0.49074074074074076)},\n",
       " 'social goal inference': {'2009': (1, 1.0)},\n",
       " 'large viewpoint variations': {'2016': (1, 1.0)},\n",
       " 'original graph': {'2014': (1, 0.3888888888888889),\n",
       "  '2015': (1, 0.5),\n",
       "  '2017': (1, 0.5277777777777778)},\n",
       " 'kernel smoothing': {'2017': (1, 0.5)},\n",
       " 'current measurement': {'2011': (1, 0.4444444444444444)},\n",
       " 'new metric structure': {'2017': (1, 1.0)},\n",
       " 'sequential time points': {'2007': (1, 0.925925925925926)},\n",
       " 'wise class labels': {'2015': (1, 0.8888888888888888)},\n",
       " 'intrinsic image decomposition': {'2017': (1, 0.8814814814814815)},\n",
       " 'expectation wrt': {'2007': (1, 0.4444444444444444)},\n",
       " 'matching kernels': {'2011': (1, 0.4444444444444444)},\n",
       " 'improved inference translates': {'2015': (1, 1.0)},\n",
       " 'supervised learner': {'2010': (1, 0.48148148148148157),\n",
       "  '2011': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444)},\n",
       " 'optimal complexity bound': {'2017': (1, 0.8888888888888888)},\n",
       " 'amortised variational inference': {'2017': (1, 1.0)},\n",
       " 'subspace estimation': {'2013': (1, 0.4444444444444444)},\n",
       " 'two popular factorization': {'2016': (1, 1.0)},\n",
       " 'neighborhood structure': {'2012': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'center variable': {'2015': (1, 0.5555555555555556)},\n",
       " '1 regularization': {'2011': (1, 0.4166666666666667)},\n",
       " 'human time': {'2017': (1, 0.4444444444444444)},\n",
       " 'accelerated proximal gradient': {'2013': (1, 1.0), '2015': (1, 1.0)},\n",
       " 'performance numerically': {'2017': (1, 0.4444444444444444)},\n",
       " 'new construction': {'2014': (1, 0.4444444444444444)},\n",
       " 'sgd algorithms based': {'2015': (1, 1.0)},\n",
       " 'semantic meaning': {'2009': (1, 0.4444444444444444)},\n",
       " 'delay embedding': {'2009': (1, 0.4444444444444444)},\n",
       " 'episodic finite mdps': {'2016': (1, 0.9444444444444444)},\n",
       " 'feature structures': {'2010': (1, 0.48148148148148157),\n",
       "  '2014': (1, 0.48148148148148157)},\n",
       " 'bayesian spike': {'2011': (1, 0.4444444444444444)},\n",
       " 'functional': {'2010': (1, 0.1111111111111111),\n",
       "  '2012': (1, 0.1111111111111111),\n",
       "  '2016': (1, 0.1111111111111111)},\n",
       " 'learning good trajectories': {'2013': (1, 0.9722222222222222)},\n",
       " 'dependent learning bounds': {'2014': (1, 0.8888888888888888),\n",
       "  '2015': (1, 0.8148148148148149)},\n",
       " 'dimensional regression': {'2013': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'scalable square': {'2011': (1, 0.4444444444444444)},\n",
       " 'prune large parts': {'2017': (1, 1.0)},\n",
       " 'mcmc algorithm depend': {'2016': (1, 0.925925925925926)},\n",
       " 'fast detection': {'2010': (1, 0.4444444444444444)},\n",
       " 'sparse bayesian classification': {'2009': (1, 0.9722222222222222)},\n",
       " 'robust assessment': {'2016': (1, 0.4444444444444444)},\n",
       " 'internal algorithm': {'2016': (1, 0.4444444444444444)},\n",
       " 'ensemble sampling': {'2017': (1, 0.4444444444444444)},\n",
       " 'nonlinear signal alignment': {'2011': (1, 0.9444444444444444)},\n",
       " 'greedy strategy': {'2011': (1, 0.4444444444444444),\n",
       "  '2013': (1, 0.4444444444444444)},\n",
       " 'label classification': {'2010': (1, 0.4444444444444444),\n",
       "  '2011': (1, 0.4444444444444444),\n",
       "  '2012': (3, 0.43209876543209874),\n",
       "  '2014': (1, 0.5),\n",
       "  '2015': (3, 0.48148148148148145),\n",
       "  '2017': (2, 0.462962962962963)},\n",
       " 'original ls05short algorithm': {'2008': (1, 0.824074074074074)},\n",
       " 'supervised regression based': {'2009': (1, 0.8611111111111112)},\n",
       " 'tree tuning': {'2013': (1, 0.4444444444444444)},\n",
       " 'convex games': {'2009': (1, 0.4444444444444444)},\n",
       " 'general insufficient': {'2009': (1, 0.4444444444444444)},\n",
       " 'specific noise models': {'2008': (1, 0.9444444444444444)},\n",
       " 'full dataset directly': {'2017': (1, 0.9444444444444444)},\n",
       " 'sequential models': {'2008': (1, 0.4444444444444444)},\n",
       " 'unsupervised lm adaptation': {'2008': (1, 0.8888888888888888)},\n",
       " 'purely stochastic case': {'2013': (1, 0.8888888888888888)},\n",
       " 'local context': {'2017': (1, 0.4444444444444444)},\n",
       " 'learning performs': {'2010': (1, 0.40740740740740744)},\n",
       " 'hilbert space counterpart': {'2011': (1, 0.9722222222222222)},\n",
       " 'alternating estimation': {'2017': (2, 0.41666666666666663)},\n",
       " 'rectangles dataset significantly': {'2014': (1, 0.9444444444444444)},\n",
       " 'approximate optimization': {'2007': (1, 0.5)},\n",
       " 'joint optimization': {'2013': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.5555555555555556)},\n",
       " 'special regularization term': {'2012': (1, 1.0)},\n",
       " 'sparse regularizer along': {'2014': (1, 1.0)},\n",
       " 'iterative learning algorithm': {'2014': (1, 0.851851851851852)},\n",
       " 'noise proportional': {'2008': (1, 0.4444444444444444)},\n",
       " 'component shared embedding': {'2016': (1, 0.7777777777777778)},\n",
       " 'svi algorithm': {'2014': (1, 0.40740740740740744)},\n",
       " 'noise': {'2007': (3, 0.1111111111111111),\n",
       "  '2008': (6, 0.13888888888888887),\n",
       "  '2009': (6, 0.14814814814814814),\n",
       "  '2010': (5, 0.15555555555555556),\n",
       "  '2011': (2, 0.1111111111111111),\n",
       "  '2012': (7, 0.13756613756613756),\n",
       "  '2013': (14, 0.13293650793650794),\n",
       "  '2014': (7, 0.1349206349206349),\n",
       "  '2015': (11, 0.12626262626262627),\n",
       "  '2016': (16, 0.1354166666666667),\n",
       "  '2017': (19, 0.14035087719298248)},\n",
       " 'approximation process': {'2017': (1, 0.4444444444444444)},\n",
       " 'useful measure': {'2010': (1, 0.4444444444444444)},\n",
       " 'empirical loss minimization': {'2009': (1, 0.8333333333333334)},\n",
       " 'regression coefficients share': {'2008': (1, 0.925925925925926)},\n",
       " 'general convex': {'2017': (1, 0.3888888888888889)},\n",
       " 'case setting': {'2014': (1, 0.3888888888888889)},\n",
       " 'jointly measure': {'2009': (1, 0.4722222222222222)},\n",
       " 'decentralized learning problems': {'2017': (1, 0.9333333333333333)},\n",
       " 'common assumption': {'2010': (1, 0.4444444444444444),\n",
       "  '2013': (1, 0.3333333333333333)},\n",
       " 'present efficient learning': {'2011': (1, 0.9444444444444444)},\n",
       " 'leveraging gradient information': {'2017': (1, 1.0)},\n",
       " 'object part .\"': {'2010': (1, 0.9444444444444444)},\n",
       " 'perform robust search': {'2010': (1, 0.925925925925926)},\n",
       " 'candidate object mask': {'2017': (1, 0.8703703703703705)},\n",
       " 'regularization term': {'2009': (1, 0.40740740740740744),\n",
       "  '2010': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.5555555555555556),\n",
       "  '2015': (1, 0.4444444444444444)},\n",
       " 'exploiting class': {'2015': (1, 0.5)},\n",
       " 'bayesian occam': {'2016': (1, 0.5)},\n",
       " 'submodular cover': {'2013': (2, 0.49629629629629635),\n",
       "  '2016': (1, 0.5555555555555556)},\n",
       " 'based recovery': {'2016': (1, 0.4444444444444444)},\n",
       " 'unknown noise level': {'2012': (1, 1.0)},\n",
       " 'algorithm identifies': {'2010': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.48148148148148157)},\n",
       " 'stochastic approximation approach': {'2015': (1, 0.9444444444444444)},\n",
       " 'learn high': {'2012': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'prove correct recovery': {'2014': (1, 0.9629629629629629)},\n",
       " 'scalable demand': {'2017': (1, 0.4444444444444444)},\n",
       " 'posterior contraction rates': {'2015': (1, 1.0)},\n",
       " 'efficient perceptual inference': {'2016': (1, 1.0)},\n",
       " 'probabilistic language model': {'2007': (1, 1.0)},\n",
       " 'observation histories due': {'2017': (1, 1.0)},\n",
       " 'transductive learning theory': {'2016': (1, 0.9444444444444444)},\n",
       " 'reexamine variational inference': {'2016': (1, 0.93015873015873)},\n",
       " 'discounting 3d rotations': {'2011': (1, 0.9444444444444444)},\n",
       " 'rank subspace clustering': {'2013': (2, 1.0)},\n",
       " 'identifying cell types': {'2015': (1, 1.0)},\n",
       " 'one feature vector': {'2007': (1, 0.925925925925926)},\n",
       " 'trace regression': {'2015': (1, 0.4444444444444444)},\n",
       " 'lasso ).': {'2008': (1, 0.40740740740740744)},\n",
       " 'accurate inference': {'2015': (1, 0.4444444444444444)},\n",
       " 'knowledge base models': {'2013': (1, 0.9629629629629629)},\n",
       " 'context vectors': {'2017': (1, 0.5)},\n",
       " 'carlo analysis': {'2014': (1, 0.4444444444444444)},\n",
       " 'case instances': {'2015': (1, 0.5370370370370371)},\n",
       " 'requires large memory': {'2017': (1, 1.0)},\n",
       " 'adversarial game reaches': {'2017': (1, 1.0)},\n",
       " 'proximal mirror': {'2015': (2, 0.4444444444444444)},\n",
       " 'travel time distribution': {'2017': (1, 0.9444444444444444)},\n",
       " 'estimation proceudre': {'2017': (1, 0.5185185185185185)},\n",
       " 'dimensionality reduction tasks': {'2012': (1, 0.8148148148148148)},\n",
       " 'unknown competitors': {'2016': (1, 0.4444444444444444)},\n",
       " 'binary weights': {'2015': (2, 0.462962962962963),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'mixing stochastic processes': {'2015': (1, 1.0)},\n",
       " 'probabilistic characteristics': {'2011': (1, 0.4444444444444444)},\n",
       " 'better ranking': {'2007': (1, 0.3888888888888889), '2010': (1, 0.5)},\n",
       " 'efficiently learned online': {'2012': (1, 1.0)},\n",
       " 'convex formulations': {'2008': (1, 0.5185185185185185)},\n",
       " 'multiuser detection': {'2015': (1, 0.4444444444444444)},\n",
       " 'order online methods': {'2008': (1, 0.8888888888888888)},\n",
       " 'guided probabilistic inference': {'2015': (1, 1.0)},\n",
       " 'candidate object': {'2017': (1, 0.5370370370370371)},\n",
       " 'mcmc methods since': {'2015': (1, 0.8611111111111112)},\n",
       " 'nearest neighbor classifiers': {'2011': (1, 0.9444444444444444)},\n",
       " 'general opens': {'2012': (1, 0.4444444444444444)},\n",
       " 'lda topic vectors': {'2009': (1, 0.8148148148148149)},\n",
       " 'normal scale mixtures': {'2011': (1, 0.8333333333333334)},\n",
       " 'parallel implementation': {'2013': (2, 0.4444444444444444)},\n",
       " 'wolfe optimization variants': {'2015': (1, 1.0)},\n",
       " 'three large pomdps': {'2010': (1, 0.8333333333333334)},\n",
       " 'dirichlet process mixtures': {'2015': (2, 1.0)},\n",
       " 'difficult learning tasks': {'2014': (1, 0.9444444444444444)},\n",
       " 'problem domain': {'2009': (1, 0.4444444444444444)},\n",
       " 'driven purely': {'2008': (1, 0.4444444444444444)},\n",
       " 'recent algorithm': {'2012': (1, 0.5), '2014': (1, 0.48148148148148157)},\n",
       " 'general terms': {'2016': (1, 0.4444444444444444)},\n",
       " 'dimensional real vector': {'2009': (1, 0.8888888888888888)},\n",
       " 'naive assumption': {'2013': (1, 0.4444444444444444)},\n",
       " 'standard word embedding': {'2017': (1, 0.9074074074074073)},\n",
       " 'stochastic multiarmed bandits': {'2011': (1, 0.9074074074074073)},\n",
       " 'gradient needed': {'2015': (1, 0.40740740740740744)},\n",
       " 'based probabilistic models': {'2007': (1, 0.9629629629629629)},\n",
       " 'algorithm called gap': {'2011': (1, 0.7222222222222222)},\n",
       " 'modeling confidence': {'2015': (1, 0.4444444444444444)},\n",
       " 'smooth estimation': {'2008': (1, 0.4444444444444444)},\n",
       " 'visual qa dataset': {'2016': (1, 0.8888888888888888)},\n",
       " 'margin halfspace': {'2011': (2, 0.4444444444444444)},\n",
       " 'debiased lasso': {'2016': (1, 0.4444444444444444)},\n",
       " 'maximizing mutual information': {'2012': (1, 0.9444444444444444),\n",
       "  '2013': (1, 0.8888888888888888),\n",
       "  '2016': (1, 0.874074074074074)},\n",
       " 'capturing stochastic': {'2011': (1, 0.4444444444444444)},\n",
       " 'bandit linear optimization': {'2014': (1, 1.0)},\n",
       " 'random classifier selected': {'2013': (1, 1.0)},\n",
       " 'n ))$ algorithm': {'2011': (1, 0.8148148148148149)},\n",
       " 'reducing label noise': {'2017': (1, 1.0)},\n",
       " 'domain adaptation based': {'2013': (1, 1.0)},\n",
       " 'finite state mdps': {'2007': (1, 0.8333333333333334)},\n",
       " 'expected utility algorithm': {'2010': (1, 0.8888888888888888)},\n",
       " 'embedding approaches': {'2010': (1, 0.574074074074074)},\n",
       " 'label distribution': {'2017': (1, 0.4722222222222222)},\n",
       " 'convolutional filter sensitivities': {'2014': (1, 0.9444444444444444)},\n",
       " 'binary responses ).': {'2011': (1, 0.9629629629629629)},\n",
       " 'tolerate malicious noise': {'2011': (1, 0.8888888888888888)},\n",
       " 'human action': {'2008': (1, 0.5370370370370371)},\n",
       " 'obtain profit guarantees': {'2013': (1, 1.0)},\n",
       " 'allow one path': {'2013': (1, 1.0)},\n",
       " 'customized factor': {'2017': (1, 0.3888888888888889)},\n",
       " 'modeling brain dynamics': {'2012': (1, 0.9444444444444444)},\n",
       " 'dropout training improves': {'2014': (1, 0.8148148148148149)},\n",
       " 'large gap': {'2012': (1, 0.5)},\n",
       " 'partial gradient': {'2014': (1, 0.5370370370370371)},\n",
       " 'underlying network structure': {'2010': (1, 0.8888888888888888)},\n",
       " 'object approach': {'2011': (1, 0.5)},\n",
       " 'objective value retained': {'2014': (1, 1.0)},\n",
       " 'segmentation tree': {'2011': (1, 0.5)},\n",
       " 'parents per variable': {'2012': (1, 1.0)},\n",
       " 'efficient distributed learning': {'2017': (1, 1.0)},\n",
       " 'sequential observations': {'2008': (1, 0.4444444444444444)},\n",
       " 'algorithm progresses': {'2016': (1, 0.4444444444444444)},\n",
       " 'effect propelling': {'2009': (1, 0.4444444444444444)},\n",
       " 'optimization error': {'2013': (1, 0.4444444444444444)},\n",
       " 'feature approach': {'2016': (1, 0.3888888888888889)},\n",
       " 'far richer class': {'2016': (1, 1.0)},\n",
       " 'gamma construction': {'2016': (1, 0.4444444444444444)},\n",
       " 'purely convolutional': {'2017': (1, 0.4444444444444444)},\n",
       " 'multiple computational steps': {'2015': (1, 1.0)},\n",
       " 'evolving binary matrices': {'2010': (1, 1.0)},\n",
       " 'margin gaussian mixture': {'2014': (1, 0.9555555555555555)},\n",
       " 'another different distribution': {'2008': (1, 0.911111111111111)},\n",
       " 'cnn design': {'2015': (1, 0.5)},\n",
       " 'gaussian regression': {'2011': (1, 0.4444444444444444)},\n",
       " 'specific decision boundaries': {'2013': (1, 0.8888888888888888)},\n",
       " 'parallel matrix multiplications': {'2013': (1, 1.0)},\n",
       " 'large population': {'2008': (1, 0.4444444444444444)},\n",
       " 'unknown spatiotemporal characteristics': {'2007': (1, 1.0)},\n",
       " 'fast posterior inference': {'2015': (1, 1.0)},\n",
       " 'input graph': {'2017': (1, 0.4444444444444444)},\n",
       " 'distributed way': {'2010': (1, 0.4444444444444444)},\n",
       " 'shot learning refers': {'2017': (1, 0.9629629629629629)},\n",
       " 'tailed multivariate distributions': {'2010': (1, 0.8703703703703705)},\n",
       " 'nonlinear cascade models': {'2012': (1, 0.8703703703703705)},\n",
       " 'large feature space': {'2008': (1, 0.925925925925926)},\n",
       " 'time using tree': {'2013': (1, 0.911111111111111)},\n",
       " 'larger class': {'2007': (1, 0.4444444444444444),\n",
       "  '2015': (3, 0.4259259259259259),\n",
       "  '2016': (2, 0.39814814814814814)},\n",
       " 'identifying protein functions': {'2017': (1, 0.8888888888888888)},\n",
       " 'optimal strategy associated': {'2012': (1, 1.0)},\n",
       " 'human behavior': {'2009': (2, 0.41666666666666663),\n",
       "  '2012': (1, 0.4444444444444444)},\n",
       " 'markov chain monte': {'2010': (1, 1.0), '2012': (1, 1.0)},\n",
       " 'instead return': {'2014': (1, 0.5)},\n",
       " 'practical statistical implementation': {'2016': (1, 1.0)},\n",
       " 'kernel parameters': {'2008': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'underlying gaussian assumption': {'2014': (1, 1.0)},\n",
       " 'art classification performance': {'2012': (1, 1.0)},\n",
       " 'pure binary models': {'2009': (1, 0.9444444444444444)},\n",
       " 'large variable': {'2010': (1, 0.3888888888888889)},\n",
       " 'collaboratively ranking': {'2016': (1, 0.48148148148148157)},\n",
       " 'wishart prior': {'2012': (1, 0.4444444444444444)},\n",
       " 'asl 1 regularization': {'2015': (1, 1.0)},\n",
       " 'maximum degree': {'2013': (1, 0.5), '2014': (1, 0.4444444444444444)},\n",
       " 'recurrent convolution layer': {'2017': (1, 0.9444444444444444)},\n",
       " 'partial cover': {'2016': (1, 0.5185185185185185)},\n",
       " 'campaign budget': {'2008': (1, 0.4444444444444444)},\n",
       " 'task learning framework': {'2017': (2, 0.8805555555555555)},\n",
       " 'nonconconvex optimization problems': {'2012': (1, 0.9444444444444444)},\n",
       " 'spurious bias structure': {'2016': (1, 0.9333333333333333)},\n",
       " 'measure embedding viewpoint': {'2011': (1, 1.0)},\n",
       " 'achieve high accuracy': {'2017': (1, 0.8888888888888888)},\n",
       " 'structured poisson process': {'2012': (1, 1.0)},\n",
       " 'online procedure': {'2015': (1, 0.4444444444444444)},\n",
       " 'policy performance': {'2017': (1, 0.48148148148148157)},\n",
       " 'novel scheme': {'2009': (1, 0.48148148148148157),\n",
       "  '2014': (1, 0.4444444444444444),\n",
       "  '2017': (3, 0.46296296296296297)},\n",
       " 'studied low': {'2016': (1, 0.3888888888888889)},\n",
       " 'force field adaptation': {'2008': (1, 0.8888888888888888)},\n",
       " 'different distribution': {'2016': (1, 0.4444444444444444)},\n",
       " 'new dfo algorithm': {'2012': (1, 0.7777777777777778)},\n",
       " 'evaluation setting': {'2008': (1, 0.4444444444444444)},\n",
       " 'nearly isometric embedding': {'2016': (1, 1.0)},\n",
       " 'true partitioning cells': {'2017': (1, 0.8888888888888888)},\n",
       " 'financial context': {'2011': (1, 0.4444444444444444)},\n",
       " 'fully adversarial setting': {'2011': (1, 1.0)},\n",
       " 'joint prediction': {'2016': (1, 0.4444444444444444)},\n",
       " 'high efficiency': {'2012': (1, 0.5)},\n",
       " 'provide tight upper': {'2016': (1, 1.0)},\n",
       " 'infinite hierarchical model': {'2010': (1, 1.0)},\n",
       " 'actual process': {'2012': (1, 0.4444444444444444)},\n",
       " 'joint feature': {'2017': (1, 0.4444444444444444)},\n",
       " 'traditional variational learning': {'2015': (1, 1.0)},\n",
       " 'stable learning process': {'2008': (1, 1.0)},\n",
       " 'specific low': {'2008': (1, 0.4444444444444444)},\n",
       " 'width bayesian networks': {'2015': (1, 0.7592592592592593)},\n",
       " 'factor graph': {'2008': (1, 0.4444444444444444),\n",
       "  '2009': (2, 0.4722222222222222),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'prove positive results': {'2014': (1, 0.8888888888888888)},\n",
       " 'distribution': {'2007': (3, 0.12962962962962962),\n",
       "  '2008': (7, 0.15396825396825392),\n",
       "  '2009': (11, 0.13131313131313135),\n",
       "  '2010': (11, 0.13888888888888895),\n",
       "  '2011': (11, 0.14646464646464646),\n",
       "  '2012': (11, 0.1262626262626263),\n",
       "  '2013': (12, 0.14197530864197536),\n",
       "  '2014': (10, 0.12777777777777777),\n",
       "  '2015': (13, 0.1495726495726496),\n",
       "  '2016': (20, 0.1425925925925926),\n",
       "  '2017': (29, 0.14559386973180075)},\n",
       " 'leading design paradigm': {'2016': (1, 0.8888888888888888)},\n",
       " 'setting auditing': {'2013': (1, 0.4444444444444444)},\n",
       " 'selective attention': {'2008': (1, 0.3888888888888889),\n",
       "  '2014': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'carlo': {'2010': (1, 0.1111111111111111), '2012': (1, 0.1111111111111111)},\n",
       " 'online advertising': {'2008': (1, 0.4444444444444444),\n",
       "  '2010': (1, 0.4444444444444444),\n",
       "  '2016': (2, 0.5370370370370371),\n",
       "  '2017': (2, 0.4444444444444444)},\n",
       " 'alternative gradient': {'2012': (1, 0.5)},\n",
       " 'importance sampling procedure': {'2017': (1, 1.0)},\n",
       " 'probabilistic classification decisions': {'2014': (1, 0.9444444444444444)},\n",
       " 'sampling probabilities dependent': {'2016': (1, 0.8629629629629628)},\n",
       " 'grained object recognition': {'2012': (1, 1.0), '2016': (1, 1.0)},\n",
       " 'comparative evaluation': {'2012': (1, 0.4444444444444444)},\n",
       " 'algorithm normspecsync leads': {'2016': (1, 0.8888888888888888)},\n",
       " 'thus jeffreys prior': {'2013': (1, 0.8888888888888888)},\n",
       " 'probabilistic inference may': {'2014': (1, 1.0)},\n",
       " 'object frequencies': {'2008': (1, 0.5)},\n",
       " 'variable': {'2008': (2, 0.1111111111111111),\n",
       "  '2010': (2, 0.1388888888888889),\n",
       "  '2011': (2, 0.1111111111111111),\n",
       "  '2012': (1, 0.2222222222222222),\n",
       "  '2013': (1, 0.24074074074074073),\n",
       "  '2014': (3, 0.1111111111111111),\n",
       "  '2015': (2, 0.1111111111111111),\n",
       "  '2016': (3, 0.1111111111111111)},\n",
       " 'fully adversarial model': {'2017': (1, 1.0)},\n",
       " 'fixed design setting': {'2013': (1, 0.8888888888888888)},\n",
       " 'joint support recovery': {'2008': (1, 0.8518518518518517)},\n",
       " 'bilinear transfer functions': {'2017': (1, 1.0)},\n",
       " 'variance residual decomposition': {'2013': (1, 1.0)},\n",
       " 'input dataset onto': {'2015': (1, 0.8888888888888888)},\n",
       " 'scale clusters problematic': {'2014': (1, 1.0)},\n",
       " 'decentralized computation': {'2017': (1, 0.4444444444444444)},\n",
       " 'bayesian sets': {'2011': (1, 0.5)},\n",
       " 'gradient iteration ica': {'2013': (1, 0.7962962962962963)},\n",
       " 'strongly discriminative optimization': {'2013': (1, 1.0)},\n",
       " 'probabilistic programming': {'2016': (1, 0.4444444444444444)},\n",
       " 'descent procedure': {'2012': (1, 0.4444444444444444)},\n",
       " 'kronecker product structure': {'2015': (1, 0.9444444444444444),\n",
       "  '2016': (1, 0.9444444444444444)},\n",
       " 'deep boltzmann machine': {'2011': (2, 0.9722222222222222)},\n",
       " 'unknown parameters': {'2010': (1, 0.4222222222222222),\n",
       "  '2012': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.5),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'kernel permits': {'2009': (1, 0.5)},\n",
       " 'regression models': {'2009': (1, 0.4444444444444444)},\n",
       " 'geometric averages': {'2013': (1, 0.5555555555555556)},\n",
       " 'additive combinations': {'2015': (1, 0.4444444444444444)},\n",
       " 'establish posterior consistency': {'2017': (1, 1.0)},\n",
       " 'maximum marginal probability': {'2015': (1, 0.9444444444444444)},\n",
       " 'improved task accuracy': {'2017': (1, 1.0)},\n",
       " 'rational consequence': {'2009': (1, 0.4444444444444444)},\n",
       " 'intractable inference': {'2010': (1, 0.3888888888888889),\n",
       "  '2012': (1, 0.4444444444444444)},\n",
       " 'human teacher': {'2017': (1, 0.3888888888888889)},\n",
       " 'adaptive parameter setting': {'2016': (1, 0.8888888888888888)},\n",
       " 'waveform driven plasticity': {'2012': (1, 1.0)},\n",
       " 'dimensional regular grids': {'2016': (1, 1.0)},\n",
       " 'learning procedure seems': {'2007': (1, 1.0)},\n",
       " 'generative model perspective': {'2014': (1, 0.9444444444444444)},\n",
       " 'optimal linear estimation': {'2015': (1, 1.0)},\n",
       " 'general expression': {'2016': (1, 0.4444444444444444)},\n",
       " 'new stochastic variance': {'2017': (1, 1.0)},\n",
       " 'nearest neighbor strategies': {'2011': (1, 0.9444444444444444)},\n",
       " 'algorithm delivers': {'2015': (1, 0.5)},\n",
       " 'sparse graph structure': {'2011': (1, 0.8888888888888888)},\n",
       " 'multiple time steps': {'2016': (1, 0.8888888888888888), '2017': (1, 1.0)},\n",
       " 'proposed inference approach': {'2011': (1, 0.8888888888888888)},\n",
       " 'improving robustness': {'2016': (1, 0.4444444444444444)},\n",
       " 'analyzing large networks': {'2016': (1, 1.0)},\n",
       " 'disentangled': {'2015': (1, 0.1111111111111111),\n",
       "  '2017': (2, 0.1111111111111111)},\n",
       " 'pca problems': {'2010': (1, 0.3888888888888889)},\n",
       " 'new oracle inequality': {'2011': (1, 1.0)},\n",
       " 'shot classification task': {'2013': (1, 1.0)},\n",
       " 'cauchy kernel': {'2012': (1, 0.5)},\n",
       " 'online version': {'2016': (1, 0.48148148148148157)},\n",
       " 'action depends': {'2014': (1, 0.3333333333333333)},\n",
       " 'dimensional multi': {'2017': (2, 0.4444444444444444)},\n",
       " 'maximum eigenvalue': {'2017': (1, 0.4444444444444444)},\n",
       " 'bayesian lasso': {'2013': (1, 0.5)},\n",
       " 'unsupervised structure discovery': {'2012': (1, 1.0)},\n",
       " 'undirected graphical models': {'2009': (2, 0.9166666666666667),\n",
       "  '2012': (1, 0.9361111111111112),\n",
       "  '2013': (5, 0.9844444444444445),\n",
       "  '2017': (2, 0.9629629629629629)},\n",
       " 'various feature representations': {'2008': (1, 0.925925925925926)},\n",
       " 'structured exploration': {'2016': (1, 0.4444444444444444)},\n",
       " 'correcting code design': {'2008': (1, 1.0)},\n",
       " 'composite optimization': {'2017': (1, 0.4444444444444444)},\n",
       " 'performing cp decomposition': {'2016': (1, 0.851851851851852)},\n",
       " 'categorical distribution': {'2017': (1, 0.4444444444444444)},\n",
       " 'feature encodes': {'2012': (1, 0.5)},\n",
       " 'recently proposed algorithm': {'2012': (1, 0.8888888888888888),\n",
       "  '2013': (1, 0.8888888888888888)},\n",
       " 'large parameter': {'2013': (1, 0.4444444444444444)},\n",
       " 'better performance guarantees': {'2015': (1, 1.0)},\n",
       " 'tractable inference': {'2008': (1, 0.4444444444444444)},\n",
       " 'bayesian point': {'2017': (1, 0.4444444444444444)},\n",
       " 'sparsity analysis': {'2017': (1, 0.5)},\n",
       " 'sequential algorithms': {'2011': (1, 0.4444444444444444)},\n",
       " 'active scheme': {'2011': (1, 0.5)},\n",
       " 'algorithm applies': {'2015': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.40740740740740744)},\n",
       " 'modeling paired input': {'2013': (1, 0.9444444444444444)},\n",
       " 'robust distribution comparison': {'2011': (1, 1.0), '2012': (1, 1.0)},\n",
       " 'geometric mean': {'2014': (1, 0.4444444444444444),\n",
       "  '2016': (2, 0.4444444444444444)},\n",
       " 'generating distribution': {'2015': (1, 0.4444444444444444)},\n",
       " 'fast amortized inference': {'2017': (1, 1.0)},\n",
       " 'tabular reinforcement learning': {'2016': (1, 0.9444444444444444),\n",
       "  '2017': (1, 1.0)},\n",
       " 'topic model': {'2009': (1, 0.4444444444444444),\n",
       "  '2012': (3, 0.46913580246913583),\n",
       "  '2013': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4947089947089947)},\n",
       " 'continuous optimization': {'2013': (1, 0.4444444444444444),\n",
       "  '2016': (2, 0.4444444444444444)},\n",
       " 'presented bound': {'2017': (1, 0.3888888888888889)},\n",
       " 'dimensional representations': {'2010': (1, 0.4444444444444444),\n",
       "  '2011': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.3888888888888889),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'large probability': {'2010': (1, 0.4444444444444444),\n",
       "  '2015': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'faster evaluation': {'2016': (1, 0.4444444444444444)},\n",
       " 'multiple related sources': {'2011': (1, 1.0)},\n",
       " 'given prior': {'2013': (1, 0.4444444444444444)},\n",
       " 'distribution family': {'2007': (1, 0.4444444444444444)},\n",
       " 'optimizing ranking accuracy': {'2014': (1, 0.8611111111111112)},\n",
       " 'many inference settings': {'2012': (1, 1.0)},\n",
       " 'reveals novel results': {'2015': (1, 0.9444444444444444)},\n",
       " 'incremental algorithm': {'2011': (1, 0.4444444444444444)},\n",
       " 'output regression': {'2008': (1, 0.4444444444444444), '2012': (2, 0.5)},\n",
       " 'nonparametric models': {'2009': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.4444444444444444)},\n",
       " 'sparse predictor': {'2012': (1, 0.5)},\n",
       " 'general family': {'2009': (1, 0.4444444444444444),\n",
       "  '2011': (2, 0.4444444444444444),\n",
       "  '2016': (1, 0.5),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'ordinal embedding': {'2016': (2, 0.4907407407407407),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'stochastic mutli': {'2016': (1, 0.4444444444444444)},\n",
       " 'distributed neural representations': {'2016': (1, 1.0)},\n",
       " 'parallel clustering process': {'2015': (1, 0.9333333333333333)},\n",
       " 'dirichlet process prior': {'2009': (1, 1.0), '2013': (1, 1.0)},\n",
       " 'ellipsoid algorithm': {'2011': (1, 0.3888888888888889)},\n",
       " 'regularized stochastic learning': {'2009': (1, 1.0)},\n",
       " 'convex polytope constructed': {'2017': (1, 0.9444444444444444)},\n",
       " 'limited parametric interpretation': {'2017': (1, 0.9444444444444444)},\n",
       " 'proving high': {'2015': (1, 0.5)},\n",
       " 'approach scalable': {'2017': (1, 0.4444444444444444)},\n",
       " 'unknown gamma': {'2011': (1, 0.3888888888888889)},\n",
       " 'thesestatistical estimation problems': {'2014': (1, 1.0)},\n",
       " 'visually matching people': {'2010': (1, 1.0)},\n",
       " 'predicting useful neighborhoods': {'2014': (1, 1.0)},\n",
       " 'steepest descent algorithm': {'2012': (1, 0.9629629629629629)},\n",
       " 'scientific context': {'2017': (1, 0.4444444444444444)},\n",
       " 'grossly suboptimal performance': {'2011': (1, 1.0)},\n",
       " 'sparse auto': {'2015': (1, 0.4444444444444444)},\n",
       " 'related algorithm': {'2013': (1, 0.4222222222222222)},\n",
       " 'pu learning': {'2017': (2, 0.4444444444444444)},\n",
       " 'radial universal kernel': {'2016': (1, 0.8888888888888888)},\n",
       " 'performing bayesian learning': {'2015': (1, 1.0)},\n",
       " 'general threshold model': {'2017': (1, 0.9629629629629629)},\n",
       " 'general networks': {'2014': (1, 0.4166666666666667)},\n",
       " 'develop novel methods': {'2015': (1, 0.9444444444444444)},\n",
       " 'existing composition theorems': {'2016': (1, 0.8333333333333334)},\n",
       " 'much finer scale': {'2014': (1, 0.9444444444444444)},\n",
       " '3d image segmentation': {'2016': (1, 0.9166666666666666)},\n",
       " 'safe policy gradients': {'2017': (1, 1.0)},\n",
       " 'active research fields': {'2012': (1, 1.0)},\n",
       " 'bayesian multi': {'2009': (1, 0.4444444444444444)},\n",
       " 'dropout': {'2013': (2, 0.18333333333333335),\n",
       "  '2014': (3, 0.1851851851851852),\n",
       "  '2015': (2, 0.16666666666666666),\n",
       "  '2016': (7, 0.15476190476190474),\n",
       "  '2017': (5, 0.15999999999999998)},\n",
       " 'minimum weight matching': {'2017': (1, 1.0)},\n",
       " 'window classifier yields': {'2009': (1, 1.0)},\n",
       " 'global objective': {'2015': (2, 0.4722222222222222)},\n",
       " 'algorithm achieves': {'2008': (1, 0.4444444444444444),\n",
       "  '2012': (2, 0.4444444444444444),\n",
       "  '2014': (3, 0.44753086419753085),\n",
       "  '2015': (2, 0.41666666666666663),\n",
       "  '2017': (5, 0.45925925925925926)},\n",
       " 'scalable variational inference': {'2017': (1, 1.0)},\n",
       " 'reeb graph': {'2011': (1, 0.3888888888888889)},\n",
       " 'bayesian information criterion': {'2008': (1, 0.9629629629629629),\n",
       "  '2010': (1, 1.0)},\n",
       " 'perform online updates': {'2008': (1, 0.7777777777777778)},\n",
       " 'metric learning seeks': {'2015': (1, 1.0)},\n",
       " 'design new estimators': {'2016': (1, 0.8888888888888888)},\n",
       " 'indirect measurement': {'2017': (1, 0.4444444444444444)},\n",
       " 'object images': {'2008': (1, 0.462962962962963)},\n",
       " 'om kernel approximation': {'2014': (1, 0.9333333333333333)},\n",
       " 'estimation accuracy': {'2013': (1, 0.4444444444444444),\n",
       "  '2016': (1, 0.4444444444444444)},\n",
       " 'word context': {'2014': (1, 0.4722222222222222)},\n",
       " 'randomized optimization method': {'2017': (1, 0.8888888888888888)},\n",
       " 'compute spectral decomposition': {'2014': (1, 1.0)},\n",
       " 'polynomial optimization problems': {'2013': (1, 0.9444444444444444)},\n",
       " 'kernel ?).': {'2012': (1, 0.5185185185185185)},\n",
       " 'regularization': {'2008': (8, 0.1527777777777778),\n",
       "  '2009': (5, 0.1648148148148148),\n",
       "  '2010': (5, 0.17037037037037037),\n",
       "  '2011': (4, 0.1527777777777778),\n",
       "  '2012': (2, 0.19444444444444442),\n",
       "  '2013': (6, 0.13888888888888887),\n",
       "  '2014': (2, 0.1111111111111111),\n",
       "  '2015': (4, 0.12962962962962962),\n",
       "  '2016': (3, 0.1111111111111111),\n",
       "  '2017': (8, 0.14583333333333334)},\n",
       " 'model generates high': {'2017': (1, 1.0)},\n",
       " 'discovering sparse representations': {'2012': (1, 1.0)},\n",
       " 'cast bayesian inference': {'2016': (1, 0.9777777777777779)},\n",
       " 'estimating lasso risk': {'2013': (1, 1.0)},\n",
       " 'sgd transit': {'2016': (1, 0.3888888888888889)},\n",
       " 'novel convex relaxation': {'2013': (1, 0.925925925925926)},\n",
       " 'symmetric relationships used': {'2015': (1, 0.925925925925926)},\n",
       " 'multiple gradients': {'2017': (1, 0.5)},\n",
       " 'generalised tensor factorisation': {'2011': (1, 1.0)},\n",
       " 'optimally fast': {'2014': (1, 0.3888888888888889)},\n",
       " 'learning however': {'2011': (1, 0.4444444444444444)},\n",
       " 'stronger assumption': {'2011': (1, 0.5)},\n",
       " 'unified theoretical account': {'2013': (1, 1.0)},\n",
       " 'algorithm greedily shrinks': {'2016': (1, 0.8888888888888888)},\n",
       " 'novel online technique': {'2017': (1, 0.8888888888888888)},\n",
       " 'higher dimensional case': {'2013': (1, 0.8888888888888888)},\n",
       " 'strategic settings': {'2016': (1, 0.4444444444444444)},\n",
       " 'cluster tree provides': {'2016': (1, 0.9500000000000001)},\n",
       " 'backward activation algorithm': {'2012': (1, 1.0)},\n",
       " 'online resource allocation': {'2016': (1, 0.9444444444444444)},\n",
       " 'domain adaptation': {'2007': (1, 0.4444444444444444),\n",
       "  '2008': (1, 0.4444444444444444),\n",
       "  '2010': (1, 0.5370370370370371),\n",
       "  '2011': (1, 0.4444444444444444),\n",
       "  '2012': (2, 0.4444444444444444),\n",
       "  '2013': (1, 0.4444444444444444),\n",
       "  '2016': (3, 0.4537037037037037),\n",
       "  '2017': (5, 0.4722222222222222)},\n",
       " 'worst margin violators': {'2008': (1, 1.0)},\n",
       " 'schmidt metric': {'2014': (2, 0.4444444444444444)},\n",
       " 'neighborhoods using large': {'2014': (1, 0.8888888888888888)},\n",
       " 'bandit': {'2011': (2, 0.19444444444444442),\n",
       "  '2014': (1, 0.16666666666666666),\n",
       "  '2016': (2, 0.1111111111111111)},\n",
       " 'single positive sample': {'2016': (1, 0.9074074074074073)},\n",
       " 'pairwise similarity measure': {'2012': (1, 1.0)},\n",
       " 'proposed algorithm uses': {'2015': (1, 0.925925925925926)},\n",
       " 'evaluate performance': {'2008': (1, 0.4444444444444444)},\n",
       " 'geometric loss function': {'2016': (1, 0.925925925925926)},\n",
       " 'expensive objective functions': {'2015': (1, 1.0)},\n",
       " 'convolutional spatial transformer': {'2016': (1, 1.0)},\n",
       " 'bci speller performance': {'2008': (1, 1.0)},\n",
       " 'tree branch': {'2011': (1, 0.4444444444444444)},\n",
       " 'diffusion decision making': {'2012': (1, 1.0)},\n",
       " 'tensor multilinear rank': {'2014': (1, 0.8055555555555556)},\n",
       " 'general loss function': {'2014': (1, 0.8888888888888888),\n",
       "  '2015': (1, 0.8796296296296295)},\n",
       " 'rigorous bayesian learning': {'2013': (1, 0.8888888888888888)},\n",
       " 'learning concept graphs': {'2010': (1, 1.0)},\n",
       " 'general result': {'2011': (2, 0.4907407407407408),\n",
       "  '2015': (1, 0.3888888888888889),\n",
       "  '2016': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'compressive image recovery': {'2017': (1, 0.9444444444444444)},\n",
       " 'infer social structure': {'2012': (1, 0.9444444444444444)},\n",
       " 'robust deconvolution': {'2014': (1, 0.4444444444444444)},\n",
       " 'ordinary lasso would': {'2009': (1, 1.0)},\n",
       " 'positive semidefinite matrix': {'2008': (1, 1.0),\n",
       "  '2009': (1, 0.9444444444444444),\n",
       "  '2015': (1, 0.9259259259259258)},\n",
       " 'bootstrap strategy': {'2008': (1, 0.4444444444444444)},\n",
       " 'tensor entries': {'2016': (1, 0.4444444444444444)},\n",
       " 'certain correction factor': {'2017': (1, 1.0)},\n",
       " 'parallel direction method': {'2014': (1, 1.0)},\n",
       " 'class variance': {'2012': (1, 0.4444444444444444)},\n",
       " 'joint demodulation': {'2011': (1, 0.4444444444444444)},\n",
       " 'implicit curriculum': {'2017': (1, 0.4444444444444444)},\n",
       " 'gibbs sampling method': {'2012': (1, 0.9722222222222222)},\n",
       " 'parallel sampling': {'2013': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'many practical situations': {'2008': (1, 1.0)},\n",
       " 'stochastic gradient techniques': {'2014': (1, 1.0), '2015': (1, 1.0)},\n",
       " 'across multiple datasets': {'2015': (1, 1.0)},\n",
       " 'probabilistic independence': {'2010': (1, 0.5)},\n",
       " 'tight lower bounds': {'2015': (1, 0.925925925925926)},\n",
       " 'error bound analysis': {'2016': (1, 1.0)},\n",
       " 'novel continuous relaxation': {'2012': (1, 0.9444444444444444)},\n",
       " 'making events': {'2010': (1, 0.4444444444444444)},\n",
       " 'novel learning scheme': {'2008': (1, 0.8888888888888888)},\n",
       " 'agent reinforcement learning': {'2016': (1, 0.8888888888888888),\n",
       "  '2017': (1, 1.0)},\n",
       " 'structured multilabel prediction': {'2015': (1, 1.0)},\n",
       " 'latent parse trees': {'2012': (1, 1.0)},\n",
       " 'ranking problem': {'2007': (1, 0.4444444444444444),\n",
       "  '2011': (1, 0.4444444444444444)},\n",
       " 'give approximation guarantees': {'2012': (1, 0.9444444444444444)},\n",
       " 'rank r': {'2011': (1, 0.3888888888888889)},\n",
       " 'proposed algorithm improves': {'2017': (1, 1.0)},\n",
       " 'robust classification problem': {'2007': (1, 0.9444444444444444)},\n",
       " 'predictive learning': {'2017': (1, 0.5462962962962963)},\n",
       " 'demand estimation': {'2013': (1, 0.4444444444444444)},\n",
       " 'minimization principle': {'2017': (1, 0.4444444444444444)},\n",
       " 'either expectation maximisation': {'2012': (1, 0.8888888888888888)},\n",
       " 'relatively low variance': {'2010': (1, 1.0)},\n",
       " 'many graphical models': {'2017': (1, 1.0)},\n",
       " 'sparse measurements': {'2009': (1, 0.4444444444444444)},\n",
       " 'world dataset': {'2008': (1, 0.4444444444444444)},\n",
       " 'slow': {'2008': (3, 0.1111111111111111),\n",
       "  '2009': (2, 0.1111111111111111),\n",
       "  '2010': (1, 0.1111111111111111),\n",
       "  '2011': (1, 0.1111111111111111),\n",
       "  '2012': (1, 0.1111111111111111),\n",
       "  '2013': (2, 0.1111111111111111),\n",
       "  '2014': (2, 0.1111111111111111),\n",
       "  '2015': (4, 0.12499999999999999),\n",
       "  '2016': (1, 0.1111111111111111),\n",
       "  '2017': (5, 0.11111111111111112)},\n",
       " 'private databases': {'2008': (1, 0.4444444444444444)},\n",
       " 'parametric adp approaches': {'2012': (1, 0.8333333333333334)},\n",
       " 'multiple processors': {'2009': (1, 0.4444444444444444)},\n",
       " 'motion segmentation': {'2009': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'without extra supervision': {'2017': (1, 1.0)},\n",
       " 'single latent vector': {'2016': (1, 1.0)},\n",
       " 'including proximal gradient': {'2014': (1, 1.0)},\n",
       " 'invariant sparse representations': {'2015': (1, 1.0)},\n",
       " 'like sparsity': {'2010': (1, 0.4444444444444444)},\n",
       " 'one extract unknown': {'2008': (1, 1.0)},\n",
       " 'convex relaxation approach': {'2011': (1, 1.0),\n",
       "  '2015': (1, 0.8333333333333334)},\n",
       " 'scale learning problems': {'2007': (1, 0.8333333333333334),\n",
       "  '2008': (1, 1.0),\n",
       "  '2010': (1, 1.0),\n",
       "  '2012': (1, 1.0)},\n",
       " 'estimating shannon': {'2012': (1, 0.4444444444444444)},\n",
       " 'unlike mcmc methods': {'2013': (1, 0.8888888888888888)},\n",
       " 'continual learning': {'2017': (3, 0.46296296296296297)},\n",
       " 'justifies practical computations': {'2017': (1, 0.9444444444444444)},\n",
       " 'unified meta': {'2017': (1, 0.4444444444444444)},\n",
       " 'private estimators': {'2015': (1, 0.4444444444444444)},\n",
       " 'dimensional domains': {'2017': (1, 0.4444444444444444)},\n",
       " 'quadratic dependence': {'2012': (1, 0.4444444444444444),\n",
       "  '2014': (1, 0.4444444444444444),\n",
       "  '2017': (1, 0.4444444444444444)},\n",
       " 'feature graphs constructed': {'2008': (1, 0.8888888888888888)},\n",
       " 'cost structure': {'2012': (2, 0.4444444444444444)},\n",
       " 'solving large': {'2010': (1, 0.4444444444444444),\n",
       "  '2012': (1, 0.4444444444444444),\n",
       "  '2013': (2, 0.39814814814814814)},\n",
       " 'markov chain': {'2012': (1, 0.4444444444444444),\n",
       "  '2013': (2, 0.4444444444444444),\n",
       "  '2015': (4, 0.4305555555555555),\n",
       "  '2016': (1, 0.3888888888888889),\n",
       "  '2017': (3, 0.4444444444444444)},\n",
       " 'dependence': {'2007': (1, 0.2222222222222222),\n",
       "  '2008': (2, 0.1111111111111111),\n",
       "  '2009': (1, 0.1111111111111111),\n",
       "  '2010': (2, 0.1111111111111111),\n",
       "  '2011': (4, 0.1111111111111111),\n",
       "  '2012': (2, 0.1111111111111111),\n",
       "  '2013': (4, 0.1111111111111111),\n",
       "  '2015': (3, 0.1111111111111111),\n",
       "  '2016': (7, 0.1375661375661376),\n",
       "  '2017': (4, 0.1111111111111111)},\n",
       " 'subspace selection': {'2007': (1, 0.5925925925925926)},\n",
       " 'view learning': {'2010': (1, 0.5),\n",
       "  '2011': (2, 0.4722222222222222),\n",
       "  '2014': (1, 0.4444444444444444)},\n",
       " 'variational bayesian pca': {'2012': (1, 1.0)},\n",
       " 'distributed optimization algorithm': {'2013': (1, 0.8888888888888888)},\n",
       " 'classifier assumption made': {'2016': (1, 0.9555555555555555)},\n",
       " 'dataset constructed': {'2016': (1, 0.4444444444444444)},\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all unigrams\n",
    "\n",
    "unigrams = set()\n",
    "\n",
    "for word in info_1.keys():\n",
    "    if len(word.split()) == 1:\n",
    "        unigrams.add(word)\n",
    "        \n",
    "len(unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'total_count': [], 'variations': [], 'word': 'multivariate'},\n",
       " {'total_count': [], 'variations': [], 'word': 'sensing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'regularization'},\n",
       " {'total_count': [], 'variations': [], 'word': 'maximum'},\n",
       " {'total_count': [], 'variations': [], 'word': 'probabilistic'},\n",
       " {'total_count': [], 'variations': [], 'word': 'symmetric'},\n",
       " {'total_count': [], 'variations': [], 'word': 'construction'},\n",
       " {'total_count': [], 'variations': [], 'word': 'deep'},\n",
       " {'total_count': [], 'variations': [], 'word': 'structured'},\n",
       " {'total_count': [], 'variations': [], 'word': 'transfer'},\n",
       " {'total_count': [], 'variations': [], 'word': 'modeling'},\n",
       " {'total_count': [], 'variations': [], 'word': 'decentralized'},\n",
       " {'total_count': [], 'variations': [], 'word': 'shot'},\n",
       " {'total_count': [], 'variations': [], 'word': 'making'},\n",
       " {'total_count': [], 'variations': [], 'word': 'conjugate'},\n",
       " {'total_count': [], 'variations': [], 'word': 'metric'},\n",
       " {'total_count': [], 'variations': [], 'word': 'permutation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'multi'},\n",
       " {'total_count': [], 'variations': [], 'word': 'variable'},\n",
       " {'total_count': [], 'variations': [], 'word': 'attention'},\n",
       " {'total_count': [], 'variations': [], 'word': 'path'},\n",
       " {'total_count': [], 'variations': [], 'word': 'bandit'},\n",
       " {'total_count': [], 'variations': [], 'word': 'semi'},\n",
       " {'total_count': [], 'variations': [], 'word': 'manifold'},\n",
       " {'total_count': [], 'variations': [], 'word': 'large'},\n",
       " {'total_count': [], 'variations': [], 'word': 'structural'},\n",
       " {'total_count': [], 'variations': [], 'word': 'additive'},\n",
       " {'total_count': [], 'variations': [], 'word': 'asynchronous'},\n",
       " {'total_count': [], 'variations': [], 'word': 'cold'},\n",
       " {'total_count': [], 'variations': [], 'word': 'mirror'},\n",
       " {'total_count': [], 'variations': [], 'word': 'exploiting'},\n",
       " {'total_count': [], 'variations': [], 'word': 'scale'},\n",
       " {'total_count': [], 'variations': [], 'word': 'action'},\n",
       " {'total_count': [], 'variations': [], 'word': 'choice'},\n",
       " {'total_count': [], 'variations': [], 'word': 'minimization'},\n",
       " {'total_count': [], 'variations': [], 'word': 'average'},\n",
       " {'total_count': [], 'variations': [], 'word': 'convolution'},\n",
       " {'total_count': [], 'variations': [], 'word': 'fast'},\n",
       " {'total_count': [], 'variations': [], 'word': 'hilbert'},\n",
       " {'total_count': [], 'variations': [], 'word': 'sparsity'},\n",
       " {'total_count': [], 'variations': [], 'word': 'invariance'},\n",
       " {'total_count': [], 'variations': [], 'word': 'latent'},\n",
       " {'total_count': [], 'variations': [], 'word': 'unlabeled'},\n",
       " {'total_count': [], 'variations': [], 'word': 'submodular'},\n",
       " {'total_count': [], 'variations': [], 'word': 'scalable'},\n",
       " {'total_count': [], 'variations': [], 'word': 'guided'},\n",
       " {'total_count': [], 'variations': [], 'word': 'recovery'},\n",
       " {'total_count': [], 'variations': [], 'word': 'tensor'},\n",
       " {'total_count': [], 'variations': [], 'word': 'general'},\n",
       " {'total_count': [], 'variations': [], 'word': 'factor'},\n",
       " {'total_count': [], 'variations': [], 'word': 'wolfe'},\n",
       " {'total_count': [], 'variations': [], 'word': 'regression'},\n",
       " {'total_count': [], 'variations': [], 'word': 'factorization'},\n",
       " {'total_count': [], 'variations': [], 'word': 'cover'},\n",
       " {'total_count': [], 'variations': [], 'word': 'low'},\n",
       " {'total_count': [], 'variations': [], 'word': 'detection'},\n",
       " {'total_count': [], 'variations': [], 'word': 'poisson'},\n",
       " {'total_count': [], 'variations': [], 'word': 'evaluation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'measurement'},\n",
       " {'total_count': [], 'variations': [], 'word': 'message'},\n",
       " {'total_count': [], 'variations': [], 'word': 'generative'},\n",
       " {'total_count': [], 'variations': [], 'word': 'slow'},\n",
       " {'total_count': [], 'variations': [], 'word': 'motor'},\n",
       " {'total_count': [], 'variations': [], 'word': 'collaborative'},\n",
       " {'total_count': [], 'variations': [], 'word': 'driven'},\n",
       " {'total_count': [], 'variations': [], 'word': 'reduction'},\n",
       " {'total_count': [], 'variations': [], 'word': 'proposal'},\n",
       " {'total_count': [], 'variations': [], 'word': 'crowdsourcing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'unknown'},\n",
       " {'total_count': [], 'variations': [], 'word': 'practical'},\n",
       " {'total_count': [], 'variations': [], 'word': 'case'},\n",
       " {'total_count': [], 'variations': [], 'word': 'stochastic'},\n",
       " {'total_count': [], 'variations': [], 'word': 'passing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'neighbor'},\n",
       " {'total_count': [], 'variations': [], 'word': 'algorithm'},\n",
       " {'total_count': [], 'variations': [], 'word': 'graph'},\n",
       " {'total_count': [], 'variations': [], 'word': 'aggregation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'human'},\n",
       " {'total_count': [], 'variations': [], 'word': 'budget'},\n",
       " {'total_count': [], 'variations': [], 'word': 'bound'},\n",
       " {'total_count': [], 'variations': [], 'word': 'dependence'},\n",
       " {'total_count': [], 'variations': [], 'word': 'embedding'},\n",
       " {'total_count': [], 'variations': [], 'word': 'classifier'},\n",
       " {'total_count': [], 'variations': [], 'word': 'active'},\n",
       " {'total_count': [], 'variations': [], 'word': 'dimensional'},\n",
       " {'total_count': [], 'variations': [], 'word': 'attribute'},\n",
       " {'total_count': [], 'variations': [], 'word': 'pca'},\n",
       " {'total_count': [], 'variations': [], 'word': 'online'},\n",
       " {'total_count': [], 'variations': [], 'word': 'objective'},\n",
       " {'total_count': [], 'variations': [], 'word': 'coordinate'},\n",
       " {'total_count': [], 'variations': [], 'word': 'subspace'},\n",
       " {'total_count': [], 'variations': [], 'word': 'effect'},\n",
       " {'total_count': [], 'variations': [], 'word': 'balanced'},\n",
       " {'total_count': [], 'variations': [], 'word': 'parallel'},\n",
       " {'total_count': [], 'variations': [], 'word': 'binary'},\n",
       " {'total_count': [], 'variations': [], 'word': 'process'},\n",
       " {'total_count': [], 'variations': [], 'word': 'oracle'},\n",
       " {'total_count': [], 'variations': [], 'word': 'hashing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'margin'},\n",
       " {'total_count': [], 'variations': [], 'word': 'annotation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'knowledge'},\n",
       " {'total_count': [], 'variations': [], 'word': 'strategic'},\n",
       " {'total_count': [], 'variations': [], 'word': 'distribution'},\n",
       " {'total_count': [], 'variations': [], 'word': 'sparse'},\n",
       " {'total_count': [], 'variations': [], 'word': 'logistic'},\n",
       " {'total_count': [], 'variations': [], 'word': 'adaptation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'unified'},\n",
       " {'total_count': [], 'variations': [], 'word': 'supervision'},\n",
       " {'total_count': [], 'variations': [], 'word': 'robust'},\n",
       " {'total_count': [], 'variations': [], 'word': 'safe'},\n",
       " {'total_count': [], 'variations': [], 'word': 'law'},\n",
       " {'total_count': [], 'variations': [], 'word': 'adversarial'},\n",
       " {'total_count': [], 'variations': [], 'word': 'dictionary'},\n",
       " {'total_count': [], 'variations': [], 'word': 'label'},\n",
       " {'total_count': [], 'variations': [], 'word': 'supervised'},\n",
       " {'total_count': [], 'variations': [], 'word': 'cascade'},\n",
       " {'total_count': [], 'variations': [], 'word': 'link'},\n",
       " {'total_count': [], 'variations': [], 'word': 'design'},\n",
       " {'total_count': [], 'variations': [], 'word': 'novel'},\n",
       " {'total_count': [], 'variations': [], 'word': 'object'},\n",
       " {'total_count': [], 'variations': [], 'word': 'predicting'},\n",
       " {'total_count': [], 'variations': [], 'word': 'tree'},\n",
       " {'total_count': [], 'variations': [], 'word': 'forest'},\n",
       " {'total_count': [], 'variations': [], 'word': 'optimization'},\n",
       " {'total_count': [], 'variations': [], 'word': 'geometric'},\n",
       " {'total_count': [], 'variations': [], 'word': 'structure'},\n",
       " {'total_count': [], 'variations': [], 'word': 'optimistic'},\n",
       " {'total_count': [], 'variations': [], 'word': 'bayesian'},\n",
       " {'total_count': [], 'variations': [], 'word': 'dynamical'},\n",
       " {'total_count': [], 'variations': [], 'word': 'convolutional'},\n",
       " {'total_count': [], 'variations': [], 'word': 'gan'},\n",
       " {'total_count': [], 'variations': [], 'word': 'decomposition'},\n",
       " {'total_count': [], 'variations': [], 'word': 'subset'},\n",
       " {'total_count': [], 'variations': [], 'word': 'gradient'},\n",
       " {'total_count': [], 'variations': [], 'word': 'rational'},\n",
       " {'total_count': [], 'variations': [], 'word': 'assumption'},\n",
       " {'total_count': [], 'variations': [], 'word': 'multiclass'},\n",
       " {'total_count': [], 'variations': [], 'word': 'feature'},\n",
       " {'total_count': [], 'variations': [], 'word': 'estimation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'estimating'},\n",
       " {'total_count': [], 'variations': [], 'word': 'interpretable'},\n",
       " {'total_count': [], 'variations': [], 'word': 'sampling'},\n",
       " {'total_count': [], 'variations': [], 'word': 'disentangled'},\n",
       " {'total_count': [], 'variations': [], 'word': 'optimality'},\n",
       " {'total_count': [], 'variations': [], 'word': 'functional'},\n",
       " {'total_count': [], 'variations': [], 'word': '3d'},\n",
       " {'total_count': [], 'variations': [], 'word': 'tight'},\n",
       " {'total_count': [], 'variations': [], 'word': 'implicit'},\n",
       " {'total_count': [], 'variations': [], 'word': 'group'},\n",
       " {'total_count': [], 'variations': [], 'word': 'coupled'},\n",
       " {'total_count': [], 'variations': [], 'word': 'newton'},\n",
       " {'total_count': [], 'variations': [], 'word': 'partitioning'},\n",
       " {'total_count': [], 'variations': [], 'word': 'domain'},\n",
       " {'total_count': [], 'variations': [], 'word': 'inference'},\n",
       " {'total_count': [], 'variations': [], 'word': 'frank'},\n",
       " {'total_count': [], 'variations': [], 'word': 'gated'},\n",
       " {'total_count': [], 'variations': [], 'word': 'observation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'setting'},\n",
       " {'total_count': [], 'variations': [], 'word': 'convex'},\n",
       " {'total_count': [], 'variations': [], 'word': 'multiple'},\n",
       " {'total_count': [], 'variations': [], 'word': 'private'},\n",
       " {'total_count': [], 'variations': [], 'word': 'performance'},\n",
       " {'total_count': [], 'variations': [], 'word': 'identifying'},\n",
       " {'total_count': [], 'variations': [], 'word': 'agent'},\n",
       " {'total_count': [], 'variations': [], 'word': 'infinite'},\n",
       " {'total_count': [], 'variations': [], 'word': 'finite'},\n",
       " {'total_count': [], 'variations': [], 'word': 'acceleration'},\n",
       " {'total_count': [], 'variations': [], 'word': 'guarantees'},\n",
       " {'total_count': [], 'variations': [], 'word': 'weighted'},\n",
       " {'total_count': [], 'variations': [], 'word': 'lasso'},\n",
       " {'total_count': [], 'variations': [], 'word': 'joint'},\n",
       " {'total_count': [], 'variations': [], 'word': 'distributed'},\n",
       " {'total_count': [], 'variations': [], 'word': 'class'},\n",
       " {'total_count': [], 'variations': [], 'word': 'context'},\n",
       " {'total_count': [], 'variations': [], 'word': 'kernel'},\n",
       " {'total_count': [], 'variations': [], 'word': 'segmentation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'fairness'},\n",
       " {'total_count': [], 'variations': [], 'word': 'solving'},\n",
       " {'total_count': [], 'variations': [], 'word': 'decision'},\n",
       " {'total_count': [], 'variations': [], 'word': 'dataset'},\n",
       " {'total_count': [], 'variations': [], 'word': 'coding'},\n",
       " {'total_count': [], 'variations': [], 'word': 'testing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'return'},\n",
       " {'total_count': [], 'variations': [], 'word': 'noise'},\n",
       " {'total_count': [], 'variations': [], 'word': 'expectation'},\n",
       " {'total_count': [], 'variations': [], 'word': 'polynomial'},\n",
       " {'total_count': [], 'variations': [], 'word': 'nonparametric'},\n",
       " {'total_count': [], 'variations': [], 'word': 'maximizing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'compressed'},\n",
       " {'total_count': [], 'variations': [], 'word': 'measure'},\n",
       " {'total_count': [], 'variations': [], 'word': 'alignment'},\n",
       " {'total_count': [], 'variations': [], 'word': 'sgd'},\n",
       " {'total_count': [], 'variations': [], 'word': 'strategy'},\n",
       " {'total_count': [], 'variations': [], 'word': 'short'},\n",
       " {'total_count': [], 'variations': [], 'word': 'rank'},\n",
       " {'total_count': [], 'variations': [], 'word': 'parametric'},\n",
       " {'total_count': [], 'variations': [], 'word': 'matching'},\n",
       " {'total_count': [], 'variations': [], 'word': 'mcmc'},\n",
       " {'total_count': [], 'variations': [], 'word': 'lifted'},\n",
       " {'total_count': [], 'variations': [], 'word': 'positive'},\n",
       " {'total_count': [], 'variations': [], 'word': 'smooth'},\n",
       " {'total_count': [], 'variations': [], 'word': 'task'},\n",
       " {'total_count': [], 'variations': [], 'word': 'hierarchical'},\n",
       " {'total_count': [], 'variations': [], 'word': 'prior'},\n",
       " {'total_count': [], 'variations': [], 'word': 'mixing'},\n",
       " {'total_count': [], 'variations': [], 'word': 'ranking'},\n",
       " {'total_count': [], 'variations': [], 'word': 'completion'},\n",
       " {'total_count': [], 'variations': [], 'word': 'posterior'},\n",
       " {'total_count': [], 'variations': [], 'word': 'dropout'},\n",
       " {'total_count': [], 'variations': [], 'word': 'template'},\n",
       " {'total_count': [], 'variations': [], 'word': 'learning'},\n",
       " {'total_count': [], 'variations': [], 'word': 'chain'},\n",
       " {'total_count': [], 'variations': [], 'word': 'robustness'},\n",
       " {'total_count': [], 'variations': [], 'word': 'monte'},\n",
       " {'total_count': [], 'variations': [], 'word': 'carlo'},\n",
       " {'total_count': [], 'variations': [], 'word': 'descent'},\n",
       " {'total_count': [], 'variations': [], 'word': 'sequential'},\n",
       " {'total_count': [], 'variations': [], 'word': 'armed'},\n",
       " {'total_count': [], 'variations': [], 'word': 'composition'},\n",
       " {'total_count': [], 'variations': [], 'word': 'walk'},\n",
       " {'total_count': [], 'variations': [], 'word': 'high'},\n",
       " {'total_count': [], 'variations': [], 'word': 'topic'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nested dictionary: per unigram, list of years and unigram counts, per year, count of each variation\n",
    "\n",
    "info_2 = []\n",
    "\n",
    "for uni in unigrams:\n",
    "    for word, years in info_1.items():\n",
    "        if word == uni:\n",
    "            info_2.append({\n",
    "                'word': uni,\n",
    "                'variations': [],\n",
    "                'total_count': []\n",
    "            })\n",
    "            \n",
    "info_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(info_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in info_2:\n",
    "    uni = entry['word']\n",
    "    for word, years in info_1.items():\n",
    "        if len(years.items()) >= 2:\n",
    "            tokens = word.split()\n",
    "            for token in tokens:\n",
    "                if token == uni:\n",
    "                    entry['variations'].append({\n",
    "                        'n-gram': word,\n",
    "                        'years': [ { 'year': int(year), 'count': count[0] } for year, count in years.items() ]\n",
    "                    })\n",
    "                    if len(entry['total_count']) == 0:\n",
    "                        for year, count in years.items():\n",
    "                            entry['total_count'].append({\n",
    "                                'year': int(year),\n",
    "                                'count': count[0]\n",
    "                            })\n",
    "                    else:\n",
    "                        for year, count in years.items():\n",
    "                            in_entry = False\n",
    "                            for ct in entry['total_count']:\n",
    "                                if int(year) == ct['year']:\n",
    "                                    in_entry = True\n",
    "                                    ct['count'] += count[0]\n",
    "                            if not in_entry:\n",
    "                                entry['total_count'].append({\n",
    "                                    'year': int(year),\n",
    "                                    'count': count[0]\n",
    "                                })\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'multivariate regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'multivariate losses',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'multivariate hawkes process',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'multivariate'},\n",
       " {'total_count': [{'count': 5, 'year': 2016},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'sensing',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'compressed sensing',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'compressive sensing',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'compressive sensing mri',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'sensing'},\n",
       " {'total_count': [{'count': 18, 'year': 2009},\n",
       "   {'count': 8, 'year': 2014},\n",
       "   {'count': 12, 'year': 2010},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 13, 'year': 2013},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 12, 'year': 2011},\n",
       "   {'count': 12, 'year': 2008},\n",
       "   {'count': 14, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'regularization term',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'regularization',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 8, 'year': 2017}]},\n",
       "   {'n-gram': 'posterior regularization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'based regularization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'regularization schemes',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'adaptive regularization',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'regularization parameter',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'regularization functions',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'regularization approaches',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'regularization theory',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel regularization',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex regularization',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'trace norm regularization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse regularization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'natural regularization',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'spectral regularization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'regularization function',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'norm regularization',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'regularization'},\n",
       " {'total_count': [{'count': 10, 'year': 2014},\n",
       "   {'count': 9, 'year': 2013},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 12, 'year': 2012},\n",
       "   {'count': 13, 'year': 2016},\n",
       "   {'count': 11, 'year': 2011},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 13, 'year': 2015},\n",
       "   {'count': 18, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'maximum degree',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'maximum',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'maximum likelihood estimation',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'maximum node',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'maximum amount',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'maximum likelihood',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'exact maximum',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'joint maximum',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'maximum likelihood learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'global maximum',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'maximum entropy principle',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'maximum mean discrepancy',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'maximum entropy distribution',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'maximum variance',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'maximum likelihood estimates',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'maximum likelihood estimator',\n",
       "    'years': [{'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'maximum number',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'maximum likelihood training',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'approximate maximum',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'maximum'},\n",
       " {'total_count': [{'count': 28, 'year': 2016},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 6, 'year': 2007},\n",
       "   {'count': 16, 'year': 2012},\n",
       "   {'count': 14, 'year': 2017},\n",
       "   {'count': 15, 'year': 2011},\n",
       "   {'count': 13, 'year': 2009},\n",
       "   {'count': 14, 'year': 2014},\n",
       "   {'count': 13, 'year': 2015},\n",
       "   {'count': 17, 'year': 2010},\n",
       "   {'count': 8, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'probabilistic code',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic approach',\n",
       "    'years': [{'count': 3, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'probabilistic setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'probabilistic manner',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'probabilistic low',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic fashion',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probabilistic models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'probabilistic modeling',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'probabilistic dependencies',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'probabilistic',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'probabilistic inference algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel probabilistic model',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'probabilistic graphical models',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'probabilistic model',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'probabilistic pca',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'probabilistic program',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'probabilistic graphical model',\n",
       "    'years': [{'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic techniques',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probabilistic inference',\n",
       "    'years': [{'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'probabilistic programs',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'probabilistic analysis',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'new probabilistic model',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'probabilistic machine learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probabilistic method',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'probabilistic framework',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic formulation',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic bounds',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'probabilistic submodular models',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate probabilistic inference',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'probabilistic generative model',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'probabilistic'},\n",
       " {'total_count': [{'count': 6, 'year': 2016},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'symmetric tensors',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'symmetric matrices',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'symmetric group',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'symmetric',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'symmetric'},\n",
       " {'total_count': [{'count': 3, 'year': 2011},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 6, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'kernel construction',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'explicit construction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'breaking construction',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'feature construction',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'construction',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]}],\n",
       "  'word': 'construction'},\n",
       " {'total_count': [{'count': 10, 'year': 2009},\n",
       "   {'count': 60, 'year': 2016},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 96, 'year': 2017},\n",
       "   {'count': 27, 'year': 2014},\n",
       "   {'count': 28, 'year': 2015},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'unsupervised deep learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'deep architectures',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'deep networks',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 8, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'deep models',\n",
       "    'years': [{'count': 4, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'deep belief net',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'deep belief networks',\n",
       "    'years': [{'count': 2, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'deep multi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'deep convolutional networks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep learning models',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep boltzmann machines',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learn deep features',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'deep model',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'deep neural architectures',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'deep feed',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'deep learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 26, 'year': 2017}]},\n",
       "   {'n-gram': 'deep architectures trained',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'deep belief nets',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'deep neural network',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 6, 'year': 2014}]},\n",
       "   {'n-gram': 'deep network architecture',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'deep generative models',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'new deep architecture',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep neural networks',\n",
       "    'years': [{'count': 23, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised deep learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep learning architectures',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'deep reinforcement learning',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'deep learning framework',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'trained deep network',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'deep learning methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'deep learning approaches',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep network',\n",
       "    'years': [{'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'deep architecture',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'deep generative model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'deep'},\n",
       " {'total_count': [{'count': 14, 'year': 2010},\n",
       "   {'count': 11, 'year': 2013},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 11, 'year': 2015},\n",
       "   {'count': 12, 'year': 2017},\n",
       "   {'count': 13, 'year': 2014},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 3, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'structured graphs',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'structured outputs',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'structured way',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured parameters',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'structured svms',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'structured prediction tasks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'structured distributions',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'structured prediction problems',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured output learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'structured output prediction',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'structured estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured graphical models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'structured output',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured sparsity',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'structured problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'structured prediction',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 6, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'structured data',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'structured prior',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'structured predictors',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'structured'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 4, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 12, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'transfer learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'transfer',\n",
       "    'years': [{'count': 8, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'transfer knowledge',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'knowledge transfer',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'transfer'},\n",
       " {'total_count': [{'count': 11, 'year': 2009},\n",
       "   {'count': 19, 'year': 2017},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 18, 'year': 2016},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 13, 'year': 2012},\n",
       "   {'count': 13, 'year': 2013},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 4, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'statistical modeling',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'modeling spatio',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'mixture modeling',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'polyphonic music modeling',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'factor modeling',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sequence modeling',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'topic modeling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic modeling',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'layer modeling',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'modeling capacity',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'modeling framework',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'modeling distributions',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'statistical image modeling',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'generative modeling',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'joint modeling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'modeling multi',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'language modeling',\n",
       "    'years': [{'count': 4, 'year': 2016},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'modeling',\n",
       "    'years': [{'count': 6, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 7, 'year': 2017}]}],\n",
       "  'word': 'modeling'},\n",
       " {'total_count': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'decentralized',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'decentralized'},\n",
       " {'total_count': [{'count': 6, 'year': 2016},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 6, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'shot learning scenario',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'shot learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'one shot',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'shot'},\n",
       " {'total_count': [{'count': 14, 'year': 2012},\n",
       "   {'count': 19, 'year': 2015},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 19, 'year': 2014},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 11, 'year': 2010},\n",
       "   {'count': 8, 'year': 2008},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 16, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'making decisions',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'making use',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'making',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 12, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 8, 'year': 2010},\n",
       "     {'count': 7, 'year': 2008},\n",
       "     {'count': 10, 'year': 2015},\n",
       "     {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'decision making',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'perceptual decision making',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'thus making',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sequential decision making',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'making problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]}],\n",
       "  'word': 'making'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 3, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'conjugate models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'conjugate gradient method',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'conjugate exponential family',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'conjugate'},\n",
       " {'total_count': [{'count': 10, 'year': 2009},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 9, 'year': 2013},\n",
       "   {'count': 12, 'year': 2012},\n",
       "   {'count': 10, 'year': 2014},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 14, 'year': 2011},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 18, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'metric',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'new metric',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2012}]},\n",
       "   {'n-gram': 'mahalanobis distance metric',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'performance metric',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'compact metric spaces',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'chosen metric',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'wasserstein metric',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'euclidean metric',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'underlying metric',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'metric spaces',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2016}]},\n",
       "   {'n-gram': 'learned metric',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'metric learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'distance metric learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'metric learning',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'metric properties',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'metric space',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'distance metric',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'metric learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'metric'},\n",
       " {'total_count': [{'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'permutation distances',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'permutation',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'permutation testing',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'random permutation',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'permutation'},\n",
       " {'total_count': [{'count': 48, 'year': 2012},\n",
       "   {'count': 41, 'year': 2015},\n",
       "   {'count': 34, 'year': 2010},\n",
       "   {'count': 43, 'year': 2013},\n",
       "   {'count': 93, 'year': 2017},\n",
       "   {'count': 55, 'year': 2014},\n",
       "   {'count': 38, 'year': 2011},\n",
       "   {'count': 46, 'year': 2016},\n",
       "   {'count': 24, 'year': 2009},\n",
       "   {'count': 26, 'year': 2008},\n",
       "   {'count': 5, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'use multi',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'adaptive multi',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'parametric multi',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'contextual multi',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'stochastic multi',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'robust multi',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'based multi',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'scale multi',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'modern multi',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse multi',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'resulting multi',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'deep multi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'efficient multi',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'standard multi',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel multi',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exploiting multi',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'three multi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'existing multi',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'secure multi',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'recurrent multi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'new multi',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large multi',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'modeling multi',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'clustered multi',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'multi',\n",
       "    'years': [{'count': 21, 'year': 2009},\n",
       "     {'count': 5, 'year': 2007},\n",
       "     {'count': 33, 'year': 2013},\n",
       "     {'count': 40, 'year': 2012},\n",
       "     {'count': 46, 'year': 2014},\n",
       "     {'count': 39, 'year': 2016},\n",
       "     {'count': 31, 'year': 2011},\n",
       "     {'count': 29, 'year': 2010},\n",
       "     {'count': 20, 'year': 2008},\n",
       "     {'count': 32, 'year': 2015},\n",
       "     {'count': 76, 'year': 2017}]},\n",
       "   {'n-gram': 'learning multi',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised multi',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'proposed multi',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'consider multi',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'multi'},\n",
       " {'total_count': [{'count': 10, 'year': 2015},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 10, 'year': 2017},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 5, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'variable',\n",
       "    'years': [{'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'response variable',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'target variable',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'one variable',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'latent variable model',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variable selection',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'latent variable',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'decision variable',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'latent variable models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'single variable',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'variable'},\n",
       " {'total_count': [{'count': 18, 'year': 2017},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 11, 'year': 2016},\n",
       "   {'count': 15, 'year': 2015},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'selective attention',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'attention mechanism',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'visual attention',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'attracted much attention',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'received much attention',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human visual attention',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'attention',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 12, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 8, 'year': 2017}]},\n",
       "   {'n-gram': 'gained considerable attention',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'received considerable attention',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'attention mechanisms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'attention'},\n",
       " {'total_count': [{'count': 4, 'year': 2016},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 5, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'latent path',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'path',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'sample path',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'path'},\n",
       " {'total_count': [{'count': 24, 'year': 2016},\n",
       "   {'count': 9, 'year': 2011},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 12, 'year': 2015},\n",
       "   {'count': 15, 'year': 2017},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 16, 'year': 2013},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'bandit',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bandit convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic bandit problems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'armed bandit setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bandit problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bandit algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bandit problem',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'armed bandit problems',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'contextual bandit problems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'bandit feedback',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'armed bandit',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bandit settings',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'armed bandit problem',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'bandit setting',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'bandit'},\n",
       " {'total_count': [{'count': 20, 'year': 2009},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 15, 'year': 2016},\n",
       "   {'count': 7, 'year': 2007},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 7, 'year': 2010},\n",
       "   {'count': 9, 'year': 2008},\n",
       "   {'count': 17, 'year': 2015},\n",
       "   {'count': 34, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'positive semi',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'semi',\n",
       "    'years': [{'count': 19, 'year': 2009},\n",
       "     {'count': 6, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 8, 'year': 2012},\n",
       "     {'count': 10, 'year': 2014},\n",
       "     {'count': 11, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 9, 'year': 2008},\n",
       "     {'count': 16, 'year': 2015},\n",
       "     {'count': 33, 'year': 2017}]},\n",
       "   {'n-gram': 'new semi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'existing semi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'combinatorial semi',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'semi'},\n",
       " {'total_count': [{'count': 5, 'year': 2016},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 7, 'year': 2010},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 7, 'year': 2011},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'manifold learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'manifold structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'longitudinal manifold',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'data manifold',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'riemannian manifold',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'grassmann manifold',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'manifold learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'manifold',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'manifold optimization',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'manifold'},\n",
       " {'total_count': [{'count': 37, 'year': 2009},\n",
       "   {'count': 61, 'year': 2014},\n",
       "   {'count': 42, 'year': 2011},\n",
       "   {'count': 86, 'year': 2016},\n",
       "   {'count': 49, 'year': 2010},\n",
       "   {'count': 70, 'year': 2015},\n",
       "   {'count': 65, 'year': 2013},\n",
       "   {'count': 59, 'year': 2012},\n",
       "   {'count': 86, 'year': 2017},\n",
       "   {'count': 30, 'year': 2008},\n",
       "   {'count': 10, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'large images',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'large database',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'large probability',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'solving large',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large scale datasets',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'large training sets',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large data set',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large family',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'two large',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large collections',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large data sets',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'large scale applications',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'large values',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large databases',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'large alphabets',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exponentially large',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large network',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'large',\n",
       "    'years': [{'count': 9, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 27, 'year': 2013},\n",
       "     {'count': 26, 'year': 2012},\n",
       "     {'count': 20, 'year': 2014},\n",
       "     {'count': 33, 'year': 2016},\n",
       "     {'count': 17, 'year': 2011},\n",
       "     {'count': 22, 'year': 2010},\n",
       "     {'count': 12, 'year': 2008},\n",
       "     {'count': 28, 'year': 2015},\n",
       "     {'count': 37, 'year': 2017}]},\n",
       "   {'n-gram': 'many large',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'large fraction',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large scale problems',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'large set',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'several large',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large networks',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large dataset',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large scale classification',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'large populations',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'large margin learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning large',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large data',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large clusters',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'large datasets',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'large neural populations',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'large number',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 8, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 5, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'large amounts',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'large instances',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large scale learning',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large range',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large real',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large problem instances',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'three large',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'large models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'large numbers',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'relatively large number',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large amount',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'large graphs',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'large multi',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'truly large',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large corpus',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'arbitrarily large',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'large variance',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large scale',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'first large',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'large problems',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'large class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'large pool',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'large sets',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'large data sizes',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large scale non',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'large collection',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'large neuronal populations',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sufficiently large',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'large enough',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'large body',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large margin',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'large variety',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'large state spaces',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'large'},\n",
       " {'total_count': [{'count': 3, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 2, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'structural assumptions',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'structural equation model',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structural changes',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'structural properties',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'structural',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'structural sparsity',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'structural'},\n",
       " {'total_count': [{'count': 4, 'year': 2009},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 3, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'additive model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'additive',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'additive noise',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'additive noise models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse additive model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'additive models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'additive'},\n",
       " {'total_count': [{'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'asynchronous algorithms',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'asynchronous',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'asynchronous'},\n",
       " {'total_count': [{'count': 3, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 1, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'cold',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'cold start problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'cold'},\n",
       " {'total_count': [{'count': 2, 'year': 2017},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'mirror',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'mirror descent algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'accelerated mirror descent',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'mirror descent',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'mirror'},\n",
       " {'total_count': [{'count': 11, 'year': 2017},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 8, 'year': 2014},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'exploiting multi',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exploiting structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'exploiting',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 10, 'year': 2017}]}],\n",
       "  'word': 'exploiting'},\n",
       " {'total_count': [{'count': 33, 'year': 2017},\n",
       "   {'count': 13, 'year': 2010},\n",
       "   {'count': 18, 'year': 2012},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 28, 'year': 2016},\n",
       "   {'count': 22, 'year': 2013},\n",
       "   {'count': 10, 'year': 2009},\n",
       "   {'count': 27, 'year': 2015},\n",
       "   {'count': 20, 'year': 2014},\n",
       "   {'count': 16, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'scale optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'scale learning problems',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'large scale datasets',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'scale problems',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'scale data',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'scale exponentially',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale optimization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'scale multi',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large scale applications',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'easily scale',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'scale well',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2016}]},\n",
       "   {'n-gram': 'scale distributed training',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'scale setting',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large scale problems',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'large scale classification',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'scale applications',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'scale tasks',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'large scale learning',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'scale beyond',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale networks',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'scale',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 10, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 10, 'year': 2015},\n",
       "     {'count': 13, 'year': 2017}]},\n",
       "   {'n-gram': 'scale learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale efficiently',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale datasets',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'time scale',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'large scale',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'scale structure',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'scale dataset',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'large scale non',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'scale graphical models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'scale poorly',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale data sets',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'scale'},\n",
       " {'total_count': [{'count': 18, 'year': 2017},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 20, 'year': 2011},\n",
       "   {'count': 15, 'year': 2016},\n",
       "   {'count': 12, 'year': 2013},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 6, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'action values',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'chosen action',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'action space',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'temporal action localization',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'action potential',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'best action',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'action classification',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'human action recognition',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'action spaces',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'greedy action selection',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'action models',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'action',\n",
       "    'years': [{'count': 8, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 9, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 7, 'year': 2013}]},\n",
       "   {'n-gram': 'action potential generation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'optimal action',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'action pairs',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'action potentials',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'video action recognition',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'action pair',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'action recognition',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014}]}],\n",
       "  'word': 'action'},\n",
       " {'total_count': [{'count': 3, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 5, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 14, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'choice',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 11, 'year': 2015},\n",
       "     {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'choice tasks',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'proper choice',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'choice behavior',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'choice axiom',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'careful choice',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'choice'},\n",
       " {'total_count': [{'count': 19, 'year': 2017},\n",
       "   {'count': 9, 'year': 2014},\n",
       "   {'count': 13, 'year': 2015},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 11, 'year': 2013},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 11, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'alternating minimization algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'norm minimization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general submodular minimization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'nuclear norm minimization',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'regret minimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular minimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bellman residual minimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'minimization problems',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'counterfactual regret minimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'minimization problem',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'empirical risk minimization',\n",
       "    'years': [{'count': 6, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'minimization algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'risk minimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'alternating minimization',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'minimization',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'efficient minimization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'rank minimization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'minimization'},\n",
       " {'total_count': [{'count': 8, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 10, 'year': 2017},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'weighted average',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'average degree',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'average',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'average ).',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'triggered average',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'mean average precision',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'average'},\n",
       " {'total_count': [{'count': 4, 'year': 2016},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 1, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'convolution',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'convolution operations',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'convolution'},\n",
       " {'total_count': [{'count': 5, 'year': 2007},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 14, 'year': 2017},\n",
       "   {'count': 8, 'year': 2008},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 20, 'year': 2014},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 10, 'year': 2009},\n",
       "   {'count': 18, 'year': 2015},\n",
       "   {'count': 18, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'fast variational inference',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'fast similarity search',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'fast closed',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'fast method',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'fast alternative',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'fast mixing',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'fast prediction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'fast algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'fast convergence',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'fast computation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'fast rates',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'fast two',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'fast learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'fast',\n",
       "    'years': [{'count': 8, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 12, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'provably fast',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'fast algorithms',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'fast learning rate',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'extremely fast',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'fast inference',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'fast'},\n",
       " {'total_count': [{'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'hilbert spaces',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'kernel hilbert spaces',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'hilbert space',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2014}]}],\n",
       "  'word': 'hilbert'},\n",
       " {'total_count': [{'count': 9, 'year': 2009},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 12, 'year': 2013},\n",
       "   {'count': 12, 'year': 2008},\n",
       "   {'count': 11, 'year': 2010},\n",
       "   {'count': 14, 'year': 2016},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 14, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'promote sparsity',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'induce sparsity',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'unknown sparsity',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'enforce sparsity',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'sparsity assumptions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparsity',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 7, 'year': 2008},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'extreme data sparsity',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparsity level',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparsity pattern',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparsity properties',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured sparsity',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'joint sparsity constraints',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'joint sparsity',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'group sparsity',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'structural sparsity',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'sparsity'},\n",
       " {'total_count': [{'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 2, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'translational invariance',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'invariance',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]}],\n",
       "  'word': 'invariance'},\n",
       " {'total_count': [{'count': 17, 'year': 2009},\n",
       "   {'count': 20, 'year': 2013},\n",
       "   {'count': 22, 'year': 2016},\n",
       "   {'count': 18, 'year': 2014},\n",
       "   {'count': 19, 'year': 2012},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 13, 'year': 2008},\n",
       "   {'count': 9, 'year': 2011},\n",
       "   {'count': 28, 'year': 2017},\n",
       "   {'count': 18, 'year': 2010},\n",
       "   {'count': 16, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'latent feature models',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'latent representation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'latent causes',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'latent dynamical model',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'latent information',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'latent variables',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'latent topics',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'latent features',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'latent function',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'latent variable model',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'latent codes',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'binary latent variables',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'latent states',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'latent factor model',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'latent embeddings',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'latent structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'latent code',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'latent dirichlet allocation',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'latent gaussian models',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'latent source model',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'latent components',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'latent structures',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'latent variable',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'latent path',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'latent',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'latent functions',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'latent factors',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'latent space',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'latent variable models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'latent feature space',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'latent state',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'latent'},\n",
       " {'total_count': [{'count': 7, 'year': 2009},\n",
       "   {'count': 6, 'year': 2007},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 4, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'unlabeled data',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'unlabeled examples',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'use unlabeled data',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unlabeled training data',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'unlabeled points',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'unlabeled samples',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'unlabeled'},\n",
       " {'total_count': [{'count': 16, 'year': 2016},\n",
       "   {'count': 17, 'year': 2017},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 13, 'year': 2014},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 6, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'submodular function',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular cover',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'general submodular minimization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'monotone submodular functions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'submodular minimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'submodular optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular function subject',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'submodular energies',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular function maximization',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular maximization',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'general submodular functions',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'submodular functions',\n",
       "    'years': [{'count': 6, 'year': 2017},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013}]},\n",
       "   {'n-gram': 'monotone submodular function',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'submodular cover problem',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular set cover',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular set functions',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'minimizing submodular functions',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'approximately submodular functions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'probabilistic submodular models',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'submodular'},\n",
       " {'total_count': [{'count': 15, 'year': 2014},\n",
       "   {'count': 8, 'year': 2013},\n",
       "   {'count': 12, 'year': 2015},\n",
       "   {'count': 12, 'year': 2017},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 11, 'year': 2012},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'scalable approach',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scalable algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'scalable solutions',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'scalable algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'scalable methods',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scalable',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008}]},\n",
       "   {'n-gram': 'scalable implementation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'scalable training',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'highly scalable',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'scalable inference',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'scalable'},\n",
       " {'total_count': [{'count': 3, 'year': 2017},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'guided',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'guided policy search',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'guided'},\n",
       " {'total_count': [{'count': 3, 'year': 2010},\n",
       "   {'count': 12, 'year': 2015},\n",
       "   {'count': 12, 'year': 2016},\n",
       "   {'count': 7, 'year': 2017},\n",
       "   {'count': 12, 'year': 2011},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 10, 'year': 2014},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'sparse signal recovery',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimal recovery',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'recovery algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'recovery algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'support recovery performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'recovery guarantee',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'successful recovery',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse recovery problem',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exact recovery',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'support recovery',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'rank matrix recovery',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'recovery performance',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'recovery',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'perfect recovery',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse recovery',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'signal recovery',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stable recovery',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'recovery'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 5, 'year': 2017},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 10, 'year': 2013},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'tensor',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'rank tensor',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'tensor decompositions',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'tensor decomposition',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'tensor completion',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'tensor factorization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tensor structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'tensor power method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tensor candecomp',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'tensor'},\n",
       " {'total_count': [{'count': 41, 'year': 2017},\n",
       "   {'count': 55, 'year': 2014},\n",
       "   {'count': 17, 'year': 2009},\n",
       "   {'count': 26, 'year': 2011},\n",
       "   {'count': 46, 'year': 2016},\n",
       "   {'count': 34, 'year': 2015},\n",
       "   {'count': 9, 'year': 2007},\n",
       "   {'count': 29, 'year': 2013},\n",
       "   {'count': 20, 'year': 2012},\n",
       "   {'count': 16, 'year': 2010},\n",
       "   {'count': 12, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'general polytopes',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general family',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'general loss function',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general result',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general log',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general framework based',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general methodology',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 12, 'year': 2014},\n",
       "     {'count': 13, 'year': 2016},\n",
       "     {'count': 10, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 18, 'year': 2017}]},\n",
       "   {'n-gram': 'general submodular minimization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'general framework',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 11, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013}]},\n",
       "   {'n-gram': 'general learning framework',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'general model',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'general non',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'general class',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'general np',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'general loss functions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'general technique',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general formalism',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'general problems',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'general approach',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'general assumptions',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'general context',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'general settings',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general method',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'general hard',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'general intractable',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general case',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general sufficient conditions',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'general setting',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'general notion',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'general question',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general submodular functions',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'general theory',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general set',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'general graphs',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'general algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general problem',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'general noise models',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'general form',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'general enough',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'general mechanism',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'general analysis',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'general bounds',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general formulation',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'general'},\n",
       " {'total_count': [{'count': 9, 'year': 2009},\n",
       "   {'count': 16, 'year': 2014},\n",
       "   {'count': 8, 'year': 2008},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 9, 'year': 2015},\n",
       "   {'count': 16, 'year': 2017},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 15, 'year': 2016},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 3, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'factor models',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'factor graph',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'factor analysis',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'constant factor',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'approximation factor',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'discount factor',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'factor modeling',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'factor',\n",
       "    'years': [{'count': 10, 'year': 2017},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'latent factor model',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'process factor analysis',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'logarithmic factor',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'factor graphs',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'factor'},\n",
       " {'total_count': [{'count': 4, 'year': 2016},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 3, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'wolfe algorithm',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'wolfe',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 6, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'wolfe'},\n",
       " {'total_count': [{'count': 27, 'year': 2009},\n",
       "   {'count': 19, 'year': 2016},\n",
       "   {'count': 17, 'year': 2008},\n",
       "   {'count': 21, 'year': 2014},\n",
       "   {'count': 26, 'year': 2013},\n",
       "   {'count': 28, 'year': 2012},\n",
       "   {'count': 17, 'year': 2011},\n",
       "   {'count': 42, 'year': 2017},\n",
       "   {'count': 20, 'year': 2015},\n",
       "   {'count': 17, 'year': 2010},\n",
       "   {'count': 3, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'nonparametric regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'dimensional regression',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'output regression',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'task regression',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'kernel regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse linear regression',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'regression problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'regression model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'regression algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'valued regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'ordinal regression',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse regression',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'least squares regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'regression coefficients',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'kernel ridge regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'regularized logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'linear regression models',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'regression trees',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'multivariate regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'regression surfaces',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'ridge regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'linear regression',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'regression',\n",
       "    'years': [{'count': 7, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 11, 'year': 2017}]},\n",
       "   {'n-gram': 'regression task',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'regression function',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'regression tasks',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'regression problem',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'locally weighted regression',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'parametric regression',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'gaussian process regression',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'squares regression',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'isotonic regression',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'weighted regression',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'robust regression',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'linear regression problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'regression'},\n",
       " {'total_count': [{'count': 2, 'year': 2011},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 8, 'year': 2014},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'based stochastic factorization',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'nonnegative matrix factorization',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rank factorization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'factorization machines',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'matrix factorization',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'natural factorization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tensor factorization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'factorization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'negative matrix factorization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2016}]}],\n",
       "  'word': 'factorization'},\n",
       " {'total_count': [{'count': 5, 'year': 2016},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'submodular cover',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'submodular cover problem',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular set cover',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'cover',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010}]}],\n",
       "  'word': 'cover'},\n",
       " {'total_count': [{'count': 16, 'year': 2009},\n",
       "   {'count': 37, 'year': 2016},\n",
       "   {'count': 34, 'year': 2013},\n",
       "   {'count': 43, 'year': 2017},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 21, 'year': 2012},\n",
       "   {'count': 26, 'year': 2014},\n",
       "   {'count': 32, 'year': 2015},\n",
       "   {'count': 4, 'year': 2007},\n",
       "   {'count': 22, 'year': 2011},\n",
       "   {'count': 18, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'low rank matrix',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'low sample complexity',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'low dimensional representation',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'low computational complexity',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'low error',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'low',\n",
       "    'years': [{'count': 12, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 28, 'year': 2013},\n",
       "     {'count': 12, 'year': 2012},\n",
       "     {'count': 18, 'year': 2014},\n",
       "     {'count': 30, 'year': 2016},\n",
       "     {'count': 17, 'year': 2011},\n",
       "     {'count': 15, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 25, 'year': 2015},\n",
       "     {'count': 35, 'year': 2017}]},\n",
       "   {'n-gram': 'low computational cost',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probabilistic low',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning low',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learn low',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'low rank',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'low dimension',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'adaptive low',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'low variance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'low noise',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'low rank approximation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'recovering low',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'low probability',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'low communication',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'low'},\n",
       " {'total_count': [{'count': 11, 'year': 2016},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 13, 'year': 2017},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 7, 'year': 2010},\n",
       "   {'count': 11, 'year': 2009},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 5, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'community detection',\n",
       "    'years': [{'count': 7, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'saliency detection',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'anomaly detection',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'detection',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'pedestrian detection',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object detection',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'detection performance',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'point detection',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'outlier detection',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'detection'},\n",
       " {'total_count': [{'count': 7, 'year': 2011},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'poisson distributions',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'poisson process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'poisson',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'poisson distribution',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'poisson'},\n",
       " {'total_count': [{'count': 8, 'year': 2016},\n",
       "   {'count': 11, 'year': 2017},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'policy policy evaluation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'evaluation forms',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'experimental evaluation demonstrates',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'extensive evaluation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'evaluation',\n",
       "    'years': [{'count': 6, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2010}]},\n",
       "   {'n-gram': 'experimental evaluation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'evaluation metrics',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'empirical evaluation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'extensive empirical evaluation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'experimental evaluation shows',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'policy evaluation',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]}],\n",
       "  'word': 'evaluation'},\n",
       " {'total_count': [{'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'measurement matrix',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'measurement',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'noisy measurement',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'measurement'},\n",
       " {'total_count': [{'count': 3, 'year': 2016},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'message passing',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'variational message passing',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'message passing inference',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate message passing',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'approximate message',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'message passing algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'message passing algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dual message',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'message',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'message'},\n",
       " {'total_count': [{'count': 18, 'year': 2014},\n",
       "   {'count': 8, 'year': 2013},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 31, 'year': 2016},\n",
       "   {'count': 35, 'year': 2017},\n",
       "   {'count': 9, 'year': 2009},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 7, 'year': 2010},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 6, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'generative approach',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'generative adversarial networks',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'generative',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'generative adversarial network',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'generative process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'generative models',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'deep generative models',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'powerful generative models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'generative modeling',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'nonlinear generative models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'generative model',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'generative adversarial nets',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep generative model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probabilistic generative model',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'generative'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 7, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'slow',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'slow convergence',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'slow'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 1, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'motor cortex',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'motor cortices',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'motor control',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'motor'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 4, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 7, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'collaborative filtering',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'collaborative',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'collaborative ranking',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'collaborative'},\n",
       " {'total_count': [{'count': 3, 'year': 2009},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 3, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'driven approach',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'driven manner',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'driven selection',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'driven model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'driven',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]}],\n",
       "  'word': 'driven'},\n",
       " {'total_count': [{'count': 15, 'year': 2017},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 17, 'year': 2015},\n",
       "   {'count': 10, 'year': 2008},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 11, 'year': 2013},\n",
       "   {'count': 10, 'year': 2014},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 6, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'kernel dimension reduction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'error reduction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'significant reduction',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised dimensionality reduction',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensionality reduction',\n",
       "    'years': [{'count': 2, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'variance reduction',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'noise reduction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'expected reduction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'nonlinear dimensionality reduction',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'dimension reduction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'reduction',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'variance reduction algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'layer feature reduction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unsupervised dimensionality reduction',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensionality reduction methods',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel reduction',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2013}]}],\n",
       "  'word': 'reduction'},\n",
       " {'total_count': [{'count': 2, 'year': 2014},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 4, 'year': 2016},\n",
       "   {'count': 1, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'proposal distribution',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'proposal',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'proposal'},\n",
       " {'total_count': [{'count': 4, 'year': 2011},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'crowdsourcing systems',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'crowdsourcing',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2014}]}],\n",
       "  'word': 'crowdsourcing'},\n",
       " {'total_count': [{'count': 13, 'year': 2017},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 11, 'year': 2012},\n",
       "   {'count': 15, 'year': 2015},\n",
       "   {'count': 15, 'year': 2016},\n",
       "   {'count': 15, 'year': 2014},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 10, 'year': 2013},\n",
       "   {'count': 6, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'unknown parameters',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unknown distribution',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'unknown smoothness',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unknown sparsity',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'unknown',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'unknown variables',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'unknown coefficients',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'unknown data',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unknown set',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'largely unknown',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'unknown subset',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'often unknown',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unknown signal',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'unknown properties',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'unknown number',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'unknown function',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'unknown'},\n",
       " {'total_count': [{'count': 21, 'year': 2016},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 15, 'year': 2017},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 12, 'year': 2010},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 19, 'year': 2014},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 3, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'practical solution',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'practical bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'practical problems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'practical implications',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'practical applications',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'practical',\n",
       "    'years': [{'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'practical use',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'significant practical importance',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'practical estimators',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'practical performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'practical algorithm',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'practical algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'practical value',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'practical usefulness',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'practical effectiveness',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'also practical',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'practical approach',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'practical settings',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'practical methods',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'practical implementation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'practical interest',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'first practical algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'practical problem',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'practical impact',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'many practical applications',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'practical'},\n",
       " {'total_count': [{'count': 49, 'year': 2016},\n",
       "   {'count': 34, 'year': 2013},\n",
       "   {'count': 27, 'year': 2009},\n",
       "   {'count': 42, 'year': 2017},\n",
       "   {'count': 41, 'year': 2014},\n",
       "   {'count': 28, 'year': 2010},\n",
       "   {'count': 29, 'year': 2012},\n",
       "   {'count': 25, 'year': 2015},\n",
       "   {'count': 21, 'year': 2011},\n",
       "   {'count': 11, 'year': 2008},\n",
       "   {'count': 7, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'important case',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'studied case',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'case guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'worst case',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'two case studies',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'case study',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'realizable case',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'case analysis',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'dimensional case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'one case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'extreme case',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'case bounds',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'general case',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'case approach',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2016}]},\n",
       "   {'n-gram': 'common case',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'case performance',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'compelling case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'discrete case',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'case regret',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'case',\n",
       "    'years': [{'count': 15, 'year': 2009},\n",
       "     {'count': 6, 'year': 2007},\n",
       "     {'count': 18, 'year': 2013},\n",
       "     {'count': 20, 'year': 2012},\n",
       "     {'count': 22, 'year': 2014},\n",
       "     {'count': 23, 'year': 2016},\n",
       "     {'count': 9, 'year': 2011},\n",
       "     {'count': 16, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 12, 'year': 2015},\n",
       "     {'count': 28, 'year': 2017}]},\n",
       "   {'n-gram': 'noiseless case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'limiting special case',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'pairwise case',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'test case',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'important special case',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'special case',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 6, 'year': 2017}]}],\n",
       "  'word': 'case'},\n",
       " {'total_count': [{'count': 16, 'year': 2014},\n",
       "   {'count': 37, 'year': 2015},\n",
       "   {'count': 46, 'year': 2017},\n",
       "   {'count': 12, 'year': 2011},\n",
       "   {'count': 15, 'year': 2012},\n",
       "   {'count': 52, 'year': 2016},\n",
       "   {'count': 10, 'year': 2009},\n",
       "   {'count': 8, 'year': 2010},\n",
       "   {'count': 25, 'year': 2013},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 2, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'stochastic gradient techniques',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic primal',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'based stochastic factorization',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'stochastic block model',\n",
       "    'years': [{'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic optimization',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 7, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic blockmodels',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic multi',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'stochastic dynamics',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'stochastic bandit problems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'stochastic first',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic gradient mcmc',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic environments',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'stochastic block models',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic approximation',\n",
       "    'years': [{'count': 3, 'year': 2017}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'stochastic linear bandits',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic optimal control',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic approximation method',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'stochastic process',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'membership stochastic blockmodel',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'stochastic gradient',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic neural networks',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'stochastic gradients',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic gradient methods',\n",
       "    'years': [{'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic setting',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic neighbor embedding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic bandits',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic processes',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'stochastic differential equations',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'stochastic approximation algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'stochastic gradient descent',\n",
       "    'years': [{'count': 13, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic transitions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic approximations',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic optimization algorithms',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic nature',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic approximation problem',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic kinetic model',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel stochastic process',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'stochastic',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic variational inference',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic gradient method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'stochastic'},\n",
       " {'total_count': [{'count': 8, 'year': 2016},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'passing',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'message passing',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'variational message passing',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'passing algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'message passing inference',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate message passing',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'message passing algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'message passing algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'passing algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016}]}],\n",
       "  'word': 'passing'},\n",
       " {'total_count': [{'count': 5, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 4, 'year': 2016},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 2, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'neighbor',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'nearest neighbor graphs',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'neighbor search',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'nearest neighbor classification',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'nearest neighbor classifier',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'stochastic neighbor embedding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'nearest neighbor',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'nearest neighbor search',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'neighbor classifier',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'nearest neighbor graph',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'neighbor'},\n",
       " {'total_count': [{'count': 138, 'year': 2013},\n",
       "   {'count': 98, 'year': 2012},\n",
       "   {'count': 66, 'year': 2008},\n",
       "   {'count': 187, 'year': 2016},\n",
       "   {'count': 95, 'year': 2011},\n",
       "   {'count': 174, 'year': 2014},\n",
       "   {'count': 134, 'year': 2015},\n",
       "   {'count': 97, 'year': 2010},\n",
       "   {'count': 207, 'year': 2017},\n",
       "   {'count': 71, 'year': 2009},\n",
       "   {'count': 32, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'hastings algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'line learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'approximate algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'iterative algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm starts',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'reinforcement learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm identifies',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'recent algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'recently proposed algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm applies',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm achieves',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'search algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm finds solutions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm requires',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm yields',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'combined algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'adaptive algorithm',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'based learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm makes',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'propagation algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm uses',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'alternating minimization algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'parallel algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'inference algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'novel algorithm based',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm provides',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'recovery algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm proceeds',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'centralized algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'wolfe algorithm',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'regression algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'fast algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'new boosting algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'algorithm estimates',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'backward greedy algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'svm algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'estimation algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'planning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'belief propagation algorithm',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'based algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'efficient learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'means algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'active learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'baseline algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'new online algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm benefits',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'classification algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning algorithm',\n",
       "    'years': [{'count': 6, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'new learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'mirror descent algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exact algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'batch algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'based clustering algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'iteration algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bandit algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm performs',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm design',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'gradient ascent algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'passing algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'algorithm based',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'boosting algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'scalable algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm generalizes',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'efficient spectral algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'task learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bfgs algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'first algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'new algorithm',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'novel sampling algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'practical algorithm',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bayesian algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'algorithm returns',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'algorithm outperforms',\n",
       "    'years': [{'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm converges',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm solves',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'meta algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm succeeds',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'like algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'existing algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sampling algorithm',\n",
       "    'years': [{'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'novel algorithm',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'simple greedy algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm used',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'weak learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm',\n",
       "    'years': [{'count': 31, 'year': 2009},\n",
       "     {'count': 15, 'year': 2007},\n",
       "     {'count': 48, 'year': 2013},\n",
       "     {'count': 33, 'year': 2012},\n",
       "     {'count': 68, 'year': 2014},\n",
       "     {'count': 77, 'year': 2016},\n",
       "     {'count': 44, 'year': 2011},\n",
       "     {'count': 44, 'year': 2010},\n",
       "     {'count': 27, 'year': 2008},\n",
       "     {'count': 62, 'year': 2015},\n",
       "     {'count': 85, 'year': 2017}]},\n",
       "   {'n-gram': 'spectral algorithm',\n",
       "    'years': [{'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'regret algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm allows',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'simple algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'dual algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'proposed algorithm outperforms',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm performs well',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'efficient online algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'minimization algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'variational bayes algorithm',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'resulting algorithm',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'product algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel distributed algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'efficient streaming algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'training algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm runs',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'gibbs sampling algorithm',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm generates',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'optimization algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm scales',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'maximization algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'algorithm converges linearly',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'em algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'original algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'exponential weights algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm combines',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'general algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'critic algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'art algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'efficient randomized algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'randomized algorithm',\n",
       "    'years': [{'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'algorithm offers',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'backward algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'approximate em algorithm',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm learns',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'online learning algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'efficient algorithm',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'greedy algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'ucb algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'effective algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm ),',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'online algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'base algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'algorithm designed',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'proposed algorithm',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 9, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 8, 'year': 2017}]},\n",
       "   {'n-gram': 'expectation maximization algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'message passing algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'first practical algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'algorithm selects',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dynamic programming algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'unified algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bp algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm using',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm obtains',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'popular algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate inference algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'developed algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'second algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm finds',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'algorithm enables us',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'new spectral algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'efficient algorithm based',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'anytime algorithm',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'algorithm relies',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'time algorithm',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'computationally efficient algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'clustering algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'optimal algorithm',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'proposed algorithm achieves',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'algorithm'},\n",
       " {'total_count': [{'count': 20, 'year': 2016},\n",
       "   {'count': 16, 'year': 2011},\n",
       "   {'count': 26, 'year': 2017},\n",
       "   {'count': 23, 'year': 2014},\n",
       "   {'count': 24, 'year': 2015},\n",
       "   {'count': 15, 'year': 2009},\n",
       "   {'count': 16, 'year': 2008},\n",
       "   {'count': 23, 'year': 2013},\n",
       "   {'count': 14, 'year': 2010},\n",
       "   {'count': 14, 'year': 2012},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'spectral graph theory',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'original graph',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'factor graph',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'complete graph',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bipartite graph',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'graph structure',\n",
       "    'years': [{'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'graph nodes',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'graph partitioning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'similarity graph',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'directed acyclic graph',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'causal graph',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'underlying graph',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'graph laplacian',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'graph',\n",
       "    'years': [{'count': 6, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 15, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 12, 'year': 2014},\n",
       "     {'count': 11, 'year': 2016},\n",
       "     {'count': 5, 'year': 2011},\n",
       "     {'count': 11, 'year': 2010},\n",
       "     {'count': 7, 'year': 2008},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 17, 'year': 2017}]},\n",
       "   {'n-gram': 'underlying graph structure',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'weighted graph',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'attributed graph',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'graph clustering',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'graph estimation',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'graph matching',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'graph transduction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'graph zeta function',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'nearest neighbor graph',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'graph sketching',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'graph embedding',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'chain graph models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'graph'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'aggregation',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rank aggregation',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'aggregation'},\n",
       " {'total_count': [{'count': 10, 'year': 2012},\n",
       "   {'count': 10, 'year': 2015},\n",
       "   {'count': 11, 'year': 2009},\n",
       "   {'count': 9, 'year': 2014},\n",
       "   {'count': 16, 'year': 2010},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 10, 'year': 2011},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 15, 'year': 2017},\n",
       "   {'count': 11, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'human faces',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human behavior',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'human learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'human activities',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'human data',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'human learners',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human feature learning',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'human brain',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'human perception',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'human visual system',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human cognition',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human feedback',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'human action recognition',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'human actions',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'human memory search',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human judgments',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'human visual attention',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'human subjects',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'human pose estimation',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'human labeling',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'human expert',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'meaningful human judgments',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'human performance',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'human',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 7, 'year': 2017}]}],\n",
       "  'word': 'human'},\n",
       " {'total_count': [{'count': 11, 'year': 2016},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'fixed memory budget',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'fixed budget',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'given budget',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'budget',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'fixed labeling budget',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'budget'},\n",
       " {'total_count': [{'count': 51, 'year': 2017},\n",
       "   {'count': 22, 'year': 2011},\n",
       "   {'count': 21, 'year': 2013},\n",
       "   {'count': 26, 'year': 2012},\n",
       "   {'count': 34, 'year': 2015},\n",
       "   {'count': 30, 'year': 2016},\n",
       "   {'count': 14, 'year': 2008},\n",
       "   {'count': 31, 'year': 2014},\n",
       "   {'count': 8, 'year': 2009},\n",
       "   {'count': 11, 'year': 2010},\n",
       "   {'count': 5, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'regret bound scales',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'error bound',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'new lower bound',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'pac bound',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'asymptotic regret bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dependent bound',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variational lower bound',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'convex upper bound',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': ')$ bound',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dependent lower bound',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'upper bound',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'performance bound',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'generalization bound',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimal bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'also bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'evidence lower bound',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'tight upper bound',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rao lower bound',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sample complexity bound',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'lower bound matches',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'lower bound',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'sample error bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'bound',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 8, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 10, 'year': 2008},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 19, 'year': 2017}]},\n",
       "   {'n-gram': 'mistake bound',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'regret lower bound',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'generalization error bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'new bound',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'regret bound',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': ')$ regret bound',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'upper confidence bound',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel lower bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'dependent regret bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'vc bound',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'approximation error bound',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'lower bound showing',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'complexity bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'free bound',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'bound'},\n",
       " {'total_count': [{'count': 6, 'year': 2017},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 11, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'quadratic dependence',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dependence',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'linear dependence',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'joint dependence',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'polynomial dependence',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'better dependence',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'optimal dependence',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dependence structure',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'dependence'},\n",
       " {'total_count': [{'count': 10, 'year': 2016},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'ordinal embedding',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'kernel embedding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'embedding',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'embedding vectors',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic neighbor embedding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'graph embedding',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'embedding'},\n",
       " {'total_count': [{'count': 8, 'year': 2017},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 8, 'year': 2008},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 5, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'binary classifier',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimal classifier',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'classifier design',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'nearest neighbor classifier',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'target classifier',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'linear classifier',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'based discriminative classifier',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'kernel classifier',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'svm classifier',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'learned classifier',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'neighbor classifier',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'object classifier',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'classifier',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]}],\n",
       "  'word': 'classifier'},\n",
       " {'total_count': [{'count': 8, 'year': 2009},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 7, 'year': 2017},\n",
       "   {'count': 8, 'year': 2013},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 10, 'year': 2015},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'based active learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'active learning policy',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'active learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'active learning',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 8, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'active area',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'active',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'active set',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'active learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian active learning',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'active'},\n",
       " {'total_count': [{'count': 16, 'year': 2010},\n",
       "   {'count': 27, 'year': 2013},\n",
       "   {'count': 29, 'year': 2014},\n",
       "   {'count': 21, 'year': 2016},\n",
       "   {'count': 21, 'year': 2011},\n",
       "   {'count': 30, 'year': 2017},\n",
       "   {'count': 12, 'year': 2015},\n",
       "   {'count': 16, 'year': 2009},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 18, 'year': 2012},\n",
       "   {'count': 5, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'dimensional subspaces',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional regression',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional representations',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dimensional gaussian mixtures',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'dimensional scaling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensional setting',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional problems',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'low dimensional representation',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensional datasets',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'dimensional limit',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional signals',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'high dimensional settings',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'dimensional gaussian distribution',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional feature space',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensional space',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional regime',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional state spaces',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'dimensional long short',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dimensional case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional parameter space',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional representation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensional embeddings',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'high dimensional data',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'dimensional structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'high dimensional inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'dimensional estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'high dimensional problems',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high dimensional vectors',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'high dimensional setting',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dimensional data',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'dimensional subspace',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional inputs',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional single',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'high dimensional',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional framework',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'dimensional distributions',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dimensional non',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dimensional analysis',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'dimensional settings',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013}]}],\n",
       "  'word': 'dimensional'},\n",
       " {'total_count': [{'count': 1, 'year': 2016},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'attribute',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'attribute'},\n",
       " {'total_count': [{'count': 2, 'year': 2017},\n",
       "   {'count': 17, 'year': 2013},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 12, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 8, 'year': 2008},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'streaming pca',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sparse pca',\n",
       "    'years': [{'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'probabilistic pca',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'robust pca',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'usual pca',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'standard pca',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse pca problem',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'exponential family pca',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'pca',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'pca ),',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 3, 'year': 2013}]}],\n",
       "  'word': 'pca'},\n",
       " {'total_count': [{'count': 18, 'year': 2009},\n",
       "   {'count': 32, 'year': 2017},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 20, 'year': 2016},\n",
       "   {'count': 24, 'year': 2014},\n",
       "   {'count': 14, 'year': 2010},\n",
       "   {'count': 13, 'year': 2008},\n",
       "   {'count': 10, 'year': 2011},\n",
       "   {'count': 19, 'year': 2013},\n",
       "   {'count': 23, 'year': 2015},\n",
       "   {'count': 3, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'online convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'online learning algorithms',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'online advertising',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'online algorithms',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online mondrian forests',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online learning',\n",
       "    'years': [{'count': 9, 'year': 2009},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 10, 'year': 2013},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'online learning setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online methods',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'new online algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online framework',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'online linear optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'online optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'online learner',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'online learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online learning framework',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'theoretic online learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'efficient online algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008}]},\n",
       "   {'n-gram': 'free online learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'online prediction',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online fashion',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online learning algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online approximation',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'online algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'online setting',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'online learning approaches',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online planning',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'online inference',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'online'},\n",
       " {'total_count': [{'count': 7, 'year': 2009},\n",
       "   {'count': 34, 'year': 2017},\n",
       "   {'count': 19, 'year': 2013},\n",
       "   {'count': 20, 'year': 2016},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 14, 'year': 2014},\n",
       "   {'count': 23, 'year': 2015},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'training objective',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'objective functions',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'nonconvex objective functions',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'based objective',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'variational objective',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'learning objective',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'objective function',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 11, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013}]},\n",
       "   {'n-gram': 'convex objective functions',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'objective directly',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'new objective function',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex objective function',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'objective',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 9, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 13, 'year': 2017}]},\n",
       "   {'n-gram': 'means objective',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'convex objective',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'objective'},\n",
       " {'total_count': [{'count': 4, 'year': 2011},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 10, 'year': 2017},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 6, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 2, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'coordinate descent method',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'local coordinate coding',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'coordinate descent',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'coordinate descent approach',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'coordinate',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'local coordinate system',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'block coordinate descent',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'randomized coordinate descent',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'coordinate'},\n",
       " {'total_count': [{'count': 4, 'year': 2017},\n",
       "   {'count': 8, 'year': 2014},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 4, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'subspace clustering',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'subspace identification',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'linear subspace',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'independent subspace analysis',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'dimensional subspace',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'subspace',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'subspace'},\n",
       " {'total_count': [{'count': 7, 'year': 2017},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 3, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'combined effect',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'causal effect',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'effect',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'effect models',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'effect'},\n",
       " {'total_count': [{'count': 1, 'year': 2017},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'balanced',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'balanced regime',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'balanced'},\n",
       " {'total_count': [{'count': 9, 'year': 2014},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'parallel sampling',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'parallel algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'parallel architectures',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'parallel',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'parallel inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'parallel computation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'parallel computations',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'parallel computing environment',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'parallel'},\n",
       " {'total_count': [{'count': 11, 'year': 2016},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 10, 'year': 2012},\n",
       "   {'count': 6, 'year': 2014},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 13, 'year': 2013},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'binary weights',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'binary classification',\n",
       "    'years': [{'count': 4, 'year': 2015},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 5, 'year': 2013}]},\n",
       "   {'n-gram': 'binary',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2013}]},\n",
       "   {'n-gram': 'binary classifier',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'binary matrices',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'binary tree',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'binary latent variables',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'binary variables',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'binary classification problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'binary prediction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'binary hashing',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'binary codes',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016}]},\n",
       "   {'n-gram': 'binary matrix completion',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'binary matrix',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'binary classifiers',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'binary'},\n",
       " {'total_count': [{'count': 23, 'year': 2013},\n",
       "   {'count': 20, 'year': 2015},\n",
       "   {'count': 28, 'year': 2009},\n",
       "   {'count': 17, 'year': 2011},\n",
       "   {'count': 21, 'year': 2008},\n",
       "   {'count': 30, 'year': 2017},\n",
       "   {'count': 8, 'year': 2007},\n",
       "   {'count': 21, 'year': 2012},\n",
       "   {'count': 24, 'year': 2014},\n",
       "   {'count': 25, 'year': 2016},\n",
       "   {'count': 15, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'data generating process',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dirichlet process prior',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'gaussian process model',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gaussian process',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'training process',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'gaussian process adapter',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'breaking process',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'poisson process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'optimization process',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'process',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'yor process',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'point process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'stochastic process',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gaussian process models',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'noise process',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning process',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'process factor analysis',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'beta process',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'point process observations',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'indian buffet process',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'generative process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'task gaussian process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'chinese restaurant process',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'gaussian process framework',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'generation process',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'stage process',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'determinantal point process',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gaussian process prior',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'dirichlet process',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'gaussian process regression',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'one process',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'markov decision process',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel stochastic process',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multivariate hawkes process',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'hierarchical dirichlet process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'diffusion process',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'process'},\n",
       " {'total_count': [{'count': 4, 'year': 2009},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 4, 'year': 2016},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 6, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'oracle inequality',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'oracle',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 6, 'year': 2017}]}],\n",
       "  'word': 'oracle'},\n",
       " {'total_count': [{'count': 4, 'year': 2016},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'hashing',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'locality sensitive hashing',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'sensitive hashing',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'spectral hashing',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'minwise hashing',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'binary hashing',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bit minwise hashing',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2010}]}],\n",
       "  'word': 'hashing'},\n",
       " {'total_count': [{'count': 2, 'year': 2011},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 6, 'year': 2014},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 7, 'year': 2017},\n",
       "   {'count': 9, 'year': 2016},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 2, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'margin learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'margin posterior constraints',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'margin',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'multiclass margin',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'large margin learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'margin approach',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'margin bounds',\n",
       "    'years': [{'count': 2, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'margin condition',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'significant margin',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'margin classification',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'margin properties',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'large margin',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]}],\n",
       "  'word': 'margin'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'annotation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'image annotation',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'annotation'},\n",
       " {'total_count': [{'count': 30, 'year': 2017},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 7, 'year': 2009},\n",
       "   {'count': 9, 'year': 2011},\n",
       "   {'count': 24, 'year': 2016},\n",
       "   {'count': 20, 'year': 2014},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 11, 'year': 2012},\n",
       "   {'count': 15, 'year': 2015},\n",
       "   {'count': 8, 'year': 2008},\n",
       "   {'count': 9, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'transfer knowledge',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'knowledge discovery',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'best knowledge',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'prior knowledge',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'incorporating domain knowledge',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'incorporate domain knowledge',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'require knowledge',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'transferring knowledge',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'full knowledge',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'knowledge gradient',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'knowledge',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 8, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 12, 'year': 2014},\n",
       "     {'count': 14, 'year': 2016},\n",
       "     {'count': 5, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 13, 'year': 2015},\n",
       "     {'count': 18, 'year': 2017}]},\n",
       "   {'n-gram': 'priori knowledge',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'knowledge transfer',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'knowledge representation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'domain knowledge',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bayesian dark knowledge',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'specific knowledge',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'knowledge'},\n",
       " {'total_count': [{'count': 3, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'strategic buyers',\n",
       "    'years': [{'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'strategic behavior',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'strategic'},\n",
       " {'total_count': [{'count': 38, 'year': 2014},\n",
       "   {'count': 48, 'year': 2015},\n",
       "   {'count': 54, 'year': 2016},\n",
       "   {'count': 7, 'year': 2007},\n",
       "   {'count': 27, 'year': 2009},\n",
       "   {'count': 36, 'year': 2013},\n",
       "   {'count': 25, 'year': 2012},\n",
       "   {'count': 35, 'year': 2011},\n",
       "   {'count': 25, 'year': 2010},\n",
       "   {'count': 21, 'year': 2008},\n",
       "   {'count': 84, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'proposal distribution',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'asymptotic distribution',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'distribution',\n",
       "    'years': [{'count': 11, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 12, 'year': 2013},\n",
       "     {'count': 11, 'year': 2012},\n",
       "     {'count': 10, 'year': 2014},\n",
       "     {'count': 20, 'year': 2016},\n",
       "     {'count': 11, 'year': 2011},\n",
       "     {'count': 11, 'year': 2010},\n",
       "     {'count': 7, 'year': 2008},\n",
       "     {'count': 13, 'year': 2015},\n",
       "     {'count': 29, 'year': 2017}]},\n",
       "   {'n-gram': 'robust distribution comparison',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'unknown distribution',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'estimated distribution',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sampling distribution',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'correct stationary distribution',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stationary distribution',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'gaussian distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'distribution represented',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'underlying distribution',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'dimensional gaussian distribution',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'arbitrary probability distribution',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'discrete distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'predictive distribution',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'underlying data distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'entire distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'target distribution',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'variational distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'joint distribution',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'arbitrary distribution',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'one distribution',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'distribution families',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'uniform distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'conditional distribution',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'input distribution',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'limiting distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'fixed distribution',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'desired target distribution',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dirichlet distribution',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multinomial distribution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tailed distribution',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'probability distribution',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'cumulative distribution networks',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'full distribution',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'maximum entropy distribution',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'distribution induced',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'instrumental sampling distribution',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'underlying probability distribution',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'true distribution',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'distribution matching',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'source distribution',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'data distribution',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 9, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'error distribution',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probability distribution defined',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'poisson distribution',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exact distribution',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'posterior distribution',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'data generating distribution',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'statistical distribution',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'prior distribution',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'distribution'},\n",
       " {'total_count': [{'count': 18, 'year': 2009},\n",
       "   {'count': 16, 'year': 2013},\n",
       "   {'count': 23, 'year': 2010},\n",
       "   {'count': 29, 'year': 2015},\n",
       "   {'count': 11, 'year': 2007},\n",
       "   {'count': 32, 'year': 2014},\n",
       "   {'count': 19, 'year': 2012},\n",
       "   {'count': 32, 'year': 2011},\n",
       "   {'count': 31, 'year': 2016},\n",
       "   {'count': 30, 'year': 2017},\n",
       "   {'count': 13, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'sparse bayesian learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sparse signal recovery',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse representation',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'sparse models',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse linear regression',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse coding model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'finding sparse solutions',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'sparse codes',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sparse coding problem',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse multi',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse estimator',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sparse structure',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse features',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sparse components',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 5, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 10, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse regression',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'jointly sparse',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse linear models',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse matrix',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse solution',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse rewards',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse solutions',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learn sparse representations',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse coding',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse linear model',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'sparse signal',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse polynomials',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse variant',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse recovery problem',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse pca',\n",
       "    'years': [{'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse signals',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse additive model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse sketch',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning sparse representations',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse vector',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse estimation',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'sparse matrices',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'group sparse coding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'sparse vectors',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sparse regularization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse set',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse data',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse pca problem',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sparse graphs',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse gaussian processes',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse pseudo',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse combination',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse recovery',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse prior',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse precision matrices',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse case',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse non',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'sparse'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 4, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'logistic',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'regularized logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'logistic loss',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]}],\n",
       "  'word': 'logistic'},\n",
       " {'total_count': [{'count': 11, 'year': 2017},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 3, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'domain adaptation',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'adaptation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'unsupervised domain adaptation',\n",
       "    'years': [{'count': 4, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'domain adaptation problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'frequency adaptation',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'simple adaptation',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised domain adaptation',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'adaptation'},\n",
       " {'total_count': [{'count': 7, 'year': 2017},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 2, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'unified model',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'unified way',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'unified explanation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'unified approach',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unified analysis',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'unified',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'unified algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unified framework',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'unified view',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unified formulation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'unified'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'supervision',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'minimal supervision',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'weak supervision',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'strong supervision',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'supervision'},\n",
       " {'total_count': [{'count': 4, 'year': 2009},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 12, 'year': 2013},\n",
       "   {'count': 12, 'year': 2012},\n",
       "   {'count': 13, 'year': 2014},\n",
       "   {'count': 12, 'year': 2016},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 32, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'robust',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 10, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 11, 'year': 2015},\n",
       "     {'count': 22, 'year': 2017}]},\n",
       "   {'n-gram': 'robust distribution comparison',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'robust inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'fairly robust',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'robust policies',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'robust algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'robust optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'robust multi',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'robust learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'robust discriminative models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'robust pca',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'distributionally robust optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'robust estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'relatively robust',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'robust mdps',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'robust regression',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'robust'},\n",
       " {'total_count': [{'count': 1, 'year': 2016},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'safe',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'safe'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'law behavior',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'law',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'law'},\n",
       " {'total_count': [{'count': 12, 'year': 2016},\n",
       "   {'count': 29, 'year': 2017},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'generative adversarial networks',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'adversarial training',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'adversarial losses',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'adversarial environments',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'adversarial networks',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'adversarial setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'adversarial examples',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'generative adversarial network',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'adversarial',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'adversarial settings',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'generative adversarial nets',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'adversarial'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'dictionary',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'dictionary learning',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'dictionary'},\n",
       " {'total_count': [{'count': 12, 'year': 2017},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 13, 'year': 2015},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 7, 'year': 2009},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 3, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'label classification',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'label taxonomy',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'label proportions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'label',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'class label',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'label noise',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'label complexity',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'label prediction',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'label matrix',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'label information',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'label learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'label queries',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'label set',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'label'},\n",
       " {'total_count': [{'count': 28, 'year': 2017},\n",
       "   {'count': 19, 'year': 2010},\n",
       "   {'count': 16, 'year': 2015},\n",
       "   {'count': 7, 'year': 2011},\n",
       "   {'count': 22, 'year': 2016},\n",
       "   {'count': 17, 'year': 2012},\n",
       "   {'count': 10, 'year': 2013},\n",
       "   {'count': 18, 'year': 2009},\n",
       "   {'count': 16, 'year': 2008},\n",
       "   {'count': 15, 'year': 2014},\n",
       "   {'count': 5, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'supervised problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised learner',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised learning approach',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised approaches',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'supervised clustering',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised dimensionality reduction',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised framework',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised setting',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2010}]},\n",
       "   {'n-gram': 'supervised learning based',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised learning task',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'fully supervised',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'supervised learning',\n",
       "    'years': [{'count': 10, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'supervised settings',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'standard supervised learning',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised models',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised classification',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'supervised',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'supervised training',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'supervised deep learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised manner',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised multi',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised learning tasks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised learning methods',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'supervised domain adaptation',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised topic models',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'supervised'},\n",
       " {'total_count': [{'count': 4, 'year': 2017},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 2, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'independent cascade model',\n",
       "    'years': [{'count': 3, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'cascade',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'independent cascade models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'cascade'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 2, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'link prediction',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'link functions',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'link analysis',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'link function',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'link',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'link prediction accuracy',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'link prediction task',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'link'},\n",
       " {'total_count': [{'count': 30, 'year': 2017},\n",
       "   {'count': 10, 'year': 2013},\n",
       "   {'count': 24, 'year': 2016},\n",
       "   {'count': 16, 'year': 2014},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 9, 'year': 2011},\n",
       "   {'count': 17, 'year': 2015},\n",
       "   {'count': 8, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 2, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'design new algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'algorithm design',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'classifier design',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'design matrix',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2014}]},\n",
       "   {'n-gram': 'design efficient algorithms',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'design choices',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'design',\n",
       "    'years': [{'count': 8, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 10, 'year': 2014},\n",
       "     {'count': 23, 'year': 2016},\n",
       "     {'count': 7, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 22, 'year': 2017}]},\n",
       "   {'n-gram': 'design algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'optimal experimental design',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'system design',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'design'},\n",
       " {'total_count': [{'count': 36, 'year': 2016},\n",
       "   {'count': 28, 'year': 2010},\n",
       "   {'count': 40, 'year': 2012},\n",
       "   {'count': 19, 'year': 2015},\n",
       "   {'count': 55, 'year': 2017},\n",
       "   {'count': 33, 'year': 2013},\n",
       "   {'count': 18, 'year': 2009},\n",
       "   {'count': 18, 'year': 2014},\n",
       "   {'count': 17, 'year': 2008},\n",
       "   {'count': 24, 'year': 2011},\n",
       "   {'count': 3, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'novel extension',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel kernel',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'novel characterization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel scheme',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'novel mcmc sampler',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel measure',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel categories',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel algorithm based',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel non',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'novel application',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel notion',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel theory',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel framework',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'novel information',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel subclass',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel estimator',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'novel multi',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel analysis',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'novel perspective',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel data',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel sampling algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'novel methodology',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel interpretation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'novel bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel formulation',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'novel procedure',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel algorithm',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'novel probabilistic model',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel classes',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel regularization',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel results',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel distributed algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel approach',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'novel model',\n",
       "    'years': [{'count': 3, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel method',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 9, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008}]},\n",
       "   {'n-gram': 'novel mechanism',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel problem formulation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'novel use',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'develop novel techniques',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel lower bound',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel variant',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel two',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel classification method',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel technique',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'novel combination',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel stochastic process',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel prior',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'novel approach based',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'novel family',\n",
       "    'years': [{'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel co',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel reduction',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'novel',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'novel architecture',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]}],\n",
       "  'word': 'novel'},\n",
       " {'total_count': [{'count': 14, 'year': 2016},\n",
       "   {'count': 15, 'year': 2012},\n",
       "   {'count': 19, 'year': 2011},\n",
       "   {'count': 18, 'year': 2010},\n",
       "   {'count': 16, 'year': 2009},\n",
       "   {'count': 18, 'year': 2014},\n",
       "   {'count': 14, 'year': 2017},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 8, 'year': 2013},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 10, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'grained object recognition',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object classification',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'object segmentation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'object instances',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': '3d object reconstruction',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': '3d object recognition',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'object',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'visual object recognition',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'object categories',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'inferring object shape',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'object location',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'object recognition tasks',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'object detection',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'object recognition',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'object category',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'object tracking',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object classes',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'object classifier',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'object parts',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object localization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object detector',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'object'},\n",
       " {'total_count': [{'count': 3, 'year': 2009},\n",
       "   {'count': 4, 'year': 2007},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 4, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'predicting',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]}],\n",
       "  'word': 'predicting'},\n",
       " {'total_count': [{'count': 17, 'year': 2013},\n",
       "   {'count': 20, 'year': 2012},\n",
       "   {'count': 17, 'year': 2011},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 7, 'year': 2009},\n",
       "   {'count': 9, 'year': 2017},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 12, 'year': 2010},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 12, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'tree decomposition',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parse tree',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'tree structures',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'binary tree',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'tree search',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'decision tree',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'carlo tree search',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'phylogenetic tree',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'game tree',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tree',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 10, 'year': 2013},\n",
       "     {'count': 10, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 12, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 10, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'minimum spanning tree',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'tree structure',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'tree graphical models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'search tree',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'cluster tree',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'locally tree',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2012}]}],\n",
       "  'word': 'tree'},\n",
       " {'total_count': [{'count': 3, 'year': 2016},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'forest',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'random forest',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'forest'},\n",
       " {'total_count': [{'count': 16, 'year': 2009},\n",
       "   {'count': 79, 'year': 2017},\n",
       "   {'count': 31, 'year': 2012},\n",
       "   {'count': 100, 'year': 2016},\n",
       "   {'count': 45, 'year': 2014},\n",
       "   {'count': 29, 'year': 2010},\n",
       "   {'count': 12, 'year': 2008},\n",
       "   {'count': 54, 'year': 2015},\n",
       "   {'count': 39, 'year': 2013},\n",
       "   {'count': 31, 'year': 2011},\n",
       "   {'count': 5, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'online convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'constrained optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'based optimization method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'joint optimization',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'continuous optimization',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'iterative optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'based optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'smooth optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'combinatorial optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimization problems',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014}]},\n",
       "   {'n-gram': 'bandit convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'box optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic optimization',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 7, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'robust optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian optimization',\n",
       "    'years': [{'count': 7, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 11, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'distributed optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'parameter optimization',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'scale optimization',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'practical bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'resulting optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex optimization problems',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'constrained optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'convex optimization framework',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'statistical optimization',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimization method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'revenue optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sparse optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'efficient optimization',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'optimization process',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'discrete optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'optimization algorithms',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'strongly convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'combinatorial optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'submodular optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online linear optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'difficult optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'order optimization methods',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'batch bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'single optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'order optimization',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'corresponding optimization problem',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'online optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'proposed optimization methods',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex optimization approach',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'task bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'convex optimization',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'associated optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'optimization algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributionally robust optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'constrained convex optimization',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'optimization framework',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex optimization program',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'stochastic optimization algorithms',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'optimization problem',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'optimization',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 7, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 17, 'year': 2016},\n",
       "     {'count': 8, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 20, 'year': 2017}]},\n",
       "   {'n-gram': 'online optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'convex optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'optimization performance',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'free optimization',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'riemannian optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimization procedure',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'local optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'normalized optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'nonconvex optimization',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'manifold optimization',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'global optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'resulting optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'auc optimization',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'optimization methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'optimization'},\n",
       " {'total_count': [{'count': 5, 'year': 2016},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'geometric mean',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'geometric relationships',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'geometric property',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'geometric properties',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'geometric measures',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'geometric',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'geometric brownian motion',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'geometric structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]}],\n",
       "  'word': 'geometric'},\n",
       " {'total_count': [{'count': 36, 'year': 2014},\n",
       "   {'count': 27, 'year': 2012},\n",
       "   {'count': 37, 'year': 2016},\n",
       "   {'count': 24, 'year': 2015},\n",
       "   {'count': 18, 'year': 2009},\n",
       "   {'count': 38, 'year': 2017},\n",
       "   {'count': 29, 'year': 2010},\n",
       "   {'count': 35, 'year': 2013},\n",
       "   {'count': 17, 'year': 2008},\n",
       "   {'count': 28, 'year': 2011},\n",
       "   {'count': 9, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'neighborhood structure',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'kronecker product structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'temporal structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'manifold structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'causal structure learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dependency structure',\n",
       "    'years': [{'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'network structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'protein structure prediction',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'causal structure',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'graph structure',\n",
       "    'years': [{'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'underlying structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse structure',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'structure learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'additional structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'covariance structure',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'structure',\n",
       "    'years': [{'count': 8, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 10, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 16, 'year': 2014},\n",
       "     {'count': 15, 'year': 2016},\n",
       "     {'count': 15, 'year': 2011},\n",
       "     {'count': 15, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 14, 'year': 2015},\n",
       "     {'count': 17, 'year': 2017}]},\n",
       "   {'n-gram': 'complex structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'finite sum structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'rich structure',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'separable structure',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'cluster structure',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'exploiting structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'tensor structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'local structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'rank structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'latent structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'dimensional structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'common structure',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'community structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'problem structure',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'graphical model structure',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parameter structure',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'underlying graph structure',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'tree structure',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'new data structure',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'data structure',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'block structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'scale structure',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'statistical structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'geometric structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'model structure',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'spatial structure',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'conditional independence structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'special structure',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'arbitrary structure',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'dependence structure',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'structure'},\n",
       " {'total_count': [], 'variations': [], 'word': 'optimistic'},\n",
       " {'total_count': [{'count': 42, 'year': 2016},\n",
       "   {'count': 22, 'year': 2014},\n",
       "   {'count': 30, 'year': 2009},\n",
       "   {'count': 38, 'year': 2013},\n",
       "   {'count': 31, 'year': 2012},\n",
       "   {'count': 17, 'year': 2010},\n",
       "   {'count': 14, 'year': 2008},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 22, 'year': 2017},\n",
       "   {'count': 26, 'year': 2015},\n",
       "   {'count': 16, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'hierarchical bayesian models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sparse bayesian learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian non',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian hierarchical models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian information criterion',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'use bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'fully bayesian approach',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian network',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'bayesian nonparametric approach',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'bayesian methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian optimization',\n",
       "    'years': [{'count': 7, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 11, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian bounds',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'practical bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian hierarchical clustering',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'nonparametric bayesian approach',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'bayesian filtering',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'bayesian entropy estimation',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian approach',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'hierarchical bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'bayesian treatment',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'bayesian learning',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate bayesian computation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'variational bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'bayesian logistic regression',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian parameter estimation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian generalization',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian nonparametrics',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'batch bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'optimal bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bayesian games',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian algorithm',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'novel bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'fully bayesian',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'nonparametric bayesian method',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'bayesian models',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'learning bayesian networks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian neural networks',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variational bayesian',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'task bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'nonparametric bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian quadrature',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'parametric bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian posterior',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian networks',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian framework',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian interpretation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian analysis',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'based bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bayesian active learning',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian settings',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric bayesian models',\n",
       "    'years': [{'count': 4, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'approximate bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian inference',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'nonparametric bayesian statistics',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian dark knowledge',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dynamic bayesian networks',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian nonparametric models',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'bayesian'},\n",
       " {'total_count': [{'count': 4, 'year': 2014},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'dynamical model',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'latent dynamical model',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'linear dynamical system',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'linear dynamical systems',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dynamical systems',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'nonlinear dynamical systems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'complex dynamical systems',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'dynamical'},\n",
       " {'total_count': [{'count': 23, 'year': 2016},\n",
       "   {'count': 13, 'year': 2014},\n",
       "   {'count': 21, 'year': 2015},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 21, 'year': 2017},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'convolutional filters',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convolutional networks',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'fully convolutional network',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'convolutional neural network',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'deep convolutional networks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convolutional kernel networks',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'convolutional neural networks',\n",
       "    'years': [{'count': 9, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'convolutional neural net',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convolutional',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convolutional layer',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'convolutional nets',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convolutional neural nets',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convolutional lstm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convolutional layers',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convolutional network',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stream convolutional networks',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'convolutional'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 9, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'gan',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 8, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gan ),',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'gan'},\n",
       " {'total_count': [{'count': 9, 'year': 2014},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 9, 'year': 2016},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'matrix decomposition',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'tree decomposition',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dual decomposition',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'tensor decomposition',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'decomposition',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'dynamic mode decomposition',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'singular value decomposition',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'spectral decomposition',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'decomposition'},\n",
       " {'total_count': [{'count': 8, 'year': 2011},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 17, 'year': 2017},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 13, 'year': 2012},\n",
       "   {'count': 15, 'year': 2014},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 11, 'year': 2015},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'representative subset',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'weighted subset',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'small subset',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'heaviest subset',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'unknown subset',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'optimal subset',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'subset selection',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'diverse subset',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'random subset',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'subset',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 9, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 11, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 11, 'year': 2017}]}],\n",
       "  'word': 'subset'},\n",
       " {'total_count': [{'count': 21, 'year': 2013},\n",
       "   {'count': 37, 'year': 2015},\n",
       "   {'count': 20, 'year': 2014},\n",
       "   {'count': 42, 'year': 2016},\n",
       "   {'count': 58, 'year': 2017},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 12, 'year': 2008},\n",
       "   {'count': 8, 'year': 2010},\n",
       "   {'count': 12, 'year': 2012},\n",
       "   {'count': 16, 'year': 2011},\n",
       "   {'count': 4, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'accelerated proximal gradient',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic gradient techniques',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'accelerated gradient method',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'gradient computations',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'exploding gradient problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic gradient mcmc',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gradient values',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'natural gradient',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'policy gradient algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'including gradient descent',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gradient descent methods',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'natural policy gradient',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'projected gradient descent',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'policy gradient',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'noisy gradient',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'gradient ascent algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'full gradient',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'gradient ascent',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic gradient',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'adaptive gradient methods',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'conjugate gradient method',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'stochastic gradient methods',\n",
       "    'years': [{'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'gradient estimates',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'proximal gradient',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gradient update',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'conditional gradient method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'knowledge gradient',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'lipschitz continuous gradient',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'gradient',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 15, 'year': 2017}]},\n",
       "   {'n-gram': 'stochastic gradient descent',\n",
       "    'years': [{'count': 13, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'gradient methods',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'policy gradient methods',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'policy gradient estimation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'gradient direction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'gradient step',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'gradient descent',\n",
       "    'years': [{'count': 7, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2008}]},\n",
       "   {'n-gram': 'gradient updates',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'gradient method',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'stochastic gradient method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'natural gradient descent',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'gradient'},\n",
       " {'total_count': [{'count': 1, 'year': 2014},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'rational',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'rational behavior',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'rational agent',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rational model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2008}]},\n",
       "   {'n-gram': 'rational decision',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'rational'},\n",
       " {'total_count': [{'count': 7, 'year': 2010},\n",
       "   {'count': 12, 'year': 2013},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 7, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 12, 'year': 2016},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 11, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'common assumption',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'weak assumption',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'assumption',\n",
       "    'years': [{'count': 6, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 9, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 11, 'year': 2016},\n",
       "     {'count': 5, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 10, 'year': 2017}]},\n",
       "   {'n-gram': 'reasonable assumption',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'independence assumption',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'prior assumption',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'cluster assumption',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'strong convexity assumption',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'assumption'},\n",
       " {'total_count': [{'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'multiclass margin',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'multiclass',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multiclass problems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'multiclass'},\n",
       " {'total_count': [{'count': 8, 'year': 2009},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 18, 'year': 2014},\n",
       "   {'count': 13, 'year': 2010},\n",
       "   {'count': 19, 'year': 2011},\n",
       "   {'count': 24, 'year': 2016},\n",
       "   {'count': 19, 'year': 2012},\n",
       "   {'count': 10, 'year': 2017},\n",
       "   {'count': 11, 'year': 2015},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 6, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'latent feature models',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'feature structures',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'feature learning',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'feature learning problem',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'distinctive feature',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'feature vectors',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'feature dimension',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'feature spaces',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'human feature learning',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'dimensional feature space',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'feature extraction',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'feature extractor',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'feature map',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'layer feature reduction',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'feature extraction procedure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'local feature',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'feature',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 7, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'attractive feature',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'perform feature selection',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'key feature',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'unsupervised feature selection',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'unsupervised feature learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'feature selection',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'feature representation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'feature space',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'feature construction',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'feature values',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'feature matching',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'latent feature space',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'feature maps',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'feature'},\n",
       " {'total_count': [{'count': 22, 'year': 2009},\n",
       "   {'count': 32, 'year': 2015},\n",
       "   {'count': 31, 'year': 2016},\n",
       "   {'count': 32, 'year': 2013},\n",
       "   {'count': 35, 'year': 2017},\n",
       "   {'count': 7, 'year': 2007},\n",
       "   {'count': 14, 'year': 2010},\n",
       "   {'count': 12, 'year': 2008},\n",
       "   {'count': 21, 'year': 2012},\n",
       "   {'count': 14, 'year': 2011},\n",
       "   {'count': 36, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'optimal estimation',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'estimation accuracy',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'estimation problem',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'posteriori estimation',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'estimation bias',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'maximum likelihood estimation',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'model parameter estimation',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'map estimation',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'divergence estimation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'contrastive estimation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'nonparametric density estimation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'bayesian entropy estimation',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'articulated pose estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'estimation algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'linear estimation',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'pose estimation',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'bayesian parameter estimation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'nonparametric estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'rank estimation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'estimation error bounds',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'parametric estimation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'estimation procedures',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dimensional estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'joint estimation',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'minimax estimation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sparse estimation',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'robust estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'kernel density estimation',\n",
       "    'years': [{'count': 3, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'human pose estimation',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'depth estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'policy gradient estimation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'distributed statistical estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'consistent estimation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'graph estimation',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'distributed estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'accurate estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'estimation procedure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'set estimation',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'estimation',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 14, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 6, 'year': 2008},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 14, 'year': 2017}]},\n",
       "   {'n-gram': 'statistical estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'probability estimation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'parameter estimation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'density estimation',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'estimation error',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'estimation problems',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'inverse covariance estimation',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'estimation'},\n",
       " {'total_count': [{'count': 13, 'year': 2016},\n",
       "   {'count': 15, 'year': 2017},\n",
       "   {'count': 13, 'year': 2012},\n",
       "   {'count': 14, 'year': 2013},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 10, 'year': 2015},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 13, 'year': 2010},\n",
       "   {'count': 8, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'estimating mutual information',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'efficiently estimating',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'estimating parameters',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'accurately estimating',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'consider estimating',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'estimating',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 12, 'year': 2013},\n",
       "     {'count': 12, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 12, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'estimating high',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'estimating'},\n",
       " {'total_count': [{'count': 4, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 2, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'interpretable way',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'interpretable features',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'interpretable',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014}]}],\n",
       "  'word': 'interpretable'},\n",
       " {'total_count': [{'count': 18, 'year': 2011},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 15, 'year': 2010},\n",
       "   {'count': 17, 'year': 2012},\n",
       "   {'count': 33, 'year': 2014},\n",
       "   {'count': 32, 'year': 2013},\n",
       "   {'count': 26, 'year': 2015},\n",
       "   {'count': 38, 'year': 2016},\n",
       "   {'count': 31, 'year': 2017},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 9, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'sampling methods',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sampling rate',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parallel sampling',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sampling distribution',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'uniform sampling',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sampling algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'scheduled sampling',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'random sampling',\n",
       "    'years': [{'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'carlo sampling',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sampling',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 11, 'year': 2015},\n",
       "     {'count': 14, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 14, 'year': 2014},\n",
       "     {'count': 19, 'year': 2016},\n",
       "     {'count': 8, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 14, 'year': 2017}]},\n",
       "   {'n-gram': 'novel sampling algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'importance sampling',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'monte carlo sampling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sampling algorithm',\n",
       "    'years': [{'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'sampling bias',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'thompson sampling',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'policy sampling',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'efficient sampling',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gibbs sampling algorithm',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'annealed importance sampling',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sampling efficiency',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'instrumental sampling distribution',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gibbs sampling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'ancestor sampling',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'slice sampling',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'posterior sampling',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'adaptive sampling',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sampling based',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'based sampling',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'mcmc sampling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'sampling approaches',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'sampling'},\n",
       " {'total_count': [{'count': 3, 'year': 2017},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'disentangled',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learn disentangled representations',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'disentangled'},\n",
       " {'total_count': [{'count': 9, 'year': 2016},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 10, 'year': 2015},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'minimax optimality',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'optimality result',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'global optimality',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'optimality',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 6, 'year': 2013}]},\n",
       "   {'n-gram': 'optimality criteria',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'optimality'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 7, 'year': 2010},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'functional',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'functional consequences',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'functional regions',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'functional connectivity',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'functional form',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'functional data',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'functional'},\n",
       " {'total_count': [{'count': 11, 'year': 2016},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 2, 'year': 2013}],\n",
       "  'variations': [{'n-gram': '3d space',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': '3d object reconstruction',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': '3d object recognition',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': '3d shape reconstruction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': '3d reconstruction',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': '3d shape',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': '3d point clouds',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': '3d',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': '3d rotation',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': '3d data',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': '3d objects',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': '3d'},\n",
       " {'total_count': [{'count': 4, 'year': 2014},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 3, 'year': 2016},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'tight upper bound',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tight bounds',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'tight',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'tight'},\n",
       " {'total_count': [{'count': 1, 'year': 2016},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 1, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'implicit',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'implicit'},\n",
       " {'total_count': [{'count': 8, 'year': 2011},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 9, 'year': 2014},\n",
       "   {'count': 11, 'year': 2016},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 5, 'year': 2017},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'overlapping group lasso',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'group level',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'group lasso',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'group sparse coding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'symmetric group',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'group',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'group sparsity',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]}],\n",
       "  'word': 'group'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 3, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'coupled',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]}],\n",
       "  'word': 'coupled'},\n",
       " {'total_count': [{'count': 3, 'year': 2016},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'sampled newton methods',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'newton methods',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'newton method',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'newton',\n",
       "    'years': [{'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'newton'},\n",
       " {'total_count': [{'count': 3, 'year': 2009},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'graph partitioning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'adaptively partitioning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'partitioning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2008}]}],\n",
       "  'word': 'partitioning'},\n",
       " {'total_count': [{'count': 25, 'year': 2017},\n",
       "   {'count': 4, 'year': 2007},\n",
       "   {'count': 17, 'year': 2012},\n",
       "   {'count': 20, 'year': 2016},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 11, 'year': 2010},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 9, 'year': 2009},\n",
       "   {'count': 5, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'source domain',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'domain adaptation',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'domain experts',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unsupervised domain adaptation',\n",
       "    'years': [{'count': 4, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'domain',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 8, 'year': 2017}]},\n",
       "   {'n-gram': 'domain adaptation problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'continuous domain',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'domain expert',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'incorporating domain knowledge',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'incorporate domain knowledge',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'domain size',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'compressed domain',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'discrete domain',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'frequency domain',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'challenging continuous domain',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'one domain',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'supervised domain adaptation',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'domain knowledge',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'target domain',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'feasible domain',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'domain'},\n",
       " {'total_count': [{'count': 16, 'year': 2007},\n",
       "   {'count': 59, 'year': 2012},\n",
       "   {'count': 32, 'year': 2010},\n",
       "   {'count': 27, 'year': 2009},\n",
       "   {'count': 60, 'year': 2017},\n",
       "   {'count': 57, 'year': 2013},\n",
       "   {'count': 79, 'year': 2014},\n",
       "   {'count': 57, 'year': 2016},\n",
       "   {'count': 32, 'year': 2011},\n",
       "   {'count': 19, 'year': 2008},\n",
       "   {'count': 61, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'fast variational inference',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'intractable inference',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'use bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'robust inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'approximate inference',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'exact inference',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'inference algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'posterior inference',\n",
       "    'years': [{'count': 4, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'topic inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'causal inference',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'lifted inference',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'efficient inference',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variational inference algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'map inference problem',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'inference',\n",
       "    'years': [{'count': 7, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 18, 'year': 2013},\n",
       "     {'count': 17, 'year': 2012},\n",
       "     {'count': 22, 'year': 2014},\n",
       "     {'count': 20, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 11, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 12, 'year': 2015},\n",
       "     {'count': 20, 'year': 2017}]},\n",
       "   {'n-gram': 'inference problem',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'method allows inference',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'inference procedure',\n",
       "    'years': [{'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variational bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'based inference algorithms',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'parallel inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'selective inference',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'message passing inference',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'flexible inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'time inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'probabilistic inference algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'inference tasks',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'lifted inference algorithms',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'approximate inference approach',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'inference algorithms',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'perform inference',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016}]},\n",
       "   {'n-gram': 'high dimensional inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'model inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'inference framework',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'box variational inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'probabilistic inference',\n",
       "    'years': [{'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'mcmc inference',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'performing efficient inference',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'statistical inference',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'nonparametric bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'sequential inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'amortized inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'based inference',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'inference scheme',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'inference problems',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'inference task',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'distributed variational inference',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate inference algorithms',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'map inference',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'product inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'approximate map inference',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'based bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'optimal inference',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate inference algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'online inference',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic variational inference',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate probabilistic inference',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'approximate bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variational inference',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'bayesian inference',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'scalable inference',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'fast inference',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'marginal inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'efficient exact inference',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'inference'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 5, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'frank',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 6, 'year': 2017},\n",
       "     {'count': 5, 'year': 2015}]}],\n",
       "  'word': 'frank'},\n",
       " {'total_count': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'gated recurrent unit',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'gated'},\n",
       " {'total_count': [{'count': 5, 'year': 2009},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 6, 'year': 2014},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'observation model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'observation spaces',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'noisy observation',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'observation space',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'partial observation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'observation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'key observation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'noisy linear observation',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'observation noise',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'observation'},\n",
       " {'total_count': [{'count': 45, 'year': 2017},\n",
       "   {'count': 24, 'year': 2011},\n",
       "   {'count': 27, 'year': 2013},\n",
       "   {'count': 42, 'year': 2015},\n",
       "   {'count': 36, 'year': 2014},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 42, 'year': 2016},\n",
       "   {'count': 14, 'year': 2012},\n",
       "   {'count': 18, 'year': 2010},\n",
       "   {'count': 9, 'year': 2008},\n",
       "   {'count': 3, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'probabilistic setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'dimensional setting',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'agnostic setting',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'online learning setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'armed bandit setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'supervised setting',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 4, 'year': 2010}]},\n",
       "   {'n-gram': 'unsupervised setting',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'scale setting',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'nonparametric setting',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'kernel setting',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'adversarial setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'linear setting',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gaussian setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'noisy setting',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic setting',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'standard setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'batch setting',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'general setting',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'reinforcement learning setting',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'offline setting',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'task setting',\n",
       "    'years': [{'count': 2, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'setting',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 19, 'year': 2015},\n",
       "     {'count': 11, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 17, 'year': 2014},\n",
       "     {'count': 25, 'year': 2016},\n",
       "     {'count': 14, 'year': 2011},\n",
       "     {'count': 9, 'year': 2010},\n",
       "     {'count': 7, 'year': 2008},\n",
       "     {'count': 25, 'year': 2017}]},\n",
       "   {'n-gram': 'new setting',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'high dimensional setting',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bandit setting',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online setting',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'streaming setting',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'free setting',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'generic setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'usual setting',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'simple setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'setting'},\n",
       " {'total_count': [{'count': 23, 'year': 2009},\n",
       "   {'count': 68, 'year': 2017},\n",
       "   {'count': 31, 'year': 2012},\n",
       "   {'count': 65, 'year': 2016},\n",
       "   {'count': 46, 'year': 2014},\n",
       "   {'count': 23, 'year': 2010},\n",
       "   {'count': 38, 'year': 2013},\n",
       "   {'count': 19, 'year': 2011},\n",
       "   {'count': 41, 'year': 2015},\n",
       "   {'count': 15, 'year': 2008},\n",
       "   {'count': 5, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'online convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'convex cone',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'convex relaxation approach',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex analysis',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex objectives',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'convex functions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bandit convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'strongly convex objectives',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex program',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'strongly convex',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'strongly convex functions',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'convex optimization problems',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'convex upper bound',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'convex surrogate',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'convex relaxation methods',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'convex optimization framework',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex combination',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'convex programs',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'convex relaxation',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'strongly convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex loss functions',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'convex envelope',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'convex burer',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'convex hull',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'convex constraints',\n",
       "    'years': [{'count': 3, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'convex objective functions',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'convex programming',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'convex body',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex loss',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'convex optimization approach',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'convex regularization',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'convex loss function',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'convex two',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'convex losses',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex optimization',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'smooth convex function',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'convex formulation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'constrained convex optimization',\n",
       "    'years': [{'count': 3, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'convex objective function',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic convex optimization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'convex',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 14, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 14, 'year': 2017}]},\n",
       "   {'n-gram': 'convex sets',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'constrained convex program',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex optimization program',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'convex objective',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'convex function',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convex optimization problem',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'convex problem',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'convex problems',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'convex procedure',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'convex relaxations',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'convex surrogates',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'convex'},\n",
       " {'total_count': [{'count': 13, 'year': 2009},\n",
       "   {'count': 12, 'year': 2011},\n",
       "   {'count': 18, 'year': 2017},\n",
       "   {'count': 15, 'year': 2016},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 15, 'year': 2012},\n",
       "   {'count': 14, 'year': 2010},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 9, 'year': 2013},\n",
       "   {'count': 7, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'multiple kernels',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'multiple time steps',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'multiple',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'multiple layers',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'multiple outputs',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'multiple labels',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'multiple time scales',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multiple kernel learning',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple views',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'multiple neurons',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple applications',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'multiple users',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple levels',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'multiple variables',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multiple tasks',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'multiple classes',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple functions',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple agents',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'multiple sources',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple factors',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'multiple data sets',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple types',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple stimuli',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'multiple scales',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'multiple objectives',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'multiple environments',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning multiple tasks',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'multiple subsets',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'multiple features',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multiple datasets',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'multiple'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'private data',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'differentially private',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'private information',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'private',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'private'},\n",
       " {'total_count': [{'count': 129, 'year': 2017},\n",
       "   {'count': 63, 'year': 2014},\n",
       "   {'count': 81, 'year': 2016},\n",
       "   {'count': 52, 'year': 2011},\n",
       "   {'count': 50, 'year': 2012},\n",
       "   {'count': 12, 'year': 2007},\n",
       "   {'count': 62, 'year': 2015},\n",
       "   {'count': 29, 'year': 2009},\n",
       "   {'count': 41, 'year': 2010},\n",
       "   {'count': 55, 'year': 2013},\n",
       "   {'count': 23, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'performance measures',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'empirical performance',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'comparable performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'theoretical performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'favorable performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'compare performance',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'generalization performance',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'performance metrics',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'learning performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'better performance',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'statistical performance',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2014}]},\n",
       "   {'n-gram': 'performance',\n",
       "    'years': [{'count': 11, 'year': 2009},\n",
       "     {'count': 5, 'year': 2007},\n",
       "     {'count': 26, 'year': 2013},\n",
       "     {'count': 20, 'year': 2012},\n",
       "     {'count': 18, 'year': 2014},\n",
       "     {'count': 24, 'year': 2016},\n",
       "     {'count': 24, 'year': 2011},\n",
       "     {'count': 22, 'year': 2010},\n",
       "     {'count': 6, 'year': 2008},\n",
       "     {'count': 19, 'year': 2015},\n",
       "     {'count': 48, 'year': 2017}]},\n",
       "   {'n-gram': 'relative performance',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'optimal performance',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'achieves better performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'support recovery performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'recognition performance',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'good empirical performance',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'performance bound',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'significantly improve performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'performance metric',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'improve performance',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'substantial performance boost',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'superior predictive performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'superior performance',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'strong performance',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'good performance',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'student performance',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'performance may',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high performance',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'strong empirical performance',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'practical performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'performance gains',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'achieve high performance',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'best performance',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'classification performance',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'performance measure',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'demonstrate superior performance',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'achieve similar performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'promising performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'clustering performance',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'predictive performance',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'case performance',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'performance compared',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'show performance gains',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'competitive performance',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'prediction performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'art predictive performance',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'improve generalization performance',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'performance guarantee',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'achieve superior performance',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'performance guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'art performance',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 9, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 14, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 17, 'year': 2017}]},\n",
       "   {'n-gram': 'sample performance',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'better predictive performance',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tracking performance',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'task performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'improved performance',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'prove performance guarantees',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'shown competitive performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'detection performance',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'measuring performance',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'best possible performance',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'recovery performance',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'performance relative',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'poor performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'computational performance',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimization performance',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'overall performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'human performance',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'performance improvements',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'improves performance',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'asymptotic performance',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'improving classification performance',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'show improved performance',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'excellent performance',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]}],\n",
       "  'word': 'performance'},\n",
       " {'total_count': [{'count': 5, 'year': 2010},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 5, 'year': 2017},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 3, 'year': 2016},\n",
       "   {'count': 3, 'year': 2011},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'identifying patients',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'identifying',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]}],\n",
       "  'word': 'identifying'},\n",
       " {'total_count': [{'count': 14, 'year': 2016},\n",
       "   {'count': 16, 'year': 2017},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 10, 'year': 2010},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 4, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'agent reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'agent learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'agent domains',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'learning agent',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'agent',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 8, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'agent observes',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rational agent',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'agent'},\n",
       " {'total_count': [{'count': 2, 'year': 2017},\n",
       "   {'count': 7, 'year': 2012},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 3, 'year': 2016},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 3, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'infinite data',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'infinite relational model',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'potentially infinite number',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'infinite dimension',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'infinite mixtures',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'infinite number',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'infinite',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'infinite'},\n",
       " {'total_count': [{'count': 2, 'year': 2009},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 11, 'year': 2015},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 16, 'year': 2017},\n",
       "   {'count': 2, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'finite set',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'finite sample',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'finite mixture',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'finite number',\n",
       "    'years': [{'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'finite sum structure',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'finite samples',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'finite difference',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'finite sample analysis',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'finite',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 11, 'year': 2017}]},\n",
       "   {'n-gram': 'first finite',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'provide finite',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'finite'},\n",
       " {'total_count': [{'count': 1, 'year': 2016},\n",
       "   {'count': 5, 'year': 2017},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'acceleration',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'acceleration'},\n",
       " {'total_count': [{'count': 12, 'year': 2011},\n",
       "   {'count': 15, 'year': 2012},\n",
       "   {'count': 28, 'year': 2016},\n",
       "   {'count': 26, 'year': 2015},\n",
       "   {'count': 14, 'year': 2014},\n",
       "   {'count': 8, 'year': 2010},\n",
       "   {'count': 30, 'year': 2017},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 13, 'year': 2013},\n",
       "   {'count': 3, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'sample complexity guarantees',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'provable regret guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'give guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'case guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'formal guarantees',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'theoretical guarantees',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'global convergence guarantees',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'statistical guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'consistency guarantees',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'prove guarantees',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'strong theoretical guarantees',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'art guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'guarantees',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'safety guarantees',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'give theoretical guarantees',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'convergence guarantees',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'provable guarantees',\n",
       "    'years': [{'count': 6, 'year': 2017},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'strong statistical guarantees',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'guarantees $\\\\ epsilon',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'provide guarantees',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'performance guarantees',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'learning guarantees',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'prove performance guarantees',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'provide theoretical guarantees',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'guarantees'},\n",
       " {'total_count': [{'count': 6, 'year': 2016},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 2, 'year': 2017},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 3, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'weighted subset',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'weighted average',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'weighted graphs',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'weighted',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'weighted sum',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'weighted majority votes',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'weighted first',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'weighted graph',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'locally weighted regression',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'weighted trace',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'weighted regression',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'weighted'},\n",
       " {'total_count': [{'count': 11, 'year': 2014},\n",
       "   {'count': 13, 'year': 2013},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 6, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 7, 'year': 2010},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 5, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'lasso .\"',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'overlapping group lasso',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'g ., lasso',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'lasso',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 9, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'task lasso',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'graphical lasso',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'generalized lasso',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'group lasso',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'fused lasso',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'lasso'},\n",
       " {'total_count': [{'count': 15, 'year': 2017},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 7, 'year': 2008},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 8, 'year': 2009},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 3, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'joint distributions',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'joint optimization',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'joint dependence',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'joint learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'joint',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2016}]},\n",
       "   {'n-gram': 'joint dynamics',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'joint maximum',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'joint distribution',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'joint training',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'joint estimation',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'joint properties',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'joint modeling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'joint model',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'joint sparsity constraints',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'joint analysis',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'joint sparsity',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'joint'},\n",
       " {'total_count': [{'count': 7, 'year': 2017},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 4, 'year': 2007},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'distributed system',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'distributed optimization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed fashion',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'distributed representations',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'scale distributed training',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'distributed setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'distributed manner',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'identically distributed',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'distributed',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'distributed ml',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel distributed algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed learning',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'distributed variational inference',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed algorithms',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed statistical estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'distributed estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed implementations',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'distributed'},\n",
       " {'total_count': [{'count': 44, 'year': 2014},\n",
       "   {'count': 46, 'year': 2013},\n",
       "   {'count': 62, 'year': 2015},\n",
       "   {'count': 62, 'year': 2016},\n",
       "   {'count': 7, 'year': 2007},\n",
       "   {'count': 21, 'year': 2009},\n",
       "   {'count': 29, 'year': 2011},\n",
       "   {'count': 34, 'year': 2012},\n",
       "   {'count': 72, 'year': 2017},\n",
       "   {'count': 27, 'year': 2010},\n",
       "   {'count': 18, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'function class',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'larger class',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'class labels',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'equivalence class',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'rich class',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'general class',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'class',\n",
       "    'years': [{'count': 9, 'year': 2009},\n",
       "     {'count': 5, 'year': 2007},\n",
       "     {'count': 21, 'year': 2013},\n",
       "     {'count': 12, 'year': 2012},\n",
       "     {'count': 17, 'year': 2014},\n",
       "     {'count': 22, 'year': 2016},\n",
       "     {'count': 11, 'year': 2011},\n",
       "     {'count': 13, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 24, 'year': 2015},\n",
       "     {'count': 33, 'year': 2017}]},\n",
       "   {'n-gram': 'hypothesis class',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'broad class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 10, 'year': 2017}]},\n",
       "   {'n-gram': 'class prior',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'model class',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'class svm',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'class label',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'novel class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'concept class',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'useful class',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'class balance',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'object class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'known function class',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'much broader class',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'particular class',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'wide class',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'positive class',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'wider class',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'richer class',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'popular class',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'natural class',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'given hypothesis class',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'certain class',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'restricted class',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'class classification',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'new class',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'entire class',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'important class',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'broader class',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'class'},\n",
       " {'total_count': [{'count': 10, 'year': 2009},\n",
       "   {'count': 4, 'year': 2007},\n",
       "   {'count': 15, 'year': 2013},\n",
       "   {'count': 14, 'year': 2012},\n",
       "   {'count': 18, 'year': 2014},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 9, 'year': 2011},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 11, 'year': 2008},\n",
       "   {'count': 15, 'year': 2015},\n",
       "   {'count': 22, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'context',\n",
       "    'years': [{'count': 10, 'year': 2009},\n",
       "     {'count': 4, 'year': 2007},\n",
       "     {'count': 14, 'year': 2013},\n",
       "     {'count': 13, 'year': 2012},\n",
       "     {'count': 16, 'year': 2014},\n",
       "     {'count': 16, 'year': 2016},\n",
       "     {'count': 9, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 11, 'year': 2008},\n",
       "     {'count': 13, 'year': 2015},\n",
       "     {'count': 21, 'year': 2017}]},\n",
       "   {'n-gram': 'context modulation',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'context vector',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'general context',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'context'},\n",
       " {'total_count': [{'count': 29, 'year': 2016},\n",
       "   {'count': 21, 'year': 2010},\n",
       "   {'count': 6, 'year': 2007},\n",
       "   {'count': 18, 'year': 2015},\n",
       "   {'count': 34, 'year': 2017},\n",
       "   {'count': 24, 'year': 2008},\n",
       "   {'count': 22, 'year': 2009},\n",
       "   {'count': 12, 'year': 2013},\n",
       "   {'count': 21, 'year': 2012},\n",
       "   {'count': 15, 'year': 2011},\n",
       "   {'count': 16, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'novel kernel',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'covariance kernel',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'kernel parameters',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel dimension reduction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'kernel regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'kernel learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'kernel embeddings',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'kernel embedding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multiple kernel learning',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'kernel machines',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'definite kernel',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'kernel construction',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'stationary kernel function',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'kernel matrices',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'convolutional kernel networks',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'kernel ridge regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'original kernel',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'kernel change',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'kernel setting',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'kernel k',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'kernel method',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'kernel perceptron',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel evaluations',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'kernel',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 9, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 8, 'year': 2010},\n",
       "     {'count': 7, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'indefinite kernel matrix',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'kernel clustering',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel functions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'kernel classifier',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'transition kernel',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gaussian kernel',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'kernel bayes',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'many kernel methods',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel space',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'kernel matrix',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel density estimation',\n",
       "    'years': [{'count': 3, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel mean',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'nonparametric kernel',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'kernel methods',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'kernel measures',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel hilbert spaces',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'kernel extension',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'kernel function',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'kernel'},\n",
       " {'total_count': [{'count': 7, 'year': 2009},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 4, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'motion segmentation',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'based segmentation',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'object segmentation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'semantic segmentation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'image segmentation',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011}]},\n",
       "   {'n-gram': 'segmentation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'segmentation'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2014},\n",
       "   {'count': 9, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'fairness',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 9, 'year': 2017}]}],\n",
       "  'word': 'fairness'},\n",
       " {'total_count': [{'count': 9, 'year': 2010},\n",
       "   {'count': 12, 'year': 2013},\n",
       "   {'count': 11, 'year': 2012},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 17, 'year': 2016},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 12, 'year': 2015},\n",
       "   {'count': 12, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'solving large',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'solving',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 9, 'year': 2013},\n",
       "     {'count': 9, 'year': 2012},\n",
       "     {'count': 11, 'year': 2014},\n",
       "     {'count': 16, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 10, 'year': 2017}]},\n",
       "   {'n-gram': 'efficiently solving',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'repeatedly solving',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'requires solving',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximately solving',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'solving'},\n",
       " {'total_count': [{'count': 18, 'year': 2014},\n",
       "   {'count': 12, 'year': 2012},\n",
       "   {'count': 7, 'year': 2007},\n",
       "   {'count': 11, 'year': 2008},\n",
       "   {'count': 12, 'year': 2010},\n",
       "   {'count': 16, 'year': 2013},\n",
       "   {'count': 14, 'year': 2016},\n",
       "   {'count': 9, 'year': 2011},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 16, 'year': 2017},\n",
       "   {'count': 20, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'optimal decision',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'optimal decision rule',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'decision function',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'decision epochs',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'decision boundary',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'decision making',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'decision trees',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'decision tree',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'markov decision processes',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 5, 'year': 2013}]},\n",
       "   {'n-gram': 'simple decision heuristics',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'world decision',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'decision boundaries',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'perceptual decision making',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'sequential decision making',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'decision rule',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'markov decision process',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sequential decision',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'decision',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'decision variable',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'sequential decision problem',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'rational decision',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'randomized decision trees',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'decision space',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'many sequential decision',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'decision maker',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'decision'},\n",
       " {'total_count': [{'count': 20, 'year': 2016},\n",
       "   {'count': 14, 'year': 2014},\n",
       "   {'count': 10, 'year': 2013},\n",
       "   {'count': 15, 'year': 2017},\n",
       "   {'count': 15, 'year': 2015},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 2, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'new dataset',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'benchmark dataset',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'standard benchmark dataset',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'full dataset',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'whole dataset',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'large dataset',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'small dataset',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'mnist dataset',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'given dataset',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'pascal voc dataset',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'synthetic dataset',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'scale dataset',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'massive dataset',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'dataset',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 14, 'year': 2016},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 8, 'year': 2017}]}],\n",
       "  'word': 'dataset'},\n",
       " {'total_count': [{'count': 5, 'year': 2009},\n",
       "   {'count': 5, 'year': 2016},\n",
       "   {'count': 7, 'year': 2011},\n",
       "   {'count': 11, 'year': 2010},\n",
       "   {'count': 4, 'year': 2007},\n",
       "   {'count': 7, 'year': 2017},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'coding scheme',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'local coordinate coding',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'sparse coding model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'sparse coding problem',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sensory coding',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse coding',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'coding theory',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'group sparse coding',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'predictive coding scheme',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'coding',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]}],\n",
       "  'word': 'coding'},\n",
       " {'total_count': [{'count': 9, 'year': 2016},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 3, 'year': 2010},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'testing phase',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'hypothesis testing',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sample testing',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'permutation testing',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'testing',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'testing whether',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]}],\n",
       "  'word': 'testing'},\n",
       " {'total_count': [{'count': 1, 'year': 2009},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 3, 'year': 2016},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'return',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'expected return',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'return'},\n",
       " {'total_count': [{'count': 16, 'year': 2009},\n",
       "   {'count': 31, 'year': 2017},\n",
       "   {'count': 5, 'year': 2007},\n",
       "   {'count': 23, 'year': 2013},\n",
       "   {'count': 13, 'year': 2012},\n",
       "   {'count': 13, 'year': 2014},\n",
       "   {'count': 28, 'year': 2016},\n",
       "   {'count': 13, 'year': 2011},\n",
       "   {'count': 11, 'year': 2010},\n",
       "   {'count': 11, 'year': 2008},\n",
       "   {'count': 21, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'reduce noise',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'noise',\n",
       "    'years': [{'count': 6, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 14, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 16, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 6, 'year': 2008},\n",
       "     {'count': 11, 'year': 2015},\n",
       "     {'count': 19, 'year': 2017}]},\n",
       "   {'n-gram': 'input noise',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'heteroscedastic noise',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'noise correlations',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'noise reduction',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'random noise',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'noise rate',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'independent noise',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'noise process',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gaussian noise',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'additive noise',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'white noise',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bounded noise',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'arbitrary noise',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'additive noise models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'label noise',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'noise ratio',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'low noise',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'tsybakov noise',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'noise level',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'noise variance',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sensor noise',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'observation noise',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'general noise models',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'tailed noise',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'exogenous noise',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'noise'},\n",
       " {'total_count': [{'count': 5, 'year': 2009},\n",
       "   {'count': 14, 'year': 2015},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 10, 'year': 2012},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 11, 'year': 2016},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 11, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'expectation',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 7, 'year': 2017}]},\n",
       "   {'n-gram': 'expectation maximization algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'expectation propagation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'expectation maximization',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'expectation'},\n",
       " {'total_count': [{'count': 16, 'year': 2016},\n",
       "   {'count': 13, 'year': 2015},\n",
       "   {'count': 20, 'year': 2017},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 1, 'year': 2011}],\n",
       "  'variations': [{'n-gram': 'polynomial dependence',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'polynomial kernels',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'present polynomial',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'polynomial size',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'time polynomial',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'polynomial',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 6, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'polynomial number',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'first polynomial',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'fully polynomial',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'polynomial time',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'polynomial time complexity',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'polynomial decay',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'polynomial'},\n",
       " {'total_count': [{'count': 16, 'year': 2009},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 11, 'year': 2012},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 3, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'nonparametric regression',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'nonparametric models',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric statistics',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'bayesian nonparametric approach',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'nonparametric bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'nonparametric bayesian approach',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric density estimation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'nonparametric representation',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric state',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'nonparametric setting',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'nonparametric estimation',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'nonparametric bayesian method',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'nonparametric bayesian inference',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'nonparametric prior',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'nonparametric',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric model',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'nonparametric kernel',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'nonparametric approach',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'nonparametric bayesian models',\n",
       "    'years': [{'count': 4, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'nonparametric method',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'nonparametric bayesian statistics',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'bayesian nonparametric models',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'nonparametric'},\n",
       " {'total_count': [{'count': 8, 'year': 2016},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 4, 'year': 2015},\n",
       "   {'count': 11, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'maximizing mutual information',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'maximizing',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 10, 'year': 2017}]},\n",
       "   {'n-gram': 'maximizing influence',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'maximizing'},\n",
       " {'total_count': [{'count': 2, 'year': 2007},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 3, 'year': 2009},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 2, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'compressed',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'compressed domain',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'compressed data',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'compressed sensing',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]}],\n",
       "  'word': 'compressed'},\n",
       " {'total_count': [{'count': 8, 'year': 2008},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 12, 'year': 2017},\n",
       "   {'count': 9, 'year': 2010},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 8, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'measure inequalities',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'novel measure',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'measure uncertainty',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'similarity measure',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'performance measure',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'true measure',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'measure',\n",
       "    'years': [{'count': 6, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 9, 'year': 2014},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 4, 'year': 2008},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 10, 'year': 2017}]},\n",
       "   {'n-gram': 'error measure',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'new measure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'measure maximization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'measure'},\n",
       " {'total_count': [{'count': 5, 'year': 2009},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 2, 'year': 2012},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 2, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'alignment',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'subject alignment',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'alignment'},\n",
       " {'total_count': [{'count': 4, 'year': 2016},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 9, 'year': 2015},\n",
       "   {'count': 14, 'year': 2017},\n",
       "   {'count': 2, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'sgd',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 11, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'sgd ).',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'sgd'},\n",
       " {'total_count': [{'count': 6, 'year': 2011},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 7, 'year': 2017},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 3, 'year': 2016},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2008},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 3, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'greedy strategy',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'strategy',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'optimal strategy',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'efficient strategy',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'proposed strategy',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'strategy'},\n",
       " {'total_count': [{'count': 5, 'year': 2017},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 3, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'long short',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'dimensional long short',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'short amount',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'short runs',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'short',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]}],\n",
       "  'word': 'short'},\n",
       " {'total_count': [{'count': 19, 'year': 2009},\n",
       "   {'count': 15, 'year': 2011},\n",
       "   {'count': 20, 'year': 2015},\n",
       "   {'count': 27, 'year': 2017},\n",
       "   {'count': 28, 'year': 2014},\n",
       "   {'count': 21, 'year': 2016},\n",
       "   {'count': 23, 'year': 2013},\n",
       "   {'count': 10, 'year': 2012},\n",
       "   {'count': 14, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'rank approximation',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'rank tensor',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'low rank matrix',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'rank',\n",
       "    'years': [{'count': 8, 'year': 2009},\n",
       "     {'count': 9, 'year': 2015},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 11, 'year': 2014},\n",
       "     {'count': 9, 'year': 2016},\n",
       "     {'count': 6, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'rank factorization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'rank matrix approximation',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'low rank',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'rank models',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rank estimation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rank structure',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'one rank',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'rank representation',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'rank matrix',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'rank tensors',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'rank approximations',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'rank matrix completion',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'low rank approximation',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'rank minimization',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'rank aggregation',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'rank methods',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'rank matrix recovery',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'rank algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'rank matrices',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'rank constraint',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'rank'},\n",
       " {'total_count': [{'count': 6, 'year': 2013},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 7, 'year': 2017},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 6, 'year': 2010},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'parametric multi',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parametric approach',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'parametric setup',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'parametric estimation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'parametric extension',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'parametric learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parametric models',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'parametric model',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'parametric bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'parametric representation',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'parametric assumptions',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parametric methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'parametric rate',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'parametric regression',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'parametric',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'parametric statistics',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'parametric family',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017}]}],\n",
       "  'word': 'parametric'},\n",
       " {'total_count': [{'count': 6, 'year': 2009},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 1, 'year': 2012},\n",
       "   {'count': 10, 'year': 2017},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 1, 'year': 2015},\n",
       "   {'count': 4, 'year': 2014},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 6, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'orthogonal matching pursuit',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'moment matching',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'matching',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'semantic matching',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'matching lower bounds',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'matching tasks',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'inexact matching',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'graph matching',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'distribution matching',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'feature matching',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'matching pursuit',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 3, 'year': 2008}]}],\n",
       "  'word': 'matching'},\n",
       " {'total_count': [{'count': 7, 'year': 2014},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 11, 'year': 2016},\n",
       "   {'count': 9, 'year': 2015},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 4, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'mcmc ).',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'novel mcmc sampler',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'stochastic gradient mcmc',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'aware mcmc',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'mcmc methods',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'mcmc ),',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'mcmc inference',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'mcmc',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'particle mcmc',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'mcmc sampling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]}],\n",
       "  'word': 'mcmc'},\n",
       " {'total_count': [{'count': 2, 'year': 2016},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'lifted inference',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'lifted',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'lifted inference algorithms',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2010}]}],\n",
       "  'word': 'lifted'},\n",
       " {'total_count': [{'count': 3, 'year': 2009},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 14, 'year': 2014},\n",
       "   {'count': 5, 'year': 2016},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 7, 'year': 2013},\n",
       "   {'count': 11, 'year': 2017},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'positive semidefinite matrix',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'positive semi',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'positive definite kernels',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'positive constant',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'false positive rate',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'positive',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'true positive rate',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'positive definite matrices',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'positive semidefinite',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'positive class',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'positive labels',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'positive results',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'positive'},\n",
       " {'total_count': [{'count': 13, 'year': 2016},\n",
       "   {'count': 11, 'year': 2014},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 5, 'year': 2009},\n",
       "   {'count': 13, 'year': 2013},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 6, 'year': 2015},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 1, 'year': 2007},\n",
       "   {'count': 3, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'smooth optimization problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'smooth term',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'smooth problems',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016}]},\n",
       "   {'n-gram': 'smooth functions',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'smooth loss function',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'smooth function',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'smooth convex function',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'smooth',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'smooth loss functions',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'smooth'},\n",
       " {'total_count': [{'count': 49, 'year': 2016},\n",
       "   {'count': 21, 'year': 2008},\n",
       "   {'count': 19, 'year': 2009},\n",
       "   {'count': 61, 'year': 2017},\n",
       "   {'count': 29, 'year': 2013},\n",
       "   {'count': 23, 'year': 2011},\n",
       "   {'count': 33, 'year': 2014},\n",
       "   {'count': 28, 'year': 2012},\n",
       "   {'count': 27, 'year': 2010},\n",
       "   {'count': 27, 'year': 2015},\n",
       "   {'count': 3, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'machine translation task',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'task gaussian processes',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'task regression',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'challenging task',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'second task',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'task classification',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'classification task',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'desired task',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'key task',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'task lasso',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'complex task',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'task learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'difficult task',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'task learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'task loss',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'task instructions',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'supervised learning task',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learn task',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'given task',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'specific task',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'task problems',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'task learning problem',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'french translation task',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning task',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'task bayesian optimization',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'task gaussian process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'single task',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'one task',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'task setting',\n",
       "    'years': [{'count': 2, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'regression task',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'inference task',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'important task',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'task performance',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'machine learning task',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'target task',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'task correlations',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'fundamental task',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'task',\n",
       "    'years': [{'count': 11, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 11, 'year': 2013},\n",
       "     {'count': 12, 'year': 2012},\n",
       "     {'count': 18, 'year': 2014},\n",
       "     {'count': 34, 'year': 2016},\n",
       "     {'count': 10, 'year': 2011},\n",
       "     {'count': 15, 'year': 2010},\n",
       "     {'count': 6, 'year': 2008},\n",
       "     {'count': 18, 'year': 2015},\n",
       "     {'count': 34, 'year': 2017}]},\n",
       "   {'n-gram': 'link prediction task',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'task'},\n",
       " {'total_count': [{'count': 8, 'year': 2016},\n",
       "   {'count': 9, 'year': 2014},\n",
       "   {'count': 6, 'year': 2013},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 15, 'year': 2012},\n",
       "   {'count': 3, 'year': 2008},\n",
       "   {'count': 4, 'year': 2009}],\n",
       "  'variations': [{'n-gram': 'hierarchical bayesian models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bayesian hierarchical models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'bayesian hierarchical clustering',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'hierarchical extension',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'hierarchical neural network',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'hierarchical bayesian model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'hierarchical organization',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'hierarchical reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'hierarchical model',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'hierarchical softmax',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'hierarchical',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012}]},\n",
       "   {'n-gram': 'hierarchical classification',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'hierarchical prior',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'hierarchical dirichlet processes',\n",
       "    'years': [{'count': 2, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'hierarchical dense sets',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'hierarchical clustering',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'hierarchical models',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'hierarchical dirichlet process',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'hierarchical manner',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'hierarchical'},\n",
       " {'total_count': [{'count': 28, 'year': 2017},\n",
       "   {'count': 9, 'year': 2007},\n",
       "   {'count': 20, 'year': 2012},\n",
       "   {'count': 21, 'year': 2016},\n",
       "   {'count': 26, 'year': 2014},\n",
       "   {'count': 21, 'year': 2010},\n",
       "   {'count': 9, 'year': 2009},\n",
       "   {'count': 22, 'year': 2013},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 9, 'year': 2015},\n",
       "   {'count': 6, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'prior information',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'dirichlet process prior',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'gp prior',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gaussian prior',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'prior work',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 5, 'year': 2013}]},\n",
       "   {'n-gram': 'prior state',\n",
       "    'years': [{'count': 3, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'class prior',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'slab prior',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 3, 'year': 2014}]},\n",
       "   {'n-gram': 'prior knowledge',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'optimal prior',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'uniform prior',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'prior assumption',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'prior works',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'nonparametric prior',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'hierarchical prior',\n",
       "    'years': [{'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'prior art',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'gaussian process prior',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'outperform prior methods',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'prior approaches',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'prior distributions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'novel prior',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gamma prior',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'prior expectations',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sparse prior',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'structured prior',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'prior',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 5, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 4, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 5, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'new prior',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'prior distribution',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'prior'},\n",
       " {'total_count': [{'count': 3, 'year': 2014},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 5, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016},\n",
       "   {'count': 1, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'fast mixing',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'mixing',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'mixing time',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'mixing parameters',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'mixing properties',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 2, 'year': 2012}]}],\n",
       "  'word': 'mixing'},\n",
       " {'total_count': [{'count': 4, 'year': 2007},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 5, 'year': 2011},\n",
       "   {'count': 8, 'year': 2017},\n",
       "   {'count': 6, 'year': 2014},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 9, 'year': 2012},\n",
       "   {'count': 7, 'year': 2009},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 2, 'year': 2015},\n",
       "   {'count': 1, 'year': 2016}],\n",
       "  'variations': [{'n-gram': 'better ranking',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'ranking problem',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'global ranking',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'ranking models',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'k ranking',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'ranking algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'ranking functions',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bipartite ranking',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'collaborative ranking',\n",
       "    'years': [{'count': 2, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'ranking',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 6, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'ranking data',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'ranking'},\n",
       " {'total_count': [{'count': 4, 'year': 2009},\n",
       "   {'count': 12, 'year': 2015},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 6, 'year': 2014},\n",
       "   {'count': 8, 'year': 2016},\n",
       "   {'count': 2, 'year': 2011},\n",
       "   {'count': 5, 'year': 2010},\n",
       "   {'count': 11, 'year': 2013},\n",
       "   {'count': 2, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'matrix completion',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'matrix completion methods',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'tensor completion',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'rank matrix completion',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'matrix completion problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'matrix completion problem',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'binary matrix completion',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'completion',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'completion'},\n",
       " {'total_count': [{'count': 15, 'year': 2016},\n",
       "   {'count': 13, 'year': 2014},\n",
       "   {'count': 19, 'year': 2015},\n",
       "   {'count': 12, 'year': 2012},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 8, 'year': 2011},\n",
       "   {'count': 18, 'year': 2013},\n",
       "   {'count': 7, 'year': 2009},\n",
       "   {'count': 23, 'year': 2017},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 3, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'posterior regularization',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'variational posterior',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'posterior inference',\n",
       "    'years': [{'count': 4, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'posterior mean',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'margin posterior constraints',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'true posterior',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]},\n",
       "   {'n-gram': 'posterior',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 8, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'bayesian posterior',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'posterior probability',\n",
       "    'years': [{'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'approximate posterior',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'inferred posterior',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'posterior sampling',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'posterior distributions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'posterior distribution',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'exact posterior',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'posterior'},\n",
       " {'total_count': [{'count': 7, 'year': 2016},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 4, 'year': 2013},\n",
       "   {'count': 6, 'year': 2017},\n",
       "   {'count': 2, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'dropout',\n",
       "    'years': [{'count': 7, 'year': 2016},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'g ., dropout',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dropout training',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2013}]}],\n",
       "  'word': 'dropout'},\n",
       " {'total_count': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'template',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'template'},\n",
       " {'total_count': [{'count': 121, 'year': 2008},\n",
       "   {'count': 182, 'year': 2012},\n",
       "   {'count': 158, 'year': 2009},\n",
       "   {'count': 276, 'year': 2016},\n",
       "   {'count': 164, 'year': 2013},\n",
       "   {'count': 149, 'year': 2011},\n",
       "   {'count': 149, 'year': 2010},\n",
       "   {'count': 36, 'year': 2007},\n",
       "   {'count': 191, 'year': 2014},\n",
       "   {'count': 396, 'year': 2017},\n",
       "   {'count': 186, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'line learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'online learning algorithms',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'spectral learning methods',\n",
       "    'years': [{'count': 2, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse bayesian learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'optimal learning rates',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'transfer learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'learning high',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'reinforcement learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning meaningful representations',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'dependent learning bounds',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'tabular reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'agent reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'scale learning problems',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'view learning',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'machine learning due',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'end learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'learning goal',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning rates',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'feature learning',\n",
       "    'years': [{'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'machine learning problems',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'unsupervised deep learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'either learning',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'human learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning bounds',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'provably learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised learning approach',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'manifold learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'machine learning models',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'efficient reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'inverse reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010}]},\n",
       "   {'n-gram': 'learning invariant representations',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning rule',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'derive learning rates',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'feature learning problem',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'agent learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'based learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'based active learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'kernel learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning macro',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning kernels',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning neural networks',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'reinforcement learning problem',\n",
       "    'years': [{'count': 3, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'causal structure learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'facilitates learning',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'online learning',\n",
       "    'years': [{'count': 9, 'year': 2009},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 10, 'year': 2013},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'paced learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'general learning framework',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'margin learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'optimal reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'hyperparameter learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'many machine learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'learning parameters',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'multiple kernel learning',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'undiscounted reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning performance',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'efficient learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'imitation learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'machine learning systems',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'online learning setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'jointly learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016}]},\n",
       "   {'n-gram': 'robust learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'consider learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sparse learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'contrastive learning',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sequential learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'multitask learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'active learning policy',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'multitask learning',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'machine learning purposes',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'human feature learning',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'e ., learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'linear learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning low',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'joint learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'efficient learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'supervised learning based',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'active learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning behaviour',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'deep learning models',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'unsupervised learning models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'bayesian learning',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'reinforcement learning approach',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'learning non',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning time',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 4, 'year': 2014}]},\n",
       "   {'n-gram': 'structure learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'efficient learning',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning algorithm',\n",
       "    'years': [{'count': 6, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'unsupervised learning',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 4, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'new learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'structured learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'model learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'hierarchical reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'apprenticeship learning',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 3, 'year': 2010}]},\n",
       "   {'n-gram': 'structured output learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'preference learning',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning mechanism',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'active learning',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 7, 'year': 2015},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 8, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'spectral learning',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning curve',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'machine learning applications',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'task learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'large margin learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning large',\n",
       "    'years': [{'count': 2, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'shot learning scenario',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'statistical machine learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2007}]},\n",
       "   {'n-gram': 'learning algorithms',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'deep learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 8, 'year': 2015},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 6, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 26, 'year': 2017}]},\n",
       "   {'n-gram': 'learning agent',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning process',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning representations',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'machine learning research',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'task learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 5, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 6, 'year': 2017}]},\n",
       "   {'n-gram': 'local learning rule',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'online learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'instance learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 4, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'learning objective',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'efficient learning procedure',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'policy learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'reinforcement learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'supervised learning task',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'hebbian learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'supervised learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'online learning framework',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'maximum likelihood learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning problem',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'weak learning algorithm',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'lifelong learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'batch learning',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'reinforcement learning',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 10, 'year': 2016},\n",
       "     {'count': 4, 'year': 2011},\n",
       "     {'count': 6, 'year': 2010},\n",
       "     {'count': 5, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 20, 'year': 2017}]},\n",
       "   {'n-gram': 'learning bayesian networks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised learning',\n",
       "    'years': [{'count': 10, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 6, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 7, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 12, 'year': 2017}]},\n",
       "   {'n-gram': 'robot learning',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'large scale learning',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'fast learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning mixtures',\n",
       "    'years': [{'count': 3, 'year': 2014}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'simple learning rule',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'theoretic online learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'new learning method',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'task learning problem',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'regularized learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'based reinforcement learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'residual learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'regret learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning speed',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'reinforcement learning setting',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'shot learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 5, 'year': 2013},\n",
       "     {'count': 5, 'year': 2017}]},\n",
       "   {'n-gram': 'parametric learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'metric learning problem',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'learning task',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'statistical relational learning',\n",
       "    'years': [{'count': 2, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning models',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'agnostic learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'sequence learning',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'learning framework',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'scale learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning sparse representations',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'efficiently learning',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'statistical learning theory',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'distributed learning',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'passive learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'new learning framework',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'standard supervised learning',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning theory',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'distance metric learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'perceptron learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'representation learning',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'based learning techniques',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'machine learning algorithms',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'computational learning theory',\n",
       "    'years': [{'count': 2, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'active learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning method',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'label learning',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'make learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'free online learning',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'unsupervised learning tasks',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning guarantees',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'manifold learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'online learning algorithm',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning capacity',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'unsupervised feature learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'reinforcement learning agents',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'probabilistic machine learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning networks',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'machine learning task',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning approach',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning curves',\n",
       "    'years': [{'count': 3, 'year': 2009}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning rate',\n",
       "    'years': [{'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'supervised deep learning',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep learning architectures',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning hmms',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'metric learning',\n",
       "    'years': [{'count': 4, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'statistical learning problems',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'many learning problems',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'bayesian active learning',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning problems',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'successful learning',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'learning multi',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'learning causal graphs',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep reinforcement learning',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'deep learning framework',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'based learning',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'bayesian reinforcement learning',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'online learning approaches',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'dictionary learning',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning features',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning graphical models',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'many learning tasks',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sensitive learning',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'deep learning methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learning multiple tasks',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'learning ensembles',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'learning halfspaces',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'fast learning rate',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 2, 'year': 2011}]},\n",
       "   {'n-gram': 'discriminative learning',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'learning rules',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2014}]},\n",
       "   {'n-gram': 'learning model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'metric learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2013}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'optimal learning',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'supervised learning tasks',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'deep learning approaches',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'supervised learning methods',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'machine learning',\n",
       "    'years': [{'count': 13, 'year': 2009},\n",
       "     {'count': 27, 'year': 2015},\n",
       "     {'count': 15, 'year': 2013},\n",
       "     {'count': 13, 'year': 2012},\n",
       "     {'count': 18, 'year': 2014},\n",
       "     {'count': 29, 'year': 2016},\n",
       "     {'count': 9, 'year': 2011},\n",
       "     {'count': 7, 'year': 2010},\n",
       "     {'count': 8, 'year': 2008},\n",
       "     {'count': 41, 'year': 2017}]},\n",
       "   {'n-gram': 'concept learning',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'actively learning',\n",
       "    'years': [{'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'machine learning community',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'learning svms',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning temporal dependencies',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'modern machine learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'statistical learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'machine learning techniques',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'learning shift',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'machine learning tasks',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'various learning tasks',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning setting',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'many learning algorithms',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'learning settings',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'machine learning approach',\n",
       "    'years': [{'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'learning',\n",
       "    'years': [{'count': 40, 'year': 2009},\n",
       "     {'count': 8, 'year': 2007},\n",
       "     {'count': 42, 'year': 2013},\n",
       "     {'count': 48, 'year': 2012},\n",
       "     {'count': 55, 'year': 2014},\n",
       "     {'count': 76, 'year': 2016},\n",
       "     {'count': 38, 'year': 2011},\n",
       "     {'count': 48, 'year': 2010},\n",
       "     {'count': 27, 'year': 2008},\n",
       "     {'count': 43, 'year': 2015},\n",
       "     {'count': 103, 'year': 2017}]}],\n",
       "  'word': 'learning'},\n",
       " {'total_count': [{'count': 1, 'year': 2010},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 4, 'year': 2016},\n",
       "   {'count': 4, 'year': 2017},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 2, 'year': 2014},\n",
       "   {'count': 1, 'year': 2008}],\n",
       "  'variations': [{'n-gram': 'markov chain monte',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'markov chain',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2017},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 4, 'year': 2015}]},\n",
       "   {'n-gram': 'chain',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'chain structures',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'chain graph models',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2015}]}],\n",
       "  'word': 'chain'},\n",
       " {'total_count': [{'count': 6, 'year': 2009},\n",
       "   {'count': 2, 'year': 2007},\n",
       "   {'count': 3, 'year': 2013},\n",
       "   {'count': 8, 'year': 2012},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 12, 'year': 2016},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 2, 'year': 2010},\n",
       "   {'count': 2, 'year': 2008},\n",
       "   {'count': 3, 'year': 2015},\n",
       "   {'count': 13, 'year': 2017}],\n",
       "  'variations': [{'n-gram': 'robustness',\n",
       "    'years': [{'count': 5, 'year': 2009},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 3, 'year': 2013},\n",
       "     {'count': 7, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 12, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 13, 'year': 2017}]},\n",
       "   {'n-gram': 'robustness properties',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2012}]}],\n",
       "  'word': 'robustness'},\n",
       " {'total_count': [{'count': 3, 'year': 2010},\n",
       "   {'count': 5, 'year': 2012},\n",
       "   {'count': 9, 'year': 2016},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 3, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'markov chain monte',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'monte carlo integration',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'sequential monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'monte',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013}]},\n",
       "   {'n-gram': 'monte carlo sampling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'monte carlo methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'monte carlo approximation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'hamiltonian monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'monte'},\n",
       " {'total_count': [{'count': 4, 'year': 2010},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 10, 'year': 2016},\n",
       "   {'count': 2, 'year': 2009},\n",
       "   {'count': 5, 'year': 2014},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 4, 'year': 2011},\n",
       "   {'count': 3, 'year': 2013}],\n",
       "  'variations': [{'n-gram': 'carlo',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'carlo planning',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'monte carlo integration',\n",
       "    'years': [{'count': 2, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'carlo sampling',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sequential monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'carlo tree search',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'monte carlo sampling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'monte carlo methods',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'monte carlo approximation',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'carlo integration',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'hamiltonian monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2015}]}],\n",
       "  'word': 'carlo'},\n",
       " {'total_count': [{'count': 8, 'year': 2011},\n",
       "   {'count': 8, 'year': 2013},\n",
       "   {'count': 4, 'year': 2009},\n",
       "   {'count': 30, 'year': 2017},\n",
       "   {'count': 6, 'year': 2012},\n",
       "   {'count': 26, 'year': 2015},\n",
       "   {'count': 12, 'year': 2014},\n",
       "   {'count': 16, 'year': 2016},\n",
       "   {'count': 5, 'year': 2008},\n",
       "   {'count': 3, 'year': 2007},\n",
       "   {'count': 1, 'year': 2010}],\n",
       "  'variations': [{'n-gram': 'coordinate descent method',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'coordinate descent',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 4, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'including gradient descent',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'gradient descent methods',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'projected gradient descent',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'mirror descent algorithm',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'coordinate descent approach',\n",
       "    'years': [{'count': 2, 'year': 2014}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'block coordinate descent',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'accelerated mirror descent',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'mirror descent',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'stochastic gradient descent',\n",
       "    'years': [{'count': 13, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 6, 'year': 2015},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 8, 'year': 2016},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 3, 'year': 2013}]},\n",
       "   {'n-gram': 'randomized coordinate descent',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'descent',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'descent direction',\n",
       "    'years': [{'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'gradient descent',\n",
       "    'years': [{'count': 7, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 3, 'year': 2008}]},\n",
       "   {'n-gram': 'natural gradient descent',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'descent'},\n",
       " {'total_count': [{'count': 6, 'year': 2009},\n",
       "   {'count': 13, 'year': 2017},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 3, 'year': 2014},\n",
       "   {'count': 7, 'year': 2016},\n",
       "   {'count': 2, 'year': 2013},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 2, 'year': 2012}],\n",
       "  'variations': [{'n-gram': 'sequential learning',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sequential effects',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'sequential monte carlo',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sequential inference',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'sequential',\n",
       "    'years': [{'count': 2, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'remove sequential dependencies',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'sequential decision making',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2017},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'sequential mnist',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sequential decision',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sequential decision problem',\n",
       "    'years': [{'count': 1, 'year': 2008}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'inherently sequential',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2016}]},\n",
       "   {'n-gram': 'processing sequential data',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'sequential data',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'many sequential decision',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 1, 'year': 2013}]}],\n",
       "  'word': 'sequential'},\n",
       " {'total_count': [{'count': 12, 'year': 2016},\n",
       "   {'count': 6, 'year': 2011},\n",
       "   {'count': 4, 'year': 2012},\n",
       "   {'count': 7, 'year': 2014},\n",
       "   {'count': 11, 'year': 2013},\n",
       "   {'count': 4, 'year': 2008},\n",
       "   {'count': 8, 'year': 2015},\n",
       "   {'count': 12, 'year': 2017},\n",
       "   {'count': 2, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'armed bandit setting',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'armed bandit problems',\n",
       "    'years': [{'count': 2, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'armed bandit',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 6, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'armed bandits',\n",
       "    'years': [{'count': 5, 'year': 2017},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 4, 'year': 2013},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'armed bandit problem',\n",
       "    'years': [{'count': 2, 'year': 2017},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 2, 'year': 2016},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 2, 'year': 2013}]}],\n",
       "  'word': 'armed'},\n",
       " {'total_count': [{'count': 3, 'year': 2016},\n",
       "   {'count': 1, 'year': 2011},\n",
       "   {'count': 1, 'year': 2013},\n",
       "   {'count': 1, 'year': 2017},\n",
       "   {'count': 2, 'year': 2014}],\n",
       "  'variations': [{'n-gram': 'composition',\n",
       "    'years': [{'count': 3, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 2, 'year': 2014}]}],\n",
       "  'word': 'composition'},\n",
       " {'total_count': [{'count': 1, 'year': 2017},\n",
       "   {'count': 1, 'year': 2010},\n",
       "   {'count': 3, 'year': 2012},\n",
       "   {'count': 1, 'year': 2015}],\n",
       "  'variations': [{'n-gram': 'random walk',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]}],\n",
       "  'word': 'walk'},\n",
       " {'total_count': [{'count': 76, 'year': 2017},\n",
       "   {'count': 60, 'year': 2014},\n",
       "   {'count': 36, 'year': 2010},\n",
       "   {'count': 41, 'year': 2013},\n",
       "   {'count': 34, 'year': 2012},\n",
       "   {'count': 59, 'year': 2016},\n",
       "   {'count': 29, 'year': 2009},\n",
       "   {'count': 44, 'year': 2015},\n",
       "   {'count': 24, 'year': 2011},\n",
       "   {'count': 19, 'year': 2008},\n",
       "   {'count': 8, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'learning high',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'learn high',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'high dimensions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 2, 'year': 2012},\n",
       "     {'count': 8, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2011},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 4, 'year': 2017}]},\n",
       "   {'n-gram': 'high level',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'real high',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'handle high',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high dimensional settings',\n",
       "    'years': [{'count': 1, 'year': 2014}, {'count': 2, 'year': 2010}]},\n",
       "   {'n-gram': 'high computational complexity',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'modern high',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'high computational costs',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'high performance',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'high accuracy',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 2, 'year': 2007},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'high probability',\n",
       "    'years': [{'count': 3, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 4, 'year': 2012},\n",
       "     {'count': 5, 'year': 2014},\n",
       "     {'count': 5, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 3, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 5, 'year': 2015},\n",
       "     {'count': 9, 'year': 2017}]},\n",
       "   {'n-gram': 'high correlations',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'achieve high performance',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'generating high',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 3, 'year': 2017}]},\n",
       "   {'n-gram': 'high levels',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'sufficiently high',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'high success rate',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'high confidence',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'high dimensional data',\n",
       "    'years': [{'count': 2, 'year': 2009},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'high dimensional inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'high dimension',\n",
       "    'years': [{'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'high',\n",
       "    'years': [{'count': 18, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 33, 'year': 2013},\n",
       "     {'count': 18, 'year': 2012},\n",
       "     {'count': 34, 'year': 2014},\n",
       "     {'count': 40, 'year': 2016},\n",
       "     {'count': 13, 'year': 2011},\n",
       "     {'count': 17, 'year': 2010},\n",
       "     {'count': 11, 'year': 2008},\n",
       "     {'count': 27, 'year': 2015},\n",
       "     {'count': 47, 'year': 2017}]},\n",
       "   {'n-gram': 'high complexity',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high density regions',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high degree',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2008},\n",
       "     {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'high dimensional problems',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high dimensional vectors',\n",
       "    'years': [{'count': 1, 'year': 2010}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'high dimensional setting',\n",
       "    'years': [{'count': 1, 'year': 2012}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'high dimensional',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high dimensionality',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2012}]},\n",
       "   {'n-gram': 'estimating high',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2010}]},\n",
       "   {'n-gram': 'high computational cost',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 2, 'year': 2017}]},\n",
       "   {'n-gram': 'generate high',\n",
       "    'years': [{'count': 1, 'year': 2017},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2015}]},\n",
       "   {'n-gram': 'high quality',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'high computation complexity',\n",
       "    'years': [{'count': 1, 'year': 2007}, {'count': 1, 'year': 2011}]}],\n",
       "  'word': 'high'},\n",
       " {'total_count': [{'count': 9, 'year': 2009},\n",
       "   {'count': 10, 'year': 2014},\n",
       "   {'count': 5, 'year': 2013},\n",
       "   {'count': 14, 'year': 2012},\n",
       "   {'count': 7, 'year': 2011},\n",
       "   {'count': 6, 'year': 2016},\n",
       "   {'count': 7, 'year': 2015},\n",
       "   {'count': 3, 'year': 2017},\n",
       "   {'count': 4, 'year': 2010},\n",
       "   {'count': 6, 'year': 2008},\n",
       "   {'count': 5, 'year': 2007}],\n",
       "  'variations': [{'n-gram': 'topic model',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2014},\n",
       "     {'count': 1, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012}]},\n",
       "   {'n-gram': 'important topic',\n",
       "    'years': [{'count': 1, 'year': 2011}, {'count': 1, 'year': 2012}]},\n",
       "   {'n-gram': 'topic inference',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2015}]},\n",
       "   {'n-gram': 'undirected topic model',\n",
       "    'years': [{'count': 1, 'year': 2009}, {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'topic modeling',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2017},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 1, 'year': 2015},\n",
       "     {'count': 3, 'year': 2016},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 2, 'year': 2010},\n",
       "     {'count': 1, 'year': 2013}]},\n",
       "   {'n-gram': 'central topic',\n",
       "    'years': [{'count': 1, 'year': 2016}, {'count': 1, 'year': 2008}]},\n",
       "   {'n-gram': 'topic',\n",
       "    'years': [{'count': 4, 'year': 2009},\n",
       "     {'count': 3, 'year': 2007},\n",
       "     {'count': 3, 'year': 2015},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 3, 'year': 2014},\n",
       "     {'count': 2, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 3, 'year': 2008},\n",
       "     {'count': 1, 'year': 2017}]},\n",
       "   {'n-gram': 'topic distributions',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2011}]},\n",
       "   {'n-gram': 'topic models',\n",
       "    'years': [{'count': 1, 'year': 2009},\n",
       "     {'count': 2, 'year': 2015},\n",
       "     {'count': 2, 'year': 2013},\n",
       "     {'count': 3, 'year': 2012},\n",
       "     {'count': 2, 'year': 2014},\n",
       "     {'count': 1, 'year': 2016},\n",
       "     {'count': 3, 'year': 2011},\n",
       "     {'count': 1, 'year': 2010},\n",
       "     {'count': 2, 'year': 2008}]},\n",
       "   {'n-gram': 'popular topic',\n",
       "    'years': [{'count': 1, 'year': 2017}, {'count': 1, 'year': 2014}]},\n",
       "   {'n-gram': 'supervised topic models',\n",
       "    'years': [{'count': 1, 'year': 2007},\n",
       "     {'count': 1, 'year': 2012},\n",
       "     {'count': 1, 'year': 2014}]}],\n",
       "  'word': 'topic'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('final.json', 'w+') as f:\n",
    "    json.dump(info_2, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

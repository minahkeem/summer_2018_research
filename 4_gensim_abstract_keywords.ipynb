{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import keywords as k\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'nyuvis-web.poly.edu', 'port':80, 'url_prefix':\n",
    "                    'es'},])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo_abs = es.count(index='nips_papers', body={\n",
    "    'query': {\n",
    "        'match': {\n",
    "            'abstract': 'Abstract Missing'\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = es.count(index='nips_papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keywords for document abstracts\n",
    "\n",
    "doc_list = []\n",
    "tot_count_abstracts = tot['count']-wo_abs['count']\n",
    "\n",
    "#curr_year = 2007\n",
    "temp = []\n",
    "\n",
    "res = es.search(index='nips_papers', body = {\n",
    "    \"_source\": ['id', 'year', 'abstract'],\n",
    "    \"size\": tot_count_abstracts,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must_not\": {\n",
    "                \"match\": {\n",
    "                    \"abstract\": \"Abstract Missing\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "#sampling code\n",
    "'''while curr_year != 2018:\n",
    "    #10 samples of documents each year\n",
    "    res = es.search(index = 'nips_papers', body = {\n",
    "        \"_source\": ['id', 'year', 'abstract'],\n",
    "        \"size\": 20,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must_not\": {\n",
    "                    \"match\": {\n",
    "                        \"abstract\": \"Abstract Missing\"\n",
    "                    }\n",
    "                },\n",
    "                \"must\": {\n",
    "                    \"match\": {\n",
    "                        \"year\": str(curr_year)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    #append the documents of curr_year to the document list\n",
    "    for entry in res['hits']['hits']:\n",
    "        doc_list.append(entry['_source'])\n",
    "    \n",
    "    if len(res['hits']['hits']) != 0:\n",
    "        temp.append({curr_year:len(res['hits']['hits'])})\n",
    "    \n",
    "    curr_year += 1'''\n",
    "\n",
    "for entry in res['hits']['hits']:\n",
    "    doc_list.append(entry['_source'])\n",
    "\n",
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9fa189b0c9fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mkeywords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'abstract'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         abs_keyw_list.append({\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\gensim\\summarization\\keywords.py\u001b[0m in \u001b[0;36mkeywords\u001b[1;34m(text, ratio, words, split, scores, pos_filter, lemmatize, deacc)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;31m# Ranks the tokens using the PageRank algorithm. Returns dict of lemma -> score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m     \u001b[0mpagerank_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[0mextracted_lemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpagerank_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\gensim\\summarization\\pagerank_weighted.py\u001b[0m in \u001b[0;36mpagerank_weighted\u001b[1;34m(graph, damping)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \"\"\"\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0madjacency_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_adjacency_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[0mprobability_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_probability_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\gensim\\summarization\\pagerank_weighted.py\u001b[0m in \u001b[0;36mbuild_adjacency_matrix\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mneighbors_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0medge_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python35\\lib\\site-packages\\gensim\\summarization\\graph.py\u001b[0m in \u001b[0;36medge_weight\u001b[1;34m(self, edge)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \"\"\"\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_edge_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWEIGHT_ATTRIBUTE_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_WEIGHT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "abs_keyw_list = []\n",
    "\n",
    "for doc in doc_list:\n",
    "    keywords = k(doc['abstract'], split = True)\n",
    "    for word in keywords:\n",
    "        abs_keyw_list.append({\n",
    "            'keyword': word,\n",
    "            'doc_id': doc['id'],\n",
    "            'year': doc['year']\n",
    "        })\n",
    "\n",
    "len(abs_keyw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('TR_abstract_nips_v1.csv', 'w', newline='') as f:\n",
    "    header_present = False\n",
    "    for doc in abs_keyw_list:\n",
    "        if not header_present:\n",
    "            w = csv.DictWriter(f, doc.keys())\n",
    "            w.writeheader()\n",
    "            header_present = True\n",
    "        w.writerow(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
